[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/2008/index.html",
    "href": "posts/2008/index.html",
    "title": "Western Blot - Purified (His column) decorin, FST, LAP & telethonin",
    "section": "",
    "text": "10uL of each sample from yesterday (binding supe, washes and elution fractions) were mixed with 2x sample reducing buffer and boiled 5 mins. Samples were loaded onto Pierce 4-20% Tris-Glycine SDS/PAGE gels. 10uL of SeeBlue ladder was loaded. 5uL of positive control lysate was loaded. Gels were run @ 150V for 45mins.\nGels were transferred to nitrocellulose membrane (equilibrated in tris-glycine transfer buffer for 5mins) @15V for 15mins. Membrane washed briefly in 1x TBS-T, then blocked for 1hr. Gel was stained for 1hr in Coomassie stain and then destained w/ 10% acetic acid until bands were clearly visible.\n\nGel #1 - Decorin samples\n\nLane #1 - Ladder\nLane #2 - Positive control lysate\nLane #3 - Binding solution\nLane #4 - Wash\nLane #5 - Elution fraction #1\nLane #6 - Elution fraction #2\nLane #7 - Elution fraction #3\nLane #8 - Elution fraction #4\nLane #9 - Elution fraction #5\nLane #10 - Elution fraction #6\nLane #11 - Elution fraction #7\nLane #12 - Elution fraction #8\n\n\nGel #2 - FST samples\n\nLane #1 - Binding solution\nLane #2 - Wash\nLane #3 - Ladder\nLane #4 - Positive control lysate\nLane #5 - Elution fraction #1\nLane #6 - Elution fraction #2\nLane #7 - Elution fraction #3\nLane #8 - Elution fraction #4\nLane #9 - Elution fraction #5\nLane #10 - Elution fraction #6\nLane #11 - Elution fraction #7\nLane #12 - Elution fraction #8\n\n\nGel #3 - LAP samples\n\nLane #1 - Ladder\nLane #2 - Positive control lysate\nLane #3 - Elution fraction #1\nLane #4 - Elution fraction #2\nLane #5 - Elution fraction #3\nLane #6 - Elution fraction #4\nLane #7 - Elution fraction #5\nLane #8 - Elution fraction #6\nLane #9 - Elution fraction #7\nLane #10 - Elution fraction #8\nLane #11 - Binding solution\nLane #12 - Wash\n\n\nGel #4 - Telethonin samples\n\nLane #1 - Binding solution\nLane #2 - Wash\nLane #3 - Ladder\nLane #4 - Positive control lysate\nLane #5 - Elution fraction #1\nLane #6 - Elution fraction #2\nLane #7 - Elution fraction #3\nLane #8 - Elution fraction #4\nLane #9 - Elution fraction #5\nLane #10 - Elution fraction #6\nLane #11 - Elution fraction #7\nLane #12 - Elution fraction #8\nResults:\nGels all have protein, but no elution fractions exhibit just a single band. Additionally, most of the samples across the different genes show similar banding patterns.\nPrimary Ab (anti-6x His) was added to membrane at a 1:15,000 dilution. This incubated for 1hr. Used Ab solution was stored @ 4C.\nMembrane was washed with 1x TBS-T and fresh blocking solution was added per the protocol.\nSecondary Ab (DAR HRP) was added to membrane @ 1:15,000 dilution and incubated for 30mins.\nMembrane was washed with 1x TBS-T per the protocol.\nBlots were developed using Millipore Immobilon chemiluminescent regent and imaged.\nResults:\nNONE! All four membranes are completely blank. Not even a signal from the positive control lysate. Infuriating! Why? Transfer was performed in the correct orientation (this was confirmed by the presence of the ladder dye on the membranes post-transfer). The same Ab stocks and developer stock were used as a couple of weeks ago, so these shouldn’t be a concern. Ab was definitely added to all the samples, so that’s ruled out. Ugh."
  },
  {
    "objectID": "posts/2008/2008-11-13-western-blot-purified-his-column-decorin-fst-lap-telethonin/index.html",
    "href": "posts/2008/2008-11-13-western-blot-purified-his-column-decorin-fst-lap-telethonin/index.html",
    "title": "Western Blot - Purified (His column) decorin, FST, LAP & telethonin",
    "section": "",
    "text": "10uL of each sample from yesterday (binding supe, washes and elution fractions) were mixed with 2x sample reducing buffer and boiled 5 mins. Samples were loaded onto Pierce 4-20% Tris-Glycine SDS/PAGE gels. 10uL of SeeBlue ladder was loaded. 5uL of positive control lysate was loaded. Gels were run @ 150V for 45mins.\nGels were transferred to nitrocellulose membrane (equilibrated in tris-glycine transfer buffer for 5mins) @15V for 15mins. Membrane washed briefly in 1x TBS-T, then blocked for 1hr. Gel was stained for 1hr in Coomassie stain and then destained w/ 10% acetic acid until bands were clearly visible.\n\nGel #1 - Decorin samples\n\nLane #1 - Ladder\nLane #2 - Positive control lysate\nLane #3 - Binding solution\nLane #4 - Wash\nLane #5 - Elution fraction #1\nLane #6 - Elution fraction #2\nLane #7 - Elution fraction #3\nLane #8 - Elution fraction #4\nLane #9 - Elution fraction #5\nLane #10 - Elution fraction #6\nLane #11 - Elution fraction #7\nLane #12 - Elution fraction #8\n\n\nGel #2 - FST samples\n\nLane #1 - Binding solution\nLane #2 - Wash\nLane #3 - Ladder\nLane #4 - Positive control lysate\nLane #5 - Elution fraction #1\nLane #6 - Elution fraction #2\nLane #7 - Elution fraction #3\nLane #8 - Elution fraction #4\nLane #9 - Elution fraction #5\nLane #10 - Elution fraction #6\nLane #11 - Elution fraction #7\nLane #12 - Elution fraction #8\n\n\nGel #3 - LAP samples\n\nLane #1 - Ladder\nLane #2 - Positive control lysate\nLane #3 - Elution fraction #1\nLane #4 - Elution fraction #2\nLane #5 - Elution fraction #3\nLane #6 - Elution fraction #4\nLane #7 - Elution fraction #5\nLane #8 - Elution fraction #6\nLane #9 - Elution fraction #7\nLane #10 - Elution fraction #8\nLane #11 - Binding solution\nLane #12 - Wash\n\n\nGel #4 - Telethonin samples\n\nLane #1 - Binding solution\nLane #2 - Wash\nLane #3 - Ladder\nLane #4 - Positive control lysate\nLane #5 - Elution fraction #1\nLane #6 - Elution fraction #2\nLane #7 - Elution fraction #3\nLane #8 - Elution fraction #4\nLane #9 - Elution fraction #5\nLane #10 - Elution fraction #6\nLane #11 - Elution fraction #7\nLane #12 - Elution fraction #8\nResults:\nGels all have protein, but no elution fractions exhibit just a single band. Additionally, most of the samples across the different genes show similar banding patterns.\nPrimary Ab (anti-6x His) was added to membrane at a 1:15,000 dilution. This incubated for 1hr. Used Ab solution was stored @ 4C.\nMembrane was washed with 1x TBS-T and fresh blocking solution was added per the protocol.\nSecondary Ab (DAR HRP) was added to membrane @ 1:15,000 dilution and incubated for 30mins.\nMembrane was washed with 1x TBS-T per the protocol.\nBlots were developed using Millipore Immobilon chemiluminescent regent and imaged.\nResults:\nNONE! All four membranes are completely blank. Not even a signal from the positive control lysate. Infuriating! Why? Transfer was performed in the correct orientation (this was confirmed by the presence of the ladder dye on the membranes post-transfer). The same Ab stocks and developer stock were used as a couple of weeks ago, so these shouldn’t be a concern. Ab was definitely added to all the samples, so that’s ruled out. Ugh."
  },
  {
    "objectID": "posts/2008/2008-11-14-mass-spec-band-1-from-20081106/index.html",
    "href": "posts/2008/2008-11-14-mass-spec-band-1-from-20081106/index.html",
    "title": "Mass Spec - Band #1 from 20081106",
    "section": "",
    "text": "Trypsin digested band from MSTN1b + red muscle extract co-IP (~75kDa) was delivered for mass spec analysis. Data in 2-3 weeks."
  },
  {
    "objectID": "posts/2008/2008-12-24-rrna-removal-v-tubiashii-total-rna-from-yesterday/index.html",
    "href": "posts/2008/2008-12-24-rrna-removal-v-tubiashii-total-rna-from-yesterday/index.html",
    "title": "rRNA Removal - V. tubiashii total RNA from yesterday",
    "section": "",
    "text": "rRNA removal was continued from O/N precipitation. Processed the samples according to the Ambion MICROBExpress Kit protocol and resuspended final pellets in 25uL of The RNA Storage Solution. Samples were spec’d on the NanoDrop."
  },
  {
    "objectID": "posts/2008/2008-12-24-rrna-removal-v-tubiashii-total-rna-from-yesterday/index.html#section",
    "href": "posts/2008/2008-12-24-rrna-removal-v-tubiashii-total-rna-from-yesterday/index.html#section",
    "title": "rRNA Removal - V. tubiashii total RNA from yesterday",
    "section": "",
    "text": "Samples were stored @ -80C in Sam’s RNA Box #1."
  },
  {
    "objectID": "posts/2008/2008-11-17-sdspagewestern-purified-his-column-fst-samples-from-20081112/index.html",
    "href": "posts/2008/2008-11-17-sdspagewestern-purified-his-column-fst-samples-from-20081112/index.html",
    "title": "SDS/PAGE/Western - Purified (His column) FST samples from 20081112",
    "section": "",
    "text": "10uL of each sample from 20081112 (binding supe, washes and elution fractions) were mixed with 2x sample reducing buffer and boiled 5 mins. Samples were loaded onto Pierce 4-20% Tris-Glycine SDS/PAGE gels. 10uL of SeeBlue ladder was loaded. 5uL of positive control lysate was loaded. Gel was run @ 150V for 45mins.\nGel was transferred to nitrocellulose membrane (equilibrated in tris-glycine transfer buffer for 5mins) @15V for 15mins. Membrane washed briefly in 1x TBS-T, then blocked for 1hr. Gel was stained for 1hr in Coomassie stain and then destained w/ 10% acetic acid until bands were clearly visible.\n\nLane #1 - Ladder\nLane #2 - Positive control lysate\nLand #3 - Binding supe\nLane #4 - Wash\nLane #5 - Elution fraction #1\nLane #6 - Elution fraction #2\nLane #7 - Elution fraction #3\nLane #8 - Elution fraction #4\nLane #9 - Elution fraction #5\nLane #10 - Elution fraction #6\nLane #11 - Elution fraction #7\nLane #12 - Elution fraction #8\nPrimary Ab (anti-6x His) was added to membrane at a 1:10,000 dilution. This incubated for 1hr. Used Ab solution was stored @ 4C.\nMembrane was washed with 1x TBS-T and fresh blocking solution was added per the protocol.\nSecondary Ab (DAR HRP) was added to membrane @ 1:15,000 dilution and incubated for 30mins.\nMembrane was washed with 1x TBS-T per the protocol.\nBlots were developed using Millipore Immobilon chemiluminescent regent and imaged.\nResults:\nWestern is totally blank. Again. Absolutely no signal at all detected. Not even a smudge/blob/dot/forceps mark/crease. Nothing."
  },
  {
    "objectID": "posts/2008/2008-12-29-rna-gel-v-tubiashii-mrna-samples-from-20081224/index.html",
    "href": "posts/2008/2008-12-29-rna-gel-v-tubiashii-mrna-samples-from-20081224/index.html",
    "title": "RNA Gel - V. tubiashii mRNA samples (from 20081224)",
    "section": "",
    "text": "external image 20081229.png\n\n\nLane 1 - Empty Lane 2 - Total RNA, Control Lane 3 - mRNA, Control Lane 4 - Total RNA, Vibrio+gigas Lane 5 - mRNA, Vibrio+gigas\nResults:\nrRNA removal seems to have worked relatively well. Still some residual rRNA present in the mRNA samples. Will submit 200ng of the Vibrio+gigas mRNA to HTGU for Illumina sequencing."
  },
  {
    "objectID": "posts/2008/2008-12-12-sdspagewestern-attempt-to-fixidentify-problems-with-westerns/index.html",
    "href": "posts/2008/2008-12-12-sdspagewestern-attempt-to-fixidentify-problems-with-westerns/index.html",
    "title": "SDS/PAGE/Western - Attempt to fix/identify problem(s) with Westerns",
    "section": "",
    "text": "Will use two different antibodies and two different development methods: chromogenic (Invitrogen Western Breeze) and chemiluminescent.\nLoaded four sets of MSTN1b active form protein (in 1x TBS) of 15uL protein + 15uL reducing sample buffer (after boiling for 5mins.) onto a Pierce 4-20% tris-hepes gel. Also loaded four sets of 10uL SeeBlue ladder, along with 5uL of positive control lysate. These were each loaded into the same lane. Ran gel @ 150V for 45mins. Samples were transferred to nitrocellulose 15V for 15mins. Gel was stained with Coomassie stain for 45 mins and then destained with 10% acetic acid until bands were clearly visible.\n\nSamples are loaded as: Ladder, MSTN1b, blank. Repeat across gel.\nMembrane was cut into four pieces: two for standard Western blotting and two for the colorimetric development. These were blocked in 15mL of blocking solution (standard) or 10mL of blocking solution (chromogenic) for 30mins. Primary antibodies used were anti-c-Myc (mouse) and anti-His (rabbit). For the standard Western, they were used at a 1:5000 dilution. For the colorimetric, they were used at a 1:1000 dilution (per the antibody info sheet). Membranes were incubated with primary antibodies for 1 hr. Membranes were washed per the protocol. Secondary antibodies (GAR AP for chromogenic; DAR HRP & GAM HRP for chemiluminescent) were added. 1:3000 dilution for chromogenic and 1:5000 dilution for chemiluminescent. Incubated for 30 mins. Membranes were washed per the protocol.\nChromogenic: Added substrate to membranes and incubated for ~5mins. until band was very prominent.\n\nResults:\nProminent band is MSTN1b. Smearing is commonly seen with this recombinant protein. Positive control lysate (12-tag marker) was not detected.\nChemiluminescent: Added 4mL total of Millipore Immobilon chemiluminescent reagent to both membranes. 10 min. expsoure.\n\nResults:\nMembrane on the left only shows detection of MSTN1b and not the positive control lysate. The membrane on the right shows both MSTN and the positive control lysate."
  },
  {
    "objectID": "posts/2008/2008-12-09-sdspagewestern-anti-hsp70-ab-test/index.html",
    "href": "posts/2008/2008-12-09-sdspagewestern-anti-hsp70-ab-test/index.html",
    "title": "SDS/PAGE/Western - anti-HSP70 Ab test",
    "section": "",
    "text": "Test of the new [anti-HSP70 Ab (ABR cat# MA3-006)(https://aquacul4.fish.washington.edu/Protocols:Information%20Sheets/Product%20Information%20Sheets/Antibodies/ABR%20-%20HSP70%20Ab.jpg). Gigas gill protein extracts from 20080617 (both control and Vibrio exposure samples) were each pooled to result in 10ug protein of control and 10ug protein of VE in a volume of 10uL each. The two samples were mixed with an equal volume of 2x sample reducing buffer. O. rubescans samples were taken from Rachel’s -20C box. 15uL of each sample was mixed with 2x sample reducing buffer. All samples were boiled for 5mins and spot spun. Samples were loaded onto Pierce 4-20% Tris-Glycine SDS/PAGE gels. 10uL of SeeBlue ladder was loaded. Gel was run @ 150V for 45mins.\nGel was transferred to nitrocellulose membrane (equilibrated in tris-glycine transfer buffer for 5mins) @15V for 20mins. Membrane washed briefly in 1x TBS-T, then blocked for 1hr. in 15mL of blocking solution. Primary Ab was added at a 1:5000 dilution per the HSP70 data sheet and incubated O/N @ 4C. Gel was stained for 1hr in Coomassie stain and then destained w/ 10% acetic acid O/N.\n\nLane #1 - Ladder\nLane #2 - Gigas gill control pool\nLane #3 - Gigas vibrio exposure pool\nLane #4 - O. rubescans “mucus from suction” 10/24\nLane #5 - O. rubescans “UW 11/21”\nLane #6 - O. rubescans “Bucket 11/21”\nLane #7 - O. rubescans “water/mucus from bucket 10/24”\nLane #8 - O. rubescans “skin 11/21”\nResults: The two oyster samples are the only two that are visible on the coomassie stained gel. I will have to talk to Rachel concerning the columes of O. rubescans proteins that she loaded on her gels, as it is NOT clear in her notebook entries. Additionally, the gel did not destain very well."
  },
  {
    "objectID": "posts/2008/2008-12-17-vibrio-challenge-continued-from-yesterday-3/index.html",
    "href": "posts/2008/2008-12-17-vibrio-challenge-continued-from-yesterday-3/index.html",
    "title": "Vibrio challenge CONTINUED (from yesterday)",
    "section": "",
    "text": "One of the two starter cultures from yesterday were used to inoculate 500mL 1x LB+1% NaCl and incubated O/N @ 30C 200RPM."
  },
  {
    "objectID": "posts/2008/2008-12-16-sdspagewestern-anti-hsp70-ab-re-test/index.html",
    "href": "posts/2008/2008-12-16-sdspagewestern-anti-hsp70-ab-re-test/index.html",
    "title": "SDS/PAGE/Western - anti-HSP70 Ab Re-test",
    "section": "",
    "text": "Another attempt to determine appropriate amounts of anti-HSP70 Ab [(ABR cat# MA3-006)(https://aquacul4.fish.washington.edu/Protocols:Information%20Sheets/Product%20Information%20Sheets/Antibodies/ABR%20-%20HSP70%20Ab.jpg)and/or protein needed for better detection of HSP70 in Gigas protein samples. Gigas gill protein extracts from 20080617 (both control and Vibrio exposure samples) were each pooled. The two samples were mixed with an equal volume of 2x sample reducing buffer. 100uL of hemolymph were extracted from Gigas muscles and mixed with an equal volume of 2x sample reducing buffer. Samples were boiled for 5mins. and loaded onto a Pierce 4-20% tris-hepes gel. Also loaded 10uL of SeeBlue ladder. Ran gel @ 150V for 45mins. Samples were transferred to nitrocellulose 20V for 30mins. Well locations were marked on the membrane with a pencil. Gel was stained with Coomassie stain for 30 mins and then destained with 10% acetic acid until bands were clearly visible.\n\n\n\nexternal image 20081216.JPG\n\n\nLane 1 - Ladder Lane 2 - Control (20ug) Lane 3 - VE (20ug) Lane 4 - Hemos (40uL) Lane 5 - Control (10ug) Lane 6 - VE (10ug) Lane 7 - Hemos (20uL)\nLane 8 - Control (20ug) Lane 9 - VE (20ug) Lane 10 - Hemos (40uL) Lane 11 - Control (10ug) Lane 12 - VE (10ug)\nMembrane was cut in two (between lanes 7 & 8) for probing with two different primary Ab concentrations: 1:5000 (per the manufacturer’s suggestion) and 1:2500. Membranes were incubated 1hr. in 15 mL of blocking solution. Primary Ab was added at the two above mentioned concentrations to the respective membrane and incubated 1hr. Membranes were washed with 1x TBS-T 3 x 10mins. Secondary Ab (DAM-HRP) was added with blocking solution to the membranes at a 1:2500 dilution and incubated 30mins. Membranes were washed with 1x TBS-T 3 x 10mins. Membranes were developed with Millipore Immobilon Western Chemiluminescent reagent and imaged together.\nResults:\nNo image of any sort! Not even the pencil marks were visible. Just a blank screen. I’m starting to suspect that something is wrong with the imaging system or something. This is basically a repeat of the Western on 20081210 which worked. Now I’m not sure what to do at all. This blows."
  },
  {
    "objectID": "posts/2008/2008-12-22-rna-isolation-v-tubiashii-from-challenge-see-20081216/index.html",
    "href": "posts/2008/2008-12-22-rna-isolation-v-tubiashii-from-challenge-see-20081216/index.html",
    "title": "RNA Isolation - V. tubiashii from challenge (see 20081216)",
    "section": "",
    "text": "Added 10mL TriReagent to 2 x 50mL pellets (5.63 x 10^11 total bacteria; see calcs on 20081219) from the control samples collected on 20081219. Added 10mL TriReagent to 1 x 50mL pellet (1.835 x 10^12 total bacteria; see calcs on 20081219) from the V.tubi + oyster samples collected on 20081219. Scaled rest of RNA protocol to match. Resuspended pellets in 100uL 0.1%DEPC-H2O. Samples were NanoDropped.\n\n\n\nexternal image 20081222%20RNA%20SJW.PNG\n\n\nThe V. tubi + gigas sample was eventually diluted to contain 400uL (see final reading for that sample above).\nRNA samples were precipitated O/N @ -20C according to Ambion protocol."
  },
  {
    "objectID": "posts/2008/2008-12-19-vibrio-challenge-continued-from-yesterday/index.html",
    "href": "posts/2008/2008-12-19-vibrio-challenge-continued-from-yesterday/index.html",
    "title": "Vibrio challenge CONTINUED (from yesterday)",
    "section": "",
    "text": "Significantly more bacteria in the container containing autoclaved oysters. Collected 2 x 50mL from each treatment. Collected ~750mL from each treatment. Cells were pelleted 4000RPM, 15mins, 4C. Supe was removed and pellets frozen @ -80C.\n100uL of a 1:1,000,000 dilution of the control bacteria were plated on 1x LB + 1% NaCl plates and incubated O/N @ RT. 100uL of a 1:10,000,000 dilution of the exposed bacteria were plated on 1x LB + 1% NaCl plates and incubated O/N @ RT. Control colony count the next day = 563 colony forming units (CFU). Exposed colony count the next day = 367 CFU.\nControl Calculations 563 CFU/100uL = 5.63 CFU/uL 5.63 CFU/uL x 1:1,000,000 dilution = 5.63 x 10^6 CFU/uL 5.63 x 10^6 CFU/uL x 1000uL/mL = 5.63 x 10^9 CFU/mL\nExposed Calculations 367 CFU/100uL = 3.67 CFU/uL 3.67 CFU/uL x 1:10,000,000 dilution = 3.67 x 10^7 CFU/uL 3.67 x 10^7 CFU/uL x 1000uL/mL = 3.67 x 10^10 CFU/mL"
  },
  {
    "objectID": "posts/2009/2009-01-02-sdspage-western-blot-test-of-hsp70-ab-on-heat-stressed-shellfish-for-fish441/index.html",
    "href": "posts/2009/2009-01-02-sdspage-western-blot-test-of-hsp70-ab-on-heat-stressed-shellfish-for-fish441/index.html",
    "title": "SDS/PAGE, Western Blot - Test of HSP70 Ab on heat stressed shellfish for FISH441",
    "section": "",
    "text": "Pacific oysters, a mussel, barnacles and a clam (sp. ?) were transferred from the holding tank to a large beaker with sea water which was placed into a 37C water bath. The shellfish were incubated in this water bath for ~3hrs. Tissues were collected from each, transferred to a 50mL conical tube and immediately placed in a dry ice/ethanol bath:\nOyster - gills, muscle and mantle\nClam - whole clam\nMussel - whole mussel\nBarnacles - whole barnacles\n0.02 - 0.07g of each tissue were weighed, added to a 1.5mL tube containing 0.5mL CelLytic MT + protease inhibitors and homogenized. For the barnacles, ~8 barnacles were transferred to a weigh boat and smashed with a hammer. This was then transferred to a 1.5mL tube with CelLytic MT + protease inhibitors. Tubes were spun @ max speed @ 4C for 10mins. Supe was transferred to a fresh 1.5mL snap cap tube. 15uL of each sample was transferred to a screw cap tube containing 15uL of 2X reducing sample buffer. Tubes were boiled for 5mins and then spun for 1min @ max speed @ 4C. Samples were loaded on Pierce 4-20% Tris-HEPES SDS PAGE gels and run 150V for 45mins. 10uL of SeeBlue Plus ladder was also loaded on the gel.\nGel, membrane, and blotting paper were soaked for 15mins in transfer buffer (Pierce recipe w/methanol). Proteins were transferred to nitrocellulose membranse for 30mins @ 20V. Gel was stained for ~40mins in Coomassie stain and then destained w/10% acetic acid solution until bands were clearly visible.\n\nWestern blotting was done according to Invitrogen WesternBreeze Chromogenic (anti-mouse) protocol. Primary HSP70 Ab was used at a 1:3000 dilution (per the Meistertzheim et al. paper)."
  },
  {
    "objectID": "posts/2009/2009-09-30-bioanalyzer-submission-ricks-trout-rbc-samples-various-dates/index.html",
    "href": "posts/2009/2009-09-30-bioanalyzer-submission-ricks-trout-rbc-samples-various-dates/index.html",
    "title": "Bioanalyzer Submission - Rick’s trout RBC samples (various dates)",
    "section": "",
    "text": "Submitted Rick’s trout RBC samples to FHRC for bioanalysis using the PicoChip for use with the SOLiD WTK. Submission sheet is here.\nResults: Received 20091001.\n\nLanes 1 & 2 = ribo-depleted AND polyA enriched\nLanes 3 & 4 = ribo-depleted only\nLanes 5 & 6 = total RNA\nLanes 7 & 8 = ribo-depleted only"
  },
  {
    "objectID": "posts/2009/2009-10-22-rna-isolation-herring-liver-samples/index.html",
    "href": "posts/2009/2009-10-22-rna-isolation-herring-liver-samples/index.html",
    "title": "RNA Isolation - Herring Liver Samples",
    "section": "",
    "text": "RNA was isolated according to protocol. Pellets were resuspended in 200uL of 0.1%DEPC-H2O, heated @ 55C for 5 mins, spec’d and stored @ -80C in the “Herring RNA Box #1”.\nResults:\n\nRNA looks good. Will speak with Steven how to proceed and whether or not to check for gDNA carryover."
  },
  {
    "objectID": "posts/2009/2009-06-03-pcr-c-pugetti-dna-from-20090513-20090526/index.html",
    "href": "posts/2009/2009-06-03-pcr-c-pugetti-dna-from-20090513-20090526/index.html",
    "title": "PCR - C.pugetti DNA from 20090513 & 20090526",
    "section": "",
    "text": "This is a repeat of yesterday’s PCR with a fresh working stock in hopes of eliminating the source of contamination seen in the negative control yesterday.\n\nLane 1 - 100bp ladder\nLane 2 - 5/13 DNA\nLane 3 - 5/26 DNA\nLane 4 - Empty\nLane 5 - H2O\nResults: Same problem as yesterday. Water sample is contaminated. This suggests that the primer stocks are contaminated. Likely due to the use of non-sterile, “old” TE for reconstitution of the primer stocks. Will re-order them and reconstitute them sterily."
  },
  {
    "objectID": "posts/2009/2009-01-23-mrna-isolation-hard-clam-gill-and-hemo-rna/index.html",
    "href": "posts/2009/2009-01-23-mrna-isolation-hard-clam-gill-and-hemo-rna/index.html",
    "title": "mRNA Isolation - Hard Clam gill and hemo RNA",
    "section": "",
    "text": "mRNA was isolated according to Ambion PolyA Purist protocol. After mixing samples with resin, samples were incubated @ RT for 1hr. Samples were washed per the protocol. However, the hemo sample was not clearing from the spin columns with the protocol-directed 3 min. spins. The column had to be spun up to 15 mins. in order for the column to clear. :(\n\nResults: The gill mRNA looks good (~1.8ug). The concentration of the hemo sample is extremely low and is below the error threshold for the NanoDrop, but it may not be that bad. The samples are in a relatively large volume (~200uL) and the yield is expected to be very small. So, I will precipitate these samples O/N @ -20C according to Ambion PolyA Purist protocol in order to concentrate them."
  },
  {
    "objectID": "posts/2009/2009-12-02-rna-precipitation-herring-liver-rna-for-solid-libraries/index.html",
    "href": "posts/2009/2009-12-02-rna-precipitation-herring-liver-rna-for-solid-libraries/index.html",
    "title": "RNA Precipitation - Herring Liver RNA for SOLiD Libraries",
    "section": "",
    "text": "50uL of RNA from each of the following were precipitated O/N @ -20C:\n2L HKOD09 - 2.157 ug/uL x 50uL = 107.85ug\n4L HTOG09 - 2.089 ug/uL x 50uL = 104.45ug\n3L HSITK09 - 1.089 ug/uL x 50uL = 54.45ug\n6L HPWS09 - 1.703 ug/uL x 50uL = 85.15ug\n0.1 volumes (5uL) of 3M NaOAc ph = 5.2 was added to each sample. Then 2 volumes (110uL) of 100% EtOH was added. Samples were vortexed and incubated O/N @ -20C."
  },
  {
    "objectID": "posts/2009/2009-04-10-pcr-baysea-scallop-hybrids/index.html",
    "href": "posts/2009/2009-04-10-pcr-baysea-scallop-hybrids/index.html",
    "title": "PCR - Bay/Sea scallop hybrids",
    "section": "",
    "text": "Because Rony’s results from her PCR did not match her previous results for the positive controls, I ran the PCRs myself on the controls and the hybrids. Anneal temp 50C. PCR set up, samples, etc. are here.\n\nResults: The positive controls still do not match the results Rony got in two consecutive PCR attempts. However, the Bay_Actin_Rv2 and Sea_Actin_Rv3 primers do result in clearly distinguishable differences between bay and sea scallop gDNA. Lane 2 (bay gDNA/bay actin primer) has a large, ~1000bp band and lane 7 (sea gDNA/sea actin primer) produces a ~300bp band. Unfortunately, this does provide us with any useful info. Something needs to be reworked (i.e. possibly new target gene) in order to start getting some useful results.\nHowever, the results we did get definitely confirm that the hybrids are NEITHER hybrids nor bay scallop, due to the fact that no bands are present in any other sample than the bay scallop gDNA samples."
  },
  {
    "objectID": "posts/2009/2009-10-24-rna-precipitation-herring-liver-samples/index.html",
    "href": "posts/2009/2009-10-24-rna-precipitation-herring-liver-samples/index.html",
    "title": "RNA Precipitation - Herring Liver Samples",
    "section": "",
    "text": "A subset of samples (4 samples from each group) were pooled (see spreadsheet, green-highlighted samples), each providing ~68ug of RNA. The pooled sample was split into two tubes (435uL/tube). 0.1 vols (43.5uL) of 3M NaOAC (pH=5.2) were added, then 2 vols of 100% EtOH (957uL). Tubes were vortexed and incubated @ -80C for 30mins. RNA was pelleted by spinning 16,000g, 30mins, 4C. Supe was removed, pellets washed with 70% EtOH. Tubes were spun 16,000, 10mins, 4C. Supe removed. Pellets were resuspended in 250uL of RNase-free H2O and stored @-80C until Monday for mRNA isolation."
  },
  {
    "objectID": "posts/2009/2009-12-05-rna-isolation-sepia-samples/index.html",
    "href": "posts/2009/2009-12-05-rna-isolation-sepia-samples/index.html",
    "title": "RNA Isolation - Sepia samples",
    "section": "",
    "text": "Isolated RNA from 7 sepia samples received 20091125. Samples were removed from RNA Later, blotted and homogenized in 500uL of TriReagent. 500uL of additional TriReagent was added to the tubes after homogenization. Procedure was followed normally. The sepia retina RNA was isolated separately from the other samples and was resuspended in 100uL of 0.1% DEPC-H2O. The remaining samples were isolated and resuspended in 20uL of 0.1% DEPC-H2O. Nearly all samples had some sort of purple tint to them, ranging from almost black to extremely faint purple hue. The samples were spec’d and then stored @ -80C in Sam’s RNA Box #1.\nResults:\n\nNearly all of the samples exhibited very strange curves and mediocre 260/280 ratios (for RNA). Could be due to the “purple stuff” carryover or possibly an effect of the RNA Later from which the samples were stored."
  },
  {
    "objectID": "posts/2009/2009-08-06-qpcr-calibration-test-of-opticon-2-2/index.html",
    "href": "posts/2009/2009-08-06-qpcr-calibration-test-of-opticon-2-2/index.html",
    "title": "qPCR - Calibration test of Opticon 2",
    "section": "",
    "text": "Due to results of Opticon testing from 20090722, we have acquired FAM Calibartion Dye from Bio-Rad. Although not listed online or on the product itself, Bio-Rad customer service informed me that the concentration = 1mM. The calibration protocol in the Opticon 2 manual (p. 10-4) says to use 0.3uM (Cf) in 50uL. Will follow this info. Made up 15mLs of dye solution and distributed 50uL into each well of 3 plates. Tested all three plates on two different machines (Opticon 2 and Friedman lab’s).\nResults: This did not produce any useable information whatsoever. In fact, the Friedman lab’s machine didn’t detect any signal at all from any of the three plates. Not sure what the story is.\nUPDATE Received email correspondence from Carl Fisher of Bio-Rad and he has indicated that this is not the proper dye and that the conentration is not anywhere near 1mM (although he can’t find any info on what the concentration might be). He has told me to order a different part number (10006046) that is NOT listed anywhere on the Bio-Rad website."
  },
  {
    "objectID": "posts/2009/2009-02-25-reverse-transcription-v-tubiashii-dnased-rna-from-yesterday/index.html",
    "href": "posts/2009/2009-02-25-reverse-transcription-v-tubiashii-dnased-rna-from-yesterday/index.html",
    "title": "Reverse Transcription - V.tubiashii DNAsed RNA (from yesterday)",
    "section": "",
    "text": "Set up the MMLV RT rxns with random primers using ~833ng DNAsed RNA (prepared yesterday) according to the Promega MMLV Product Insert. This procedure is slightly different than what is in our lab protocol for RT rxns. Here is the workup for the rxns. cDNA was stored @ -20C in the “Vibrio” box."
  },
  {
    "objectID": "posts/2009/2009-06-02-dna-gel-jgi-qc-check-of-c-pugetti-dna-from-20090526/index.html",
    "href": "posts/2009/2009-06-02-dna-gel-jgi-qc-check-of-c-pugetti-dna-from-20090526/index.html",
    "title": "DNA Gel - JGI QC check of C. pugetti DNA from 20090526",
    "section": "",
    "text": "Lane 1 - 15ng standard (5uL)\nLane 2 - 31ng standard (5uL)\nLane 3 - 63ng standard (5uL)\nLane 4 - Marker 2 (5uL)\nLane 5 - C. pugetti DNA (5uL: 4uL + 1uL 5x dye)\nLane 6 - Marker 3 (5uL)\nLane 7 - 125ng standard\nLane 8 - 250ng standard (5uL)\nLane 9 - 500ng standard (5uL)\nResults: Looks great! Will run PCR using universal 16s primers for sequencing."
  },
  {
    "objectID": "posts/2009/2009-06-06-bacteria-c-pugetti-culture-1x-1l/index.html",
    "href": "posts/2009/2009-06-06-bacteria-c-pugetti-culture-1x-1l/index.html",
    "title": "Bacteria - C.pugetti culture (1x 1L)",
    "section": "",
    "text": "Inoculated 1x 1L of MB + biphenyl crystals from frozen stock. Incubated 28C, 200RPM. MB was autoclaved with the biphenyl crystals."
  },
  {
    "objectID": "posts/2009/2009-12-09-rna-adapter-hybridization-and-ligation-herring-liver-mrna-for-solid-libraries/index.html",
    "href": "posts/2009/2009-12-09-rna-adapter-hybridization-and-ligation-herring-liver-mrna-for-solid-libraries/index.html",
    "title": "RNA Adapter Hybridization and Ligation - Herring Liver mRNA for SOLiD Libraries",
    "section": "",
    "text": "RNA from yesterday was speedvac’d to dryness and resuspended in 3uL of nuclease-free H2O. Samples were mixed with Adaptor Mix A and hybridized according to Ambion WTK protocol. Samples were then ligated for 16hrs @ 16C, according to Ambion WTK protocol."
  },
  {
    "objectID": "posts/2009/2009-04-15-gdna-isolation-two-new-dungan-isolates/index.html",
    "href": "posts/2009/2009-04-15-gdna-isolation-two-new-dungan-isolates/index.html",
    "title": "gDNA Isolation - Two new Dungan isolates",
    "section": "",
    "text": "Isolated gDNA from the following two samples:\nMIE-14y\nVNTc-1.2-C1/G10\nSamples were spun @ 16,000g @ RT for 2mins. No visible pellets in either sample. EtOH was removed. “Pellets” were washed in 1x PBS (pH=7.6) two times and then the Qiagen DNEasy Kit protocol was followed. Samples were incubated @ 55C with Proteinase K for ~2hrs.\n\nResults: Both samples show really, really low quantities of gDNA."
  },
  {
    "objectID": "posts/2009/2009-04-09-qpcr-repeat-modified-of-yesterdays-abalone-cdna-check/index.html",
    "href": "posts/2009/2009-04-09-qpcr-repeat-modified-of-yesterdays-abalone-cdna-check/index.html",
    "title": "qPCR - Repeat (modified) of yesterday’s abalone cDNA check",
    "section": "",
    "text": "qPCR was performed with 16s_sybr primers on a subset of the “No RT” cDNA rxns from yesterday at both 55C and 60C. Sample set up and plate layout is here.\nResults: Still getting signals in the “No RT” rxns and possibly in the waters. Cut run short to start another. Will test Lisa’s previously DNased RNA."
  },
  {
    "objectID": "posts/2009/2009-07-07-dna-precipitation-dungan-mie-14v-gdna-from-earlier-today/index.html",
    "href": "posts/2009/2009-07-07-dna-precipitation-dungan-mie-14v-gdna-from-earlier-today/index.html",
    "title": "DNA Precipitation - Dungan MIE-14v gDNA from earlier today",
    "section": "",
    "text": "Added 1/10 volume of 3M NaOAc (pH = 5.2) to sample (10uL) and then 2 volumes of ice cold 100% EtOH to samples (220uL). Mixed thoroughly and incubated O/N @ -20c."
  },
  {
    "objectID": "posts/2009/2009-09-17-mrna-isolation-gigas-bb-and-dh-samples-previously-treated-with-ribominus-kit-by-mac-2/index.html",
    "href": "posts/2009/2009-09-17-mrna-isolation-gigas-bb-and-dh-samples-previously-treated-with-ribominus-kit-by-mac-2/index.html",
    "title": "mRNA Isolation - Gigas BB and DH samples previously treated with Ribominus Kit (by Mac)",
    "section": "",
    "text": "Was given 1ug of each of these two RNA samples and processed them with Promega’s PolyA Tract Kit according to protocol. After elution, the samples were EtOH precipitated @ -20C for 30mins, pelleted 30mins 16,000g for 30mins, 4C. Supe removed, RNA washed with 1mL 70% EtOH and spun 15mins 16,000g, 4C. Supe removed. Resusupended in 15uL of 0.1% DEPC-H2O and spec’d.\nResults: No measurable amount of RNA in either sample. Samples were stored @ -80C."
  },
  {
    "objectID": "posts/2009/2009-05-15-gdna-isolation-gigas-dermo-samples/index.html",
    "href": "posts/2009/2009-05-15-gdna-isolation-gigas-dermo-samples/index.html",
    "title": "gDNA Isolation - Gigas Dermo Samples",
    "section": "",
    "text": "Transferred tissue from previously Chelexed samples:\nWP3, WP7, WP13, WP14, WP15, CY1 - These all tested negative for virginica gDNA (18s qPCR by Rony on DATE)\nCY42, CY36 - These tested positive for virginica gDNA (18s qPCR by Rony on DATE).\nUsed Qiagen DNeasy Kit. Digested samples for 3 hrs. at 55C in Proteinase K according to protocol.\n\nResults: Horrible. Virtually no DNA in any of these samples. Additionally, the quality of the DNA is atrocious. Not sure what to do now."
  },
  {
    "objectID": "posts/2009/2009-12-03-hard-clam-challenge-qpx-strain-s-1-continued-from-yesterday/index.html",
    "href": "posts/2009/2009-12-03-hard-clam-challenge-qpx-strain-s-1-continued-from-yesterday/index.html",
    "title": "Hard Clam Challenge - QPX Strain S-1 (continued from yesterday)",
    "section": "",
    "text": "All clams appeared to be alive and well. Most had their siphons out when I arrived to start collecting tissues. Clams were shucked after 24hr challenge. Gill and mantle samples were collected in separate 1.5mL snap cap tubes, stored briefly on ice and transferred to -80C in “Hard Clam QPX Challenge 12/2/2009.” box."
  },
  {
    "objectID": "posts/2009/2009-12-17-pcr-sepia-cdna-and-dnased-rna/index.html",
    "href": "posts/2009/2009-12-17-pcr-sepia-cdna-and-dnased-rna/index.html",
    "title": "PCR - Sepia cDNA and DNased RNA",
    "section": "",
    "text": "Set up PCR on recent Sepia cDNA and DNased RNA samples using both S. officianalis_rhodopsin_F, R primers & Sep_op_F2, R2 primers. After yesterday’s intirguing PCR results, we need to confirm that the DNased RNA is free of contaminating gDNA. Additionally, we want to excise bands from the cDNA samples for sequencing. PCR set up is here. RNA was prepped as though making cDNA; diluted 0.2ug of DNased RNA in a final volume of 25uL. Used 1uL of this for PCRs.\nRhodopsin primers require 3mM Mg2+ in the PCR rxn and the opsin primers require 2mM Mg2+ in the PCR rxn. 25mM Mg2+ was added as required and is shown on the PCR set up link above.\nResults: n00b alert! The gel below is a repeat of yesterday’s PCR, except with DNased RNA samples added to verify no gDNA carryover. However, you’ll notice that the PCR results on the cDNA don’t look identical to yesterday’s PCR. Ugh.\n\nGel Loading (from left to right):\nOpsin Primers (top half of gel), Rhodopsin Primers (same loading order, bottom half of gel)\nRNA samples (left sides of gel), cDNA samples (right sides of gel)\n1 - 100bp ladder\n2 - retina\n3 - fin\n4 - 4th arm\n5 - dorsal mantle center\n6 - dorsal mantle side\n7 - ventral mantle center\n8 - ventral mantle side\n9 - H2O\nLoading is repeated in the above order for the cDNA, which is the right halves of the gel.\nWell, the good news is that no signal is seen in the DNased RNA samples, thus confirming that there is no detectable gDNA carryover.\nOpsin Primers\nWe see a band in the retina, fin & ventral mantle center samples as we did yesterday. However, we see a band in the 4th arm sample, which was not present yesterday. We also do NOT see a band in the ventral mantle side sample like we did yesterday. Negative controls are negative.\nRhodopsin Primers\nWe see a band in the retina and fin samples as we did yesterday. However, we no longer see the dual bands in the ventral mantle center as were seen yesterday. Negative controls are negative.\nBands were excised from the gel, placed in 1.5mL snap cap tubes and stored in the -20C in Sam’s “Purified Inserts” box.\nBecause of the lack of repeated results, I will repeat this PCR for a third time, with just the cDNA again, to see if I can duplicate one set of results…"
  },
  {
    "objectID": "posts/2009/2009-10-01-rna-isolation-tims-adult-gigas-challenge-samples/index.html",
    "href": "posts/2009/2009-10-01-rna-isolation-tims-adult-gigas-challenge-samples/index.html",
    "title": "RNA Isolation - Tim’s adult gigas challenge samples",
    "section": "",
    "text": "RNA was isolated using 500uL of TriReagent for all samples. Samples were resuspended in 100uL of 0.1%DEPC-H2O and spec’d. Samples stored in Tim’s “NAME OF BOX” box.\nResults:\n\nAC# = Air Control Sample\nCC# = CO2 Control Sample\nAV# = Air Vibrio Sample\nCV# = CO2 Vibrio Sample\nAll the samples look really good, even those that exhibited dark coloration carried over from extraction. Will check for gDNA contamination."
  },
  {
    "objectID": "posts/2009/2009-10-14-qpcrs-tims-adult-gigas-challenge-cdna-from-20091009/index.html",
    "href": "posts/2009/2009-10-14-qpcrs-tims-adult-gigas-challenge-cdna-from-20091009/index.html",
    "title": "qPCRs - Tim’s adult gigas challenge cDNA (from 20091009)",
    "section": "",
    "text": "Set up qPCR with Cg_P450 primers and TNFRAF3’/5’ primers. Plate layout/setup is here.\nResults: Processed with PCR Miner. Normalized to EF1. Standard Error bars. Here is spreadsheet with workup.\n \nP450: The two control samples (AC & CC) show significant difference in expression between the Air and CO2 treated samples. The Vibrio treated samples (AV & CV) show no difference in expression between Air and CO2 treatments.\nThe Air samples (AC & AV) show significant difference in expression between the Control (AC) and Vibrio treated (AV) samples.\nTNFRAF3: Expression levels of the Vibrio treated samples (AV &CV) were too low for Miner processing.\nThere are significant differences in expression between the Air (AC) and CO2 treated (CC) samples.\n\n\n\n\n\nSet up qPCR with Cg_IkB primers and Cg_Prx6 primers. Plate layout/setup is here.\nResults: Processed with PCR Miner. Normalized to EF1. Standard Error bars. Here is spreadsheet with workup.\n\nIkB:\nNo difference in expression between Air (AC & AV) and CO2 (CC & CV) treatments.\nAppears to be a significant difference between the Air Control (AC) and the Air Vibrio treated (AV) samples.\nPrx6:\nSignificant difference in expression between Air Control (AC) and CO2 Control (CC) samples, but no difference in the Vibrio treated samples.\nSignificant difference in expression between the Air Control (AC) and the Air Vibrio treated (AV) samples, but no difference in the CO2 treated Vibrio samples (CC & CV)."
  },
  {
    "objectID": "posts/2009/2009-07-08-qpcr-dnased-abalone-dg-rna-from-20090625-2/index.html",
    "href": "posts/2009/2009-07-08-qpcr-dnased-abalone-dg-rna-from-20090625-2/index.html",
    "title": "qPCR - DNased Abalone Dg RNA from 20090625",
    "section": "",
    "text": "Ran qPCR on DNased Abalone Dg RNA (07:12 Set), gDNA (06:50-10) and clean cDNA (from 20090422) using primers (H.crach_h-1fg_intron_Fw/Rv) designed to bind only to a region in an intron of the H.cracherodii hemocyanin gene. PCR setup/plate layout is here. Anneal temp of 50C was used.\nResults: No PCR products in any samples, not even the positive control. It seems that the primers don’t work. Will design new primers, probably from a different species of abalone since there was essentially only one gene in H.cracherodii that had any intron sequence available.."
  },
  {
    "objectID": "posts/2009/2009-04-27-bacteria-c-pugetti-liquid-culture/index.html",
    "href": "posts/2009/2009-04-27-bacteria-c-pugetti-liquid-culture/index.html",
    "title": "Bacteria - C. pugetti liquid culture",
    "section": "",
    "text": "Results: It has now been 8 days since revival of the ATCC freeze dried culture. The media still looks a bit cloudy, but hasn’t really changed since the second or third day post-revival. Of note, there does seem to be an accumulation of clumps in the tube. These may or may not be clumps of cells. Will consult with Steven when he returns. Might need to pass cells and take some ODs to really assess changes in growth as these cells may not be as robust as E. coli or other common lab cultures."
  },
  {
    "objectID": "posts/2009/2009-06-24-dnase-treatment-abalone-dg-rna-0712-set/index.html",
    "href": "posts/2009/2009-06-24-dnase-treatment-abalone-dg-rna-0712-set/index.html",
    "title": "DNase Treatment - Abalone Dg RNA (07:12 set)",
    "section": "",
    "text": "DNase treated the 07:12 set of Abalone Dg RNA. Also, respec’d the RNA prior to proceeding. Followed Ambion’s Turbo DNA-free Kit rigorous protocol. Here are the calcs/workup for the DNase treatment. This used previously untreated RNA."
  },
  {
    "objectID": "posts/2009/2009-02-13-trypsin-digestion-vibrio-2d-spots-continued-from-yesterday/index.html",
    "href": "posts/2009/2009-02-13-trypsin-digestion-vibrio-2d-spots-continued-from-yesterday/index.html",
    "title": "Trypsin digestion - Vibrio 2D spots CONTINUED (from yesterday)",
    "section": "",
    "text": "Sample prep was continued from yesterday. SpeedVac’d final, pooled elutions for 1.5hrs. Stored tubes @ -80C. Will submit samples 2-1 and 2-2 for mass spec analysis."
  },
  {
    "objectID": "posts/2009/2009-06-26-qpcr-mv-hemocyte-cdna-from-20090614-7/index.html",
    "href": "posts/2009/2009-06-26-qpcr-mv-hemocyte-cdna-from-20090614-7/index.html",
    "title": "qPCR - MV hemocyte cDNA from 20090614",
    "section": "",
    "text": "Set up qPCR with Cv_18s_F/R primers. Plate layout/PCR set up is here. This is a second rep. Used 1:20 cDNA plate made by Mac as template.\nResults: Waters are clean. Still some samples that aren’t coming up. Will eventually run those samples using undiluted cDNA. To be analyzed later with other genes that Mac has run."
  },
  {
    "objectID": "posts/2009/2009-01-21-rna-precipitation-of-hard-clam-hemo-rna-from-20090116/index.html",
    "href": "posts/2009/2009-01-21-rna-precipitation-of-hard-clam-hemo-rna-from-20090116/index.html",
    "title": "RNA - Precipitation of Hard Clam Hemo RNA from 20090116",
    "section": "",
    "text": "RNA isolated on 20090116 was precipitated over the weekend @ -20C. Samples were treated according to Ambion PolyA Purist protocol and resuspended in 100uL of 0.1% DEPC-H2O. Samples were stored in the red “hard clam” box @ -80C.\n\nResults: 260/280 look good for both gill and hemo samples. 260/230 looks OK for gill, but looks horrible (as usual) for hemos."
  },
  {
    "objectID": "posts/2009/2009-05-12-qpcr-macs-gigas-dnased-rna-from-earlier-today/index.html",
    "href": "posts/2009/2009-05-12-qpcr-macs-gigas-dnased-rna-from-earlier-today/index.html",
    "title": "qPCR - Mac’s gigas DNased RNA from earlier today",
    "section": "",
    "text": "Performed qPCR on the DNased oyster RNA from earlier today with Gigas_18s_F/R primers to verify removal of detectable gDNA in the samples, since the qPCR from 20090508 indicated residual gDNA was still present in some of the DNase treated RNA. Plate layout/set up is here.\nResults: Samples BB# 2, 5, 6, 15 still came up as positive for gDNA contamination. These will NOT be used to make cDNA for subsequent qPCRs."
  },
  {
    "objectID": "posts/2009/2009-10-10-reverse-transcription-tims-adult-gigas-challenge-dnased-rna-from-20091008/index.html",
    "href": "posts/2009/2009-10-10-reverse-transcription-tims-adult-gigas-challenge-dnased-rna-from-20091008/index.html",
    "title": "Reverse Transcription - Tim’s adult gigas challenge DNased RNA (from 20091008)",
    "section": "",
    "text": "Performed RT rxns. Setup is here. cDNA was subsequently diluted 1:4 (added 75uL H2O to each well) to properly mirror Tim’s previous qPCRs.\nUPDATE: cDNA plate was discarded 20120320 by SJW."
  },
  {
    "objectID": "posts/2009/2009-06-05-rna-isolation-abalone-dg-project-samples/index.html",
    "href": "posts/2009/2009-06-05-rna-isolation-abalone-dg-project-samples/index.html",
    "title": "RNA Isolation - Abalone Dg Project Samples",
    "section": "",
    "text": "RNA was isolated from the following samples using the MoBio RNA PowerSoil Kit according to protocol:\n\nResults: RNA looks fabulous (as always from the PowerSoil kit). Will DNase treat the samples tomorrow."
  },
  {
    "objectID": "posts/2009/2009-10-07-reverse-transcriptioncdna-purificationemulsion-pcr-ligation-rxns-of-trout-fragmented-rna-for-solid-wtk-from-yesterday/index.html",
    "href": "posts/2009/2009-10-07-reverse-transcriptioncdna-purificationemulsion-pcr-ligation-rxns-of-trout-fragmented-rna-for-solid-wtk-from-yesterday/index.html",
    "title": "Reverse Transcription/cDNA purification/Emulsion PCR - Ligation rxns of trout fragmented RNA for SOLiD WTK (from yesterday)",
    "section": "",
    "text": "The four samples from yesterday were prepared according to the Agilent SOLiD WTK protocol. Briefly:\nResults: All four samples appear to have cDNA. Interestingly, the “Amped cDNA trout RBC control ribo(-)” sample was the sample that had no detectable RNA after fragmentation, BUT this sample produced the highest yield of cDNA… See below.\n1.5uL of each sample was transferred to a 0.5mL snap cap tube and stored @ -80C in the “Samples for Bioanalyzer” box for submission on the DNA 1000 Chip.\n\n\nThe Yellow/Brown plot above is the “Amped cDNA trout RBC poly I:C ribo(-) & polyA” sample and exhibits a strange profile at the 220-230nm range that differs than the three other samples."
  },
  {
    "objectID": "posts/2009/2009-12-04-sequencing-dungan-isolates-lake-trout-hrm-and-emma-dd-cloning/index.html",
    "href": "posts/2009/2009-12-04-sequencing-dungan-isolates-lake-trout-hrm-and-emma-dd-cloning/index.html",
    "title": "Sequencing - Dungan Isolates, Lake Trout HRM and Emma DD cloning",
    "section": "",
    "text": "Submitted 1.5 plates for Sanger sequencing. Dungan isolates prepared by me, Lake Trout HRM prepared by Rony and Emma’s differential display cloning samples prepared by her. All primers were prepped by me. See the sequencing log for samples and plate layout."
  },
  {
    "objectID": "posts/2009/2009-06-25-dnase-treatment-abalone-dg-rna/index.html",
    "href": "posts/2009/2009-06-25-dnase-treatment-abalone-dg-rna/index.html",
    "title": "DNase Treatment - Abalone Dg RNA",
    "section": "",
    "text": "DNase treated Abalone Dg RNA. Followed Ambion’s Turbo DNA-free Kit rigorous protocol. Here are the calcs/workup for the DNase treatment. This used previously untreated RNA."
  },
  {
    "objectID": "posts/2009/2009-07-06-bacteria-c-pugetti-liquid-cultures/index.html",
    "href": "posts/2009/2009-07-06-bacteria-c-pugetti-liquid-cultures/index.html",
    "title": "Bacteria - C. pugetti liquid cultures",
    "section": "",
    "text": "Inoculated 3 x 5mL Marine Broth + biphenyl crystals (UV sterilized) cultures from frozen stock in 50mL Falcon tubes. Incubated 200RPM, 28C. Will use these are starter cultures to inoculate larger cultures."
  },
  {
    "objectID": "posts/2009/2009-06-09-pcr-c-pugetti-gdna-from-20090513-20090526/index.html",
    "href": "posts/2009/2009-06-09-pcr-c-pugetti-gdna-from-20090513-20090526/index.html",
    "title": "PCR - C.pugetti gDNA from 20090513 & 20090526",
    "section": "",
    "text": "Previous PCRs from 20090601 & 20090602 both showed contamination in the negative control. Suspect that the primer stocks were contaminated due to the usage of older, non-sterile TE for reconstitution. New stocks were received and reconstituted with filter-sterilized TE. Working stocks were made with filter-sterilized Nanopure H2O. All pipettes, tips, tubes, racks were UV-sterilized in the biological hood. The PCR reaction was set up in the biological hood. PCR set up is here. Used universal 16s bacteria primers (27F, 1492R). Sequences from Sara Kelly. Anneal 60C.\n\nLane 1 - 100bp ladder\nLane 2 - gDNA (5/13/2009)\nLane 3 - gDNA (5/26/2009)\nLane 4 - H2O\nLane 5 - H2O\nLane 6 - H2O\nLane 7 - H2O\nResults: Still contamination in the water-only samples!!!"
  },
  {
    "objectID": "posts/2009/2009-04-03-pcr-new-dungan-isolates-2/index.html",
    "href": "posts/2009/2009-04-03-pcr-new-dungan-isolates-2/index.html",
    "title": "PCR - New Dungan isolates",
    "section": "",
    "text": "Ran PCR with GoTaq on the new Dungan isolate gDNA from yesterday. PCR set up is here. 53C annealing temp.\n\nLane 1 - Hyperladder\nLane 2 - 17t\nLane 4 - H5\nLane 6 - 12t\nLane 7 - Hyperladder\nLane 8 - 1.5t\nLane 10 - 1.2t\nLane 12 - 11t\nlane 13 - Hyperladder\nLane 14 - 13t\nLane 16 - 19t\nLane 18 - H2O\nLane 19 - Hyperladder\nLane 20 - H2O\nResults: All the bands present are a bit larger than 400bp. However, the bottom band in the H5 sample is larger than any band present in any other samples. Additionally, the largest band in the H5 sample is between 800-1000bp. Bands were cut out from H5 (two bands: Top, Bottom), 1.5t, 1.2t, 13t. These will be purified and sequenced.\nIt’s also interesting to note that the bands present in this gel are found in the same samples as the last time this analysis was done. See Kevin’s Notebook, 20090212."
  },
  {
    "objectID": "posts/2009/2009-07-09-dna-precipitation-continued-dungan-mie-14v-gdna-from-yesterday/index.html",
    "href": "posts/2009/2009-07-09-dna-precipitation-continued-dungan-mie-14v-gdna-from-yesterday/index.html",
    "title": "DNA Precipitation CONTINUED - Dungan MIE-14v gDNA from yesterday",
    "section": "",
    "text": "Sample was pelleted by spinning in a microcentrifuge @ max speed, 4C for 30mins. Supe was removed and sample CAREFULLY washed with 1mL 70% EtOH. Sample was spun in a microcentrifuge @ max speed, 4C for 10mins. Supe was removed, sample brought up in 10uL of TE and spec’d.\n\nResults: Nothing. Absolutely no DNA in this sample at all. It’s odd that the Qiagen Kit procedure (even without the lysozyme treatment) has worked on all the other Dungan isolates, but not this one. I wonder if the EtOH storage is having an effect on the cells; lysing them for some reason? Maybe the cells should be sent to us in culture medium instead?"
  },
  {
    "objectID": "posts/2009/2009-04-17-sequencing-dungan-isolates/index.html",
    "href": "posts/2009/2009-04-17-sequencing-dungan-isolates/index.html",
    "title": "Sequencing - Dungan isolates",
    "section": "",
    "text": "Submitted two plates for sequencing. Each sample two times from each direction.\nPlate #1\nPlate #2"
  },
  {
    "objectID": "posts/2009/2009-12-24-qpcrs-bb-dh-cdna-from-yesterday/index.html",
    "href": "posts/2009/2009-12-24-qpcrs-bb-dh-cdna-from-yesterday/index.html",
    "title": "qPCRs - BB & DH cDNA (from yesterday)",
    "section": "",
    "text": "qPCR was set up on these cDNAs using the following primers:\nEW778094 (“Ficolin 3”) -\nAJ422120.p.cg.6 (“MDR49”, “Multidrug resistance protein homolog 49”) - This was upregulated in DH SOLiD data.\nqPCR set up and plate layout can be found here."
  },
  {
    "objectID": "posts/2009/2009-12-24-qpcrs-bb-dh-cdna-from-yesterday/index.html#section",
    "href": "posts/2009/2009-12-24-qpcrs-bb-dh-cdna-from-yesterday/index.html#section",
    "title": "qPCRs - BB & DH cDNA (from yesterday)",
    "section": "",
    "text": "Results:\nqPCR Data File (Opticon): 20091224_092959.tad\nData workup: PROPS BB_DH Gene Expression Miner Workup\nPreliminary results show that the EW778094 primer set looks bad; bad fluorescence profile and poor melt curves. Primers may require optimization.\nqPCR was set up on these cDNAs using the following primers:\nAM855874.p.cg.6 (“CP17A”, “Steroid 17-alpha-hydroxylase/17”) - This was upregulated in DH SOLiD data.\nAM857078.p.cg.6 (“C1QT4”, Complement C1q tumor necrosis factor-related protein 4”) - This was upregulated in DH SOLiD data.\nqPCR set up and plate layout can be found here.\nResults:\nqPCR Data File (Opticon): 20091224_125230.tad\nData workup: PROPS BB_DH Gene Expression Miner Workup"
  },
  {
    "objectID": "posts/2009/2009-07-23-bacteria-c-pugetti-culture-from-20090713/index.html",
    "href": "posts/2009/2009-07-23-bacteria-c-pugetti-culture-from-20090713/index.html",
    "title": "Bacteria - C.pugetti culture (from 20090713)",
    "section": "",
    "text": "1L liquid culture (grown for 10 days) was split into two UV-sterilized bottles. Cells were pelleted in a Sorvall T21 centrifuge using the bucket rotor for 30mins @ 4200RPM, 4C. Supe was removed and bacterial pellets were stored @ -20C."
  },
  {
    "objectID": "posts/2009/2009-06-12-dnase-treatment-mv-hemocyte-rna-from-earlier-today/index.html",
    "href": "posts/2009/2009-06-12-dnase-treatment-mv-hemocyte-rna-from-earlier-today/index.html",
    "title": "DNase Treatment - MV hemocyte RNA from earlier today",
    "section": "",
    "text": "The entire 20uL of RNA were treated with Ambion’s Turbo DNA-free kit according to protocol and spec’d.\n\nMac performed qPCR on the DNase-treated RNAs to verify removal of residual gDNA.\nResults: Samples 3326: B23, A25, A22, B14, A21, A10 B22 came up positive for residual gDNA. Will retreat these samples and qPCR again."
  },
  {
    "objectID": "posts/2009/2009-10-21-rna-isolation-herring-liver-samples-lhpws09-1-6/index.html",
    "href": "posts/2009/2009-10-21-rna-isolation-herring-liver-samples-lhpws09-1-6/index.html",
    "title": "RNA Isolation - Herring Liver Samples (LHPWS09 1-6)",
    "section": "",
    "text": "From Seeb Lab. Homogenized entire liver samples in 5mL of TriReagent with the Tissue Tearers. In essence, based on the manufacturer’s recommendation, this means the ratio of tissue:TriReagent was ~2x. Transferred 0.5mL of homogenized liver sample to 1.5mL snap cap tubes and added an additional 0.5mL of TriReagent, to adjust the ratio of tissue: TriReagent to ~1x. Samples were then stored @ -80C. These will be further processed once all remaining liver samples have been homogenized inTriReagent."
  },
  {
    "objectID": "posts/2009/2009-07-06-qpcr-mv-hemocyte-cdna-from-20090614-2/index.html",
    "href": "posts/2009/2009-07-06-qpcr-mv-hemocyte-cdna-from-20090614-2/index.html",
    "title": "qPCR - MV hemocyte cDNA from 20090614",
    "section": "",
    "text": "Set up qPCR with Cv_18s_F/R primers on the following samples that had previously come up negative in both reps using the diluted (1:20) cDNA that Mac had made specifically for the 18s runs:\n3326A13\n2100B07\n3219A06\n2100B15\n3326A11\n2100B12\n2100A03\nPlate layout/PCR set up is here.\nResults: Waters are clean. However, the following samples still are negative for an 18s amplicon:"
  },
  {
    "objectID": "posts/2009/2009-07-22-qpcr-gigas-dna-for-opticon-testing/index.html",
    "href": "posts/2009/2009-07-22-qpcr-gigas-dna-for-opticon-testing/index.html",
    "title": "qPCR - Gigas DNA for Opticon testing",
    "section": "",
    "text": "Due to some weird anomolies seen during my previous qPCRs with the H.crach RNA/cDNA samples (positive controls produced good fluorescence when tested in Column 1 of the Opticon, but consistently failed to produce virtually any fluorescence when in Column 6 of the Opticon), I’ve decided to check the Opticon’s fluorescence detection.\nqPCR setup/plate layout is here. I’ve made a master mix using Cg_HSP70_F/R primers designed by Mac. gDNA is BB #11 (0.49ug/uL) from 20090519. The gDNA will be added to the master mix. All wells will be tested.\nResults: Unfortunately, this does not look as tight as it should. The Cts range from 23.9 - 26.6 (Cts from Opticon 2 with default threshold settings). This is nearly a 3 cycle difference which represents a nearly 10-fold difference in “expression.”"
  },
  {
    "objectID": "posts/2009/2009-04-06-pcr-new-dungan-isolates/index.html",
    "href": "posts/2009/2009-04-06-pcr-new-dungan-isolates/index.html",
    "title": "PCR - New Dungan isolates",
    "section": "",
    "text": "Repeat of PCR from 20090403, but using AmpliTaq and 50C annealing temp. PCR set up is here.\n\nLane 1 - Hyperladder\nLane 2 - 19t\nLane 3 - 100bp ladder\nLane 4 - 13t\nLane 6 - 17t\nLane 8 - 1.5t\nLane 9 - Hyperladder\nLane 10 - 1.2t\nLane 12 - 11t\nLane 13 - 100bp ladder\nLane 14 - H5\nLane 16 - 12t\nLane 17 - 100bp Ladder\nLane 18 - H2O\nLane 19 - H2O\nLane 20 - Hyperladder\nResults: Nothing amplified! Possibly due to age of polymerase (?); over a year old. Will wait to repeat for new primers to arrive (EukA/B)."
  },
  {
    "objectID": "posts/2009/2009-04-16-pcr-two-new-dungan-isolates/index.html",
    "href": "posts/2009/2009-04-16-pcr-two-new-dungan-isolates/index.html",
    "title": "PCR - Two new Dungan isolates",
    "section": "",
    "text": "Repeat of yesterday’s PCR, but with AmpliTaq, less gDNA and 50uL rxn volume. PCR set up is here.\n\nGel loaded and run by Steven. Not entirely sure of the loading order. However, it doesn’t really matter…\nResults: Still absolutely nothing.\nUPDATE: Noticed on 20090713 that the reactions didn’t have dNTPs. Probably explains why it didn’t work!"
  },
  {
    "objectID": "posts/2009/2009-06-12-rna-isolation-marthas-vineyard-mv-hemocytes/index.html",
    "href": "posts/2009/2009-06-12-rna-isolation-marthas-vineyard-mv-hemocytes/index.html",
    "title": "RNA Isolation - Martha’s Vineyard (MV) hemocytes",
    "section": "",
    "text": "Samples were pelleted at 100g, 4C for 10mins. The supe was mostly removed, leaving ~50uL of supe above the pellets. RNA was isolated according to the TriReagent protocol from the following samples:\n3226:\n\nA7\nA10\nA15\nA17\nA20\nA22\nA26\n3326:\nB1\nB8\nB10\nB13\nB14\nB22\nB26\nB29\n\nRNAs were resuspended in 10uL of 0.1% DEPC-H2O. They will be DNase treated."
  },
  {
    "objectID": "posts/2009/2009-07-07-gdna-isolation-dungan-isolate-mie-14v/index.html",
    "href": "posts/2009/2009-07-07-gdna-isolation-dungan-isolate-mie-14v/index.html",
    "title": "gDNA Isolation - Dungan isolate MIE-14v",
    "section": "",
    "text": "Cells stored in EtOH were pelleted 5000g, 10mins, 25C. A brownish smear was present along the inside of the tube after spinning; not really a pellet per se. Supe was removed and cells were washed twice with 1X PBS. The smear was reduced to a pellet after the first wash in PBS. The second wash resulted in a slightly smaller pellet, but a pellet was present nonetheless before proceeding. Cells were subjected to an enzymatic lysis in 180uL of a TE/Triton X-100/lysozyme mixture as described in the Qiagen DNeasy Kit for Gram-Positive Bacteria (and for cells having substantial cell walls). Cells were incubated in this mixture for 30mins @ 37C. 25uL of proteinase K and 200uL of Buffer AL were then added and the mixture was incubated @ 70C for 30mins. Protocol then followed the “normal” steps for isolation of gDNA. Sample was eluted in 100uL of Buffer AE and then spec’d.\n\nResults: Well, it doesn’t look like there is any DNA at all… Will try precipitating the sample and bringing up the DNA (if there’s any) in a small volume. It should be noted that I spec’d these samples using the “RNA” setting, so the constant for concentration calcs is wrong (40), but doing quick math using the DNA constant (50) shows that there’s still almost nothing there…"
  },
  {
    "objectID": "posts/2009/2009-09-29-ribosomal-depleted-rna-ricks-trout-rbc-samples-for-the-solid-wtk/index.html",
    "href": "posts/2009/2009-09-29-ribosomal-depleted-rna-ricks-trout-rbc-samples-for-the-solid-wtk/index.html",
    "title": "Ribosomal-depleted RNA - Rick’s trout RBC samples for the SOLiD WTK",
    "section": "",
    "text": "Prior to starting the procedure, 0.5uL of total RNA was removed from each sample (control, polyI:C), diluted to ~5ng/uL. 1.5uL of each of these was transferred to a 0.5mL snap cap tube for running on the PicoChip on the Bioanalyzer. These were stored @ -80C in the “Bioanalyzer Samples” box.\nThe remaining total RNA from Rick’s trout RBC (~15uL of the “control” and 20uL of the “polyI:C”) was treated with Invitrogen’s RiboMinus Kit, according to protocol. Samples were then processed following Invitrogen’s Modified RiboMinus Concentration Module, but samples were eluted with 20uL of H2O, instead of 30uL. Samples were spec’d.\nResults:\n\nThe “poly I:C” sample looks good and gave a return of ~800ng, which is ~1% of the total starting RNA (20uL x 0.42ug/uL = 8.4ug). The “control” sample, however, is well short of the expected 1% yield. Recovery was ~220ng, which is only ~0.25% of the total starting RNA (15uL x 0.571ug/uL = 8.565ug). Will proceed to EtOH precipitate the samples in preparation for fragmentation.\nTransferred 0.75uL of the “control” sample to a 0.5mL snap cap tube containing 0.75uL of H2O. Transferred 0.25uL of the “poly I:C” sample to a 0.5mL snap cap tube containing 1.25uL of H2O. Samples were stored @ -80C in the “Bioanalyzer Samples” box."
  },
  {
    "objectID": "posts/2009/2009-10-10-qpcr-tims-adults-gigas-challenge-re-dnased-rna-from-today/index.html",
    "href": "posts/2009/2009-10-10-qpcr-tims-adults-gigas-challenge-re-dnased-rna-from-today/index.html",
    "title": "qPCR - Tim’s adults gigas challenge re-DNased RNA (from today)",
    "section": "",
    "text": "Performed qPCR using q18s primers on re-DNased RNA (1:100 dilution to match final concentration of template after making cDNA). qPCR set up and plate layout are here.\ngDNA dilutions were used as positive controls. gDNA = BB11 (0.49ug/uL) from 20090519. Used 5uL of 1:10, 1:100 and 1:000 dilutions.\nResults: re-DNase-ing the samples seems to have worked. Positive controls are the only samples to come up. Will proceed to making cDNA."
  },
  {
    "objectID": "posts/2009/2009-02-07-mrna-submission-for-agilent-bioanalyzer/index.html",
    "href": "posts/2009/2009-02-07-mrna-submission-for-agilent-bioanalyzer/index.html",
    "title": "mRNA - Submission for Agilent Bioanalyzer",
    "section": "",
    "text": "Submitted 4uL (108ng/uL) of mRNA from gigas gill (from DATE!; sometime in late August) to the Center for Array Technologies (CART) at UW. Sample was labelled “SR01”.\nResults:\n\nResults were received on 20090210. Comment from CAT staff member was that it looked “pretty good.” Here are links to [the gel (look for SR01)(https://eagle.fish.washington.edu/Arabidopsis/RNA%20Spec%20Readings/2100%20expert_EukaryoteTotal%20RNA%20Nano_DE11400776_2009-02-09_12-37-49_GEL.bmp), the electoropherogram of SR01, and the EGRAM of the ladder."
  },
  {
    "objectID": "posts/2009/2009-12-29-alaska-sockeye-salmon-sampling-with-seebs-family-13/index.html",
    "href": "posts/2009/2009-12-29-alaska-sockeye-salmon-sampling-with-seebs-family-13/index.html",
    "title": "Alaska sockeye salmon sampling (with Seebs): Family #13",
    "section": "",
    "text": "Juvenile sockeye salmon were subjected to initial heat stress of 18C. 10 fish were weighed, measured and then snap frozen in LN2. Samples were transferred to a freezer box labelled “AL Sockey Family #13” and stored @ -80C. Here is the spreadsheet with all the pertinent info."
  },
  {
    "objectID": "posts/2009/2009-03-24-qpcr-virginica-cdna-see-workup-sheet-below-for-more-info-regarding-cdna/index.html",
    "href": "posts/2009/2009-03-24-qpcr-virginica-cdna-see-workup-sheet-below-for-more-info-regarding-cdna/index.html",
    "title": "qPCR - Virginica cDNA (see workup sheet below for more info regarding cDNA)",
    "section": "",
    "text": "Set up qPCR using the following Virginica primers provided by Mac:\nCv_BgBL\nCv_BGBP\nCv_CysB\nCv_HMG\nCv_HSP70\nHere is the qPCR workup sheet ."
  },
  {
    "objectID": "posts/2009/2009-08-25-dna-precipitation-c-pugetti-dna-for-jgi-submission/index.html",
    "href": "posts/2009/2009-08-25-dna-precipitation-c-pugetti-dna-for-jgi-submission/index.html",
    "title": "DNA Precipitation - C.pugetti DNA for JGI submission",
    "section": "",
    "text": "Precipitate DNA from 20090526 to concentrate and run on gel for resubmission to JGI to see what happens. Added 0.1 volume of 3M sodium acetate, pH = 5.2 (40uL) and 2 volumes of 100% EtOH (880uL). Mixed throughly and incubated O/N @ -20C."
  },
  {
    "objectID": "posts/2009/2009-06-23-etoh-precipitation-dnased-abalone-dg-rna-from-yesterday-and-the-0712-set-dnased-by-lisa-20090306/index.html",
    "href": "posts/2009/2009-06-23-etoh-precipitation-dnased-abalone-dg-rna-from-yesterday-and-the-0712-set-dnased-by-lisa-20090306/index.html",
    "title": "EtOH Precipitation - DNased Abalone Dg RNA from yesterday AND the 07:12 set (DNased by Lisa 20090306)",
    "section": "",
    "text": "Due to the excessive number of times that these samples have been DNased, I’m concerned that the buffer is becoming too concentrated. So, I’m performing an EtOH precip on them to clean them up and then proceed with another round of DNase treatment.\n0.1 volumes of 3M sodium acetate (pH = 5.2) were added to each sample. Then, 2 volumes of 100%, ice-cold EtOH were added. Samples were mixed and stored @ -20C for 2hrs. Samples were then centrifuged @ 4C, 16,000g for 30mins. Supe removed. Added 1mL of 70% EtOH and then centrifuged samples @ 4C, 16,000g for 15mins. Supe was removed, tubes were spun briefly to pool residual EtOH and the remaining EtOH was removed. RNA was resuspended in 20uL of 0.1% DEPC-H2O and spec’d.\n\nResults: The following samples appear to have no RNA after precipitation:\n06:5-34, 37; 06:6-44, 45, 46, 47, 52; 08:4-9, 10, 13, 15-18; All of the 07:12 samples.\nSince I did not DNase the 07:12 samples, I can’t say whether or not this result was expected (e.g. due to low initial concentration). The others that have no remaining RNA are a surprise and is a bit disconcerting.\nWill take fresh RNA aliquots of those samples for DNasing. For those samples still having RNA post-recip, I will just use them as they are, as most concentrations are in the recommended range for DNasing, according to the Ambion Tubro DNA-free kit."
  },
  {
    "objectID": "posts/2009/2009-10-09-qpcr-tims-adults-gigas-challenge-dnased-rna-from-today/index.html",
    "href": "posts/2009/2009-10-09-qpcr-tims-adults-gigas-challenge-dnased-rna-from-today/index.html",
    "title": "qPCR - Tim’s adults gigas challenge DNased RNA (from today)",
    "section": "",
    "text": "Performed qPCR using q18s primers on DNased RNA (1:100 dilution to match final concentration of template after making cDNA). qPCR set up and plate layout are here.\ngDNA dilutions were used as positive controls. gDNA = BB11 (0.49ug/uL) from 20090519. Used 5uL of 1:10, 1:100 and 1:000 dilutions.\nResults: All samples, including positive controls, came up negative! Realized that I accidentally used the EF1 primers which will NOT amplify gDNA. And, to top it off, this was BEFORE going to seminar (i.e. before having any beers)."
  },
  {
    "objectID": "posts/2009/2009-10-03-dnase-treatment-tims-adult-gigas-challenge-rna-from-20090930-2/index.html",
    "href": "posts/2009/2009-10-03-dnase-treatment-tims-adult-gigas-challenge-rna-from-20090930-2/index.html",
    "title": "DNase Treatment - Tim’s adult gigas challenge RNA (from 20090930)",
    "section": "",
    "text": "Used 5uL of RNA from each sample, brought samples up to 50uL with H2O and treated according to Ambion’s Turbo DNA-free kit. Transferred treated samples to a PCR plate to facilitate further manipulation of the samples. Will perform qPCR on these samples to make sure treatment worked."
  },
  {
    "objectID": "posts/2009/2009-05-27-gdna-isolation-c-pugetti-from-20090518/index.html",
    "href": "posts/2009/2009-05-27-gdna-isolation-c-pugetti-from-20090518/index.html",
    "title": "gDNA Isolation - C. pugetti (from 20090518)",
    "section": "",
    "text": "Followed JGI “Bacterial genomic DNA isolation using CTAB” protocol(Word doc) with the following notes/changes.\nTwo, 1L cultures were transferred to 4 total jars (~500mL in each jar) for centrifugation. Jars had been briefly washed with 95% EtOH prior to use.\nCells were pelleted in Sorval T21 using a bucket rotor for 30mins., 4200RPM, 25C.\nSupe was removed and all four pellets were resuspended with a total of 10mL of TE.\nOD600 = ~2.1, so added an additional 10mL of TE.\nOD600 = ~1.2, so proceeded with procedure.\nDue to volume of the prep, the sample was split into two, 50mL centrifuge tubes (washed with 95% EtOH prior to use) prior to the addition of 5M NaCl.\nDisaster strikes! Turns out the tubes being used were not resistant to chloroform. This was realized after spinning at 18,000RPM, 25C 10mins in a Sorval SL-50T rotor in the Sorval T21 centrifuge.\nHowever…\nI recovered the aqueous phase anyway, as it was still contained in the tube and had no contact with the rotor surface(s). Due to a subsequent phenol:chloroform:IAA step, I split the aqueous phase into 24 x 1.5mL snap cap tubes and proceeded according to protocol. The final DNA pellet, prior to resuspension were combined from all the tubes into a single 1.5mL snap cap tube in a final volume of 400uL of TE.\n\nResults: DNA from today looks good with excellent yield. DNA from 20090513 doesn’t look as nice AND the concentration doesn’t jive with the QC gel that was run on 20090513. Will run out on gel according to JGI protocol to evaluate quality further."
  },
  {
    "objectID": "posts/2009/2009-05-07-rna-isolation-macs-oyster-tissues-bb-and-dh-continued-from-yesterday/index.html",
    "href": "posts/2009/2009-05-07-rna-isolation-macs-oyster-tissues-bb-and-dh-continued-from-yesterday/index.html",
    "title": "RNA Isolation - Mac’s oyster tissues (BB and DH) (CONTINUED from yesterday)",
    "section": "",
    "text": "Samples were precipitated according to TriReaget protocol. RNA was resuspended in 50uL of 0.1% DEPC-H2O and then heated @ 55C for 10mins to help dissolve the pellets. Samples will be DNase treated."
  },
  {
    "objectID": "posts/2009/2009-06-15-reverse-transcription-mv-hemocyte-dnased-rna-from-20090612/index.html",
    "href": "posts/2009/2009-06-15-reverse-transcription-mv-hemocyte-dnased-rna-from-20090612/index.html",
    "title": "Reverse Transcription - MV hemocyte DNased RNA from 20090612",
    "section": "",
    "text": "Made cDNA using Promega M-MLV RT and oligo dT primers. RT rxn set up is here. Samples were stored @ 4C until ready to use."
  },
  {
    "objectID": "posts/2009/2009-11-25-mbl-shipment-hard-clams/index.html",
    "href": "posts/2009/2009-11-25-mbl-shipment-hard-clams/index.html",
    "title": "MBL Shipment - Hard Clams",
    "section": "",
    "text": "Received hard clams from Scott Lindell today. Two bags. One group (4 live clams, 1 empty shell) labelled as “FL” and another group (9 live clams) labelled as “BX.” Clams were transferred to separate plastic shoebox containers with sea water and sand. They were stored at 15C until ready for experiment."
  },
  {
    "objectID": "posts/2009/2009-07-17-qpcr-abalone-gdna-h-crach-067-1/index.html",
    "href": "posts/2009/2009-07-17-qpcr-abalone-gdna-h-crach-067-1/index.html",
    "title": "qPCR - Abalone gDNA (H.crach 06:7-1)",
    "section": "",
    "text": "This is to test (again!) the H.crach_h-1fg_intron primers and obtain a working positive control. This gDNA is from Lisa/Nate. Acquired from them 20090717. Don’t know date/method of isolation, but this should be good, recent gDNA. qPCR plate layout/set up is here. Anneal temp 50C. Ran serial dilutions of the gDNA: undiluted, 1:10 and 1:100.\nResults: Signals look good. The undiluted comes up around 30 cycles. Should be able to use it as a positive control for gDNA detection PCRs."
  },
  {
    "objectID": "posts/2009/2009-06-11-dnase-treatment-abalone-dg-dnased-rna-from-20090605/index.html",
    "href": "posts/2009/2009-06-11-dnase-treatment-abalone-dg-dnased-rna-from-20090605/index.html",
    "title": "DNase Treatment - Abalone Dg DNased RNA from 20090605",
    "section": "",
    "text": "This is the 3rd time this will be performed on these samples. Hopefully using a different (i.e. new) kit will work. Not sure what’s going on here. Performed according to protocol."
  },
  {
    "objectID": "posts/2009/2009-01-17-rna-isolation-hard-clam-gill-hemos/index.html",
    "href": "posts/2009/2009-01-17-rna-isolation-hard-clam-gill-hemos/index.html",
    "title": "RNA Isolation - Hard clam gill, hemos",
    "section": "",
    "text": "RNA was isolated from hard clam gill (0.08g; from 20090109) and from hard clam hemos (from 20090114). One “unknown” sample (from 20090114) was also processed. Pellets were resuspended in 50uL of 0.1%DEPC-H2O. Hemo samples were pooled. Samples were spec’d.\n\nResults: 260/280 looks OK for hemos. The gill sample has excellent 260/280 and pretty good 260/230. Samples will be reprecipitated over the weekend @ -20C according to Ambion PolyA Purist protocol in preparation for mRNA isolation."
  },
  {
    "objectID": "posts/2009/2009-12-03-rna-precipitation-herring-liver-rna-for-solid-libraries-continued-from-yesterday/index.html",
    "href": "posts/2009/2009-12-03-rna-precipitation-herring-liver-rna-for-solid-libraries-continued-from-yesterday/index.html",
    "title": "RNA Precipitation - Herring Liver RNA for SOLiD Libraries (continued from yesterday)",
    "section": "",
    "text": "RNA Precipitation\nSamples were pelleted for 30mins, 16,000g @ 4C. Supe was discarded, samples quick spun, residual supe removed and then washed with 1mL 70% EtOH. Tubes were vortexed until pellet came off of bottom of tube and then spun 15mins, 16,000g @ 4C. Supe was discarded, samples quick spun, residual supe removed and then resuspended in 250uL of 0.1% DEPC-H2O in preparation for mRNA isolation using the Ambion Micro PolyA Purist Kit.\n\n\nmRNA Isolation\nClean RNA from earlier today was processed according to the Ambion Micro PolyA Purist Kit to isolate mRNA. This procedure was done two times to ensure full mRNA enrichment of the samples. Samples were then spec’d.\nResults:\n\nYields:\n3L - 10.66 ng/uL x 200uL = 2.132ug\n6L - 6.97 ng/uL x 200uL = 1.394ug\n2L - 10.89 ng/uL x 200uL = 2.178ug\n4L - 6.43 ng/uL x 200uL = 1.286ug\n\n\nmRNA Precipitation\nPrecipitation of mRNA from earlier today in preparation for fragmentation. Fragmentation requires mRNA volumes of <8uL, so after precipitation I will resuspend pellets in 8uL of 0.1% DEPC-H2O. Will use 1ug (this means 1/2 of 3L and 2L & all of 6L and 4L) of mRNA from each sample for precipitation. Remainder of 3L and 2L samples were stored @ -80C in “Herring RNA Box #1.”Samples were precipitated by adding 0.1 volumes 5M ammonium acetate, 1uL glycogen and 2 volumes of 100% EtOH. Samples were incubated O/N @ -20C."
  },
  {
    "objectID": "posts/2009/2009-04-22-reverse-transcription-cdna-from-dnased-abalone-rna-from-20090420/index.html",
    "href": "posts/2009/2009-04-22-reverse-transcription-cdna-from-dnased-abalone-rna-from-20090420/index.html",
    "title": "Reverse Transcription - cDNA from DNased Abalone RNA from 20090420",
    "section": "",
    "text": "[Prepared cDNA using an equal amount of RNA from all samples (442.6ng)(https://spreadsheets.google.com/ccc?key=0AmS_90rPaQMzcHdyU1d0MDVMLWphMFdTOHUwVHFqWnc&hl=en). This amount was based on using the maximum allowable volume of RNA for the RT rxn AND the sample with the lowest [RNA] (08:3-20; 24.59ng/uL). cDNA was prepared according to the Promega MMLV RT recommendations. Here is the work up for the cDNA rxns. cDNA was stored @ -20C."
  },
  {
    "objectID": "posts/2009/2009-12-29-qpcr-bb-dh-cdna-from-20091223-2/index.html",
    "href": "posts/2009/2009-12-29-qpcr-bb-dh-cdna-from-20091223-2/index.html",
    "title": "qPCR - BB & DH cDNA (from 20091223)",
    "section": "",
    "text": "qPCR was set up on these cDNAs using the following primers:\nFP010108.p.cg.6 (“DJB12”, “DnaJ homolog subfamily B member 12”) - This was upregulated in DH SOLiD data.\nAJ565670.p.cg.6 (“TOP1”, “DNA topoisomerase 1”) - This was upregulated in BB SOLiD data.\nqPCR set up and plate layout can be found here.\nResults:\nqPCR Data File (Opticon): 20091229_164912.tad\nData workup: PROPS BB_DH Gene Expression Miner Workup"
  },
  {
    "objectID": "posts/2009/2009-08-27-primers-lake-trout-primers-for-hrm/index.html",
    "href": "posts/2009/2009-08-27-primers-lake-trout-primers-for-hrm/index.html",
    "title": "Primers - Lake Trout Primers for HRM",
    "section": "",
    "text": "The two primer plates (LTP01F, LTP01R) were received today. Primers (supplied as 10 nmoles of each) will be reconstituted with 100uL of PCR H2O to make a Cf of 100uM. Forward and reverse primers will be combined in a new plate, in equal volumes, to give a Cf of 50uM. These combined primers will be used to test them on pooled lake trout DNA to identify functional primer pairs for use in HRM."
  },
  {
    "objectID": "posts/2009/2009-11-20-mbl-shipment-mv-oysterscod/index.html",
    "href": "posts/2009/2009-11-20-mbl-shipment-mv-oysterscod/index.html",
    "title": "MBL Shipment - MV oysters/cod",
    "section": "",
    "text": "Received a shipment of various MV oysters/cod samples from Scott Lindell at MBL. However, these were NOT shipped on dry ice! Samples were put @ -80C. Will be organized at a later date."
  },
  {
    "objectID": "posts/2009/2009-04-19-bacteria-c-pugettii-culture/index.html",
    "href": "posts/2009/2009-04-19-bacteria-c-pugettii-culture/index.html",
    "title": "Bacteria - C. pugettii culture",
    "section": "",
    "text": "Rehydrated ATCC isolate according to directions. Added 5mL of 1x Marine Broth to a glass culture tube. Used 1mL of this to rehydrate ATCC sample and then added back into the culture tube. Added a few crystals of biphenyl, which had been exposed to UV for ~5mins prior. Incubated at 20C, no shaking. This was done at ~11:30AM."
  },
  {
    "objectID": "posts/2009/2009-12-10-emulsion-pcr-herring-liver-cdna-for-solid-libraries/index.html",
    "href": "posts/2009/2009-12-10-emulsion-pcr-herring-liver-cdna-for-solid-libraries/index.html",
    "title": "Emulsion PCR - Herring Liver cDNA for SOLiD Libraries",
    "section": "",
    "text": "Emulsion PCR was performed with the two inner gel bands cut out earlier today according to the Ambio WTK protocol. PCR was run for 15 cycles. After the PCR, the samples were cleaned up using the Invitrogen PureLink PCR Micro Kit, according to the Ambion WTK protocol. The cleaned up cDNA (referred to as “libraries” from now on) was spec’d prior to running on the Bioanalyzer.\nResults:\n\nAll samples look good EXCEPT for 4L. It has a terrible 260/230 ratio and has a very low concentration, relative to the other three samples. Although not pictured here, the absorbance curve of the 4L sample was extremely poor and broad, unlike the other three samples."
  },
  {
    "objectID": "posts/2009/2009-07-17-qpcr-abalone-cdna-0712-set-from-332009-by-lisa-and-dnased-rna-from-20090623-2/index.html",
    "href": "posts/2009/2009-07-17-qpcr-abalone-cdna-0712-set-from-332009-by-lisa-and-dnased-rna-from-20090623-2/index.html",
    "title": "qPCR - Abalone cDNA (07:12 set from 3/3/2009 by Lisa) and DNased RNA (from 20090623)",
    "section": "",
    "text": "This is being done to check whether or not there is gDNA contamination in these cDNA and DNased RNA. Will use H.crach_h-1fg_intron primers. gDNA 07:12-15 was used as a positive control, based on results from yesterday’s qPCR. qPCR plate layout/set up is here. Anneal temp 50C.\nResults: Everything came up negative, including the positive control! Also, the machine experienced an error at ~cycle 39, so no melting curve info. See below."
  },
  {
    "objectID": "posts/2009/2009-12-17-pcr-sepia-cdna-2/index.html",
    "href": "posts/2009/2009-12-17-pcr-sepia-cdna-2/index.html",
    "title": "PCR - Sepia cDNA",
    "section": "",
    "text": "This is an exact repeat of the PCR from yesterday, due to inconsistencies between repeated PCRs from yesterday and earlier today. Here’s yesterday’s workup. Samples were stored @ 4C O/N after completion of PCR. Gell was run on 20091217.\nResults: This is getting embarrassing. Opsin results are same as yesterday (good!), but Rhodopsin results are slightly different than yesterday’s AND the day before yesterday’s results!\n\nGel Loading (from left to right):\nOpsin Primers (lanes 2-10), Rhodopsin Primers (same loading order, lanes 12-20)\n1 - 100bp ladder\n2 - retina\n3 - fin\n4 - 4th arm\n5 - dorsal mantle center\n6 - dorsal mantle side\n7 - ventral mantle center\n8 - ventral mantle side\n9 - H2O\n10 - H2O\nOpsin Primers\nWe see a band in the retina, fin, 4th arm, & ventral mantle center samples as we did yesterday. This replicates yesterday’s PCR results, which is good. Negative controls are clean. Bands will be excised and stored @-20C in Sam’s “Purified Inserts” box for eventual sequencing. NOTE: This gel was run on 20091217 and the tubes are dated as such!\nRhodopsin Primers\nA single band is present in the retina, dorsal mantle center and ventral mantle center samples. We see TWO bands in the fin sample. These results differ from yesterday’s in that yesterday, a single band was present ONLY in the retina and fin samples. Two days ago there was a single band in each of the retina and fin samples and two bands in the ventral mantle center sample. Bands will be excised and stored @-20C in Sam’s “Purified Inserts” box for eventual sequencing. NOTE: This gel was run on 20091217 and the tubes are dated as such!\nI am going to repeat these PCRs again. I can’t stand the fact that I am getting such freaking inconsistent results in an extremely simple PCR. Aaargh!"
  },
  {
    "objectID": "posts/2009/2009-06-03-rna-isolation-abalone-dg-project/index.html",
    "href": "posts/2009/2009-06-03-rna-isolation-abalone-dg-project/index.html",
    "title": "RNA Isolation - Abalone Dg Project",
    "section": "",
    "text": "Isolated RNA using the MoBio RNA PowerSoil Kit according to protocol from the following samples:\n06:6-45\n06:6-49\n06:6-50\n06:6-51\n06:6-52\n08:4-6\n08:4-9\n08:4-10\n\nResults: RNA looks fabulous (as always from the PowerSoil kit). Will DNase treat the samples tomorrow."
  },
  {
    "objectID": "posts/2009/2009-09-10-hrm-lake-trout-snps-hrm_white-02/index.html",
    "href": "posts/2009/2009-09-10-hrm-lake-trout-snps-hrm_white-02/index.html",
    "title": "HRM - Lake Trout SNPs (HRM_white-02)",
    "section": "",
    "text": "HRM_white-02\nThe following primers from primer plate LTP01 will be used for analysis of Rick’s Lake Trout DNA plate (from 4/28/2009): A3, D3, G3, A4. HRM set up is here. It is the same as that used on 20090903. A 1:10 dilution plate (from 20090903) of Rick’s Lake Trout DNA1 plate (from 4/28/2009) was used. This means approximately 20ng of DNA used in each rxn. The robot was used to add 1uL of DNA from the 96-well plate to the appropriate wells of the 384-well HRM rxn plate. Plate was spun to collect the DNA at the bottom of the wells. The wells were visually inspected to ensure that each received the DNA. 1uL of DNA was manually added to those wells that did not receive sample.\nThe master mix for each primer set was then manually dispensed to the appropriate wells in the 384-well HRM rxn plate using a “matrix” auto-pipette. The real-time PCR was run in a Roche LightCycler480 machine with the following cycling paramters:\n95C - 15mins\n45 cycles of:\n95C - 10s\n60C - 15s\n72C - 25s\nAfter the completion of the real-time run, the plate was put through the High Melt Curve protocol.\nResults:"
  },
  {
    "objectID": "posts/2009/2009-09-16-hrms-lake-trout-snps-hrm_white-05-hrm_white_06/index.html",
    "href": "posts/2009/2009-09-16-hrms-lake-trout-snps-hrm_white-05-hrm_white_06/index.html",
    "title": "HRMs - Lake Trout SNPs (HRM_white-05 & HRM_white_06)",
    "section": "",
    "text": "HRM_white-05\nThe following primers from primer plate LTP01 will be used for analysis of Rick’s Lake Trout DNA1 plate (from 4/28/2009): G10, C11, H11, A12. HRM set up is here. It is the same as that used on 20090903. A 1:10 dilution plate (from 20090903) of Rick’s Lake Trout DNA1 plate (from 4/28/2009) was used. This means approximately 20ng of DNA used in each rxn. The robot was used to add 1uL of DNA from the 96-well plate to the appropriate wells of the 384-well HRM rxn plate. Plate was spun to collect the DNA at the bottom of the wells. The wells were visually inspected to ensure that each received the DNA. 1uL of DNA was manually added to those wells that did not receive sample.\nThe master mix for each primer set was then manually dispensed to the appropriate wells in the 384-well HRM rxn plate using a “matrix” auto-pipette. The real-time PCR was run in a Roche LightCycler480 machine with the following cycling parameters:\n95C - 15mins\n45 cycles of:\n95C - 10s\n60C - 15s\n72C - 25s\nAfter the completion of the real-time run, the plate was put through the High Melt Curve protocol.\n\n\nHRM_white-06\nThe following primers from primer plate LTP01 will be used for analysis of Rick’s Lake Trout DNA1 plate (from 4/28/2009): E12. HRM set up is here. It is the same as that used on 20090903. A 1:10 dilution plate (from 20090903) of Rick’s Lake Trout DNA1 plate (from 4/28/2009) was used. This means approximately 20ng of DNA used in each rxn. The robot was used to add 1uL of DNA from the 96-well plate to the appropriate wells of the 384-well HRM rxn plate. Plate was spun to collect the DNA at the bottom of the wells. The wells were visually inspected to ensure that each received the DNA. 1uL of DNA was manually added to those wells that did not receive sample.\nThe master mix for each primer set was then manually dispensed to the appropriate wells in the 384-well HRM rxn plate using a “matrix” auto-pipette. The real-time PCR was run in a Roche LightCycler480 machine with the following cycling paramters:\n95C - 15mins\n45 cycles of:\n95C - 10s\n60C - 15s\n72C - 25s\nAfter the completion of the real-time run, the plate was put through the High Melt Curve protocol."
  },
  {
    "objectID": "posts/2009/2009-04-08-qpcr-abalone-cdna-qt-from-earlier-today/index.html",
    "href": "posts/2009/2009-04-08-qpcr-abalone-cdna-qt-from-earlier-today/index.html",
    "title": "qPCR - Abalone cDNA (QT) from earlier today",
    "section": "",
    "text": "qPCR was performed with 16s_sybr primers on a subset of the cDNA rxns and all of the “No RT” rxns from earlier to detect the presence of contaminating gDNA. qPCR was also performed with the Rab7_sybr primers on a subset of the cDNA rxns to check that the assay would work. The qPCR set up sheet/plate layout is here. Annealing temp = 55C.\nResults: Apparently the gDNA wipeout step did NOT work! Also, some signal in the water samples."
  },
  {
    "objectID": "posts/2009/2009-04-29-bacteria-c-pugetti-plate-from-20090424-2/index.html",
    "href": "posts/2009/2009-04-29-bacteria-c-pugetti-plate-from-20090424-2/index.html",
    "title": "Bacteria - C. pugetti plate (from 20090424)",
    "section": "",
    "text": "There appears to be growth on the plate. There is a large, bright yellow/chartreuse region on the plate where the streaking was initiated. Additionally, upon close inspection, it appears as though colonies can be seen."
  },
  {
    "objectID": "posts/2009/2009-08-26-qpcr-recalibration-of-opticon-2/index.html",
    "href": "posts/2009/2009-08-26-qpcr-recalibration-of-opticon-2/index.html",
    "title": "qPCR - Recalibration of Opticon 2",
    "section": "",
    "text": "According to the Bio-Rad rep that analyzed the calibration test on 20090824, recalibration might be a good idea. As such, we’ll do that. Old calibration file was found and backed up prior to proceeding, as generation of a new calibration file would replace the old one.\nResults: The Bio-Rad rep (Carl Fisher) has responded and said that the range of fluorescence is within the expected 2-fold difference and looks fine! Finally!"
  },
  {
    "objectID": "posts/2009/2009-11-14-hard-clams-shipment-from-rutgers/index.html",
    "href": "posts/2009/2009-11-14-hard-clams-shipment-from-rutgers/index.html",
    "title": "Hard Clams - Shipment from Rutgers",
    "section": "",
    "text": "Received Hard Clam gill samples on “wet ice” in RNA Later from Rutgers. Samples were collected on 11/4/09 (clams held in refrigerator) and preserved (gill tissue collected) on 11/9/09 according to the paper included with the samples. Samples will be stored @ -80C until we are ready to process."
  },
  {
    "objectID": "posts/2009/2009-02-21-epigenetics-experiment-gigas-treatment/index.html",
    "href": "posts/2009/2009-02-21-epigenetics-experiment-gigas-treatment/index.html",
    "title": "Epigenetics Experiment - Gigas treatment",
    "section": "",
    "text": "Set up two containers with 3L seawater and 4 gigas in each container. The treated sample contained:\n5mL of 5N NaOH\n5mL of Bl\n10mL of 1x LB\n10mL of 95% EtOH\n1mL of formamide\nBoth containers were covered, stored in the fume hood and incubated over the weekend. Experiment was started at 3:15PM."
  },
  {
    "objectID": "posts/2009/2009-03-31-rna-isolation-abalone-digestive-gland-samples-2/index.html",
    "href": "posts/2009/2009-03-31-rna-isolation-abalone-digestive-gland-samples-2/index.html",
    "title": "RNA Isolation - Abalone digestive gland samples",
    "section": "",
    "text": "Total RNA was isolated from the following abalone digestive gland samples using the RNA Powersoil Kit, according to their protocol:\n08:3-6\n08:3-7\n08:3-8\n08:3-9\n08:3-14\n08:3-15\n08:3-16\n08:3-24\n\nResults: RNA looks great. Stored @ -80C in box where samples came from."
  },
  {
    "objectID": "posts/2009/2009-10-02-qpcrs-check-gdna-contamination-with-ef1-18s-primers-in-gigas-gill-rna-from-yesterday/index.html",
    "href": "posts/2009/2009-10-02-qpcrs-check-gdna-contamination-with-ef1-18s-primers-in-gigas-gill-rna-from-yesterday/index.html",
    "title": "qPCRs - Check gDNA contamination with EF1 & 18s primers in gigas gill RNA (from yesterday)",
    "section": "",
    "text": "Ran qPCR on RNA to evaluate gDNA contamination in the samples. Dilutions of the RNA were made at 1:100, which would be the equivalent amount when making cDNA (1:25) and diluting the cDNA (1:4) prior to using in a qPCR rxn. qPCR set up is here with cycling params. Plate layout is here.\ngDNA dilutions were used as positive controls. gDNA = BB11 (0.49ug/uL) from 20090519.\nResults: Hello! I’m an idiot. Nothing amplified because the EF1 primers are designed to cross an intron/exon boundary, thus they can’t amplify gDNA. Need to use the 18s primers instead.\nThis is an exact duplicate of the earlier qPCR from today, but using the correct (18s) primers! Ran qPCR on RNA to evaluate gDNA contamination in the samples. Dilutions of the RNA were made at 1:100, which would be the equivalent amount when making cDNA (1:25) and diluting the cDNA (1:4) prior to using in a qPCR rxn. qPCR set up is here with cycling params except q18s primers are substituted instead of qEF1. Plate layout is here.\ngDNA dilutions were used as positive controls. gDNA = BB11 (0.49ug/uL) from 20090519.\nResults: All samples show gDNA contamination. Will DNase them"
  },
  {
    "objectID": "posts/2009/2009-04-02-rna-isolation-abalone-digestive-gland-samples/index.html",
    "href": "posts/2009/2009-04-02-rna-isolation-abalone-digestive-gland-samples/index.html",
    "title": "RNA Isolation - Abalone digestive gland samples",
    "section": "",
    "text": "Total RNA was isolated from the following abalone digestive gland samples using the RNA Powersoil Kit, according to their protocol:\n08:3-17\n08:3-18\n08:4-2\n08:4-3\n08:4-4\n08:4-5\n08:4-7\n08:4-8\n08:4-11\nNotes: 08:4-5 took hours to wash the column. 08:4-4 ended up with a dark RNA pellet and the reuspended RNA is discolored (brown-ish).\n\n\nResults: All the RNA looks good except for 08:4-4, but that isn’t surprising (see note above). Samples were stored @ -80C in the boxes from which the tissue samples came."
  },
  {
    "objectID": "posts/2009/2009-09-24-rna-fragmentation-ricks-trout-rbc-samples-prepped-earlier-today-see-below/index.html",
    "href": "posts/2009/2009-09-24-rna-fragmentation-ricks-trout-rbc-samples-prepped-earlier-today-see-below/index.html",
    "title": "RNA Fragmentation - Rick’s trout RBC samples prepped earlier today (see below)",
    "section": "",
    "text": "Samples were fragmented according to the Whole Transcriptome Kit protocol. Samples were then cleaned up using Invitrogen’s Modified RiboMinus Concentration Module, according to protocol. Briefly:\n\nAdded 1X volume of binding buffer (100uL)\nAdded equal volume of 100% EtOH so that [EtOH] = 50% (200uL)\n\nFollowed remainder of protocol and eluted with 20uL of H2O. Samples were spec’d.\nResults:\n\nAssuming the NanoDrop readings are accurate (according to the Whole Transcriptome Kit, these may NOT be accurate), got yields of ~93ng for the RBC Control sample and ~132ng for the RBC poly1:C sample. Transferred 1.5uL of each sample to separate 0.5mL tubes for submission to the Bioanalyzer. These were stored @ -80C in the “Bioanalyzer Samples” box. The remainder of the samples were stored @ -80C in the “Samples from Other Researchers” box."
  },
  {
    "objectID": "posts/2009/2009-07-01-qpcr-mv-hemocyte-cdna-from-20090614-6/index.html",
    "href": "posts/2009/2009-07-01-qpcr-mv-hemocyte-cdna-from-20090614-6/index.html",
    "title": "qPCR - MV hemocyte cDNA from 20090614",
    "section": "",
    "text": "Set up qPCR with Cv_CatY_F/R primers. This is a second rep. Plate layout/PCR set up is here.\nResults: Waters are clean. To be analyzed later with other genes that Mac has run."
  },
  {
    "objectID": "posts/2009/2009-07-10-qpcr-dnased-abalone-dg-rna-from-20090625/index.html",
    "href": "posts/2009/2009-07-10-qpcr-dnased-abalone-dg-rna-from-20090625/index.html",
    "title": "qPCR - DNased Abalone Dg RNA from 20090625",
    "section": "",
    "text": "Ran qPCR on gDNA (06:50-10) to test new primers (H.iris_actin_intron_Fw/Rv) designed to bind only to a region in an intron of the H.iris actin gene. Hopefully there’s enough homology between H.iris (primer source) and H.cracherodii (template source) for this to work. PCR setup/plate layout is here. Anneal temp 50C.\nResults: No signal. :("
  },
  {
    "objectID": "posts/2009/2009-12-10-reverse-transcription-herring-liver-mrna-for-solid-libraries/index.html",
    "href": "posts/2009/2009-12-10-reverse-transcription-herring-liver-mrna-for-solid-libraries/index.html",
    "title": "Reverse Transcription - Herring Liver mRNA for SOLiD Libraries",
    "section": "",
    "text": "Ligation reactions from yesterday were subject to reverse transcription according to protocol. Master mix workup info is here. Samples were incubated @ 42C, 30mins and then cleaned up using the Qiagen MiniElute PCR Purification Kit, according to the Ambion WTK protocol.\nAfter RT rxn, samples were run on a Novex 6% TBE-Urea gel according to Ambion WTK protocol. Samples were loaded, left to right: 2L, 3L, 4L, 6L. Ladders are to the left of each sample. The break in the smear in the 6L sample is a tear in the gel.\n\nThe recommended range of cDNA (100-200bp) were excised from the gel and were cut into four pieces, according to the Ambion WTK protocol. The two outer gel slices from each sample will be stored @-20C. Then proceeded to the emulsion PCR. Here is an image of the gel after the cDNA was cut out:"
  },
  {
    "objectID": "posts/2009/2009-04-24-bacteria-c-pugetti-plate/index.html",
    "href": "posts/2009/2009-04-24-bacteria-c-pugetti-plate/index.html",
    "title": "Bacteria - C. pugetti plate",
    "section": "",
    "text": "Streaked C. pugetti onto marine broth plate + a few biphenyl crystals and incubated at RT over the weekend.\nResults: No growth as of Monday, 20090427."
  },
  {
    "objectID": "posts/2009/2009-03-03-qpcr-repeat-of-20090227-qpcr-with-clean-water/index.html",
    "href": "posts/2009/2009-03-03-qpcr-repeat-of-20090227-qpcr-with-clean-water/index.html",
    "title": "qPCR - Repeat of 20090227 qPCR with clean water",
    "section": "",
    "text": "This is an exact repeat of the qPCR from Friday, but using a fresh aliquot of water for preparation. The plate layout/qPCR workup is here.\nResults: Same as Friday. Fluorescence comes up way too fast and there is contamination present in in the water. Will repeat with a fresh preparation of the primer working stocks."
  },
  {
    "objectID": "posts/2009/2009-02-25-qpcr-v-tubiashii-control-vs-autoclaved-gigas-samples-see-below/index.html",
    "href": "posts/2009/2009-02-25-qpcr-v-tubiashii-control-vs-autoclaved-gigas-samples-see-below/index.html",
    "title": "qPCR - V.tubiashii Control vs. Autoclaved gigas samples (see below)",
    "section": "",
    "text": "qPCR was performed using SensiMix/SYBR “kit” with DNAsed RNA samples and cDNA made earlier today. The plate layout/qPCR workup is here.\nResults: Generally, the amplification looks a bit odd when viewing on a log scale. However, the linear scale curves look to be normal. There doesn’t appear to be any gDNA contamination in the RNA samples, BUT the Vtub_16sV2 primers used on the RNA samples also do not produce much of a signal in the cDNA either. The melting curves for the 16s and the Vtub_OmpW primer sets have multiple peaks. Will likely order new 16s primes, due to weak signal.\nWill redo qPCR on the DNAsed RNA to make sure that the lack of detectable signal is due to lack of gDNA and NOT because the 16s primers don’t work. Also will repeat in order to have a replicate of the other samples."
  },
  {
    "objectID": "posts/2009/2009-10-28-mrna-isolation-herring-gonadovary-rna-from-20091023/index.html",
    "href": "posts/2009/2009-10-28-mrna-isolation-herring-gonadovary-rna-from-20091023/index.html",
    "title": "mRNA Isolation - Herring gonad/ovary RNA (from 20091023)",
    "section": "",
    "text": "RNA Precipitation\nSample was spun 16,000g, 30mins, 4C. Supe removed. Pellet washed with 1mL 70% EtOH. Spun 16,000g, 10mins, 4C. Supe removed. Pellet resuspended in 250uL of nuclease free H2O. Will proceed with mRNA isolation.\n\n\nmRNA Isolation\nIsolated mRNA using Ambion’s MicroPolyA Purist Kit according to protocol. Performed two rounds of isolation to decrease residual rRNA carryover that we frequently see after a single round.\nResults:\n\nStarted with ~90ug of total RNA. Yield of mRNA = 3.26ug. That is a ~3.6% recovery of mRNA."
  },
  {
    "objectID": "posts/2009/2009-09-30-rna-fragmentation-ricks-trout-rbc-samples-prepped-earlier-today/index.html",
    "href": "posts/2009/2009-09-30-rna-fragmentation-ricks-trout-rbc-samples-prepped-earlier-today/index.html",
    "title": "RNA Fragmentation - Rick’s trout RBC samples prepped earlier today",
    "section": "",
    "text": "EtOH Precipitaiton - Rick’s trout Ribosomoal-depleted RNA for SOLiD WTK (continued from yesterday)\nContinued precipitation. Spun samples 30 mins, 16,000g, 4C. Removed supe. Added 1mL 70% EtOH. Spun samples 15mins, 16,000g, 4C. Removed supe. Resuspended in 8uL H2O. Proceeded with SOLiD WTK fragmentation.\n\n\nRNA Fragmentation\nSamples were fragmented according to the Whole Transcriptome Kit protocol. Samples were then cleaned up using Invitrogen’s RiboMinus Concentration Module, according to SOLiD WTK protocol. Briefly:\n\nAdded 1X volume of binding buffer (100uL)\nAdded 100% EtOH (250uL)\nEluted with 20uL of H2O.\n\nSamples were spec’d.\nResults:\n\nControl Sample - Virtually nothing there. Hopefully it’s just too dilute for the NanoDrop, however I have a feeling this sample is bad (degraded?) 1.5uL of the sample has been transferred to a 0.5mL snap cap tube to send off for the Bioanalyzer.\nPoly I:C Sample - Looks great, excellent recovery. 0.25uL of this sample was transferred to a 0.5mL snap cap tube containing 1.25uL of H2O to send off for the Bioanalyzer.\nSamples were stored @ 80C until resutls from the Bioanalyzer are received."
  },
  {
    "objectID": "posts/2009/2009-07-07-qpcr-mv-hemocyte-cdna-from-20090614/index.html",
    "href": "posts/2009/2009-07-07-qpcr-mv-hemocyte-cdna-from-20090614/index.html",
    "title": "qPCR - MV hemocyte cDNA from 20090614",
    "section": "",
    "text": "Set up qPCR with Cv_18s_F/R primers on the following samples that had previously come up negative in both reps using the diluted (1:20) cDNA that Mac had made specifically for the 18s runs:\n3326A13\n2100B07\n3219A06\n2100B15\n3326A11\n2100B12\n2100A03\nPlate layout/PCR set up is here. This is a second rep of these samples.\nResults: Waters are clean. However, the following samples still are negative for an 18s amplicon:"
  },
  {
    "objectID": "posts/2009/2009-05-13-gdna-isolation-c-pugetti/index.html",
    "href": "posts/2009/2009-05-13-gdna-isolation-c-pugetti/index.html",
    "title": "gDNA Isolation - C.pugetti",
    "section": "",
    "text": "Isolated according to JGI protocol (Word doc). Used 100mL, 8 day old culture inoculated from a plate on 20090505. Resuspended pellets in 740uL of TE and took an OD600 via the NanoDrop. Diluted the sample appropriately to an OD600 ~ = 1.0 in a final volume of 740uL TE (see the last three measurements for OD600 of final dilution).\nFollowed protocol. Recovered 300uL of aqueous phase prior to precipitation with isopropanol (Step #21). Resuspended DNA in 20uL of H2O. Will run samples on gel according to JGI instructions.\n\nLane 1 - 15ng standard (5uL)\nLane 2 - 31ng standard (5uL)\nLane 3 - 63ng standard (5uL)\nLane 4 - Marker 2 (5uL)\nLane 5 - C. pugetti DNA (5uL: 3uL + 2uL dye)\nLane 6 - Marker 3 (5uL)\nLane 7 - 125ng standard\nLane 8 - 250ng standard (5uL)\nLane 9 - 500ng standard (5uL)\nResults: DNA looks stellar! Just like the example gel in the JGI QC documentation. however, looks to be too little TOTAL yield of DNA to send for sequencing (need"
  },
  {
    "objectID": "posts/2009/2009-12-30-qpcrs-bb-dh-cdna-from-20091223/index.html",
    "href": "posts/2009/2009-12-30-qpcrs-bb-dh-cdna-from-20091223/index.html",
    "title": "qPCRs - BB & DH cDNA (from 20091223)",
    "section": "",
    "text": "qPCR was set up on these cDNAs using the following primers:\nAJ582629.p.cg.6 (“DEF1”, “Defensin 1”) - This was upregulated in BB SOLiD data.\nCB617519.p.cg.6 (“RETST”, “All-trans retinol”) - This was upregulated in BB SOLiD data.\nqPCR set up and plate layout can be found here.\nResults:\nqPCR Data File (Opticon): 20091230_173747.tad\nData workup: PROPS BB_DH Gene Expression Miner Workup\nqPCR was set up on these cDNAs using the following primers:\nCU684779.p.cg.6 (“SEMSA”, “Semaphorin-SA”) - This was upregulated in BB SOLiD data.\nFP004879.p.cg.6 (“TIMP3”, “Metalloproteinase inhibitor 3”) - This was upregulated in BB SOLiD data.\nqPCR set up and plate layout can be found here.\nResults:\nqPCR Data File (Opticon): 20091230_143643.tad\nData workup: PROPS BB_DH Gene Expression Miner Workup"
  },
  {
    "objectID": "posts/2009/2009-01-08-bleeding-hard-clams-4/index.html",
    "href": "posts/2009/2009-01-08-bleeding-hard-clams-4/index.html",
    "title": "Bleeding - Hard Clams",
    "section": "",
    "text": "Bled 6 hard clams using a 23g 1.5 needle on a 3mL syringe. Fluid was gathered and ranged from ~0.4-1.0mL. Hemolymph was transferred to individual 1.5mL snap cap tubes and spun @ 100g for 30mins @ 4C. Most of the supe was removed, but left ~100uL in each tube to avoid disturbing any pellet. Samples were stored @ -80C in the red box with previous hard clam hemo samples. Clams were numbered and transferred to a holding tank."
  },
  {
    "objectID": "posts/2009/2009-06-25-qpcr-abalone-dg-dnased-rna-from-yesterday-and-earlier-today/index.html",
    "href": "posts/2009/2009-06-25-qpcr-abalone-dg-dnased-rna-from-yesterday-and-earlier-today/index.html",
    "title": "qPCR - Abalone Dg DNased RNA from yesterday and earlier today",
    "section": "",
    "text": "Check Abalone RNA for residual gDNA contamination after DNase treatment. Ran qPCR with H.crach_16s_SYB_F/R primers. Plate layout/PCR set up here.\nResults: Still gDNA in virtually every sample! This is totally insane. Will find/design primers that will only amplify gDNA to aid in subsequent analysis…"
  },
  {
    "objectID": "posts/2009/2009-06-19-qpcr-mv-hemocyte-cdna-from-20090614-9/index.html",
    "href": "posts/2009/2009-06-19-qpcr-mv-hemocyte-cdna-from-20090614-9/index.html",
    "title": "qPCR - MV hemocyte cDNA from 20090614",
    "section": "",
    "text": "Set up qPCR with Cv_TLR _short_F/R primers. Plate layout/PCR set up is here.\nResults: Waters are clean. Melting curves look a bit rough, though. To be analyzed later with other genes that Mac has run."
  },
  {
    "objectID": "posts/2009/2009-06-04-dnase-treatment-abalone-dg-rna-isolated-yesterday/index.html",
    "href": "posts/2009/2009-06-04-dnase-treatment-abalone-dg-rna-isolated-yesterday/index.html",
    "title": "DNase Treatment - Abalone Dg RNA isolated yesterday",
    "section": "",
    "text": "RNA from yesterday was treated according to Ambion Turbo DNA-free protocol to remove gDNA contamination. Work up is here. Will check for residual gDNA contamination once I’ve finished with another set of RNA isolations from the remainder of Abalone Dg tissue."
  },
  {
    "objectID": "posts/2009/2009-06-09-qpcr-re-dnased-abalone-dg-rna-from-earlier-today-3/index.html",
    "href": "posts/2009/2009-06-09-qpcr-re-dnased-abalone-dg-rna-from-earlier-today-3/index.html",
    "title": "qPCR - Re-DNased abalone Dg RNA from earlier today",
    "section": "",
    "text": "Done to verify removal of gDNA from RNA. Used H.crach_16s_syb_f/r primers. PCR workup/plate layout is here.\nResults: Still f’ing gDNA! I’m pretty convinced that this is indeed due to the Ambion kit I’m using being old. Got mixed up with a newer kit, but neither had dates. Mac is going to be running a qPCR later today on DNased RNA that used the other Ambion kit. I will wait until the results of her qPCR to proceed."
  },
  {
    "objectID": "posts/2009/2009-05-07-qpcr-dnased-oyster-rna-from-earlier-today/index.html",
    "href": "posts/2009/2009-05-07-qpcr-dnased-oyster-rna-from-earlier-today/index.html",
    "title": "qPCR - DNased oyster RNA from earlier today",
    "section": "",
    "text": "Performed qPCR on the DNased RNA to with Gigas_18s_F/R primers to verify removal of detectable gDNA in the samples. Plate layout/set up can be found here.\nResults: All samples produced a signal. In retrospect, this is likely due to having too much RNA for the DNase treatment. I proceeded with the DNase treatment and qPCR prior to specing the samples. Spec revealed that most of them were highly concentrated; more than the Ambion protocol recommends. Will redo the DNase treatment on a subset of the samples using the appropriate quantity of RNA."
  },
  {
    "objectID": "posts/2009/2009-04-21-qpcr-abalone-dnased-rna-from-yesterday/index.html",
    "href": "posts/2009/2009-04-21-qpcr-abalone-dnased-rna-from-yesterday/index.html",
    "title": "qPCR - Abalone DNased RNA from yesterday",
    "section": "",
    "text": "Performed qPCR to evaluate gDNA removal w/ 2x Immomx and SYTO 13. qPCR/plate set up is here.\nResults: The two cDNA samples come up as positive. No flourescence detected in any other gamples. However, melting curves look suspicous despite the fact that the “Quantitation” view indicates now amplification."
  },
  {
    "objectID": "posts/2009/2009-12-23-reverse-transcription-bb-dh-dnased-rna-from-20090514/index.html",
    "href": "posts/2009/2009-12-23-reverse-transcription-bb-dh-dnased-rna-from-20090514/index.html",
    "title": "Reverse Transcription - BB & DH DNased RNA (from 20090514)",
    "section": "",
    "text": "Made a fresh, double batch (50uL rxn instead of 25uL) of cDNA according to Promega MMLV protocol using oligo dT primers. cDNA was put into a plate for faster qPCR loading. cDNA calcs and plate layout are here. Briefly, RNA and oligo dTs were combined, brought up to 37uL, heated @ 70C for 5mins and immediately placed on ice. RT master mix was made (RT master mix calcs are here), 13uL was distributed to each well. Samples were incubated @ 42C for 1hr and then 95C for 5mins.\nUPDATE: cDNA plate was discarded 20120320 by SJW."
  },
  {
    "objectID": "posts/2009/2009-06-30-qpcrs-mv-hemocyte-cdna-from-20090614/index.html",
    "href": "posts/2009/2009-06-30-qpcrs-mv-hemocyte-cdna-from-20090614/index.html",
    "title": "qPCRs - MV hemocyte cDNA from 20090614",
    "section": "",
    "text": "qPCR - BgBL Primers\nSet up qPCR with Cv_BgBL_F/R primers. This is a second rep. Plate layout/PCR set up is here.\nResults: Waters are clean. To be analyzed later with other genes that Mac has run.\n\n\nqPCR - HMG Primers\nSet up qPCR with Cv_HMG_F/R primers. This is a second rep. Plate layout/PCR set up is here.\nResults: Waters are clean. To be analyzed later with other genes that Mac has run.\n\n\nqPCR - HSP70 Primers\nSet up qPCR with Cv_HSP70_F/R primers. This is a second rep. Plate layout/PCR set up is here.\nResults: Waters are clean. To be analyzed later with other genes that Mac has run."
  },
  {
    "objectID": "posts/2009/2009-06-11-qpcr-re-dnased-abalone-dg-rna-from-earlier-today-2/index.html",
    "href": "posts/2009/2009-06-11-qpcr-re-dnased-abalone-dg-rna-from-earlier-today-2/index.html",
    "title": "qPCR - Re-DNased abalone Dg RNA from earlier today",
    "section": "",
    "text": "This is a repeat of the previous qPCR from earlier today, BUT I think I might have used the wrong primers in the earlier qPCR (see below). Set up qPCR with the correct (I’m 100% sure of this) primers. Plate layout/workup is here.\nResults: Well, in retrospect it looks like I DID use the correct primers earlier! However, the problem is the same. But, the melting curves in the H2O-only samples don’t seem to be the same as what is being seen in the RNA samples, suggesting that the signal in the H2O-only samples are likely primer dimers (melting curve peaks are shifted to the left and are VERY low signals; barely above background).\nSo, what to do now? Mac has a mad ea suggestion to spike some water with gDNA and DNase treat the sample to assess whether or not the Dase treatment is actually working or not. I think I’ll do this."
  },
  {
    "objectID": "posts/2009/2009-05-20-dna-methylation-test-gigas-site-gdna-bb-dh-from-20090515/index.html",
    "href": "posts/2009/2009-05-20-dna-methylation-test-gigas-site-gdna-bb-dh-from-20090515/index.html",
    "title": "DNA Methylation Test - Gigas site gDNA (BB & DH) from 20090515",
    "section": "",
    "text": "Used BB & DH samples #11-17 for procedure. Followed Epigentek’s protocol. My calcs for dilutions/solutions needed are here. All solutions were made fresh before using, except for Diluted GU1 which was made at the beginning of the procedure and stored on ice in a 50mL conical wrapped in aluminum foil. Used 100ng total (50ng/uL) of each sample gDNA. No standards for a standard curve based on speaking with Mac.\n\n\n\n\n\nWELL\n\n\nSAMPLE\n\n\nWELL\n\n\nSAMPLE\n\n\n\n\nA01\n\n\nBB11\n\n\nA02\n\n\nDH11\n\n\n\n\nB01\n\n\nBB12\n\n\nB02\n\n\nDH12\n\n\n\n\nC01\n\n\nBB13\n\n\nC02\n\n\nDH13\n\n\n\n\nD01\n\n\nBB14\n\n\nD02\n\n\nDH14\n\n\n\n\nE01\n\n\nBB15\n\n\nE02\n\n\nDH15\n\n\n\n\nF01\n\n\nBB16\n\n\nF02\n\n\nDH16\n\n\n\n\nG01\n\n\nBB17\n\n\nG02\n\n\nDH17\n\n\n\n\nH01\n\n\nPos. Control\n\n\nH02\n\n\nBlank\n\n\n\n\n\n\nResults: Above is the graph of the results. Although it’s only a small difference between the two sites, it is statistically significant. [The calcs for this graph can be found here (Excel file)(https://eagle.fish.washington.edu/Arabidopsis/Notebook%20Workup%20Files/20090519%20Gigas%20DNA%20methylation%20workup%20SJW.xls). It should be noted that this graph was generated using estimated values from the standard curve provided in the manufacturer’s protocol. This was done because 1) I did not run standards to generate my own curve and 2) calculating the “% methylation” not using the formula that utilizes the standard curve was giving ridiculously high values (e.g. 350%).\nHere is the raw data generated by the plate reader for a [1s read (Excel file)(https://eagle.fish.washington.edu/Arabidopsis/Notebook%20Workup%20Files/20090519%20gDNA%20Methylation%201s%20SJW.xls) and a 0.1s (Excel file) read. Both reads have nearly identical values."
  },
  {
    "objectID": "posts/2009/2009-06-11-qpcr-re-dnased-abalone-dg-rna-from-earlier-today/index.html",
    "href": "posts/2009/2009-06-11-qpcr-re-dnased-abalone-dg-rna-from-earlier-today/index.html",
    "title": "qPCR - Re-DNased abalone Dg RNA from earlier today",
    "section": "",
    "text": "Set up qPCR. Plate layout/workup is here.\nResults: Looks like gDNA contamination is still present!! This is insane! However, the two water-only samples produced a signal suggesting that something else is contaminated. Will try just qPCR-ing water to see if I can get a clean signal. Will use “store-bought” PCR water instead of NanoPure water.\n*UPDATE**: Possibly used 16s universal bacterial primers instead of H.crach 16s primers! Doh! Will re-qPCR using the correct primers."
  },
  {
    "objectID": "posts/2009/2009-05-05-bacteria-c-pugetti-liquid-cultures-2/index.html",
    "href": "posts/2009/2009-05-05-bacteria-c-pugetti-liquid-cultures-2/index.html",
    "title": "Bacteria - C. pugetti liquid cultures",
    "section": "",
    "text": "Started two 100mL cultures in 1x Marine Broth + biphenyl. One culture was inoculated from the original liquid culture (from 20090419) and the second was inoculated with a thick loopfull of C. pugetti from the plate (from 20090424). Cultures were incubated @ 28C, 200RPM."
  },
  {
    "objectID": "posts/2009/2009-12-23-qpcr-bb-dh-cdna-from-earlier-today/index.html",
    "href": "posts/2009/2009-12-23-qpcr-bb-dh-cdna-from-earlier-today/index.html",
    "title": "qPCR - BB & DH cDNA (from earlier today)",
    "section": "",
    "text": "qPCR was set up on these cDNAs using HMGP_5’/3’ and SPI_5’/3’ primers. qPCR set up and plate layout can be found here.\nResults:\nqPCR Data File (Opticon): 20091223_144042.tad\nData workup: PROPS BB_DH Gene Expression Miner Workup"
  },
  {
    "objectID": "posts/2009/2009-04-13-pcr-baysea-scallop-gdna-isolated-earlier-today/index.html",
    "href": "posts/2009/2009-04-13-pcr-baysea-scallop-gdna-isolated-earlier-today/index.html",
    "title": "PCR - Bay/Sea scallop gDNA isolated earlier today",
    "section": "",
    "text": "Used 3 sets of reverse primers:\nBay_Actin_Rv0\nBay_Actin_Rv2\nSea_Actin_Rv2\nPrimers were slected based on information from Steven’s notebook (#8, 12/30/2007-1/3/2008). Anneal temp 53C.\nPCR set up here . Plate layout here .\nSamples were run out by Steven the following day.\nGel 1 of 3\n\nGel 2 of 3\n\nGel 3 of 3\n\nResults:"
  },
  {
    "objectID": "posts/2009/2009-10-10-dnase-treatment-re-dnase-of-tims-adult-gigas-challenge-rna-from-yesterday/index.html",
    "href": "posts/2009/2009-10-10-dnase-treatment-re-dnase-of-tims-adult-gigas-challenge-rna-from-yesterday/index.html",
    "title": "DNase Treatment - Re-DNase of Tim’s adult gigas challenge RNA (from yesterday)",
    "section": "",
    "text": "5 samples from yesterday’s treatment still came up on qPCR, so I will re-DNase those 5 samples. Followed standard protocol in Ambion’s Turbo DNA-free kit."
  },
  {
    "objectID": "posts/2009/2009-06-06-qpcr-dnased-abalone-dg-rna-from-earlier-today/index.html",
    "href": "posts/2009/2009-06-06-qpcr-dnased-abalone-dg-rna-from-earlier-today/index.html",
    "title": "qPCR - DNased abalone Dg RNA from earlier today",
    "section": "",
    "text": "Done to verify removal of gDNA from RNA. Used H.crach_16s_syb_f/r primers. PCR workup/plate layout is here.\nResults: RNA is still contaminated. Will have to re-DNase the samples."
  },
  {
    "objectID": "posts/2009/2009-06-18-qpcr-mv-hemocyte-cdna-from-20090614-10/index.html",
    "href": "posts/2009/2009-06-18-qpcr-mv-hemocyte-cdna-from-20090614-10/index.html",
    "title": "qPCR - MV hemocyte cDNA from 20090614",
    "section": "",
    "text": "Set up qPCR with Cv_BgBL_F/R primers. Plate layout/PCR set up is here.\nResults: Waters are clean. To be analyzed later with other genes that Mac has run."
  },
  {
    "objectID": "posts/2009/2009-04-15-qpcr-rab7_sybr-primers-on-abalone-rna-and-dnased-rna/index.html",
    "href": "posts/2009/2009-04-15-qpcr-rab7_sybr-primers-on-abalone-rna-and-dnased-rna/index.html",
    "title": "qPCR - Rab7_SYBR primers on abalone RNA and DNased RNA",
    "section": "",
    "text": "Attempt to find out if gDNA contamination exists iafter Ambion treatment. Previous test (on 20090414) suggests the QT Kit did not eliminate gDNA. PCR set up and plate layout here. Used Immomix and SYTO 13."
  },
  {
    "objectID": "posts/2009/2009-10-24-rna-isolation-herring-gonadovary-samples/index.html",
    "href": "posts/2009/2009-10-24-rna-isolation-herring-gonadovary-samples/index.html",
    "title": "RNA Isolation - Herring Gonad/Ovary Samples",
    "section": "",
    "text": "RNA was isolated according to protocol. Pellets were resuspended in 50uL of 0.1%DEPC-H2O, heated @ 55C for 5 mins, spec’d and stored @ -80C in the “Herring RNA Box #1”.\nResults:\n\nMost of the samples look good, however there are a number of samples that are downright bad. Either no RNA or very low concentrations with poor 260/280, 260/230 ratios."
  },
  {
    "objectID": "posts/2009/2009-04-13-gdna-isolation-baysea-scallop-and-hybrid-samples/index.html",
    "href": "posts/2009/2009-04-13-gdna-isolation-baysea-scallop-and-hybrid-samples/index.html",
    "title": "gDNA Isolation - Bay/Sea Scallop and hybrid samples",
    "section": "",
    "text": "gDNA was isolated using 500uL of 10% Chelex. Samples were heated @ 95C for 1hr w/periodic vortexing. Samples were then spun 16,000g for 5mins @ 4C. Stored @ -20C in Bay x Sea Scallop Project Box."
  },
  {
    "objectID": "posts/2009/2009-08-26-dna-precipitation-c-pugetti-dna-for-jgi-submission-continued-from-yesterday/index.html",
    "href": "posts/2009/2009-08-26-dna-precipitation-c-pugetti-dna-for-jgi-submission-continued-from-yesterday/index.html",
    "title": "DNA Precipitation - C.pugetti DNA for JGI submission (continued from yesterday)",
    "section": "",
    "text": "Sample was removed from -20C and spun @ 4C, 16,000 x g for 30mins. Supe removed, pellet washed with 1mL 70% EtOH and spun @ 4C, 16,000 x g for 15mins. Supe removed, tube spun briefly and remainder of EtOH removed. Pellet was resuspended in 100uL of 1x TE and spec’d. Sample will be run on a gel according to JGI instructions.\nResults:\n\nThe only thing that could be worse about this gel would be no sample DNA. However, what we see here (the giants smear in middle of the gel is our sample) is completely degraded OR sheared gDNA. That means this gDNA is absolutely useless now. Will start growing more cultures for another massive gDNA isolation."
  },
  {
    "objectID": "posts/2009/2009-10-13-qpcr-tims-adult-gigas-challenge-cdna-from-20091009/index.html",
    "href": "posts/2009/2009-10-13-qpcr-tims-adult-gigas-challenge-cdna-from-20091009/index.html",
    "title": "qPCR - Tim’s adult gigas challenge cDNA (from 20091009)",
    "section": "",
    "text": "Set up qPCR with Cg_HIF1 (hypoxia induced factor 1) primers and prostaglandin E2 primers. Plate layout/setup is here.\nResults: Processed with PCR Miner. Normalized to EF1. Standard Error bars. Here is spreadsheet with workup.\n\nHIF1:\nNo significant differences between any treatments.\nProstaglandin E2:\nNo significant differences between any treatments."
  },
  {
    "objectID": "posts/2009/2009-07-06-spec-reading-c-pugetti-gdna-from-20090526/index.html",
    "href": "posts/2009/2009-07-06-spec-reading-c-pugetti-gdna-from-20090526/index.html",
    "title": "Spec Reading - C.pugetti gDNA from 20090526",
    "section": "",
    "text": "A recent email from JGI indicates that they are satisfied with the quality of DNA (as seen on 20090601), however their estimate of the gDNA concentration (42ng/uL) means that we have ~16ug of DNA. They requested 50ug. Based on the gel, their calculations are reasonable. However, the NanoDrop suggests that are sample is ~1350ng/uL! So, I’ve respec’d the sample and did a few dilutions to see how it looked.\n\nResults: The undiluted sample is approximately the same concentration as initially reported. A 1:1 dilution produces the expected concentration of half the undiluted. The 1:10 and 1:100 dilutions deviate a bit from the expected concentrations, but are reasonably close. I still don’t know how to explain the discrepancy between what the gel analysis suggests vs. the NanoDrop spectrophotometric data."
  },
  {
    "objectID": "posts/2009/2009-12-24-sequencing-mac-methylation-samples-sam-rhodopsin-samples-lisa-samples/index.html",
    "href": "posts/2009/2009-12-24-sequencing-mac-methylation-samples-sam-rhodopsin-samples-lisa-samples/index.html",
    "title": "Sequencing - Mac methylation samples, Sam rhodopsin samples, Lisa samples",
    "section": "",
    "text": "Samples were submitted for sequencing. Mac prepped all Roberts Lab samples excluding the Opsin VMC gel slice 2 from 20091217-02. The gel slice was purified with Millipore spin columns. The sample was diluted 1:1 with H2O and submitted for sequencing, one time from each direction using the Sep_Op_Fw2/Rv2 primers. Plate layout can be found here on sheet labeled “20091223”."
  },
  {
    "objectID": "posts/2009/2009-10-06-adapter-ligation-ricks-trout-fragmented-controlpoly-ic-samples-for-solid-wtk/index.html",
    "href": "posts/2009/2009-10-06-adapter-ligation-ricks-trout-fragmented-controlpoly-ic-samples-for-solid-wtk/index.html",
    "title": "Adapter Ligation - Rick’s trout fragmented control/poly I:C samples for SOLiD WTK",
    "section": "",
    "text": "See the Next Gen Seq Library Database for more info. Processed the 4 samples (one set Ribominus only, one set Ribominus + PolyA enriched) according to the Agilent WTK. Briefly:\n\nSpeedvac’d samples to dryness\nResuspended RNA in 3uL H2O\nAdapter rxn. Used all 3uL of RNA (used only 1uL of RBC Ribo only sample due to high concentration)\nLigation rxn\n\nIncubated 16C for 16hrs."
  },
  {
    "objectID": "posts/2009/2009-10-23-rna-isolation-herring-gonadovary-samples-2/index.html",
    "href": "posts/2009/2009-10-23-rna-isolation-herring-gonadovary-samples-2/index.html",
    "title": "RNA Isolation - Herring Gonad/Ovary Samples",
    "section": "",
    "text": "From the Seeb Lab. Homogenized entire gonad/ovary samples in 5mL of TriReagent with the sonicator. In essence, based on the manufacturer’s recommendation, this means the ratio of tissue:TriReagent was ~2x. Transferred 0.5mL of homogenized gonad/ovary sample to 1.5mL snap cap tubes and added an additional 0.5mL of TriReagent, to adjust the ratio of tissue:TriReagent to ~1x. Samples were then stored @ -80C. These will be further processed tomorrow."
  },
  {
    "objectID": "posts/2009/2009-04-02-gdna-isolation-new-dungan-isolates/index.html",
    "href": "posts/2009/2009-04-02-gdna-isolation-new-dungan-isolates/index.html",
    "title": "gDNA Isolation - New Dungan isolates",
    "section": "",
    "text": "gDNA was isolated from the following using the Qiagen DNEasy Kit:\nxCvC-19t (3/26/2009)\nxCvE-13t (3/16/2009)\nxCvC-17t (3/18/2009)\nUNTc-1.5t (3/18/2009)\nVATm-1.2t (3/16/2009)\nxCvC-11t (3/18/2009)\nBC05Ca18c/H5 (3/27/2009)\nxCvC-12t (3/16/2009)\n500uL was of each sample was transferred to a 1.5mL snap cap tube. The samples were pelleted by spinning 5 mins @ 16,000g and washed 2x w/ 1x PBS pH=7.6. Samples were then processed according to Qiagen protocol. Initial digestion with Proteinase K was 2hrs."
  },
  {
    "objectID": "posts/2009/2009-04-10-pcr-abalone-gdnarnacdna-wnew-tollip-primer/index.html",
    "href": "posts/2009/2009-04-10-pcr-abalone-gdnarnacdna-wnew-tollip-primer/index.html",
    "title": "PCR - Abalone gDNA/RNA/cDNA w/new TOLLIP primer",
    "section": "",
    "text": "Performed a new PCR on the three types of samples listed above with new TOLLIP primers. The new TOLLIP primers (H.discus_806_F/Ab_866_Rv) surround a putative intron. Thus, they will be useful for determining the presence of gDNA contamination in RNA/cDNA. Anneal temp 55C. PCR set up is here .\n\nLane 1 - Hyperladder\nLane 2 - gDNA\nLane 3 - cDNA (QT)\nLane 4 - RNA (untreated)\nLane 5 - DNased RNA\nLane 6 - QT Kit, No RT\nLane 7 - H2O\nLane 8 - H2O\nResults: This could possibly be the most confusing gel I’ve ever had the “pleasure” of running/analyzing, despite that it only has 7 samples.\nNo band in the gDNA sample, which could be explained by the intron size being too large for amplification with a basic polymerase. The cDNA worked as expected and contains a band of ~150bp. The RNA sample has a faint band of ~750bp. The DNased RNA sample has a band of ~400bp. The differences seen betweeen the gDNA (Lane 2), RNA (Lane 4) and DNased RNA (Lane 5) are truly bizarre. The No RT sample has no band. And, to top things off, one of the H2O samples is blank , but the other one has a band of ~1500bp! Ugh. How is all of this even possible?"
  },
  {
    "objectID": "posts/2009/2009-02-12-trypsin-digestion-vibrio-2d-spots-from-20081217/index.html",
    "href": "posts/2009/2009-02-12-trypsin-digestion-vibrio-2d-spots-from-20081217/index.html",
    "title": "Trypsin digestion - Vibrio 2D spots from 20081217",
    "section": "",
    "text": "Samples were prepared according to Goodlett Lab protocol and incubated O/N on LabQuake."
  },
  {
    "objectID": "posts/2009/2009-01-12-rna-isolation-hard-clam-hemolymph-from-20090108-20090109/index.html",
    "href": "posts/2009/2009-01-12-rna-isolation-hard-clam-hemolymph-from-20090108-20090109/index.html",
    "title": "RNA Isolation - Hard Clam hemolymph from 20090108, 20090109",
    "section": "",
    "text": "1mL of TriReagent was used to isolate RNA from 3 combined tubes of hemolymph. This resulted in 10 total RNA preps. Pellets were resuspended in 100uL of 0.1% DEPC-H2O and pooled into a single tube and NanoDropped.\n\nResults: RNA solution looked very cloudy and contains a fair amount of insoluble “stuff”. 260/280 ratios also looked bad. Will precipitate O/N according to Ambion PolyA Purist Kit before isolating mRNA tomorrow."
  },
  {
    "objectID": "posts/2009/2009-08-17-qpcr-carita-primer-test-for-high-resolution-melt-hrm-curve-analysis/index.html",
    "href": "posts/2009/2009-08-17-qpcr-carita-primer-test-for-high-resolution-melt-hrm-curve-analysis/index.html",
    "title": "qPCR - Carita Primer Test for High Resolution Melt (HRM) Curve Analysis",
    "section": "",
    "text": "Ran a qPCR on Rick’s Lake Trout DNA from 4/28/2009 using primers in Carita’s CMA01 Primer Plate (Excel file). DNA was pooled (2uL from each sample), spec’d and diluted to 10ng/uL. qPCR set up is here. Plate layout matches Carita’s primer plate layout. Since we’re just looking for positive/negative samples, I ran this on the Opticon 2 despite the recent “problems” we’ve been having with it. Cycling params used with the 2x HRM M.M. are as follows:\n95C - 10mins\n40 cycles of:\n95C - 10s\n60C - 15s\n72C - 25s\nResults: Overall, looks good. Negative control is clean. Based on signal strength and clean, tight melting curves, the following primer sets (location in CMA01 primer/qPCR plates) will be used for HRM analysis tomorrow: C11, D3, E12, D3. Actually, never mind. Steven’s sent me contig info for the lake trout so we’ll just order and test primers that are more likely to produce good data instead of worrying about the salmonid primers."
  },
  {
    "objectID": "posts/2009/2009-12-02-hard-clam-challenge-qpx-strain-s-1/index.html",
    "href": "posts/2009/2009-12-02-hard-clam-challenge-qpx-strain-s-1/index.html",
    "title": "Hard Clam Challenge - QPX Strain S-1",
    "section": "",
    "text": "Challenged 2 FL hard clams and 1 BX hard clam with ~100uL of unwashed, 11 day old cultures. 2 FL hard clams and 1 BX hard clam received ~100uL of QPX media, as controls. Injections were done through the hinge using 20G1 needles and aimed for the pericardial cavity. After injections, clams were left out of water for 1.5hrs, then return to small containers of sea water. They will be incubated for 24hrs."
  },
  {
    "objectID": "posts/2009/2009-04-14-pcr-test-qt-kit-with-no-rt-abalone-rxns-from-20090408/index.html",
    "href": "posts/2009/2009-04-14-pcr-test-qt-kit-with-no-rt-abalone-rxns-from-20090408/index.html",
    "title": "PCR - Test QT Kit with No RT Abalone rxns from 20090408",
    "section": "",
    "text": "Anneal 55C. [PCR set up is here (bottom half of sheet)(https://eagle.fish.washington.edu/Arabidopsis/Notebook%20Workup%20Files/20090414-01.jpg).\n\nLane 1 - Hyperladder\nLane 2 - gDNA\nLane 3 - cDNA pool\nLane 4 - No RT 06:5-31\nLane 5 - No RT 06:6-43\nLane 6 - No RT 08:3-5\nLane 7 - No RT 08:3-6\nLane 8 - No RT 08:3-7\nLane 9 - H2O\nLane 10 - H2O\nLane 11 - 100bp ladder\nResults: No signal in the gDNA. Appropriate sized band in cDNA pool. Nothing in the water samples. HOWEVER, got bands in tow of the “No RT” rxns (08:3-6/7)!! It’s odd that the gDNA didn’t produce any signal, but there shouldn’t be any signal in the No RT rxns. This indicates gDNA contamination. Should have also tested RNA and DNased RNA. Will test these in order to determine if that system is better at eliminating gDNA carryover."
  },
  {
    "objectID": "posts/2009/2009-11-19-pcr-unknown-dunganslyons/index.html",
    "href": "posts/2009/2009-11-19-pcr-unknown-dunganslyons/index.html",
    "title": "PCR - “Unknown” Dungans/Lyons",
    "section": "",
    "text": "This is a repeat of yesterday’s set up with LABY primers, but with an annealing temp of 53C in hopes of improving the number of amplicons generated from additional samples. See yesterday’s PCR run for info on samples.\nResults: Samples were loaded 1-29 and three negative controls from left to right, top to bottom.\n\nThe lower annealing temperature clearly resulted in more products. The ~500bp band was cut from each lane and stored @ -20C. All bands will be purified using Millipore spin columns and then sent for sequencing."
  },
  {
    "objectID": "posts/2009/2009-04-21-bacteria-c-pugettii-culture-continued-from-20090419/index.html",
    "href": "posts/2009/2009-04-21-bacteria-c-pugettii-culture-continued-from-20090419/index.html",
    "title": "Bacteria - C. pugettii culture CONTINUED (from 20090419)",
    "section": "",
    "text": "Transferred 1mL of the culture to a 50mL conical containing 4mL of 1x Marine Broth and a couple crystals of biphenyl. Kept the cap loosened and incubated at 20C with shaking at 200RPM. Kept the existing culture in the incubator as well. No apparent growth."
  },
  {
    "objectID": "posts/2009/2009-12-16-pcr-sepia-cdna-from-yesterday/index.html",
    "href": "posts/2009/2009-12-16-pcr-sepia-cdna-from-yesterday/index.html",
    "title": "PCR - Sepia cDNA (from yesterday)",
    "section": "",
    "text": "Set up PCR on recent Sepia cDNA samples using both S. officianalis_rhodopsin_F, R primers & Sep_op_F2, R2 primers. PCR set up is here. Looking back at my old paper (gasp!) notebook from March 2007, I noticed that each primer set required differing amounts of Mg2+. Rhodopsin primers require 3mM Mg2+ in the PCR rxn and the opsin primers require 2mM Mg2+ in the PCR rxn. Mg2+ was added as required and is shown on the PCR set up link above.\nResults:\n\nGel Loading (from left to right):\nOpsin Primers (lanes 2-10), Rhodopsin Primers (same loading order, lanes 12-20)\n1 - 100bp ladder\n2 - retina\n3 - fin\n4 - 4th arm\n5 - dorsal mantle center\n6 - dorsal mantle side\n7 - ventral mantle center\n8 - ventral mantle side\n9 - H2O\n10 - H2O\nOpsin Primers\nWe see an intense band in the retina sample, as expected, since opsin is constitutively expressed in this tissue. We also see a band in the fin and both dorsal mantle samples.\nNegative controls are blank.\nRhodopsin Primers\nWe see an intense band in the retina sample. We also see a band in the fin sample. We see two bands in the ventral mantle center tissue, possibly suggesting a rhodopsin isoform is also being expressed in this tissue.\nNegative controls are blank.\nOverall, these results are rather intriguing because they clearly demonstrate that both genes are being differentially expressed in non-eye tissue of Sepia officianalis."
  },
  {
    "objectID": "posts/2009/2009-05-06-rna-isolation-macs-oyster-tissues-bb-and-dh-continued-from-yesterday-2/index.html",
    "href": "posts/2009/2009-05-06-rna-isolation-macs-oyster-tissues-bb-and-dh-continued-from-yesterday-2/index.html",
    "title": "RNA Isolation - Mac’s oyster tissues (BB and DH) (CONTINUED from yesterday)",
    "section": "",
    "text": "Completed the reaminder of the samples (BB#9-20 and DH#1-20) up to the point of precipitation. Isopropanol was added and stored @ -20C. Organic phase was retained for subsequenct gDNA isolation and stored @ 4C."
  },
  {
    "objectID": "posts/2009/2009-12-04-mrna-precipitation-herring-liver-mrna-for-solid-libraries-continued-from-yesterday/index.html",
    "href": "posts/2009/2009-12-04-mrna-precipitation-herring-liver-mrna-for-solid-libraries-continued-from-yesterday/index.html",
    "title": "mRNA Precipitation - Herring Liver mRNA for SOLiD Libraries (continued from yesterday)",
    "section": "",
    "text": "Spun samples 16,000g, 30mins, 4C. Discarded supe, quick spun tubes, removed residual supe, washed with 1mL 70% EtOH. Spun samples 16,000g, 15mins, 4C. Discarded supe, quick spun tubes, removed residual supe, resuspended in 8.5uL of nuclease-free H2O. Stored @ -80C until ready to proceed with fragmentation for SOLiD libraries."
  },
  {
    "objectID": "posts/2009/2009-07-15-qpcr-abalone-rnadnased-rna-dirty-and-clean-cdna/index.html",
    "href": "posts/2009/2009-07-15-qpcr-abalone-rnadnased-rna-dirty-and-clean-cdna/index.html",
    "title": "qPCR - Abalone RNA/DNased RNA & “dirty” and “clean” cDNA",
    "section": "",
    "text": "This was done to really test the detection methods we’re using for gDNA contamination in our qPCRs. qPCR plate layout/set up is here. Anneal temp 50C.\nIt should be noted that the 07:12-08 RNA was diluted 1:10 before adding to the rxns to make it similar concentration to the DNased RNA. Also, ran out of the gDNA when adding to the 16s primer rxn. Used 1uL of H2O to “wash” the stock tube and added that in hopes of still detecting something. Unfortunately this was the only stock of H.crach gDNA that came up positive in yesterday’s rxns. “Dirty” cDNA is cDNA made with DNased RNA determined to still have gDNA using 16s primers AFTER the cDNA was already made. “Clean” cDNA used DNased RNA determined to be free of gDNA BEFORE the cDNA was made.\nResults:\nSignals were present with 16s primers in the following samples:\nRNA 08:3-7, clean and dirty cDNAs and gDNA.\nThe other two primer sets only showed signals in the RNA 08:3-7.\nNothing came up in any of the DNased RNA samples."
  },
  {
    "objectID": "posts/2009/2009-10-10-qpcr-tims-adult-gigas-challenge-cdna-from-today/index.html",
    "href": "posts/2009/2009-10-10-qpcr-tims-adult-gigas-challenge-cdna-from-today/index.html",
    "title": "qPCR - Tim’s adult gigas challenge cDNA (from today)",
    "section": "",
    "text": "Set up qPCR with EF1 primers and IL17 Internal primers. Plate layout/setup is here. Note: gDNA sample used as a “positive” control will NOT amplify with the EF1 primers.\nResults: Processed with PCR Miner. Normalized to EF1. Standard Error bars. Here is spreadsheet with workup.\n\nIL17 Internal:\nNo significant differences between any treatments."
  },
  {
    "objectID": "posts/2009/2009-07-01-qpcr-mv-hemocyte-cdna-from-20090614-4/index.html",
    "href": "posts/2009/2009-07-01-qpcr-mv-hemocyte-cdna-from-20090614-4/index.html",
    "title": "qPCR - MV hemocyte cDNA from 20090614",
    "section": "",
    "text": "Set up qPCR with Cv_TLR_“short”_F/R primers. This is a second rep. Plate layout/PCR set up is here.\nResults: Waters are clean. To be analyzed later with other genes that Mac has run."
  },
  {
    "objectID": "posts/2009/2009-07-02-qpcr-mv-hemocyte-cdna-from-20090614-3/index.html",
    "href": "posts/2009/2009-07-02-qpcr-mv-hemocyte-cdna-from-20090614-3/index.html",
    "title": "qPCR - MV hemocyte cDNA from 20090614",
    "section": "",
    "text": "Set up qPCR with Cv_CIAPIN_F/R primers. This is a second rep. Plate layout/PCR set up is here."
  },
  {
    "objectID": "posts/2009/2009-07-02-qpcr-mv-hemocyte-cdna-from-20090614-3/index.html#section",
    "href": "posts/2009/2009-07-02-qpcr-mv-hemocyte-cdna-from-20090614-3/index.html#section",
    "title": "qPCR - MV hemocyte cDNA from 20090614",
    "section": "",
    "text": "Results: Waters are clean. To be analyzed later with other genes that Mac has run."
  },
  {
    "objectID": "posts/2009/2009-05-01-bacteria-c-pugetti-liquid-cultures-3/index.html",
    "href": "posts/2009/2009-05-01-bacteria-c-pugetti-liquid-cultures-3/index.html",
    "title": "Bacteria - C. pugetti liquid cultures",
    "section": "",
    "text": "Inoculated a total of 10, 5mL 1x Marine Broth in 50mL conicals. 5 tubes received 1mL of the original culture started on 20090419. 4 tubes received 1mL of the secondary culture (from 20090421). 1 tube was inoculated with a colony from the plate streaked on 20090424. Incubated all tubes @ 28C, 200RPM. Used a higher temp. to encourage faster/more robust growth."
  },
  {
    "objectID": "posts/2009/2009-04-08-cdna-abalone-rna-from-20090331-20090402/index.html",
    "href": "posts/2009/2009-04-08-cdna-abalone-rna-from-20090331-20090402/index.html",
    "title": "cDNA - Abalone RNA from 20090331 & 20090402",
    "section": "",
    "text": "cDNA was made from the above RNA samples using the Qiagen Quantitect RT Kit. The samples were laid out in a PCR plate. 274.2ng of RNA was used in the rxn for each sample, based on the lowest concentration RNA sample (08:3-20) to equalize all the samples. The Genomic Wipeout step of the kit requires 2uL of Genomic Wipeout enzyme/buffer to be added to 12uL of an RNA sample, so the calculations were done and can be found here. A check mark on the calculation sheet indicates that the water and then the RNA was added to the appropriate wells. Those with two check marks were used for a “No RT” rxn and thus, have duplicate wells (see plate layout).\nThe plate was mixed, spot spun, uncubated at 42C for 2mins and immediately placed on ice.\nThe RT and No RT master mixes were set up on ice and then added to the respective wells (see sheet here).\nUPDATE: cDNA plate was discarded 20120320 by SJW."
  },
  {
    "objectID": "posts/2009/2009-02-26-qpcr-replicate-of-v-tubiashii-control-vs-autoclaved-gigas-samples-see-yesterday/index.html",
    "href": "posts/2009/2009-02-26-qpcr-replicate-of-v-tubiashii-control-vs-autoclaved-gigas-samples-see-yesterday/index.html",
    "title": "qPCR - Replicate of V.tubiashii Control vs. Autoclaved gigas samples (see yesterday)",
    "section": "",
    "text": "This is a repeat of the qPCR from yesterday, but without the 16s and OmpW primer sets due to double peaks in melting curves yesterday. Plate layout/qPCR workup is here.\nResults: Similar to yesterday’s results, the amplification looks a bit odd when viewing on a log scale. However, the linear scale curves look to be normal. Melting curves look good for all genes examined and there is not any detectable gDNA in the RNA samples. Excellent…"
  },
  {
    "objectID": "posts/2009/2009-05-08-qpcr-re-dnased-oyster-rna-from-today/index.html",
    "href": "posts/2009/2009-05-08-qpcr-re-dnased-oyster-rna-from-today/index.html",
    "title": "qPCR - Re-DNased oyster RNA from today",
    "section": "",
    "text": "Performed qPCR on the re-DNased oyster RNA from earlier today with Gigas_18s_F/R primers to verify removal of detectable gDNA in the samples, since the initial qPCR from yesterday indicated residual gDNA was still present in the DNase treated RNA. Plate layout/set up can be found here.\nResults: About 4 samples in each site set are NEGATIVE for gDNA. That means the remainder still have detectable levels of gDNA. Boo."
  },
  {
    "objectID": "posts/2009/2009-05-14-reverse-transcription-macs-gigas-dnased-rna-from-20090512/index.html",
    "href": "posts/2009/2009-05-14-reverse-transcription-macs-gigas-dnased-rna-from-20090512/index.html",
    "title": "Reverse Transcription - Mac’s gigas DNased RNA from 20090512",
    "section": "",
    "text": "Performed RT using Promega M-MLV RT according to M-MLV protocol and used 0.5ug oligo dT per ug of RNA on all BB and DH site samples that were negative for gDNA (see qPCR results 20090512). Calculations and work up are here. Samples were set up in a plate to facilitate sample loading in subsequent qPCRs.\nUPDATE: cDNA plate was discarded 20120320 by SJW."
  },
  {
    "objectID": "posts/2009/2009-10-28-sample-submissions-to-mogene-for-454-analysis-herring-liver-and-testes-mrna/index.html",
    "href": "posts/2009/2009-10-28-sample-submissions-to-mogene-for-454-analysis-herring-liver-and-testes-mrna/index.html",
    "title": "Sample Submissions to MoGene for 454 Analysis - Herring Liver and Testes mRNA",
    "section": "",
    "text": "Submitted 400ng of liver mRNA (SR01) and 400ng of testes (gonad) mRNA (SR02) to MoGene. Samples were packed in dry ice and FedEx.\n**_UPDATE 20091028**_ FedEx had a shipping delay and the samples did not get delivered today. Will be delivered tomorrow. We will be credited the full shipping amount for this delay."
  },
  {
    "objectID": "posts/2009/2009-11-18-pcr-unkown-dunganslyons/index.html",
    "href": "posts/2009/2009-11-18-pcr-unkown-dunganslyons/index.html",
    "title": "PCR - “Unkown” Dungans/Lyons",
    "section": "",
    "text": "This was done on the numbered tubes using the LABY A/Y primers for eventual sequencing. Turns out many of the tubes have some info (other than just a number) on their sides which might provide more information regarding which isolate they actually are. PCR set up is here. Annealing temp 55C.\n\n\n\n\n\nTube-#\n\n\nSide Label\n\n\n\n\n1\n\n\nVA1423-1\n\n\n\n\n2\n\n\nVA1423 2CB\n\n\n\n\n3\n\n\nVA1423-3\n\n\n\n\n4\n\n\nVA-1423 4\n\n\n\n\n5\n\n\nVA1423-6 6\n\n\n\n\n6\n\n\nVA1423-10\n\n\n\n\n7\n\n\nVA1423-12\n\n\n\n\n8\n\n\nVA1423-15\n\n\n\n\n9\n\n\nVA1423-26\n\n\n\n\n10\n\n\nVA1423-28\n\n\n\n\n11\n\n\nVA1423-290 2003 Isolate\n\n\n\n\n12\n\n\nVA1423 29 2004 Isolate\n\n\n\n\n13\n\n\nVA-1423-33\n\n\n\n\n14\n\n\nVA1423-37\n\n\n\n\n15\n\n\nXMAC13T\n\n\n\n\n16\n\n\nX-MAC-19T\n\n\n\n\n17\n\n\nXMAC 20T\n\n\n\n\n18\n\n\nX-MAD 10T\n\n\n\n\n19\n\n\nX-MAD-14T\n\n\n\n\n20\n\n\nX-MAD-18T\n\n\n\n\n21\n\n\nXMAE 11T\n\n\n\n\n22\n\n\nXMAE 13T\n\n\n\n\n23\n\n\nBC05CA8T\n\n\n\n\n24\n\n\nBC05CA 15T\n\n\n\n\n25\n\n\nBC05CA 18T\n\n\n\n\n26\n\n\nBC05CA 20T\n\n\n\n\n27\n\n\n98 MFS 61A\n\n\n\n\n28\n\n\nCRT W 1HE/H11\n\n\n\n\n29\n\n\nCRSH 5B3\n\n\n\n\n\nResults: Samples were loaded 1-29 and three negative controls from left to right, top to bottom.\n\nThere are four prominent bands from Tubes 23, 27, 28, 29. These four bands were excised and purified with Millipore spin columns according to protocol. They will be sent for sequencing. There are faint bands visible from Tubes 9 & 11. Due to the faintness, they were not excised as there may not be enough product for sequencing. The remainder of the samples failed to produce any amplicons."
  },
  {
    "objectID": "posts/2009/2009-09-02-qpcr-hrm-lake-trout-snp-primer-test/index.html",
    "href": "posts/2009/2009-09-02-qpcr-hrm-lake-trout-snp-primer-test/index.html",
    "title": "qPCR - HRM Lake Trout SNP primer test",
    "section": "",
    "text": "Tested out the plate of Lake Trout primers (LTP01 - forward and reverse combined) for SNP detection. qPCR was performed using Roche 2x HRM M.M. qPCR set up is here. Cycling params are as follows:\n95C - 10mins\n40 cycles of:\n95C - 10s\n60C - 15s\n72C - 25s\nPlate layout matches the primer plate layout.\nResults: The following wells have signals and good, clean melting curves: A1, C1, H1, B2, A3, D2, G3, A4, E4, B5, A7, D7, H7, B8, C8, F10, G10, C11, H11, A12, E12. These are potential candidates for SNP analysis. Will test HRM analysis using these primers, each on a subset of Lake Trout DNA samples to see whether or not they’ll be truly useful for analyzing the full plate of DNA."
  },
  {
    "objectID": "posts/2009/2009-09-04-hrm-lake-trout-snps-hrm-white-01/index.html",
    "href": "posts/2009/2009-09-04-hrm-lake-trout-snps-hrm-white-01/index.html",
    "title": "HRM - Lake Trout SNPs (HRM-white-01)",
    "section": "",
    "text": "The following primers from primer plate LTP01 will be used for analysis of Rick’s Lake Trout DNA plate (from 4/28/2009): A1, C1, H1, B2. So, that’s 4 primer sets x 96 DNA samples = 384. HRM set up is here. A 1:10 dilution plate of Rick’s Lake Trout DNA1 plate (from 4/28/2009) was made for HRM. This means approximately 20ng of DNA used in each rxn. The robot was used to add 1uL of DNA from the 96-well plate to the appropriate wells of the 384-well HRM rxn plate. Plate was spun to collect the DNA at the bottom of the wells. The wells were visually inspected to ensure that each received the DNA. 1uL of DNA was manually added to those wells that did not receive sample (B23, C23).\nThe master mix for each primer set was then manually dispensed to the appropriate wells in the 384-well HRM rxn plate using a “matrix” auto-pipette. The real-time PCR was run in a Roche LightCycler480 machine with the following cycling paramters:\n95C - 15mins\n45 cycles of:\n95C - 10s\n60C - 15s\n72C - 25s\nAfter the completion of the real-time run, the plate was put through the High Melt Curve protocol.\nResults:"
  },
  {
    "objectID": "posts/2009/2009-12-16-reverse-transcription-abalone-0712-dnased-rna-from-20090623/index.html",
    "href": "posts/2009/2009-12-16-reverse-transcription-abalone-0712-dnased-rna-from-20090623/index.html",
    "title": "Reverse Transcription - Abalone 07:12 DNased RNA (from 20090623)",
    "section": "",
    "text": "Spec - DNased Abalone 07:12 RNA\nApparently, these samples had not been spec’d after DNase treatment.\nResults:\n\nSamples range in quality (260/280) from not great to perfect. Will perform calcs to make cDNA.\nSet up reverse transcription rxns using 174ng of each DNased RNA (sample 07:12-04 was limiting; only 6.1uL available), using Promega oligo dT primers and M-MLV Reverse Transcriptase according to Promega protocol. RNA/oligo dT primer workup is here. Primer and DNAsed RNA were mixed and brought up to 18.25uL with H2O. Samples were heated @ 70C for 5mins and then placed immediately on ice. The RT Master Mix set up can be found here. 6.75uL of the RT master mix was added to each tube, mixed, spot spun, incubated 42C for 1hr., 95C for 3mins and then the samples were given to Lisa in the Friedman Lab."
  },
  {
    "objectID": "posts/2009/2009-12-08-rna-fragmentation-herring-liver-mrna-for-solid-libraries/index.html",
    "href": "posts/2009/2009-12-08-rna-fragmentation-herring-liver-mrna-for-solid-libraries/index.html",
    "title": "RNA Fragmentation - Herring Liver mRNA for SOLiD Libraries",
    "section": "",
    "text": "Samples from 20091203. 0.5uL was removed from each and transferred to separate tubes and diluted to < 5ng/uL for subsequent Bioanalyzer analysis using the Pico chip. Samples were fragmented using RNase III according to the Ambion WTK protocol and then cleaned up/concentrated using the Invitrogen RiboMinus Concentration Module according to the Ambion WTK protocol.\nSamples were spec’d prior to running on the Bioanalyzer:\n\nConcentrations/absorbance values are not accurate when using the NanaDrop after using the RiboMinus Concentration module, according to the Ambion WTK protocol. However, yields seem pretty good…\nTotal, mRNA and fragmented mRNA from each of the four samples was run on the Pico chip with the Eukaryote Total RNA Bioanalyzer protocol.\nResults:\n\nThe 2L tot (total RNA) and 3L tot (total RNA) samples are clearly very good quality. 2L tot does exhibit some very slight degradation, though. 4L tot (total RNA) and 6L tot (total RNA) show a much greater degree of degradation. All mRNA samples show complete removal of any trace, contaminating rRNA. The fragmented samples (the last four samples on the gel image above) all appear to be perfect. The 4L frag sample simply has less RNA loaded and that is why it is not as dark as the other three fragmented samples. Despite the degradation in the 4L tot and 6L tot samples, the fragmentation profile looks good and we will proceed with making the cDNA libraries for those samples."
  },
  {
    "objectID": "posts/2009/2009-04-10-pcr-old-dungan-isolates-1-35-weukab-primers/index.html",
    "href": "posts/2009/2009-04-10-pcr-old-dungan-isolates-1-35-weukab-primers/index.html",
    "title": "PCR - Old Dungan isolates #1-35 w/EukA/B primers",
    "section": "",
    "text": "Steven had me re-PCR the old Dungan isolates with the new EukA/B primers. Anneal temp 50C. [PCR set up here (bottom half of sheet)(https://eagle.fish.washington.edu/Arabidopsis/Notebook%20Workup%20Files/20090410-01.jpg) .\nNOTE: Sample #30 was not in the rack of tubes that Steven gave to me.\n\nResults:"
  },
  {
    "objectID": "posts/2009/2009-11-20-herring-454-data/index.html",
    "href": "posts/2009/2009-11-20-herring-454-data/index.html",
    "title": "Herring 454 Data",
    "section": "",
    "text": "Data from MoGene was received today on two DVDs and one HDD. Data is two runs of two libraries, due to MoGene concerns that the data of the first run looked bad (too few reads). They performed a second run at no charge and provided us with that data as well.\nUPDATE 20150310\nData is located here: https://owl.fish.washington.edu/nightingales/C_pallasii/"
  },
  {
    "objectID": "posts/2009/2009-01-21-bleedingtissue-collection-hard-clams/index.html",
    "href": "posts/2009/2009-01-21-bleedingtissue-collection-hard-clams/index.html",
    "title": "Bleeding/Tissue Collection - Hard Clams",
    "section": "",
    "text": "Hemos were collected from the remaining 12 clams as before and stored @ -80C. NOTE: 4 hemocyte samples were extremely cloudy. Possibly not hemos? Maybe gonad/d.g.? Gill tissue was collected from 5 clams and stored @ -80C."
  },
  {
    "objectID": "posts/2009/2009-01-06-pcr-dungan-isolates-2/index.html",
    "href": "posts/2009/2009-01-06-pcr-dungan-isolates-2/index.html",
    "title": "PCR - Dungan Isolates",
    "section": "",
    "text": "All samples , except xCVC-11t, are already in Chelex. For xCvC-11t, pipetted a shunk of cells/tissue from source tube. Volume of liquid (EtOH) was ~75uL. Added this to screw cap tube containing 300uL of 10% Chelex solution. Vortexed and incubated @ 95C for 30mins. Vortexed and incubated other samples at 95C for 5mins. Set up PCR with AmpliTaq. Anneal temp. = 53C. PCR set up here.\n\nLane 1 - 100bp ladder\nLane 2 - xCvC-11t\nLane 3 - xCvC-12t\nLane 4 - xCvC-17t\nLane 5 - VNTc-12-C1/G10\nLane 6 - BC05Ca-18t/H5\nLane 7 - VATm-1.2t\nLane 8 - VNTc-1.5t\nLane 9 - Neg. Control\nResults: Ladder is degraded and there are no bands in any lane. Will repeat and try to duplicate Steven’s results from 20080916."
  },
  {
    "objectID": "posts/2009/2009-06-29-qpcrs-mv-hemocyte-cdna-from-20090614-2/index.html",
    "href": "posts/2009/2009-06-29-qpcrs-mv-hemocyte-cdna-from-20090614-2/index.html",
    "title": "qPCRs - MV hemocyte cDNA from 20090614",
    "section": "",
    "text": "qPCR - CysB Primers\nSet up qPCR with Cv_CysB_F/R. Plate layout/PCR set up is here.\nResults: Waters are clean. To be analyzed later with other genes that Mac has run.\n\n\nqPCR -BgBp Primers\nSet up qPCR with Cv_BgBp_F/R primers. Plate layout/PCR set up is here.\nResults: Waters are clean. To be analyzed later with other genes that Mac has run."
  },
  {
    "objectID": "posts/2009/2009-07-16-qpcr-abalone-gdna/index.html",
    "href": "posts/2009/2009-07-16-qpcr-abalone-gdna/index.html",
    "title": "qPCR - Abalone gDNA",
    "section": "",
    "text": "Used up the remainder of the one positive control gDNA that worked with all the primers in yesterday’s reaction (H.crach_h-1fg_intron, H.iris_actin_intron, H.crach_16s), so need to find a new set of gDNA to use for future positive controls. qPCR plate layout/set up is here. Anneal temp 50C. Used the following gDNA with :\n06:50-9 - This was the good gDNA used as previous controls. Added 10uL of H2O to the tube in hopes of getting more useable DNA.\n06:4-7 - No date/info available on tube.\n07:12-15 - No date/info available on tube.\nResults: Got decent signals with the H.crach_h-1fg primers for two of the three gDNAs. Will use the 07:12-15 gDNA as a positive control for tomorrow’s qPCR."
  },
  {
    "objectID": "posts/2009/2009-04-09-qpcr-check-dnased-abalone-rna-by-lisa-for-gdna/index.html",
    "href": "posts/2009/2009-04-09-qpcr-check-dnased-abalone-rna-by-lisa-for-gdna/index.html",
    "title": "qPCR - Check DNased abalone RNA (by Lisa) for gDNA",
    "section": "",
    "text": "qPCR was performed with 16s_sybr primers on the DNased RNA that Lisa did. Annel temp 55C. Sample set up and plate layout is here.\nResults: Still got signals in all of the samples, including the waters. Personally, I think the primers are contaminated or are forming crazy dimers. Lisa came by and picked up cDNA to run other genes on."
  },
  {
    "objectID": "posts/2009/2009-04-14-pcr-baysea-scallop-gdnas/index.html",
    "href": "posts/2009/2009-04-14-pcr-baysea-scallop-gdnas/index.html",
    "title": "PCR - Bay/Sea scallop gDNAs",
    "section": "",
    "text": "Used higher annealing temps to improve primer specificity, compared to yesterday’s results. PCR set up and plate layout is here.\n\nSee the PCR/plate set up link for samples. Hyperladder is placed between every 12 samples.\nResults: See this Google Spreadsheet for a summary of the 4 gels from the last two days."
  },
  {
    "objectID": "posts/2009/2009-12-12-bioanalyzer-herring-liver-cdna-for-solid-libraries/index.html",
    "href": "posts/2009/2009-12-12-bioanalyzer-herring-liver-cdna-for-solid-libraries/index.html",
    "title": "Bioanalyzer - Herring Liver cDNA for SOLiD Libraries",
    "section": "",
    "text": "Samples were run on the DNA 1000 chip for cDNA smear analysis.\nResults: 2 of the 4 samples (2L & 3L) look perfect (<20% of cDNA in the 25-150bp range). 6L has <20% of the cDNA in the 25-150bp range (which is perfect), but exhibits a “smear” from ~250-500bp. cDNA in this range suggests overamplification, which will skew gene expression profile. Can repeat PCR for 6L using outer gel slices and reduce the number of cycles to prevent overamplification, if desired. Spoke to Steven and since these samples won’t be used to evaluate gene expression (they’re for SNP discovery), we won’t worry about it for the time being.\nSample 4L has some very strange signals being generated in the ~500-800bp range. Additionally, the virtual gel image (not shown) shows a great deal of smearing, unlike the other samples."
  },
  {
    "objectID": "posts/2009/2009-07-22-rt-rxns-h-crach-dnased-rna-from-20090623/index.html",
    "href": "posts/2009/2009-07-22-rt-rxns-h-crach-dnased-rna-from-20090623/index.html",
    "title": "RT Rxns - H.crach DNased RNA (from 20090623)",
    "section": "",
    "text": "DNased RNA was used for cDNA rxns. [Workup of the amount of RNA used in each rxn (472ng/uL) is here (Google Spreadsheet)(https://spreadsheets.google.com/ccc?key=0AmS_90rPaQMzcHdyU1d0MDVMLWphMFdTOHUwVHFqWnc&hl=en), along with previous cDNA batch numbers. Actual RT master mix set up is here. Samples were given to Lisa for qPCR analysis."
  },
  {
    "objectID": "posts/2009/2009-10-09-dnase-treatment-tims-adult-gigas-challenge-rna-from-20090930/index.html",
    "href": "posts/2009/2009-10-09-dnase-treatment-tims-adult-gigas-challenge-rna-from-20090930/index.html",
    "title": "DNase Treatment - Tim’s adult gigas challenge RNA (from 20090930)",
    "section": "",
    "text": "Used 5uL of RNA from each sample, brought samples up to 50uL with H2O and treated according to Ambion’s Turbo DNA-free kit. Rigorous protocol was followed (1.5uL DNase initially + 1.5uL additional DNase after 30mins). Transferred treated samples to a PCR plate to facilitate further manipulation of the samples. Will perform qPCR on these samples to make sure treatment worked."
  },
  {
    "objectID": "posts/2009/2009-12-31-qpcr-bb-dh-cdna-from-20091223/index.html",
    "href": "posts/2009/2009-12-31-qpcr-bb-dh-cdna-from-20091223/index.html",
    "title": "qPCR - BB & DH cDNA (from 20091223)",
    "section": "",
    "text": "qPCR was set up on these cDNAs using the following primers:\nFP008495.p.cg.6 (“GSTO1”, “Glutathione S-transferase omega-1”) - This was upregulated in BB SOLiD data.\nThese were run in duplicate to take up a full PCR plate. qPCR set up and plate layout can be found here.\nResults:\nqPCR Data File (Opticon): 20091231_152520.tad\nData workup: PROPS BB_DH Gene Expression Miner Workup"
  },
  {
    "objectID": "posts/2009/2009-01-22-rna-isolation-hard-clam-hemo-from-20090121/index.html",
    "href": "posts/2009/2009-01-22-rna-isolation-hard-clam-hemo-from-20090121/index.html",
    "title": "RNA Isolation - Hard clam hemo (from 20090121)",
    "section": "",
    "text": "The 8 hemo samples were pooled and the 4 gonad/d.g. samples were pooled. RNA was isolated. The homo sample was resuspended in 100uL of 0.1%DEPC-H2O and the gonad/d.g. sample was resuspended in 50uL 0.1%DEPC-H2O. RNA was precipitated O/N @ -20C according to Ambion PolyA Purist protocol in preparation for mRNA isolation."
  },
  {
    "objectID": "posts/2009/2009-03-17-mrna-sample-submission-hard-clam-gill-1-mrna-from-20090313/index.html",
    "href": "posts/2009/2009-03-17-mrna-sample-submission-hard-clam-gill-1-mrna-from-20090313/index.html",
    "title": "mRNA Sample Submission Hard clam gill #1 mRNA from 20090313",
    "section": "",
    "text": "Submitted four samples (4uL of each) for Agilent Bioanlyzer:\nSR01 = total RNA\nSR02 = Ambion kit x 1\nSR03 = Ambion kit x 2\nSR04 = PolyA Tract kit\nResults:"
  },
  {
    "objectID": "posts/2009/2009-09-29-etoh-precipitation-ricks-trout-ribosomoal-depleted-rna-for-solid-wtk-from-today/index.html",
    "href": "posts/2009/2009-09-29-etoh-precipitation-ricks-trout-ribosomoal-depleted-rna-for-solid-wtk-from-today/index.html",
    "title": "EtOH Precipitation - Rick’s trout Ribosomoal-depleted RNA for SOLiD WTK (from today)",
    "section": "",
    "text": "The “control” and “poly I:C” samples prepared earlier today were EtOH precipitated in preparation for fragmentation.\nAdded the following to each sample:\n\n18uL 5M ammonium acetate\n1uL glycogen\n2 vols. of 100% EtOH (74uL)\n\nSamples were incubated O/N @ -80C."
  },
  {
    "objectID": "posts/2009/2009-01-23-rna-hard-clam-hemo-rna-from-20090121/index.html",
    "href": "posts/2009/2009-01-23-rna-hard-clam-hemo-rna-from-20090121/index.html",
    "title": "RNA - Hard clam hemo RNA (from 20090121)",
    "section": "",
    "text": "The two RNA samples from yesterday were precipitated and washed according to the Ambion PolyA Purist protocol and resuspended in 50uL of 0.1% DEPC-H2O.\n\nResults: RNA readings look better than they did prior to precipitation. The hemo RNA samples will be combined with previous hemo RNA samples and mRNA will be isolated using the Ambion PolyA Purist Kit."
  },
  {
    "objectID": "posts/2009/2009-06-13-qpcr-dnased-mv-hemocyte-rna-from-earlier-today-and-turbo-kit-test/index.html",
    "href": "posts/2009/2009-06-13-qpcr-dnased-mv-hemocyte-rna-from-earlier-today-and-turbo-kit-test/index.html",
    "title": "qPCR - DNased MV hemocyte RNA from earlier today AND Turbo kit test",
    "section": "",
    "text": "qPCR set up/plate layout is here. Used Cv_18s_F/R primers for the MV hemocyte RNA and Gigas_18s_F/R primers for the Turbo kit test. Anneal 55C.\nResults: DNase treatment worked on all but the following samples: B23, B14, A21. However, these three samples were slightly below the initial, background fluorescence in each sample. The Turbo kit test indicates that all three kits are working perfectly and all can/should be used with confidence for treating samples."
  },
  {
    "objectID": "posts/2009/2009-03-13-rna-precipitation-hard-clam-gill-1-rna-from-20080819/index.html",
    "href": "posts/2009/2009-03-13-rna-precipitation-hard-clam-gill-1-rna-from-20080819/index.html",
    "title": "RNA Precipitation - Hard clam gill #1 RNA from 20080819",
    "section": "",
    "text": "DNAsed RNA using Ambion Turbo DNA-free kit, following the rigorous procedure. Diluted total RNA to 0.2ug/uL (Vf = 720uL). Added 1uL DNase and incubated the tube @ 37C for 30mins. Added an additional 1uL DNase and continued incubated for 30mins. Added 0.2 volumes of DNase Inactivation Reagent (158.4uL) and incubated at RT for 10mins with periodic mixing. Pelleted inactivation reagent according to protocol and transferred supe (DNA-free RNA) to clean tube.\n\nResults: RNA looks really nice. Have a large quantity of RNA (700uL x 0.2275ug/uL = 159.25ug). Will split into four equal parts and isolate mRNA from 3 of the 4. Those three will be:\n\nAmbion kit x 1\nAmbion kit x 2\nPromega PolyA Tract kit."
  },
  {
    "objectID": "posts/2009/2009-06-06-dnase-treatment-abalone-dg-rna-isolated-yesterday-and-from-20090518/index.html",
    "href": "posts/2009/2009-06-06-dnase-treatment-abalone-dg-rna-isolated-yesterday-and-from-20090518/index.html",
    "title": "DNase Treatment - Abalone Dg RNA isolated yesterday and from 20090518",
    "section": "",
    "text": "RNA from yesterday was treated according to Ambion Turbo DNA-free protocol to remove gDNA contamination. Work up is here."
  },
  {
    "objectID": "posts/2009/2009-06-09-dnase-treatment-abalone-dg-dnased-rna-from-20090605-2/index.html",
    "href": "posts/2009/2009-06-09-dnase-treatment-abalone-dg-dnased-rna-from-20090605-2/index.html",
    "title": "DNase Treatment - Abalone Dg DNased RNA from 20090605",
    "section": "",
    "text": "Had to re-treat these samples due to residual gDNA that was NOT eliminated the first time through. Possible old Ambion kit??"
  },
  {
    "objectID": "posts/2009/2009-07-17-qpcr-abalone-cdna-0712-set-from-332009-by-lisa-and-dnased-rna-from-20090623-3/index.html",
    "href": "posts/2009/2009-07-17-qpcr-abalone-cdna-0712-set-from-332009-by-lisa-and-dnased-rna-from-20090623-3/index.html",
    "title": "qPCR - Abalone cDNA (07:12 set from 3/3/2009 by Lisa) and DNased RNA (from 20090623)",
    "section": "",
    "text": "This is nearly a repeat of the qPCR earlier today due to the fact that the positive control never amplified. This is being done to check whether or not there is gDNA contamination in these cDNA and DNased RNA. Will use H.crach_h-1fg_intron primers. In hopes of remedying the positive control issue, I have used three sets of gDNA and used 5uL instead of the usual 1uL for their respective reactions. qPCR plate layout/set up is here. Anneal temp 50C.\nResults: No detectable amplification in any gDNA sample. However, one sample did produce a melting curve peak, while no other samples did. Still doesn’t provide me with anything useable. Will get good gDNA from Freidman Lab ASAP."
  },
  {
    "objectID": "posts/2009/2009-04-20-gdna-removal-abalone-rna-from-20090402-and-20090331/index.html",
    "href": "posts/2009/2009-04-20-gdna-removal-abalone-rna-from-20090402-and-20090331/index.html",
    "title": "gDNA Removal - Abalone RNA from 20090402 and 20090331",
    "section": "",
    "text": "Transferred 50uL of RNA to fresh tubes and processed them using the Ambion Turbo DNA-free kit according to the manufacturer’s protocol."
  },
  {
    "objectID": "posts/2009/2009-04-15-pcr-two-new-dungan-isolates-from-earlier-today/index.html",
    "href": "posts/2009/2009-04-15-pcr-two-new-dungan-isolates-from-earlier-today/index.html",
    "title": "PCR - Two new Dungan isolates from earlier today",
    "section": "",
    "text": "Set up PCRs on:\nMIE-14y\nVNTc-1.2-C1/G10\nUsed Euk A/B and LABY A/Y primers. Anneal temp 50C. PCR set up is here.\nNOTE: Due to the extremely low concentrations of gDNA from these two samples, I used a large amount of gDNA in the rxns. Check the PCR set up link for actual numbers.\nLane 1 - Hyperladder (5uL)\nLane 2 - VNTc-1.2-C1/G10 (Euk primers)\nLane 3 - MIE-14y (Euk primers)\nLane 4 - H2O (Euk primers)\nLane 5 - H2O (Euk primers)\nLane 6 - VNTc-1.2-C1/G10 (Laby primers)\nLane 7 - MIE-14y (Laby primers)\nLane 8 - H2O (Laby primers)\nLane 9 - H2O (Laby primers)\nlane 10 - 100bp Ladder\nResults: Nada. Probably because of low [gDNA], but could also be due to PCR inhibitors in the gDNA. Will retry using Amplitaq and less gDNA."
  },
  {
    "objectID": "posts/2009/2009-08-27-qpcr-gigas-gdna-test-of-recalibrated-opticon-2/index.html",
    "href": "posts/2009/2009-08-27-qpcr-gigas-gdna-test-of-recalibrated-opticon-2/index.html",
    "title": "qPCR - Gigas gDNA test of recalibrated Opticon 2",
    "section": "",
    "text": "Master mix containing Gigas gDNA will be used to verify that the recalibration did work. qPCR setup/plate layout is here. I’ve made a master mix using Cg_HSP70_F/R primers designed by Mac. gDNA is BB #12 (0.445ug/uL) from 20090519. The gDNA will be added to the master mix.\nResults: The results are a bit disconcerting, as this run shows virtually the exact same pattern in fluorescence detection as that on 20090722, despite using a different set of gigas gDNA. Below is a set of graphs comparing Column 1 Ct values of the two tests from 20090722 and today:\n\nClearly, both runs exhibit virtually the same pattern of relative Ct values to each other in each respective run. Not cool."
  },
  {
    "objectID": "posts/2009/2009-05-18-c-pugetti-liquid-cultures/index.html",
    "href": "posts/2009/2009-05-18-c-pugetti-liquid-cultures/index.html",
    "title": "C.pugetti - Liquid Cultures",
    "section": "",
    "text": "Inoculated 2 x 1L of 1x Marine Broth + biphenyl crystals (in 2L flasks) using 5mL of liquid culture from 20090501. Incubated at 28C 200RPM."
  },
  {
    "objectID": "posts/2009/2009-05-18-rna-isolation-abalone-dg-project-samples-2/index.html",
    "href": "posts/2009/2009-05-18-rna-isolation-abalone-dg-project-samples-2/index.html",
    "title": "RNA Isolation - Abalone Dg Project samples",
    "section": "",
    "text": "Isolated RNA from Abalone Dg samples (see below) using MoBio RNA PowerSoil Kit according to protocol. RNA was stored @ -80C.\n\nResults: RNA quality looks great, as usual. Sample 06:6-44 has a very low yield, but was to be expected due to very small amount of starting tissue."
  },
  {
    "objectID": "posts/2009/2009-05-15-gdna-isolation-macs-bb-and-dh-site-samples/index.html",
    "href": "posts/2009/2009-05-15-gdna-isolation-macs-bb-and-dh-site-samples/index.html",
    "title": "gDNA Isolation - Mac’s BB and DH site samples",
    "section": "",
    "text": "Due to failure of gDNA isolation via the TriReagent method (see 20090511) used Qiagen DNeasy Kit. Digested samples for 3 hrs. at 55C in Proteinase K according to protocol. Performed on a subset of each site samples: BB#11-18 & DH#11-18.\n\nResults: Excellent yields and superb quality."
  },
  {
    "objectID": "posts/2009/2009-03-03-qpcr-repeat-of-qpcr-from-earlier-today-with-fresh-primer-working-stocks/index.html",
    "href": "posts/2009/2009-03-03-qpcr-repeat-of-qpcr-from-earlier-today-with-fresh-primer-working-stocks/index.html",
    "title": "qPCR - Repeat of qPCR from earlier today with fresh primer working stocks",
    "section": "",
    "text": "This is an exact repeat of the qPCR from earlier today, but using a fresh working stock of the Vtub_16s_V3 primers. The plate layout/qPCR workup is here.\nResults: Same as earlier today. Must be a bacterial contaminant somehwere that these 16s primers are picking up. Will order IGS primers that are species specific found in Lee et al. 2002."
  },
  {
    "objectID": "posts/2009/2009-06-23-dnase-treatment-abalone-dg-dnased-rna-20090610/index.html",
    "href": "posts/2009/2009-06-23-dnase-treatment-abalone-dg-dnased-rna-20090610/index.html",
    "title": "DNase Treatment - Abalone Dg DNased RNA 20090610",
    "section": "",
    "text": "This is the 4th time this RNA has been DNased. Performed using Ambion’s Tubro DNA-free Kit. Followed the “rigorous” treatment protocol."
  },
  {
    "objectID": "posts/2009/2009-05-11-dna-isolation-macs-gigas-samples-from-20090505-20090506/index.html",
    "href": "posts/2009/2009-05-11-dna-isolation-macs-gigas-samples-from-20090505-20090506/index.html",
    "title": "DNA Isolation - Mac’s gigas samples from 20090505 & 20090506",
    "section": "",
    "text": "Isolated gDNA according to Molecular Research Center TriReagent protocol from BB#1-20 and DH#1-20. Resuspended DNA in 600uL of 8mM NaOH. Spec.\n\nResults: HORRIBLE! This is some of the worst “DNA” I’ve ever seen. Peaks everywhere EXCEPT at 260nm. Here’s a link to the actual numbers. It’s a text file and is comma separated, so you should open with Excel for it to be readable.\nSpoke with Steven. Will pursue RNA instead of continuing down this path for now."
  },
  {
    "objectID": "posts/2009/2009-01-14-bleeding-hard-clams/index.html",
    "href": "posts/2009/2009-01-14-bleeding-hard-clams/index.html",
    "title": "Bleeding - Hard Clams",
    "section": "",
    "text": "Bled 7 clams from 20090108 and 20090109. Bled clams using a 23g 1.5 needle on a 3mL syringe. Fluid was gathered and ranged from ~0.4-1.0mL. Hemolymph was transferred to individual 1.5mL snap cap tubes and spun @ 100g for 30mins @ 4C. Most of the supe was removed, but left ~100uL in each tube to avoid disturbing any pellet. Samples were stored @ -80C in the red box with previous hard clam hemo samples.\nNOTE: One sample was EXTREMELY cloudy. Likely not hemos."
  },
  {
    "objectID": "posts/2009/2009-06-23-qpcr-dnased-abalone-dg-rna-from-earlier-today-and-the-0712-set-dnased-by-lisa-20090306/index.html",
    "href": "posts/2009/2009-06-23-qpcr-dnased-abalone-dg-rna-from-earlier-today-and-the-0712-set-dnased-by-lisa-20090306/index.html",
    "title": "qPCR - DNased Abalone Dg RNA from earlier today AND the 07:12 set (DNased by Lisa 20090306)",
    "section": "",
    "text": "Set up qPCR using H.crach_16s_SYBR_F/R primers. Plate layout/set up is here.\nResults: Waters are clean, but fluorescence still coming up in the samples!"
  },
  {
    "objectID": "posts/2009/2009-09-24-mrna-isolation-ricks-trout-rbc-samples-previously-treated-with-ribominus-kit-by-mac/index.html",
    "href": "posts/2009/2009-09-24-mrna-isolation-ricks-trout-rbc-samples-previously-treated-with-ribominus-kit-by-mac/index.html",
    "title": "mRNA Isolation - Rick’s trout RBC samples previously treated with Ribominus Kit (by Mac)",
    "section": "",
    "text": "Was given ~0.5ug of each of these two RNA samples and processed them with Ambion’s microPolyA Purist Kit according to protocol. After elution, the samples were EtOH precipitated @ -80C for 30mins, pelleted 30mins 16,000g for 30mins, 4C. Supe removed, RNA washed with 1mL 70% EtOH and spun 10mins 16,000g, 4C. Supe removed. Resusupended in 8uL of The RNA Storage Solution and spec’d.\nResults:\n\nYield of ~320ng for RBC Control sample and ~360ng for RBC poly1:C sample. Will proceed to Whole Transctiptome Kit fragmentation step."
  },
  {
    "objectID": "posts/2009/2009-10-08-bioanalyzer-submission-trout-rbc-colleens-gigas-ge-sample-macs-dhbb-pcr-for-solid-wtk/index.html",
    "href": "posts/2009/2009-10-08-bioanalyzer-submission-trout-rbc-colleens-gigas-ge-sample-macs-dhbb-pcr-for-solid-wtk/index.html",
    "title": "Bioanalyzer Submission - Trout RBC, Colleen’s gigas GE sample, Mac’s DH/BB PCR for SOLiD WTK",
    "section": "",
    "text": "Samples were delivered for analysis on the DNA 1000 chip.\nUPDATE 20091008 They do not have the DNA 1000 kit in stock. Will be using High Sensitivity Kit instead. Will have in stock on Tuesday.\nResults:"
  },
  {
    "objectID": "posts/2009/2009-05-12-dnase-treatment-rigorous-macs-gigas-rnare-dnased-rna-from-20090507-20090508-respectively/index.html",
    "href": "posts/2009/2009-05-12-dnase-treatment-rigorous-macs-gigas-rnare-dnased-rna-from-20090507-20090508-respectively/index.html",
    "title": "DNase Treatment (Rigorous!) - Mac’s gigas RNA/Re-DNased RNA from 20090507 & 20090508, respectively",
    "section": "",
    "text": "Followed the rigorous protocol for Ambion’s Turbo DNA-free protocol for the following RNAs:\nBB#11-20\nDH#11-20\nUsed 10ug of RNA (200ng/uL) in 50uL as directed. Here are the calcs for FF and DH.\nFollowed standard protocol on DNased samples from 20090508:\nBB#1-10\nDH#1-10\nThe standard protocol should be fine for these samples, since the procedure worked on Friday for some of them."
  },
  {
    "objectID": "posts/2009/2009-04-03-qpcr-abalone-rna-check-for-gdna/index.html",
    "href": "posts/2009/2009-04-03-qpcr-abalone-rna-check-for-gdna/index.html",
    "title": "qPCR - Abalone RNA, check for gDNA",
    "section": "",
    "text": "Abalone RNA isolated from this week was qPCR’s with 16s primers to determine if gDNA contamination was present. PCR/plate layout is here.\nResults: All samples appear to have gDNA contamination. Will use Qiagen QT Kit for cDNA."
  },
  {
    "objectID": "posts/2009/2009-06-16-qpcr-mv-hemocyte-cdna-test-immomix-syto13-vs-strategene-sybr/index.html",
    "href": "posts/2009/2009-06-16-qpcr-mv-hemocyte-cdna-test-immomix-syto13-vs-strategene-sybr/index.html",
    "title": "qPCR - MV hemocyte cDNA: Test Immomix (SYTO13) vs. Strategene SYBR",
    "section": "",
    "text": "Due to craziness seen in melting curves, fluorescence, and empty wells from the previous run, will compare SYTO vs. SYBR with select MV cDNAs. Additionally, acquired some qPCR strip caps to use instead of the ABI film. Used Cv_18s_F/R primers. qPCR set up/plate layout is here.\nResults: Both seem to work fine. H2O fluorescence is weird, but doesn’t come up in the melting curves. Strategene SYBR provides a brighter signal, but results in a higher melting temp than the SYTO."
  },
  {
    "objectID": "posts/2009/2009-07-11-qpcr-abalone-gdnacdna/index.html",
    "href": "posts/2009/2009-07-11-qpcr-abalone-gdnacdna/index.html",
    "title": "qPCR - Abalone gDNA/cDNA",
    "section": "",
    "text": "Due to lack of amplification in gDNA samples from 20090710 and 20090708 with either set of intron primers, will repeat with additional gDNA samples to make sure the primers are the problem and not the gDNA. Used the H.iris_actin_intron_Fw/Rv and the H.crach_h-1fg_intron_Fw/Rv primers. PCR setup/plate layout is here. Anneal temp 50C.\nResults: Got a weak signal (C(t) ~ 37) in only the 06:50-9 rxns, but it did work with both primer sets."
  },
  {
    "objectID": "posts/2009/2009-01-12-bleeding-hard-clams-2/index.html",
    "href": "posts/2009/2009-01-12-bleeding-hard-clams-2/index.html",
    "title": "Bleeding - Hard Clams",
    "section": "",
    "text": "Bled 8 clams from 20090108 and 20090109, #4, 6, 8, 15, 16, 17, 21, 26. Bled clams using a 23g 1.5 needle on a 3mL syringe. Fluid was gathered and ranged from ~0.4-1.0mL. Hemolymph was transferred to individual 1.5mL snap cap tubes and spun @ 100g for 30mins @ 4C. Most of the supe was removed, but left ~100uL in each tube to avoid disturbing any pellet. Samples were stored @ -80C in the red box with previous hard clam hemo samples.\nPellets were apparent in all 8 samples, whereas they had not been noticeable before in last week’s bleeds.\nAlso, 3 clams were found with cracked shells, but alive, including the one pictured below that is split open entirely."
  },
  {
    "objectID": "posts/2009/2009-03-14-mrna-isolation-hard-clam-gill-1-continued-from-yesterday/index.html",
    "href": "posts/2009/2009-03-14-mrna-isolation-hard-clam-gill-1-continued-from-yesterday/index.html",
    "title": "mRNA Isolation - hard clam gill #1 continued from yesterday",
    "section": "",
    "text": "Precipitation was continued from yesterday. Samples were resuspended in 25uL of The RNA Storage Solution (from PolyAPursit Kit) and spec’d. Samples were stored @ -80C in Sam’s RNA box."
  },
  {
    "objectID": "posts/2009/2009-07-09-pcr-baysea-scallop-dna/index.html",
    "href": "posts/2009/2009-07-09-pcr-baysea-scallop-dna/index.html",
    "title": "PCR - Bay/Sea Scallop DNA",
    "section": "",
    "text": "An additional attempt to get the actin primers to work for use in screening samples for bay/sea scallop hybrids. The scallop_actin_fw primer was used in conjunction with the following:\nbay_actin_Rv0 (Rxn 1)\nbay_actin_Rv2 (Rxn 2)\nsea_actin_Rv4 (Rxn 3)\nsea_actin_Rv5 (Rxn 4)\nPCR set up is here. Just used Bay or Sea scallop gDNA (chelexed). When/If get this working correctly, will start screening the hybrid samples. Anneal of 53C.\n\nLane 1 - 100bp Ladder\nLane 2 - Rxn 1: Bay\nLane 3 - Rxn 1: Sea\nLane 4 - Rxn 1: H2O\nLane 5 - Rxn 1: H2O\nLane 6 - Rxn 2: Bay\nLane 7 - Rxn 2: Sea\nLane 8 - Rxn 2: H2O\nLane 9 - Rxn 2: H2O\nLane 10 - Rxn 3: Bay\nLane 11 - Rxn 3: Sea\nLane 12 - Rxn 3: H2O\nLane 13 - Rxn 3: H2O\nLane 14 - Rxn 4: Bay\nLane 15 - Rxn 4: Sea\nLane 16 - Rxn 4: H2O\nLane 17 - Rxn 4: H2O\nLane 18 - 100bp Ladder\nResults: Rxn 1 shows amplification with both Bay & Sea Scallop gDNA. The bands are close in size, but look like they would be more distinguishable if run on higher percentage gel and for a longer period of time to get better separation. However, there is contamination in one of the two water samples..\nRxn 2 shows amplification of only the Bay Scallop gDNA.\nRxn 3 shows amplification in both Bay & Sea Scallop gDNA and both bands are of the exact same size.\nRxn 4 shows no amplification in either set of gDNA.\nUsing the primers used in Rxn 1 will probably allows us to succesfully screen potential hybrids. Just need to remember to use high-percentage agarose gels and run samples for longer periods of time to get sufficient separation."
  },
  {
    "objectID": "posts/2009/2009-01-13-rna-reprecipitation-of-hard-clam-rna-from-yesterday/index.html",
    "href": "posts/2009/2009-01-13-rna-reprecipitation-of-hard-clam-rna-from-yesterday/index.html",
    "title": "RNA - Reprecipitation of hard clam RNA from yesterday",
    "section": "",
    "text": "Because of the relatively large size of the pellets vs. the amount of RNA, I think another round of precipitation would be best to help remove additional residual salt carryover. Will precipitate O/N according to Ambion PolyA Purist protocol. RNA pellets were resuspended in 250uL of 0.1%DEPC-H2O and precipitated O/N @ -20C.\nNOTE: Upon adding 100% EtOH to sample, the solution turned very cloudy and a white precipitate immediately formed inside the tube. I do not think this precipitate is RNA. Tomorrow, before spinning the tube, I will transfer the supe to a fresh tube and process both tubes simultaneously. Hopefully this will remove/eliminate most of the excess salt or whatever seems to be forming the pellet."
  },
  {
    "objectID": "posts/2009/2009-12-02-mbl-shipment-hard-clam-gill-tissue-in-rna-later/index.html",
    "href": "posts/2009/2009-12-02-mbl-shipment-hard-clam-gill-tissue-in-rna-later/index.html",
    "title": "MBL Shipment - Hard Clam gill tissue in RNA Later",
    "section": "",
    "text": "Received samples from Scott Lindell today. Two Ziplock bags taped together labelled “11/16/09 Clams scudders.” The bags contain 2mL screw cap tubes with small tissue samples in RNA later. One group of tubes is labelled with FL-3 # and the other group with BX-4 #. Samples will be stored at 4C to be processed later this month."
  },
  {
    "objectID": "posts/2009/2009-08-24-qpcr-additional-calibration-test-of-opticon-2/index.html",
    "href": "posts/2009/2009-08-24-qpcr-additional-calibration-test-of-opticon-2/index.html",
    "title": "qPCR - Additional Calibration test of Opticon 2",
    "section": "",
    "text": "Based on recs from Bio-Rad rep (Carl Fisher), will repeat Opticon 2 calibration (see 20090813) test according to Opticon manual. Then, will rotate plate 180 degrees and repeat test and upload data to Bio-Rad server for analysis and evaluation.\nResults: According to the Bio-Rad rep, he thinks recalibration is in order. He pointed out that we’re seeing a 3-fold spread in fluorescence, which is outside of the “tolerable” range (which is 2-fold). Will recalibrate."
  },
  {
    "objectID": "posts/2009/2009-02-24-rna-isolation-v-tubiashii-samples-from-autoclaved-gigas-exposure-from-20081218/index.html",
    "href": "posts/2009/2009-02-24-rna-isolation-v-tubiashii-samples-from-autoclaved-gigas-exposure-from-20081218/index.html",
    "title": "RNA Isolation - V.tubiashii samples from autoclaved gigas exposure (from 20081218)",
    "section": "",
    "text": "RNA was isolated from the Control and V.tub+gigas samples from the 0, 1, & 24hr time points using 1mL TriReagent. No visible pellets. Used 20uL of 0.1%DEPC-H2O to resuspend RNA. Incubated @ 55C, 5mins. Spec’d.\n\nResults: RNA looks OK, but not great. For the “V.tub + gigas t=1” sample, the third spec reading is correct. The first two had the air bubble error.\n\nDNAse Treatment - V.tubiashii total RNA (see above)\n1ug of RNA in a volume of 12uL was DNAsed using the Ambion DNA-free Kit according to their protocol. RNA was transferred to a fresh tube and stored @ -80C in Sam’s RNA Box #1."
  },
  {
    "objectID": "posts/2009/2009-02-28-qpcr-new-16s-primers-for-v-tubiashii-control-vs-autoclaved-gigas-samples-see-20090224/index.html",
    "href": "posts/2009/2009-02-28-qpcr-new-16s-primers-for-v-tubiashii-control-vs-autoclaved-gigas-samples-see-20090224/index.html",
    "title": "qPCR - New 16s primers for V.tubiashii Control vs. Autoclaved gigas samples (see 20090224)",
    "section": "",
    "text": "qPCR was performed using SensiMix/SYBR “kit” with DNAsed RNA samples from 20090224. This qPCR used the new V.tub_16s_V3 primers in hopes of getting better amplification; both in signal intensity and elimination of the double peak seen in the melting curves from 20090224. The plate layou/qPCR workup is here.\nResults: Fluorescence comes up WAY too early; at like the 5th cycle! Also, there are two peaks in the melting curves. Additionally, there is a signal in the two water samples and the melting curve for this contamination matches up with one of the melting cure peaks seen in the actual sample melting curves. So, there is some sort of contamination somehwere. Will repeat this using a clean water for the master mix and hope the problem goes away."
  },
  {
    "objectID": "posts/2009/2009-07-13-pcr-dungan-isolate-mie-14v-gdna-from-20090708/index.html",
    "href": "posts/2009/2009-07-13-pcr-dungan-isolate-mie-14v-gdna-from-20090708/index.html",
    "title": "PCR - Dungan isolate (MIE-14v) gDNA from 20090708",
    "section": "",
    "text": "PCR of MIE-14v just to make sure that we can’t get a product from this sample, despite NanoDrop readings suggesting that there’s no DNA. Used both LABY and Euk primer sets. PCR set up is here. Anneal temp 50C.\n\nLane 1 - 100bp Ladder\nLane 2 - Euk\nLane 3 - Euk H2O\nLane 4 - Euk H2O\nLane 5 - Euk H2O\nLane 6 - LABY\nLane 7 - LABY H2O\nLane 8 - LABY H2O\nLane 9 - LABY H2O\nLane 10 - 100bp Ladder\nResults: Nothing, as expected. Need to devise a new method of isolating gDNA from these “problem” isolates."
  },
  {
    "objectID": "posts/2009/2009-10-27-mrna-isolation-herring-liver-rna-from-20091021/index.html",
    "href": "posts/2009/2009-10-27-mrna-isolation-herring-liver-rna-from-20091021/index.html",
    "title": "mRNA Isolation - Herring Liver RNA (from 20091021)",
    "section": "",
    "text": "Isolated mRNA using Ambion’s MicroPolyA Purist Kit according to protocol. Performed two rounds of isolation to decrease residual rRNA carryover that we frequently see after a single round.\nResults:\n\nStarted with ~500ug. Total yield = 5.3ug. That is a 1.06% recovery of mRNA."
  },
  {
    "objectID": "posts/2009/2009-12-15-reverse-transcription-sepia-dnased-rna/index.html",
    "href": "posts/2009/2009-12-15-reverse-transcription-sepia-dnased-rna/index.html",
    "title": "Reverse Transcription - Sepia DNased RNA",
    "section": "",
    "text": "DNase Treatment - Sepia RNA (from 20091204)\nSamples were DNase treated with Ambion’s Turbo DNA-free kit, following the rigorous protocol. Used 6uL of each sample, brought up to 50uL with H2O, added 5uL of 10x buffer and 1.5uL of DNase. Incubated 37C for 30mins, added an additional 1uL of DNase and incubated @ 37C for 30mins. Added 0.2 volumes of DNase Inactivation reagent and incubated at RT for 2mins with regular mixing. Spec’d RNA.\nResults:\n\n\n\nSet up reverse transcription rxns using 200ng of each DNased RNA, using Promega oligo dT primers and M-MLV Reverse Transcriptase according to Promega protocol. RNA/Oligo dT primer workup here. Primer and DNAsed RNA were mixed and brought up to 18.25uL with H2O. Samples were heated @ 70C for 5mins and then placed immediately on ice. The RT master mix set up can be found here. 6.75uL of the RT master mix was added to each tube, mixed, spot spun and then incubated @ 42C for 1hr, heat inactivated @ 95C for 3mins and stored @ 4C."
  },
  {
    "objectID": "posts/2009/2009-11-06-oyster-co2mechanical-stress-water-quality/index.html",
    "href": "posts/2009/2009-11-06-oyster-co2mechanical-stress-water-quality/index.html",
    "title": "Oyster CO2/Mechanical Stress - Water quality",
    "section": "",
    "text": "See Rachel’s 441 Notebook from 10/28/2009 through 11/4/2009 for experiment info. 500mL of water was collected from the CO2 and the air tanks. Water was vacuum filtered through Watman paper. The Watman paper was allowed to dry over the weekend.\nResults:\nCO2 = 35.9mg\nAir = 14.4mg"
  },
  {
    "objectID": "posts/2009/2009-09-11-hrms-lake-trout-snps-hrm_white-03-hrm_white-04/index.html",
    "href": "posts/2009/2009-09-11-hrms-lake-trout-snps-hrm_white-03-hrm_white-04/index.html",
    "title": "HRMs - Lake Trout SNPs (HRM_white-03 & HRM_white-04)",
    "section": "",
    "text": "HRM_white-03\nThe following primers from primer plate LTP01 will be used for analysis of Rick’s Lake Trout DNA1 plate (from 4/28/2009): E4, B5, A7, D7. HRM set up is here. It is the same as that used on 20090903. A 1:10 dilution plate (from 20090903) of Rick’s Lake Trout DNA1 plate (from 4/28/2009) was used. This means approximately 20ng of DNA used in each rxn. The robot was used to add 1uL of DNA from the 96-well plate to the appropriate wells of the 384-well HRM rxn plate. Plate was spun to collect the DNA at the bottom of the wells. The wells were visually inspected to ensure that each received the DNA. 1uL of DNA was manually added to those wells that did not receive sample.\nThe master mix for each primer set was then manually dispensed to the appropriate wells in the 384-well HRM rxn plate using a “matrix” auto-pipette. The real-time PCR was run in a Roche LightCycler480 machine with the following cycling paramters:\n95C - 15mins\n45 cycles of:\n95C - 10s\n60C - 15s\n72C - 25s\nAfter the completion of the real-time run, the plate was put through the High Melt Curve protocol.\n\n\nHRM_white-04\nThe following primers from primer plate LTP01 will be used for analysis of Rick’s Lake Trout DNA1 plate (from 4/28/2009): H7, B8, C8, F10. HRM set up is here. It is the same as that used on 20090903. A 1:10 dilution plate (from 20090903) of Rick’s Lake Trout DNA1 plate (from 4/28/2009) was used. This means approximately 20ng of DNA used in each rxn. The robot was used to add 1uL of DNA from the 96-well plate to the appropriate wells of the 384-well HRM rxn plate. Plate was spun to collect the DNA at the bottom of the wells. The wells were visually inspected to ensure that each received the DNA. 1uL of DNA was manually added to those wells that did not receive sample.\nThe master mix for each primer set was then manually dispensed to the appropriate wells in the 384-well HRM rxn plate using a “matrix” auto-pipette. The real-time PCR was run in a Roche LightCycler480 machine with the following cycling paramters:\n95C - 15mins\n45 cycles of:\n95C - 10s\n60C - 15s\n72C - 25s\nAfter the completion of the real-time run, the plate was put through the High Melt Curve protocol."
  },
  {
    "objectID": "posts/2009/2009-02-19-sample-submission-v-tubiashii-mass-spec/index.html",
    "href": "posts/2009/2009-02-19-sample-submission-v-tubiashii-mass-spec/index.html",
    "title": "Sample Submission - V.tubiashii Mass Spec",
    "section": "",
    "text": "Vibrio samples (2-1 and 2-2) from 20090212 were submitted to the mass spec facility."
  },
  {
    "objectID": "posts/2009/2009-04-09-pcr-dungan-isolates-from-20090402-with-euk-primers/index.html",
    "href": "posts/2009/2009-04-09-pcr-dungan-isolates-from-20090402-with-euk-primers/index.html",
    "title": "PCR - Dungan isolates from 20090402 with Euk primers",
    "section": "",
    "text": "Did PCR with new Euk primers designed by Steven. Should be one step higher taxonomically. PCR set up is here. Aneal temp 50C.\n\nLane 1 - Hyperladder\nLane 2 - 19t\nLane 4 - 13t\nLane 6 - 17t\nLane 7 - 100bp ladder\nLane 8 - 1.5t\nLane 10 - 1.2t\nLane 11 - Hyperladder\nLane 12 - 11t\nLane 14 - H5\nLane 15 - 100bp ladder\nLane 16 - 12t\nLane 18 - H2O\nLane 19 - H2O\nLaen 20 - Hyperladder\nResults: The new EukA/B primers worked wonderfully. The brightest band in each lane was excised and purified using Millipore DA spin columns. These will be stored and sequenced at a later date."
  },
  {
    "objectID": "posts/2009/2009-11-11-sequencing-lake-trout-hrm/index.html",
    "href": "posts/2009/2009-11-11-sequencing-lake-trout-hrm/index.html",
    "title": "Sequencing - Lake Trout HRM",
    "section": "",
    "text": "This is a second submission of 12 individuals from 8 primer sets. The previous sequencing run was botched because I used the combined primer plate instead of a single (forward or reverse) primer for submission.\nSequence log"
  },
  {
    "objectID": "posts/2009/2009-12-28-qpcrs-bb-dh-cdna-from-20091223-2/index.html",
    "href": "posts/2009/2009-12-28-qpcrs-bb-dh-cdna-from-20091223-2/index.html",
    "title": "qPCRs - BB & DH cDNA (from 20091223)",
    "section": "",
    "text": "qPCR was set up on these cDNAs using the following primers:\nAM861391.p.cg.6 (“BDEF”, “Big Defensin”) - This was upregulated in DH SOLiD data.\nAM904566.p.cg.6 (“GNRR2”, “Gonadotropin-releasing hormone II receptor”) - This was upregulated in DH SOLiD data.\nqPCR set up and plate layout can be found here.\nResults:\nqPCR Data File (Opticon): 20091228_102019.tad\nData workup: PROPS BB_DH Gene Expression Miner Workup\nqPCR was set up on these cDNAs using the following primers:\nCU988730.p.cg.6 (“TIMP3”, “Metalloprotease inhibitor 3”) - This was upregulated in DH SOLiD data.\nCU990442.p.cg.6 (“CALL”, “Calmodulin-like protein”) - This was upregulated in DH SOLiD data.\nqPCR set up and plate layout can be found here.\nResults:\nqPCR Data File (Opticon): 20091228_135507.tad\nData workup: PROPS BB_DH Gene Expression Miner Workup\nqPCR was set up on these cDNAs using the following primers:\nCU994646.p.cg.6 (“CATL”, “Cathepsin L”) - This was upregulated in DH SOLiD data.\nES789598.p.cg.6 (“GSTA”, “Glutathione S-transferase A”) - This was upregulated in DH SOLiD data.\nqPCR set up and plate layout can be found here.\nResults:\nqPCR Data File (Opticon): 20091228_165801.tad\nData workup: PROPS BB_DH Gene Expression Miner Workup"
  },
  {
    "objectID": "posts/2009/2009-06-23-qpcr-mv-hemocyte-cdna-from-20090614-8/index.html",
    "href": "posts/2009/2009-06-23-qpcr-mv-hemocyte-cdna-from-20090614-8/index.html",
    "title": "qPCR - MV hemocyte cDNA from 20090614",
    "section": "",
    "text": "Set up qPCR with Cv_CatL_F/R primers. Plate layout/PCR set up is here.\nResults: Waters are clean. To be analyzed later with other genes that Mac has run."
  },
  {
    "objectID": "posts/2009/2009-07-13-bacteria-c-pugetti-large-culture/index.html",
    "href": "posts/2009/2009-07-13-bacteria-c-pugetti-large-culture/index.html",
    "title": "Bacteria - C.pugetti large culture",
    "section": "",
    "text": "One of the three starter liquid cultures from 20090706 wee used to inoculate 1L of Marine Broth + biphenyl. Incubated 200RPM @ 28C."
  },
  {
    "objectID": "posts/2009/2009-07-01-qpcr-mv-hemocyte-cdna-from-20090614-5/index.html",
    "href": "posts/2009/2009-07-01-qpcr-mv-hemocyte-cdna-from-20090614-5/index.html",
    "title": "qPCR - MV hemocyte cDNA from 20090614",
    "section": "",
    "text": "Set up qPCR with Cv_CatL_F/R primers. This is a second rep. Plate layout/PCR set up is here.\nResults: Waters are clean. To be analyzed later with other genes that Mac has run."
  },
  {
    "objectID": "posts/2009/2009-06-24-qpcrs-mv-hemocyte-cdna-from-20090614-3/index.html",
    "href": "posts/2009/2009-06-24-qpcrs-mv-hemocyte-cdna-from-20090614-3/index.html",
    "title": "qPCRs - MV hemocyte cDNA from 20090614",
    "section": "",
    "text": "qPCR - CIAPIN Primers\nSet up qPCR with Cv_CIAPIN_F/R primers. Plate layout/PCR set up is here.\nResults: Waters are clean. gDNA samples did not amplify. To be analyzed later with other genes that Mac has run.\n\n\nqPCR - CatY Primers\nSet up qPCR with Cv_CatY_F/R primers. Plate layout/PCR set up is here.\nResults: Waters are clean. gDNA samples did not amplify. To be analyzed later with other genes that Mac has run."
  },
  {
    "objectID": "posts/2009/2009-03-27-rna-isolation-abalone-digestive-gland-samples-3/index.html",
    "href": "posts/2009/2009-03-27-rna-isolation-abalone-digestive-gland-samples-3/index.html",
    "title": "RNA Isolation - Abalone digestive gland samples",
    "section": "",
    "text": "Total RNA was isolated from the following abalone digestive gland samples using the RNA Powersoil Kit, according to their protocol:\n08:3-11\n08:3-12\n08:3-13\n08:3-19\n08:3-20\n08:3-21\n08:3-22\n08:3-23\nNotes: After phase separation, 3-11 and 3-12 had milky/cloudy aqueous phases. These two samples were subjected to another 10min spin @ 2500g, but this spin made no difference in their appearance. Other samples were clear or slightly translucent at worst.\n\nResults: RNA looks great in nearly all of the samples. RNA has been stored @ -80C in the same box from where the tissue was taken."
  },
  {
    "objectID": "posts/2009/2009-11-26-mbl-shipment-sepia-tissue-samples/index.html",
    "href": "posts/2009/2009-11-26-mbl-shipment-sepia-tissue-samples/index.html",
    "title": "MBL Shipment - Sepia tissue samples",
    "section": "",
    "text": "Received sepia tissue samples in RNA Later from Kendra Buresch. Here’s the list of tissue we received, according to the Post-It with the samples:\n\n4th arm\nventral mantle center\nventral mantle side\nfin\ndorsal mantle center\ndorsal mantle side\nretina x 2\n\nSamples were temporarily stored @ 4C. Will discuss with Steven on long term storage (if necessary)."
  },
  {
    "objectID": "posts/2009/2009-05-05-rna-isolation-macs-oyster-tissues-bb-and-dh/index.html",
    "href": "posts/2009/2009-05-05-rna-isolation-macs-oyster-tissues-bb-and-dh/index.html",
    "title": "RNA Isolation - Mac’s oyster tissues (BB and DH)",
    "section": "",
    "text": "Processed BB#1-8 up to the point of precipitation. Added isopropanol and stored @ -20C. Organic phase was retained for subsequent gDNA isolation and stored @ 4C."
  },
  {
    "objectID": "posts/2009/2009-10-27-rna-precipitation-herring-gonadovary-rna-from-20091023/index.html",
    "href": "posts/2009/2009-10-27-rna-precipitation-herring-gonadovary-rna-from-20091023/index.html",
    "title": "RNA Precipitation - Herring gonad/ovary RNA (from 20091023)",
    "section": "",
    "text": "A subset (3 samples from each group) of samples were pooled (see spreadsheet, green-highlighted samples), each providing ~7.5ug of RNA, yielding 112.17uL. 0.1 vols of 3M NaOAC, pH = 5.2 were added to the tube (11.22uL). 2 vols of EtOH (246.8uL) was added to the tube. Tube was vortexed to mix and incubated @ -20C O/N."
  },
  {
    "objectID": "posts/2009/2009-06-16-qpcr-mv-hemocyte-cdna-from-yesterday/index.html",
    "href": "posts/2009/2009-06-16-qpcr-mv-hemocyte-cdna-from-yesterday/index.html",
    "title": "qPCR - MV hemocyte cDNA from yesterday",
    "section": "",
    "text": "qPCR set up/plate layout is here. Used Cv_18s_F/R primers to assess samples’ “useability” for future qPCRs. Used an ABI optically clear adhesive film instead of caps. Ran out of appropriate caps.\nResults: Yep, seal was bad. Explains most of the weirdness seen. However, will compare SYTO and Strategene SYBR."
  },
  {
    "objectID": "posts/2009/2009-07-21-nanodrop-h-crach-dnased-rna-from-20090623/index.html",
    "href": "posts/2009/2009-07-21-nanodrop-h-crach-dnased-rna-from-20090623/index.html",
    "title": "NanoDrop - H.crach DNased RNA (from 20090623)",
    "section": "",
    "text": "Samples were first spec’d , since they had not been since their DNase treatement.\n\nSample 08:4-15 was spec’d later (accidentally skipped). [RNA] = 79.19ng/uL.\nCalculations were made for cDNA rxns (see tomorrow’s RT rxns for workup)."
  },
  {
    "objectID": "posts/2009/2009-07-20-qpcr-abalone-cdna-0712-set-from-332009-by-lisa-and-dnased-rna-from-20090623/index.html",
    "href": "posts/2009/2009-07-20-qpcr-abalone-cdna-0712-set-from-332009-by-lisa-and-dnased-rna-from-20090623/index.html",
    "title": "qPCR - Abalone cDNA (07:12 set from 3/3/2009 by Lisa) and DNased RNA (from 20090623)",
    "section": "",
    "text": "Now that we have a solid positive control, I’ll use the H.crach_h-1fg_intron primers to check the existing cDNA and DNased RNA. qPCR plate layout/set up is here. Anneal temp 50C.\nResults: Looks like all the cDNA and DNased RNA are negative ! Finally! Will make cDNA from the DNased RNA."
  },
  {
    "objectID": "posts/2009/2009-01-07-pcr-dungan-isolates/index.html",
    "href": "posts/2009/2009-01-07-pcr-dungan-isolates/index.html",
    "title": "PCR - Dungan Isolates",
    "section": "",
    "text": "Samples (in Chelex) were vortexed and heated @ 95C for 30mins with periodic vortexing. Tubes were spun max speed @ 4C for 2 mins to pellet Chelex. Set up PCR using Immomix master mix. Anealing temp. = 56C. PCR set up here.\n\nLane 1 - 100bp ladder\nLane 2 - xCvC-11t\nLane 3 - xCvC-12t\nLane 4 - xCvC-17t\nLane 5 - VNTc-12-C1/G10\nLane 6 - BC05Ca-18t/H5\nLane 7 - VATm-1.2t\nLane 8 - VNTc-1.5t\nLane 9 - Neg. Control\nResults: PCR seems to have worked for some of the samples. The bottom-most band in lanes 4, 5, 6, 9, & 10 were cut out and stored in “Sam’s Misc. -20C Box”. Date is 1/8/2009, since this PCR ran O/N."
  },
  {
    "objectID": "posts/2009/2009-04-30-bacteria-c-pugetti-plate-from-20090424/index.html",
    "href": "posts/2009/2009-04-30-bacteria-c-pugetti-plate-from-20090424/index.html",
    "title": "Bacteria - C. pugetti plate (from 20090424)",
    "section": "",
    "text": "An additional yellowing has occurred on the plate. This is in accordance with the Dyksterhouse et al. paper. Colonies still barely visible."
  },
  {
    "objectID": "posts/2009/2009-12-29-qpcr-bb-dh-cdna-from-20091223-and-emma-primer-sets-for-testing/index.html",
    "href": "posts/2009/2009-12-29-qpcr-bb-dh-cdna-from-20091223-and-emma-primer-sets-for-testing/index.html",
    "title": "qPCR - BB & DH cDNA (from 20091223) and Emma primer sets for testing",
    "section": "",
    "text": "qPCR was set up on these cDNAs using the following primers:\nEW778389.p.cg.6 (“DPGN”, “Serine protease inhibitor dipetalogastin”) - This was upregulated in DH SOLiD data.\nFP001672.p.cg.6 (“PGSC1”, “Peptidoglycan-recognition protein SC1a/b”) - This was upregulated in DH SOLiD data.\nIncluded three primer sets of Emma’s (matrillin, beta tub and chaperonin). These were set up with no template and done in duplicate.\nqPCR set up and plate layout can be found here.\nResults:\nqPCR Data File (Opticon): 20091229_133148.tad\nData workup: PROPS BB_DH Gene Expression Miner Workup\nEmma’s “beta tub” primers show some weird fluorescence, however none of the primer sets show any thing in the melting curve analysis."
  },
  {
    "objectID": "posts/2009/2009-06-02-pcr-c-pugetti-dna-from-20090513-20090526-2/index.html",
    "href": "posts/2009/2009-06-02-pcr-c-pugetti-dna-from-20090513-20090526-2/index.html",
    "title": "PCR - C.pugetti DNA from 20090513 & 20090526",
    "section": "",
    "text": "Performed PCR as set up here using universal bacterial 16s primers (sequences provided by Sara Kelly).\n\nLane 1 - 100bp ladder\nLane 2- 5/13 DNA\nLane 3 - 5/26 DNA\nLane 4 - H2O\nResults: Contamination in the water sample. Hopefully this is just bad technique (never thought I’d say that about myself) and not general, bacterial contamination in the primer stocks, since the stocks (nor the PCR rxns) were prepared steriley. Will repeat."
  },
  {
    "objectID": "posts/2009/2009-01-14-rna-precipitation-continued-from-yesterday/index.html",
    "href": "posts/2009/2009-01-14-rna-precipitation-continued-from-yesterday/index.html",
    "title": "RNA - Precipitation continued from yesterday",
    "section": "",
    "text": "Transferred supe to a fresh tube and added 1mL 70% EtOH to remaining pellet. Spun samples max speed @ 4C 30 mins. Removed supe and washed pellets with 1mL 70% EtOH. Spun max speed 10 mins. Removed supe . Resuspended the “supe” sample in 50uL 0.1%DEPC-H2O and the “pellet” sample in 100uL 0.1%DEPC-H2O.\n\nResults: 260/280 ratios look good. The 260/230 ratios are still horrible. Total yield from these two samples are ~5ug. Will get more hemolymph from clams in order to use more total RNA in the mRNA isolation to maximize cost saving."
  },
  {
    "objectID": "posts/2009/2009-10-06-qpcr-tims-adults-gigas-challenge-dnased-rna-from-20091002/index.html",
    "href": "posts/2009/2009-10-06-qpcr-tims-adults-gigas-challenge-dnased-rna-from-20091002/index.html",
    "title": "qPCR - Tim’s adults gigas challenge DNased RNA (from 20091002)",
    "section": "",
    "text": "Performed qPCR using q18s primers on DNased RNA (1:100 dilution to match final concentration of template after making cDNA). qPCR set up and plate layout are here.\ngDNA dilutions were used as positive controls. gDNA = BB11 (0.49ug/uL) from 20090519. Used 5uL of 1:10, 1:100 and 1:000 dilutions.\nResults: gDNA dilutions look good. However, some samples are definitely coming up before the 40 cycle mark. Will re-DNase treat these."
  },
  {
    "objectID": "posts/2009/2009-09-19-mrna-isolation-gigas-bb-and-dh-samples-previously-treated-with-ribominus-kit-by-mac/index.html",
    "href": "posts/2009/2009-09-19-mrna-isolation-gigas-bb-and-dh-samples-previously-treated-with-ribominus-kit-by-mac/index.html",
    "title": "mRNA Isolation - Gigas BB and DH samples previously treated with Ribominus Kit (by Mac)",
    "section": "",
    "text": "Was given ~0.5ug of each of these two RNA samples and processed them with Ambion’s microPolyA Purist Kit according to protocol. After elution, the samples were EtOH precipitated @ -80C for 30mins, pelleted 30mins 16,000g for 30mins, 4C. Supe removed, RNA washed with 1mL 70% EtOH and spun 10mins 16,000g, 4C. Supe removed. Resusupended in 10uL of The RNA Storage Solution and gave back to Mac."
  },
  {
    "objectID": "posts/2009/2009-01-09-bleeding-hard-clams-3/index.html",
    "href": "posts/2009/2009-01-09-bleeding-hard-clams-3/index.html",
    "title": "Bleeding - Hard Clams",
    "section": "",
    "text": "Bled 24 hard clams using a 23g 1.5 needle on a 3mL syringe. Fluid was gathered and ranged from ~0.4-1.0mL. Hemolymph was transferred to individual 1.5mL snap cap tubes and spun @ 100g for 30mins @ 4C. Most of the supe was removed, but left ~100uL in each tube to avoid disturbing any pellet. Samples were stored @ -80C in the red box wiht previous hard clam hemo samples. Clams were numbered and transferred to a holding tank. Gill and mantle tissue was collected from 10 of the clams. The collected tissue and the rest of the carcasses were stored @ -80C."
  },
  {
    "objectID": "posts/2009/2009-12-18-pcr-sepia-cdna/index.html",
    "href": "posts/2009/2009-12-18-pcr-sepia-cdna/index.html",
    "title": "PCR - Sepia cDNA",
    "section": "",
    "text": "This is an exact repeat of the PCR from yesterday, due to inconsistencies between repeated PCRs from yesterday and earlier today. Here’s yesterday’s workup\nResults:\n\nGel Loading (from left to right):\nOpsin Primers (lanes 2-10), Rhodopsin Primers (same loading order, lanes 12-20)\n1 - 100bp ladder\n2 - retina\n3 - fin\n4 - 4th arm\n5 - dorsal mantle center\n6 - dorsal mantle side\n7 - ventral mantle center\n8 - ventral mantle side\n9 - H2O\n10 - H2O\nOpsin Primers\nSingle bands in retina, fin and ventral mantle center samples. Negative controls are clean. Bands will be excised and stored @-20C in Sam’s “Purified Inserts” box for eventual sequencing. Tubes are labelled with a “2” to differentiate them from the gel run earlier today.\nRhodopsin Primers\nSingle bands in retina and fin. Double bands in ventral mantle center sample. Second band is very faint is ~700bp. Negative controls are clean. Bands, including the faint 700bp VMC, will be excised and stored @-20C in Sam’s “Purified Inserts” box for eventual sequencing. Tubes are labelled with a “2” to differentiate them from the gel run earlier today."
  },
  {
    "objectID": "posts/2009/2009-10-09-qpcr-tims-adults-gigas-challenge-dnased-rna-from-today-2/index.html",
    "href": "posts/2009/2009-10-09-qpcr-tims-adults-gigas-challenge-dnased-rna-from-today-2/index.html",
    "title": "qPCR - Tim’s adults gigas challenge DNased RNA (from today)",
    "section": "",
    "text": "Previous qPCR was done incorrectly (wrong primers), so am repeating with the correct primers. Performed qPCR using q18s primers on DNased RNA (1:100 dilution to match final concentration of template after making cDNA). qPCR set up and plate layout are here.\ngDNA dilutions were used as positive controls. gDNA = BB11 (0.49ug/uL) from 20090519. Used 5uL of 1:10, 1:100 and 1:000 dilutions.\nResults: Still had 5 samples that came up positive. Will re-DNase treat these samples and then re-qPCR them."
  },
  {
    "objectID": "posts/2009/2009-08-13-qpcr-calibration-test-of-opticon-2/index.html",
    "href": "posts/2009/2009-08-13-qpcr-calibration-test-of-opticon-2/index.html",
    "title": "qPCR - Calibration test of Opticon 2",
    "section": "",
    "text": "Received new FAM calibration reagent. It comes pre-prepared in a 1x PCR buffer (0.3uM), however there is only enough for a single plate (use 50uL/well). Will run plate in Opticon 2. Run according to the calibration protocol in the Opticon 2 manual (p. 10-4).\nResults:\n\nWell, there’s actually a signal this time as opposed to the run on 20090806. However, it’s pretty clear that the signals aren’t even close to being uniform. Or, as the manual says “tightly clustered lines”. I’m also not sure why the fluorescence decreases over time, although it could simply be degradation of the fluorophore after being hit with light. I’ve sent the results to Bio-Rad for help interpreting them."
  },
  {
    "objectID": "posts/2009/2009-01-24-mrna-precipitation-continued-from-yesterday/index.html",
    "href": "posts/2009/2009-01-24-mrna-precipitation-continued-from-yesterday/index.html",
    "title": "mRNA - Precipitation continued from yesterday",
    "section": "",
    "text": "Samples were pelleted and washed with 70% EtOH according to Ambion PolyA Purist protocol. Pellets were resuspended in 10uL of The RNA Storage Solution (included in the Ambion PolyA Purist Kit).\n\nResults: The gill mRNA looks great! Good yield and good ratios. Hemocyte mRNA looks kinda rough and a very low yield (which was to be expected)."
  },
  {
    "objectID": "posts/2009/2009-06-13-dnase-treatment-mv-hemocyte-rna-from-yesterday/index.html",
    "href": "posts/2009/2009-06-13-dnase-treatment-mv-hemocyte-rna-from-yesterday/index.html",
    "title": "DNase Treatment - MV hemocyte RNA from yesterday",
    "section": "",
    "text": "Samples 3326: B23, A25, A22, B14, A21, A10 B22 came up positive for gDNA still. These were retreated according to Ambion protocol with a brand new Turbo DNA-free DNase kit. Additionally, I tested all three existing kits by “spiking” 19uL of H2O with 1uL (~200ng) of gigas gDNA; one tube for each kit and an untreated sample. Will qPCR to see if gDNA removal was successful."
  },
  {
    "objectID": "posts/2009/2009-05-08-dnase-treatment-oyster-rna-from-yesterday/index.html",
    "href": "posts/2009/2009-05-08-dnase-treatment-oyster-rna-from-yesterday/index.html",
    "title": "DNase Treatment - Oyster RNA from yesterday",
    "section": "",
    "text": "Yesterday’s qPCR indicated that all of the RNA still contained gDNA contamination. So, took 10ug of RNA from BB #1-10 and DH#1-10 (calcs/workup BB and DH) and brought the volumes up to 50uL with 0.1% DEPC-H2O. Processed the samples according to Ambion Tubrbo DNA-free protocol. Will proceed with qPCR immediately."
  },
  {
    "objectID": "posts/2009/2009-05-07-dnase-treatment-oyster-rna-from-today/index.html",
    "href": "posts/2009/2009-05-07-dnase-treatment-oyster-rna-from-today/index.html",
    "title": "DNase Treatment - Oyster RNA from today",
    "section": "",
    "text": "All of the RNA (50uL) was DNase treated with Ambion’s Turbo DNA-free kit according to protocol. Samples were spec’d.\nResults:"
  },
  {
    "objectID": "posts/2009/2009-06-10-pcr-c-pugetti-gdna-from-20090526/index.html",
    "href": "posts/2009/2009-06-10-pcr-c-pugetti-gdna-from-20090526/index.html",
    "title": "PCR - C.pugetti gDNA from 20090526",
    "section": "",
    "text": "This is a repeat of yesterday’s PCR due to the presence of bands in the water-only samples. Will use reagents and universal 16s bacterial primers (27F & 1492R) provide by the Horner-Devine lab in hopes of: 1) getting this two work and, 2) figuring out the source of the contamination.\nAll rxns were prepared sterily and all instruments, racks, tubes, tips and water were UV-sterilized for ~45mins in the biological hood. Rxns were prepared in the biological hood. PCR setups are here. Anneal 60C. Cycling params same as yesterday.\n\nLane 1 - 100bp ladder\nLane 2 - DNA (HD Rxn 1)\nLane 2 - H2O (HD Rxn 1)\nLane 3 - H2O (HD Rxn 1)\nLane 4 - DNA (HD Rxn 2)\nLane 5 - H2O (HD Rxn 2)\nLane 6 - H2O (HD Rxn 2)\nLane 7 - DNA (SR Rxn)\nLane 8 - H2O (SR Rxn)\nLane 9 - H2O (SR Rxn)\nLane 10 - 100bp ladder\nResults: Well, we got our band and NO contamination in any H2O lanes. The super-bright, 1500bp band will be excised and purified using Millipore spin columns and submitted for sequencing. However, this gel is interesting because the primers provided by Mike (used in HD Rxn 1 and SR Rxn) did not amplify anything…"
  },
  {
    "objectID": "posts/2009/2009-03-13-mrna-isolation-hard-clam-gill-1-dnased-rna-from-today/index.html",
    "href": "posts/2009/2009-03-13-mrna-isolation-hard-clam-gill-1-dnased-rna-from-today/index.html",
    "title": "mRNA Isolation - hard clam gill #1 DNased RNA from today",
    "section": "",
    "text": "DNased RNA from earlier today was split into four equal parts (175uL = 39.8ug). Three will be used for mRNA isolation and the fourth will remain as total RNA. Three of these were precipitated according to Ambion PolyAPurist Protocol: 1/10 volume 5M ammonium acetate, 1uL glycogen and 2.5 volumes of 100% EtOH. Incubated @ -80C for 30 mins. One sample was processed with the Promega PolyA Tract kit. The remaining two samples were processed according to PolyAPurist Protocol. Of those two, one of the samples was processed a second time to evaluate the effectiveness of running a sample through the PolyAPurist Protocol twice.\nmRNA samples were precipitated O/N @ -20C according to the PolyAPurist Protocol."
  },
  {
    "objectID": "posts/2010/2010-01-05-qpcrs-tims-adult-gigas-gill-cdna-from-20091009-2/index.html",
    "href": "posts/2010/2010-01-05-qpcrs-tims-adult-gigas-gill-cdna-from-20091009-2/index.html",
    "title": "qPCRs - Tim’s Adult Gigas gill cDNA (from 20091009)",
    "section": "",
    "text": "Duplicates of earlier qPCRs.\nPrimers: Cg_HIF1 and IL17 Iso D.\nThe previous version of IL17 primers used (IL17 internal) were NOT the ones used for the paper. The IL17 Iso D are the correct primers and are the same ones that Tim previously used on the juvenille gill samples.\nqPCR set up and plate layout can be found here.\nResults:\n\n\n\n\n\n\n\n\nDuplicates of earlier qPCRs.\nPrimers: EF1 and IL17 Iso D.\nThe previous version of IL17 primers used (IL17 internal) were NOT the ones used for the paper. The IL17 Iso D are the correct primers and are the same ones that Tim previously used on the juvenille gill samples. qPCR set up and plate layout can be found here.\nResults:"
  },
  {
    "objectID": "posts/2010/2010-12-01-restriction-digestionsligations-ms-aflp/index.html",
    "href": "posts/2010/2010-12-01-restriction-digestionsligations-ms-aflp/index.html",
    "title": "Restriction Digestions/Ligations - MS-AFLP",
    "section": "",
    "text": "Reaction calculations are here. Samples were mixed and incubated @ 37C O/N (started at 6PM). Mac will take care of them tomorrow morning."
  },
  {
    "objectID": "posts/2010/2010-07-03-restriction-digests-various-gigas-gdnas-of-macs/index.html",
    "href": "posts/2010/2010-07-03-restriction-digests-various-gigas-gdnas-of-macs/index.html",
    "title": "Restriction Digests - Various gigas gDNAs of Mac’s",
    "section": "",
    "text": "Performed restriction digests. Made dilutions of all DNAs involved of 25ng/uL. Made enough for a total of 9 digests could be performed on each DNA. This allowed using 10uL of each DNA for each rxn, more mileage out of the lowest concentration sample (R37-01), and allowed for the use of master mixes when preparing the digests. All calculations/dilutions/master mixes can be seen here. Each DNA was digested individually with HpaII, MspI and undigested. Incubated the digests 4hrs @ 37C. After digestion, performed an EtOH precipitation. Added 0.1 vols of 3M NaOAc (pH=5.2), then 2.5 vols of 100% EtOH. Mixed by inversion and incubated 30mins @ -20C. Pelleted DNA 16,000g, 30mins @ 4C. Discarded supe. Washed pellets with 1mL 70% EtOH. Pelleted DNA 16,000g, 15mins, 4C. Discarded supe. Resuspended DNA in 10uL PCR H2O and spec’d.\nResults:\n\nWell, the recovery of DNA is very low. The best recovery is ~50% while the worst is around ~1%.\nI did not proceed with the intended qPCR due to the low yields and the fact that I don’t know if we’ve previously tested how sensitive our assay(s) our for our target genes. Will discuss with Steven/Mac next week."
  },
  {
    "objectID": "posts/2010/2010-01-15-qpcr-macs-bbdh-cdna-from-20091223/index.html",
    "href": "posts/2010/2010-01-15-qpcr-macs-bbdh-cdna-from-20091223/index.html",
    "title": "qPCR - Mac’s BB/DH cDNA from 20091223",
    "section": "",
    "text": "GSTA and DPGN primer sets used. These are duplicates based on initial differences seen between BB and DH expression. qPCR set up and plate layout here.\nResults:\nqPCR Data File (Opticon): 20100115_113154.tad\nData workup is here: PROPS BB_DH Gene Expression Miner Workup"
  },
  {
    "objectID": "posts/2010/2010-10-27-gdna-isolation/index.html",
    "href": "posts/2010/2010-10-27-gdna-isolation/index.html",
    "title": "gDNA Isolation",
    "section": "",
    "text": "Isolated gDNA from gray whale skin, human cheek cells (my own!) and two different species of algae (species 1, species 2) using Qiagen’s DNEasy Blood & Tissue Kit according to protocol. Incubated all samples at 55C for 1hr. Eluted DNA with 50uL of Buffer AE. Spec’d samples on NanoDrop 1000.\nCheek cells were scraped from the inside of my cheek with a sterile toothpick. The toothpick was transferred to a 1.5mL snap cap tube containing the appropriate buffer. The tube was vortexed to help dislodge cells from the toothpick. The toothpick was then removed and the sample treated according to protocol.\n1mL of algae cells were collected from each liquid culture, cells were pelleted by spinning 16,000g for 1min @ RT, supe removed, 180uL of Buffer ATL added and then vortexed to dislodge/break up pellet. Sample was treated according to protocol.\nResults:\n\nWell, no detectable quantities of DNA in 3 of the 4 samples. There appears to be something in the gray whale skin gDNA extraction, however the OD260/280 ratio is just crazy, leading me to believe that there’s not really any usable DNA present. Will give gray whale gDNA sample to Caroline for class and will talk with Steven and Caroline concerning their interest in performing another quick extraction on more algae to use for class this afternoon."
  },
  {
    "objectID": "posts/2010/2010-06-19-gdna-precipitation-sbwb-gdna-pools-prep-for-medip/index.html",
    "href": "posts/2010/2010-06-19-gdna-precipitation-sbwb-gdna-pools-prep-for-medip/index.html",
    "title": "gDNA Precipitation - SB/WB gDNA pools (prep for MeDIP)",
    "section": "",
    "text": "8 gDNA samples from SB were pooled and 8 gDNA samples from WB were pooled, using equal amounts of gDNA from each sample (1250ng) for a total of 10ug (see SB/WB Mac’s MeDIP spreadsheet for specific samples/volumes used in pooling). Since samples were stored in pH-adjusted NaOH (see 20100605), they needed to be precipitated in order to have the gDNA suspended in TE for the downstream steps of methylated DNA immunoprecipitation (MeDIP). 10% 3M sodium acetate (pH = 5.2) was added to each tube, then 2.5 vols of 100% EtOH and mixed. Samples were incubated @ -20C for 30mins. DNA was pelleted by spinning 16,000g for 30mins @ 4C. Supe was discarded. Pellets were washed with 1mL 70% EtOH and then pelleted @ 16,000g for 10mins @ 4C. Supe was discarded and gDNA was resuspended in 120uL of TE (pH = 8.0) and spec’d.\nResults:\n\nThe R37 (SB) sample pool yielded 7.056ug after precipitation and the R51 (WB) sample pool yielded 8.834ug after precipitation (started with 10ug). This is good, as 6ug is needed for MeDIP and I wanted to have some (~250ng) available for running as an un-sonicated control on the post-sonication gel. Will transfer 250ng from each pool to separate tubes and then proceed with sonication."
  },
  {
    "objectID": "posts/2010/2010-03-17-mrna-precipitation-for-solid-perch-lake-trout-herring-mrna-continued-from-yesterday/index.html",
    "href": "posts/2010/2010-03-17-mrna-precipitation-for-solid-perch-lake-trout-herring-mrna-continued-from-yesterday/index.html",
    "title": "mRNA Precipitation for SOLiD - Perch, Lake Trout, & Herring mRNA (CONTINUED from yesterday)",
    "section": "",
    "text": "mRNA was pelleted and washed according to Ambion’s MicroPolyA Purist Kit. Pellets were resuspended in 8uL nuclease-free H2O and spec’d. 0.5uL was taken from each sample, transferred to a fresh tube, diluted to ~5ng/uL and stored @ -80C for eventual Bioanalyzer analysis. mRNA samples were stored @ -80C until we receive the Ribominus Concentration Module Kit from Invitrogen (turns out we didn’t have any!) for cleaning up the RNA after fragmentation.\nResults:\n\nOverall, this mRNA doesn’t look that great. However, I did notice that all samples had (to varying degrees) particulate matter that wouldn’t dissolve. Prior to spec’ing, the particulate matter was pelleted so as to not interfere. All samples will continue to be prepped for SOLiD analysis despite poor 260/280 ratios and low yields."
  },
  {
    "objectID": "posts/2010/2010-10-26-etoh-precipitation-whale-gdna-from-20101022/index.html",
    "href": "posts/2010/2010-10-26-etoh-precipitation-whale-gdna-from-20101022/index.html",
    "title": "EtOH Precipitation - Whale gDNA from 20101022",
    "section": "",
    "text": "Precipitated whale gDNA in hopes of producing a sample with a higher concentration. Added 0.1 vols of 3M NaOAc (10uL), 2.5 vols of 100% EtOH (275uL), mixed thoroughly and incubated @ -20C for 1hr. DNA was pelleted by spinning sample @ 16,000g, 30mins, 4C. No visible pellet. Supe was removed, sample was washed with 1mL 75% EtOH, and pelleted by spinning @ 16,000g, 15mins, 4C. Supe was removed, sample resuspended in 10uL nuclease-free H2O and spec’d.\nResults:\nNo DNA to speak of (spec data not shown)."
  },
  {
    "objectID": "posts/2010/2010-01-06-qpcrs-tims-adult-gigas-gill-cdna-from-20091009/index.html",
    "href": "posts/2010/2010-01-06-qpcrs-tims-adult-gigas-gill-cdna-from-20091009/index.html",
    "title": "qPCRs - Tim’s Adult Gigas gill cDNA (from 20091009)",
    "section": "",
    "text": "Duplicates of earlier qPCRs.\nPrimers: Cg_P450 and TNFRAF_5’/3’.\nqPCR set up and plate layout are here.\nResults:\n\n\nDuplicates of earlier qPCRs.\nPrimers: Cg_IkB_F997, R1213 and Cg_Prx6_F270, R439.\nqPCR set up and plate layout can be found here.\nResults:"
  },
  {
    "objectID": "posts/2010/2010-11-23-restriction-digestions-hpaii-and-mspi-on-macs-c-gigas-gdna-samples-round-1/index.html",
    "href": "posts/2010/2010-11-23-restriction-digestions-hpaii-and-mspi-on-macs-c-gigas-gdna-samples-round-1/index.html",
    "title": "Restriction Digestions - HpaII and MspI on Mac’s C.gigas gDNA Samples: Round 1",
    "section": "",
    "text": "Set up restriction digests for subsequent analysis by methylation specific PCR (MSP). This will be the first of two rounds of digestion with the same enzyme on each sample. Samples and master mixes are here. Samples were incubated 3hr. @ 37C. All samples were heat inactivated at 80C for 30mins and then stored @ -20C."
  },
  {
    "objectID": "posts/2010/2010-04-14-templated-bead-prep-solid-libraries-abalone-cc-ce-pools-and-yellow-perch-ct-pq-libraries/index.html",
    "href": "posts/2010/2010-04-14-templated-bead-prep-solid-libraries-abalone-cc-ce-pools-and-yellow-perch-ct-pq-libraries/index.html",
    "title": "Templated Bead Prep SOLiD Libraries - Abalone CC, CE pools and yellow perch CT, PQ libraries",
    "section": "",
    "text": "All libraries were prepped according to ABI’s “full-scale” bead prep protocol. Initial bead counts were performed using a hemocytometer in a 1:200 dilution:\nFormula for calculating bead counts:\nAverage hemo count x hemo volume x hemo squares x dilution x bead volume\nInitial Bead Counts\nCC: 127, 120, 126, 113. Average = 96 Count: 96 x 10 x 25 x 200 x 200 = 9.6 x 10^8 beads\nCE: 99, 93, 115, 102. Average = 102.25 Count: 102.25 x 10 x 25 x 200 x 200 = 1.0225 x 10^9 beads\nCT: 118, 113, 109, 111. Average = 112.75 Count: 112.75 x 10 x 25 x 200 x 200 = 1.1275 x 10^9 beads\nPQ: 109, 116, 111, 86. Average = 105.5 Count: 105.5 x 10 x 25 x 200 x 200 = 1.055 x 10^9 beads\nTemplated Bead Counts\nTemplated bead counts were performed using a hemocytometer with a 1:10 dilution:\nCC: 217, 226, 208, 219 Average = 217.5 Count: 217.5 x 10 x 25 x 10 x 400 = 2.175 x 10^8 beads\nCE: 211, 169, 162, 180 Average = 180.5 Count: 180.5 x 10 x 25 x 10 x 400 = 1.805 x 10^8 beads\nCT: 223, 219, 254, 214 Average = 227.5 Count: 227.5 x 10 x 25 x 10 x 400 = 2.275 x 10^8 beads\nPQ: 176, 177, 161, 163 Average = 169.25 Count: 169.25 x 10 x 25 x 10 x 400 = 1.6925 x 10^8 beads\nTemplated Bead Recovery: Final bead count divided by initial bead count x 100 = % recovery\nCC = 2.17 x 10^8 beads/9.6 x 10^8 beads x 100 = 22.7%\nCE = 1.805 x10^8 beads/10.225 x 10^8 beads x 100 = 17.7%\nCT = 2.275 x 10^8 beads/11.275 x 10^8 beads x 100 = 20.2%\nPQ = 1.6925 x 10^8 beads/10.55 x 10^8 beads x 100 = 16.04%\nResults: Yields of templated beads look fabulous. Recoveries of templated beads are a bit on the high side (desired recoveries are between 5-15%, with 20% being the “cutoff” that Rhonda’s lab uses for runs. The CC and CT samples cross this cutoff value. Will consult with Steven to see what how he wants to proceed (i.e. new ePCRs?). Beads stored @ 4C until ready for running on the SOLiD."
  },
  {
    "objectID": "posts/2010/2010-06-25-samples-received-hard-clam-samples-from-rutgers-and-mbl/index.html",
    "href": "posts/2010/2010-06-25-samples-received-hard-clam-samples-from-rutgers-and-mbl/index.html",
    "title": "Samples Received - Hard Clam samples from Rutgers and MBL",
    "section": "",
    "text": "Important Note: These were received while I was out of lab. This notebook entry was added 20101021\nReceived sets of gill tissue and hemolymph in RNA Later from Rutgers (Emily). Here’s the note that was included with the samples.\nReceived set of gill tissue in RNA Later MBL (Scott Lindell).\nAll samples were stored @ -80C."
  },
  {
    "objectID": "posts/2010/2010-04-15-epcr-solid-libraries-lake-trout-sisco-and-herring-go-hpws09-libraries-from-20100408/index.html",
    "href": "posts/2010/2010-04-15-epcr-solid-libraries-lake-trout-sisco-and-herring-go-hpws09-libraries-from-20100408/index.html",
    "title": "ePCR SOLiD Libraries - Lake Trout Sisco and Herring G/O HPWS09 libraries (from 20100408)",
    "section": "",
    "text": "ePCR was performed for the above three mentioned SOLiD libraries using 1.5pM (180 pg/uL) of cDNA, according to the ABI “full scale” ePCR protocol. ePCRs were stored @ 4C until ready for the emulsion breaking step.\nAmounts of cDNA used to make dilutions (in 1x Low TE Buffer) of 180pg/uL:\nSisco (42.29 ng/uL): 2.13uL in 500uL\nHPWS09 (9.29 ng/uL): 1.94uL in 100uL"
  },
  {
    "objectID": "posts/2010/2010-06-06-gdna-isolation-mac-gigas-gill-samples-continued-from-yesterday/index.html",
    "href": "posts/2010/2010-06-06-gdna-isolation-mac-gigas-gill-samples-continued-from-yesterday/index.html",
    "title": "gDNA Isolation - Mac gigas gill samples (continued from yesterday)",
    "section": "",
    "text": "Continued with gDNA isolation from yesterday’s samples. Samples were gently pipetted up and down to further dissolve remaining tissue, although tissue did not dissolve entirely. Pelleted residual tissue 10mins @ 10,000g @ RT. Transferred supe to new tubes. Precipitated DNA with 0.25mL 100% EtOH. Incubated 3mins @ RT. DNA was pelleted 5mins @ 5000g @ RT. Supe was removed, pellets were washed with 1mL 75% EtOH (x2). Supe was fully removed and the pellets were resuspended in 200uL 8mM NaOH (made by Amanda Davis 5/20/10).\n1M HEPES (provided with DNAzol) was added at a 1:100 dilution to achieve a pH = 8.0. This was based on the DNAzol protocol calculations (For 1mL of 8mM NaOH, use 101uL of 0.1M HEPES = pH 8.0).\nSamples were spec’d on NanoDrop 1000 on 20100607. Used a sample with 8mM NaOH and 1M HEPES to match the pH = 8.0 of the samples.\nResults:\n\nOverall DNA quality looks good (based on 260/280 ratios). Yields seem satisfactory. Will run samples on gel to verify gDNA integrity (see below).\n250ng of each sample was run on a 1.2% TAE agarose gel. Gel was run on 20100607.\n\nThe results are pretty interesting.\nMost of the R51 samples are pretty good looking (i.e. high molecular weight band, little smearing), but there are some samples that show a high degree of degradation (e.g. #18, #19).\nAll of the R37 samples look STELLAR (i.e. high molecular weight band, no smearing)!\nThe stark differences between the R51 samples and the R37 are intriguing. Although not currently verified (as of 20100607), I suspect that the amount of tissue stored in RNA Later possibly contributes to the long term integrity of the DNA, as nearly all of the R37 samples had very little tissue in the RNA Later. Whereas the R51 tissue samples were significantly larger in virtually every sample. I will do a visual inspection of the tubes to see if there is indeed a correlation between tissue size and apparent DNA quality."
  },
  {
    "objectID": "posts/2010/2010-01-07-solid-bead-titration-herring-fragmented-cdna-library-3lhsitk09continued-from-epcr-yesterday/index.html",
    "href": "posts/2010/2010-01-07-solid-bead-titration-herring-fragmented-cdna-library-3lhsitk09continued-from-epcr-yesterday/index.html",
    "title": "SOLiD Bead Titration - Herring fragmented cDNA library 3LHSITK09(CONTINUED from ePCR yesterday)",
    "section": "",
    "text": "Completed the remainder of the procedure for template bead titration, according to the ABI “Templated Bead Preparation Guide” following the “full-scale” protocol.\nTemplated bead recovery after breaking emulsion, in a 1:200 dilution: 92, 105, 97, 99, 89, 96. Average = 96.3 beads/square\nCalculation of beads: Avg (beads/square) x Volume in hemocytometer (uL) x total # squares on hemocytometer (squares) x dilution factor = beads/uL\nTotal bead recovery: beads/uL x volume of beads (uL)\nSo, my recovery is: 96.3 beads/square x 10uL x 25 squares x 200 = 4.817x10^6 beads/uL\nTotal beads recovered: 4.817x10^6 beads/uL x 200uL = 9.63x10^8 beads.\nDesired # of beads is between 1-2 billion. I recovered 963 million. Close.\nFinal count of enriched, templated-beads: 8, 14, 16, 10. Average = 12\nMy final recovery is: 12 beads/square x 10uL x 25 sqaures x 10 = 30000 beads/uL.\nTotal enriched, templated beads recovered: 30000 beads/uL x 400uL = 12x10^6 beads.\nEnrichment efficiency percentage calculation: (# templated beads)/(Starting # beads) x 100\nMy enrichment efficiency percentage: 12x10^6 beads/9.63x10^8 beads x 100 = 1.2%\nBeads were stored @ 4C until more templated beads are generated.\nResults: The yield of beads is not entirely unexpected, according to Rhonda, because I started the procedure using only 0.5pM of the library. However, each section on an octet slide (which is what we plan on using) requires 46 million beads. Clearly this is short of that quantity. The procedure will be repeated with a greater amount of starting cDNA library. It should be noted that there is NOT a linear relationship between the amount of starting template and the amount of enriched, templated beads one ends up with in this protocol. So, even though I will be increasing the starting amount of template by 3-fold, a 3-fold increase in the amount of enriched, templated beads is NOT expected (hopefully it’ll be more than that!)."
  },
  {
    "objectID": "posts/2010/2010-06-09-gdna-isolation-mac-gigas-larvae-samples-control-larvae-6-7-10-and-5-aza-tr-larvae-6-7-10/index.html",
    "href": "posts/2010/2010-06-09-gdna-isolation-mac-gigas-larvae-samples-control-larvae-6-7-10-and-5-aza-tr-larvae-6-7-10/index.html",
    "title": "gDNA Isolation - Mac gigas larvae samples: control larvae 6.7.10 and 5-aza tr larvae 6.7.10",
    "section": "",
    "text": "Continued gDNA isolation of the above mentioned larvae samples that was started by Mac yesterday. Amount of larvae in tubes looked disproportionately large, relative to the amount of DNAzol used in the O/N Proteinase K digestion(~500uL) so I added and additional 500uL of DNAzol to each of the two samples and gently pipetted a few times to mix.\nPelleted residual tissue 10mins @ 10,000g @ RT. Transferred supe to new tubes. Precipitated DNA with 0.25mL 100% EtOH. Incubated 3mins @ RT. DNA was pelleted 5mins @ 5000g @ RT. Supe was removed, pellets were washed with 1mL 75% EtOH (x2). Supe was fully removed and the DNAs were resuspended in 800uL 8mM NaOH (made by Amanda Davis 5/20/10).\n1M HEPES (provided with DNAzol) was added at a 1:100 dilution to achieve a pH = 8.0. This was based on the DNAzol protocol calculations (For 1mL of 8mM NaOH, use 101uL of 0.1M HEPES = pH 8.0).\nSamples were spec’d on NanoDrop 1000 on 20100607. Used a sample with 8mM NaOH and 1M HEPES to match the pH = 8.0 of the samples.\nResults:\n\nYields are very good and the 260/280 ratios are pretty good. The 260/230 ratios are very poor and is likely due to the large amount of larvae used in the procedure. Will run samples on a gel to evaluate DNA integrity. **_UDPATE: Mac ran these samples on 6/9/10 (see her notebook on that date) and they look perfect.**_"
  },
  {
    "objectID": "posts/2010/2010-04-12-epcr-solid-libraries-abalone-cc-ce-pools-and-yellow-perch-ct-solid-libraries-from-20100408/index.html",
    "href": "posts/2010/2010-04-12-epcr-solid-libraries-abalone-cc-ce-pools-and-yellow-perch-ct-solid-libraries-from-20100408/index.html",
    "title": "ePCR SOLiD Libraries - Abalone CC, CE pools and yellow perch CT SOLiD libraries (from 20100408)",
    "section": "",
    "text": "Emulsion PCR (ePCR) was performed for the above three mentioned SOLiD libraries using 1.5pM (180 pg/uL) of cDNA, according to the ABI “full scale” ePCR protocol. ePCRs were stored @ 4C until ready for the emulsion breaking step.\nAmounts of cDNA used to make dilutions (in 1x Low TE Buffer) of 180pg/uL:\nCC (13.8ng/uL): 1.3uL in 100uL\nCE (23.01ng/uL): 1.56uL in 200uL\nCT (63.8ng/uL): 1.41 in 500uL"
  },
  {
    "objectID": "posts/2010/2010-04-07-gel-purification-pcr-cdna-solid-libraries-abalone-yellow-perch-lake-trout-herring/index.html",
    "href": "posts/2010/2010-04-07-gel-purification-pcr-cdna-solid-libraries-abalone-yellow-perch-lake-trout-herring/index.html",
    "title": "Gel Purification & PCR cDNA SOLiD Libraries - Abalone, Yellow Perch, Lake Trout, Herring",
    "section": "",
    "text": "cDNA was gel purified according to Ambion’s Whole Transcriptome Analysis Kit. The appropriate regions (100 - 200bp) were excised and cut in to 4, 1x5mm pieces. The two “internal” pieces were transferred to individual PCR tubes. The “outer” pieces were transferred together to a 1.5mL snap cap tube and stored @ -20C.\nThree images are below. The first two are the gels before excising the 100 - 200bp region of the gel. The third is the image of the SECOND gel after the specified region was excised. An image was not taken of Gel 1 after excision (whoops!).\nGel 1\n\nGel 2\n\nNOTE: The WB sample in the gell above is actually a yellow perch sample, NOT an abalone sample!\nGel 2 AFTER EXCISION\n\nNOTE: The WB sample in the gell above is actually a yellow perch sample, NOT an abalone sample!\n\nIn-gel PCR SOLiD Libraries - Abalone, Yellow Perch, Lake Trout, Herring\nIn-gel PCR was performed on the individual “internal” gel pieces that were excised, as described below from earlier today. PCR rxns/cycling were performed according to Ambion’s Whole Transcriptome Analysis Kit. PCR ran O/N. PCR master mix set up is here (bottom half of sheet)."
  },
  {
    "objectID": "posts/2010/2010-10-16-received-hard-clam-samples-from-rutgers/index.html",
    "href": "posts/2010/2010-10-16-received-hard-clam-samples-from-rutgers/index.html",
    "title": "Received Hard Clam Samples from Rutgers",
    "section": "",
    "text": "30 gill tissue samples in RNA Later from CA, MA, & MAX each.\n30 hemolymph samples (in RNA Later?) from CA, MA, & MAX each.\nPresumably these are from the same individuals. Tubes were boxed (a total of 3 boxes), labeled and stored @ -80C.\nHere is a note included from Emily with the samples ."
  },
  {
    "objectID": "posts/2010/2010-05-05-dna-isolation-qiagen-kit-comparison/index.html",
    "href": "posts/2010/2010-05-05-dna-isolation-qiagen-kit-comparison/index.html",
    "title": "DNA Isolation - Qiagen Kit Comparison",
    "section": "",
    "text": "Note: This information was added 20140407. Yes, you read that correctly.\nSomeone had noticed that gDNA isolated using a Qiagen DNeasy Blood & Tissue Kit we rec’d in April 2010 seemed to be yielding degraded DNA.\nThe two samples used for the comparison were a single tail (split in two equal weight pieces) from a juvenile salmon that was snap frozen, without preservatives, at the time of its collection. The samples were prepped. 0.5ug of eluted DNA was then run on a 1.2% agarose-TAE gel containing 0.1ug/mL of ethidium bromide. 5uL of Bioline’s Hyperladder I was loaded for size assessment (see link for marker layout).\nResults:\n\nClearly, there’s significant quality difference! A free replacement kit was sent by Qiagen."
  },
  {
    "objectID": "posts/2010/2010-05-27-package-recd-from-noaa-in-connecticut/index.html",
    "href": "posts/2010/2010-05-27-package-recd-from-noaa-in-connecticut/index.html",
    "title": "Package Rec’d - From NOAA in Connecticut",
    "section": "",
    "text": "Rec’d 6 15mL conical tubes with liquid cultures of various algae. It appears that we rec’d two of each culture. No note/info included with package. Tubes will be stored @ RT in the styrofoam container they arrived in. Tube labels are listed below:\nTetraselmis cheri Ply429\nTetraselmis cheri Ply429\nThalassiaosira weissflugii TW\nThalassiaosira weissflugii TW\nIsochrysis sp. T-150\nIsochrysis sp. T-150"
  },
  {
    "objectID": "posts/2010/2010-07-03-medip-sbwb-fragmented-gdna-continued-from-yesterday/index.html",
    "href": "posts/2010/2010-07-03-medip-sbwb-fragmented-gdna-continued-from-yesterday/index.html",
    "title": "MeDIP - SB/WB Fragmented gDNA (continued from yesterday)",
    "section": "",
    "text": "Continued MeDIP process from yesterday. Protein A/G beads were pelleted XXXXXXXXX, supe transferred to clean tube. Beads were washed 3x in the following fashion, each wash saved to retain unmethylated DNA:\n\n\n\nSamples were phenol:chloroform extracted and EtOH precipitated:\n\nAdded equal volume of phenol:chloroform:IAA, vortexed, spun @ 12,500g, 5mins, 4C.\nTransferred aqueous phase to clean tube.\nAdded equal volume of chloroform, vortexed, spun @ 12,500g, 5mins, 4C.\nTransferred aqueous phase to clean tube.\nAdded 0.1 vols 3M NaOAc (pH=5.2), 2.5 vols of 100% EtOH, mixed and stored @ -20C over the weekend.\n\nWill finish precipitation next week and quantify recovery."
  },
  {
    "objectID": "posts/2010/2010-09-09-reverse-transcription-dnased-hard-clam-rna-from-earlier-today/index.html",
    "href": "posts/2010/2010-09-09-reverse-transcription-dnased-hard-clam-rna-from-earlier-today/index.html",
    "title": "Reverse Transcription - DNased Hard Clam RNA from earlier today",
    "section": "",
    "text": "Prepared cDNA using 1ug of RNA from each of the 3 pools (CA, MA, MAX) and processed according to Promega’s M-MLV protocol, using oligo dT primers. Calcs and master mix set up are here. Briefly, RNA was combined with oligo dT primers, denatured @ 70C for 5mins, immediately placed on ice for 2mins, mixed with RT master mix, incubated 1hr @ 42C, 3mins @ 95C, and then stored @ -20C."
  },
  {
    "objectID": "posts/2010/2010-01-14-solid-bead-titration-herring-fragmented-cdna-libraries-2lhkod09-4lhtog09-6lhpws09/index.html",
    "href": "posts/2010/2010-01-14-solid-bead-titration-herring-fragmented-cdna-libraries-2lhkod09-4lhtog09-6lhpws09/index.html",
    "title": "SOLiD Bead Titration - Herring fragmented cDNA libraries: 2LHKOD09, 4LHTOG09, 6LHPWS09",
    "section": "",
    "text": "Continued with templated bead prep from ePCRs for these libraries. Samples were processed according to the ABI “Templated Bead Preparation Guide” following the “full-scale” protocol.\nTo see explanations of the various calculations below, see the “SOLiD Bead Titration - Herring fragmented cDNA library 3LHSITK09 (CONTINUED from ePCR yesterday)” from 20100107.\n2LHKOD09:\nInitial counts: 109, 129, 112, 115 —- Avg. = 116.25 beads/square\nBeads: 116.25 x 10 x 25 x 200 = 5.8125x10^6 beads/uL x 200uL = 1.1625x10^9 beads\nTemplated beads counts: 205, 199, 197, 210 —– Avg. = 210 beads/square\nTemplated beads: 210 x 10 x 25 x 10 = 5.06875x10^5 beads/uL x 400uL = 2.0275x10^8 beads\nEfficiency: 17.44%\n4LHTOG09:\nInitial counts: 124, 124, 117, 104 —– Avg. = 117.25 beads/sqaure\nBeads: 117.25 x 10 x 25 x 200 = 5.8625x10^6 beads/uL x 200uL = 1.1725x10^9 beads\nTemplated beads counts: 139, 135, 145, 140 —- Avg. = 139.75 beads/square\nTemplated beads: 139.75 x 10 x 25 x 10 = 3.49375x10^5 beads/uL x 400uL = 1.3975x10^8 beads\nEfficiency: 11.92%\n6LHPWS09:\nInitial counts: 135, 106, 123, 124 —- Avg. = 122 beads/square\nBeads: 122 x 10 x 25 x 200 = 6.1x10^6 beads/uL x 200uL = 1.22x10^9 beads\nTemplated beads counts: 141, 171, 164, 170 —– Avg. = 161.5 beads/square\nTemplated beads: 161.5 x 10 x 25 x 10 = 4.0375x10^5 beads/uL x 400uL = 1.615x10^8 beads\nEfficiency: 13.24%\nAll beads were stored @ 4C until ready for bead deposition and work flow analysis run.\nResults:\nRhonda Morales (from Ginger’s lab who is responsible for running/maintaining the SOLiD at the CEG) says the numbers on all samples look perfect! Will proceed to work flow analysis once Jesse’s samples are ready (ETA of Jan. 27th, 2010).\nHere are reagent lot numbers for the Bead Titration."
  },
  {
    "objectID": "posts/2010/2010-05-05-package-hard-clam-gill-tissuehemolymph-in-rna-later/index.html",
    "href": "posts/2010/2010-05-05-package-hard-clam-gill-tissuehemolymph-in-rna-later/index.html",
    "title": "Package - Hard Clam gill tissue/hemolymph in RNA later",
    "section": "",
    "text": "Rec’d package from Rutgers (Emily Pearson) containing two large Ziplock bags on “wet” ice, each of those containing smaller bags with sample tubes in them. One large bag contains gill tissue samples and the other large bag contains hemolymph samples. Samples will temporarily be stored @ 4C until they can be catalogued and boxed by Lexie later today."
  },
  {
    "objectID": "posts/2010/2010-05-12-solid-epcrs-yellow-perch-ct-wb-and-lake-trout-lean-libraries/index.html",
    "href": "posts/2010/2010-05-12-solid-epcrs-yellow-perch-ct-wb-and-lake-trout-lean-libraries/index.html",
    "title": "SOLiD ePCRs - Yellow perch CT, WB and lake trout Lean libraries",
    "section": "",
    "text": "Performed ePCRs on these samples from DATE, following the “full scale” protocol. A work flow analysis (WFA) run on these samples from the initial ePCRs/templated bead prep (DATE) revealed too many polyclonal beads, thus requiring them to be redone. ePCRs will be performed using 1.0pM (120pg/uL) of the SOLiD cDNA fragment libraries, instead of the 1.5pM (180pg/uL) used previously.\nCT -\nWB -\nLean -"
  },
  {
    "objectID": "posts/2010/2010-05-27-gdna-isolation-mac-gigas-gill-samples-2/index.html",
    "href": "posts/2010/2010-05-27-gdna-isolation-mac-gigas-gill-samples-2/index.html",
    "title": "gDNA Isolation - Mac gigas gill samples",
    "section": "",
    "text": "Set up gDNA isolation from the following samples:\nR51 01 (WB R051-0410-01)\nR51 11 (WB R051-0410-11)\nSamples were thawed from -80C. Tissue was removed from RNA Later (RNA Later gDNA isolation protocol; this protocol doesn’t indicate that anything needs to be done to the sample prior to gDNA isolation) and ~25mg was cut from each and placed in 0.5mL of DNAzol. 2.7uL of Proteinase K (Fermentas; 18.5mg/mL) was added to each tube to reach a final concentration of 100ug/mL. The digests were incubated O/N @ RT with rotation."
  },
  {
    "objectID": "posts/2010/2010-09-03-package-hard-clam-samples-from-mbl/index.html",
    "href": "posts/2010/2010-09-03-package-hard-clam-samples-from-mbl/index.html",
    "title": "Package - Hard Clam Samples from MBL",
    "section": "",
    "text": "Rec’d package from Scott Lindell @ MBL containing 65 screw cap tubes in a white microtube rack. All tubes are tissues in RNA Later (presumably). One sample (MA4-5) was lost during a brief centrifugation to get tissue sample unstuck from top of tube and in to RNA Later solution. The head of the tube snapped off and the entire tube/sample was obliterated in the rotor. Also, it appears as though all the tubes leaked RNA Later solution during transport. Samples were temporarily stored @ 4C and will be catalogued/transferred to -80C."
  },
  {
    "objectID": "posts/2010/2010-12-11-qpcr-cox-qpcr-primer-test-and-tissue-distribution/index.html",
    "href": "posts/2010/2010-12-11-qpcr-cox-qpcr-primer-test-and-tissue-distribution/index.html",
    "title": "qPCR - COX qPCR Primer Test and Tissue Distribution",
    "section": "",
    "text": "Used new cyclooxygenase primers (SR IDs 1060, 1061) to see how they performed and to evaluate tissue distribution. Tissue distribution was evaluated using the following cDNAs made on 10/27/10 from Emma:\nGigas Digestive Gland\nGigas Gill\nGigas Mantle\nGigas Muscle\nqPCR Master Mix calcs are here. Plate layout, cycling parameters, etc can be found in the qPCR Report (see Results).\nResults:\nqPCR Report (PDF).\nAmplification is present in all four tissue types and the melting curve looks good. So, these primers are good to go. Steven suggests checking to see if we see a change in gene expression from an old experiment of Gigas exposed to high levels of Vibrio tubiashii. Will round up some old cDNA for this."
  },
  {
    "objectID": "posts/2010/2010-07-10-restriction-digests-various-gigas-gdna-from-earlier-today/index.html",
    "href": "posts/2010/2010-07-10-restriction-digests-various-gigas-gdna-from-earlier-today/index.html",
    "title": "Restriction Digests - Various gigas gDNA from earlier today",
    "section": "",
    "text": "Digest master mixes are here. Digests were incubated @ 37C for 2hrs. and then heat inactivated @ 80C for 20mins."
  },
  {
    "objectID": "posts/2010/2010-09-10-qpcr-hard-clam-primers-on-cdna-from-yesterday/index.html",
    "href": "posts/2010/2010-09-10-qpcr-hard-clam-primers-on-cdna-from-yesterday/index.html",
    "title": "qPCR - Hard Clam Primers on cDNA from yesterday",
    "section": "",
    "text": "Performed qPCR on Friedman Lab machine targeting immune-related genes in hard clam. Rough plate layout/master mix calcs are here. qPCR report from Friedman Lab machine is here (PDF) and shows cycling params, plate layout and Cts.\nResults:\nCFX96 Data file is here.\nThe following primer sets failed to produce an amplicon:\nMm_TRAF6\nMercenaria_Rel\nTLR\nSTI\nCytP450-like\nRaw fluorescence data was extracted (No baseline subtraction) and processed with PCR Miner. Data workup/analysis is here. Here is a graph of those primer sets producing an amplicon. All were normalized to actin, which exhibited the smallest amount of deviation across all three samples of the normalizing/housekeeping genes analyzed.\n\n\n\nAs a preliminary run with these genes, there are a number of promising candidates that could yield some interesting data regarding the physiological response of hard clam to exposure to QPX."
  },
  {
    "objectID": "posts/2010/2010-09-09-dnase-dnasing-hard-clam-rna-from-yesterday/index.html",
    "href": "posts/2010/2010-09-09-dnase-dnasing-hard-clam-rna-from-yesterday/index.html",
    "title": "DNase - DNasing Hard Clam RNA from yesterday",
    "section": "",
    "text": "Pooled 2ug of each sample in each group (MAX, CA, MA) for a total of 6ug of RNA (3 total samples), brought volume up to 50uL and DNased using Ambion’s Turbo DNA-free following the rigorous protocol. Calcs can be seen here. Spec’d:\n\n\n\nResults:\nAll samples look pretty good. Oddly, the 260/280 ratios are absolutely perfect, despite the 260/280 ratios from each individual sample being less than stellar (see yesterday’s EtOH precipiation). Also of note is that the concentrations for all three samples are extremely close, reflecting the accuracy of the NanoDrop readings of each individual sample used for the pool as well as my pipetting. :)\nRNA was stored @ -80C in “Sam’s RNA Box #1.”\nRecovered ~50uL from each sample which means each pool yielded ~3.85ug of RNA after DNase treatment. Will proceed with making cDNA from these three pools. In the interest of time (and the failure of our Opticon), I will not verify that these do NOT still contain gDNA (and, it’s pretty unlikely that they do)."
  },
  {
    "objectID": "posts/2010/2010-11-24-phenolchloroform-extractions-and-etoh-precipitations-hapii-and-mspi-digests-from-yesterday/index.html",
    "href": "posts/2010/2010-11-24-phenolchloroform-extractions-and-etoh-precipitations-hapii-and-mspi-digests-from-yesterday/index.html",
    "title": "Phenol:Chloroform Extractions and EtOH Precipitations - HapII and MspI digests from yesterday",
    "section": "",
    "text": "Restriction digests from yesterday were mixed with equal volume (50uL) of phenol:chloroform:IAA (25:24:1) and centrifuged 16,000g for 5mins @ 4C. Aqueous phase was transferred to a clean tube and an equal volume (50uL) of chloroform was added. Samples were mixed and centrifuged 16,000g for 5mins @ 4C. Aqueous phase was transferred to clean tubes and EtOH precipitated, according to protocol. Samples were resuspended in 25uL of H2O and spec’d.\nSamples are labeled as Parent (P), #, tissue, enzyme (MspI = M, HpaII = H, Undigested = U)\nResults:\nHere is a link to a spreadsheet with ODs. Average recovery was ~734ng, which is only a 36% recovery (started with 2000ng). Will need to discuss with Mac and Steven to see if it’s worth continuing with these sample through a second round of digests/phenol:chloroform extraction/EtOH precipitation, as I don’t know what quantity of DNA is required/desired for the subsequent methylation specific PCR (MSP), OR if I should/need to perform a repeat of these 1st-round digestions in order to end up with sufficient DNA for MSP."
  },
  {
    "objectID": "posts/2010/2010-09-08-etoh-precipitation-hard-clam-rna-from-earlier-today/index.html",
    "href": "posts/2010/2010-09-08-etoh-precipitation-hard-clam-rna-from-earlier-today/index.html",
    "title": "EtOH Precipitation - Hard Clam RNA from earlier today",
    "section": "",
    "text": "RNA was mixed with 0.1 vols of 3M NAOAc (pH = 5.2) and 2.5 vols of 100% EtOH, vortexed and incubated @ -20C for 30mins. RNA was pelleted @ 16,000g, 30mins, 4C. Supe was discarded and pellet was washed with 1mL 70% EtOH. RNA was pelleted @ 16,000g, 15mins, 4C. This was step was repeated a second time. Supe was discarded, the RNA was resuspended in 50uL of 0.1% DEPC-H2O, spec’d and stored @ -80C:\n\nResults:\nInterestingly, precipitating the samples vastly improved the 260/230 ratios. However, the 260/280 ratios DECREASED for all samples except one (CA 1). Not really thrilled about this fact, nor am I sure why this would happen.\nRNA was stored @ -80C in “Sam’s RNA Box #1.”"
  },
  {
    "objectID": "posts/2010/2010-04-05-hibridizatonligation-solid-libraries-abalone-yellow-perch-lake-trout-herring/index.html",
    "href": "posts/2010/2010-04-05-hibridizatonligation-solid-libraries-abalone-yellow-perch-lake-trout-herring/index.html",
    "title": "Hibridizaton/Ligation SOLiD Libraries - Abalone, Yellow Perch, Lake Trout, Herring",
    "section": "",
    "text": "All 8 samples were hybridized/ligated according to Ambion’s Whole Transcriptome Analysis Kit using Adaptor A."
  },
  {
    "objectID": "posts/2010/2010-05-26-solid-epcrtemplated-bead-prep-lake-trout-lean-library/index.html",
    "href": "posts/2010/2010-05-26-solid-epcrtemplated-bead-prep-lake-trout-lean-library/index.html",
    "title": "SOLiD ePCR/Templated Bead Prep - Lake Trout Lean library",
    "section": "",
    "text": "ePCR was performed following ABI’s “full scale” protocol, using 1pM of SOLiD cDNA library.\nTemplated bead preparation was performed according to the “full scale” protocol.\nBead counts are calculated as follows:\nAvg bead count x # hemacytometer squares x volume in hemacytometer (uL) x dilution factor = beads/uL x suspension volume (uL) = total beads\nInitial Bead count: (1:200 dilution)\nLean: 126, 138, 122, 138 Avg. = 131\nLean: 131 x 25 x 10 x 200 = 6.55x10^6 beads/uL x 200uL = 1.31x10^9 beads\nTemplated Bead counts (1:10 dilution)\nLean: 165, 171, 186, 160 Avg. = 170.5\n170.5 x 25 x 10 x 10 = 426250 beads/uL x 400uL = 1.705x10^8 beads\nPercent Recovery Templated Beads\nLean: (1.705x10^8 beads)/(1.31x10^9 beads) x 100 = 13.02% recovery\nResults: Yield is significantly higher than the previous preparation performed with this sample. The percent recovery falls into the desired range of 5-15%, so things look good there, too. Will contact Rhonda and get info regarding when this and the other 7 samples can go on a run."
  },
  {
    "objectID": "posts/2010/2010-08-21-package-hard-clam-samples-from-rutgers/index.html",
    "href": "posts/2010/2010-08-21-package-hard-clam-samples-from-rutgers/index.html",
    "title": "Package - Hard Clam Samples from Rutgers",
    "section": "",
    "text": "Rec’d package of hard clam samples from Emily @ Rutgers on wet ice. Package contained numerous 1.5mL snap cap tubes separated in to groups in zip lock bags. Stored temporarily @ 4C. Will catalog and then store @ -80C.\nThree documents included with package:\nNote from Emily\nSample info, pg. #1\nSample info, pg. #2"
  },
  {
    "objectID": "posts/2010/2010-01-06-solid-epcr-herring-fragmented-cdna-library-3lhsitk09-from-20091209/index.html",
    "href": "posts/2010/2010-01-06-solid-epcr-herring-fragmented-cdna-library-3lhsitk09-from-20091209/index.html",
    "title": "SOLiD ePCR - Herring fragmented cDNA library: 3LHSITK09 (from 20091209)",
    "section": "",
    "text": "Processed herring fragmented cDNA library 3LHSITK09 (88.ng/uL) according to the ABI “Templated Bead Preparation Guide” following the “full-scale” protocol. Made a 1:1000 dilution (1uL library, 999uL 1x Low TE) = 88.5pg/uL. Mixed 67.8uL of this diluted sample with 32.2uL 1x Low TE to get a final concentration of 60pg/uL (500pM, according to ABI protocol). Oil phase used was previously prepared by Jesse (Seeb lab) in mid-December 2009. This oil phase is stable for 2 months @ 4C.\nePCR was started (Rhonda will put plate in fridge for storage O/N) and the rest of the procedure will be finished tomorrow."
  },
  {
    "objectID": "posts/2010/2010-03-29-bioanalyzer-for-solid-libraries-fragmented-mrna-from-perch-lake-trout-herring-rna-samples/index.html",
    "href": "posts/2010/2010-03-29-bioanalyzer-for-solid-libraries-fragmented-mrna-from-perch-lake-trout-herring-rna-samples/index.html",
    "title": "Bioanalyzer for SOLiD Libraries - Fragmented mRNA from Perch, Lake Trout & Herring RNA samples",
    "section": "",
    "text": "1uL of each sample from 20100325 was run on the Agilent 2100 Bioanalyzer on a RNA Pico 6000 chip to evaluate RNA quantity and fragmentation.\nResults:"
  },
  {
    "objectID": "posts/2010/2010-06-04-gdna-isolation-mac-gigas-gill-samples/index.html",
    "href": "posts/2010/2010-06-04-gdna-isolation-mac-gigas-gill-samples/index.html",
    "title": "gDNA Isolation - Mac gigas gill samples",
    "section": "",
    "text": "Set up gDNA isolation from the following samples:\nR51 01 - 20 (sample #11 was processed yesterday)\nR37 01 - 03, 06 - 13, 15, 16\nSamples were thawed from -80C. Tissue was removed from RNA Later (RNA Later gDNA isolation protocol; this protocol doesn’t indicate that anything needs to be done to the sample prior to gDNA isolation) and ~25mg was cut from each and placed in 0.5mL of DNAzol. 2.7uL of Proteinase K (Fermentas; 18.5mg/mL) was added to each tube to reach a final concentration of 100ug/mL. The digests were incubated @ RT O/N."
  },
  {
    "objectID": "posts/2010/2010-10-27-qpx-washes/index.html",
    "href": "posts/2010/2010-10-27-qpx-washes/index.html",
    "title": "QPX Washes",
    "section": "",
    "text": "Washed 4 day old QPX cultures. 3 isolates (S-1, TD-81, ATCC), two flasks (13mL) of each were washed in the following manner:\n\nEach flask’s contents were transferred to a 50mL conical tube.\nEach tube was topped with sterile sea water and mixed by inversion numerous times.\nTubes were centrifuged 10mins, 3000g at RT.\nTransferred mucus and pellet to empty 50mL conical tube.\nTopped with sterile sea water and mixed by inversion numerous times.\nCentrifuged 10mins, 3000g at RT.\nRemoved as much supe/mucus as possible without disturbing the pellet.\nTopped with sterile sea water and mixed by inversion numerous times.\nRepeat steps 7 through 8 until sample is mucous-free and the pellet can be resuspended.\n\nPellets were eventually resuspended in 1mL of sterile sea water, split between two 1.5mL snap cap tubes and then brought up to 1mL with sterile sea water."
  },
  {
    "objectID": "posts/2010/2010-03-18-bioanalyzer-for-solid-libraries-total-and-mrna-from-perch-lake-trout-herring-rna-samples-continued-from-yesterday/index.html",
    "href": "posts/2010/2010-03-18-bioanalyzer-for-solid-libraries-total-and-mrna-from-perch-lake-trout-herring-rna-samples-continued-from-yesterday/index.html",
    "title": "Bioanalyzer for SOLiD libraries - Total and mRNA from Perch, Lake Trout & Herring RNA samples (CONTINUED from yesterday)",
    "section": "",
    "text": "Total and mRNA aliquots (~5ng/uL) were run on the Agilent Bioanalyzer Pico RNA chips.\nResults:\nThe gel below shows the comparison/results of total RNA and subsequent mRNA isolations. The gel indicates the following:\n\nThe HPWS09 total RNA (Herring) is totally degraded, but shows the expected profile in the mRNA prep. It would be extremely interesting to see if the degradation has any effect on sequencing, as the mRNA will get fragmented any way in the next step of library construction.\nmRNA isolations worked for all samples. Although one might be inclined to say that mRNA isolation did NOT work for the WB sample, one has to take in to consideration that the gel software adjusts the gel contrast to enhance low signals. That’s why all the mRNA samples exhibit a dark background. mRNA generates a broad, relatively weak signal when compared to a total RNA sample. So, the software attempts to boost the low signal for display purposes. Thus, if we were to decrease this signal boosting (or contrast) for the WB mRNA so that the background color matched the WB total RNA background color (white), the rRNA bands visible in the WB mRNA sample would fade to a point where they would not be visible. See the electropherogram overlay (below the gel) for a more visual comparison of this concept.\n\n\nElectropherogram Overlays of WB total RNA and WB rRNA\n\nThe WB total RNA is the red graph which shows extremely high levels of rRNA (as expected). After subsequent mRNA isolation (the blue graph), the rRNA is virtually gone and no longer comprises a significant portion of the sample."
  },
  {
    "objectID": "posts/2010/2010-05-28-gdna-isolation-mac-gigas-gill-samples-continued-from-yesterday-2/index.html",
    "href": "posts/2010/2010-05-28-gdna-isolation-mac-gigas-gill-samples-continued-from-yesterday-2/index.html",
    "title": "gDNA Isolation - Mac gigas gill samples (continued from yesterday)",
    "section": "",
    "text": "Continued with gDNA isolation from yesterday’s samples. Additionally, isolated gDNA from R51 01, but homogenized the tissue (using disposable 1.5mL mortar/pestle) in 0.5mL of DNAzol and topped off to 1.0mL. All 3 samples were gently pipetted up and down to further dissolve the tissue. For those samples that were subjected to Proteinase K digestion, I transferred 100uL of the solution to a new tube containing 1mL of DNAzol, [as described in the DNAzol protocol (see “Notes, #5” part of protocol)(https://www.mrcgene.com/dnazol.htm). Tubes were incubated 10mins @ RT.\nPelleted residual tissue 10mins @ 10,000g @ 4C. Transferred supe to new tubes. Precipitated DNA with 0.5mL 100% EtOH. Incubated 3mins @ RT. DNA was pelleted 5mins @ 5000g @ 4C. Supe was removed, pellets were washed with 1mL 75% EtOH (x2). Supe was fully removed and the pellets were resuspended in 8mM NaOH (made by Amanda Davis 5/20/10). See below for volumes:\nR51 11 - 50uL\nR51 01 - 100uL\nR51 01 homogenized - 200uL\n1M HEPES (provided with DNAzol) was added at a 1:100 dilution to achieve a pH = 8.0. This was based on the DNAzol protocol calculations (For 1mL of 8mM NaOH, use 101uL of 0.1M HEPES).\nSamples were spec’d on NanoDrop 1000. Used a sample with 8mM NaOH and 1M HEPES to match the pH = 8.0 of the samples.\nResults:\n\nThe 260/280 ratios for all samples are great. Yields are significantly lower than I was expecting. However, for R51 11 and R51 01, only 100uL (1/5th) of the digestion was used as described in the protocol. I may recover the remainder of the R51 11 gDNA since remaining tissue could be a limiting factor. The homogenized sample had the highest yield (9.35ug), suggesting this may be a more efficient approach to obtaining gDNA (faster procedure and higher yields).\nThese results also demonstrate that gDNA can be successfully isolated from samples stored in RNA Later (gel pending).\nDue to low yields of the R51 11 and R51 01 samples, these will not be run on a gel until the rest of the DNA is isolated.\nIsolated the remainder of the gDNA from R51 11 and R51 01. Added an additional 0.5mL of DNAzol to each tube and pipetted up and down to further dissolve the remaining tissue. Then, proceeded as described above. Samples were resuspended in 200uL of 8mM NaOH with 2.02uL of 1M HEPES added.\nResults:\n\nBoth samples have great yields and excellent 260/280 ratios. Digestion, combined with gentle pipetting to disrupt undigested tissue, appears to lead to higher yields. However, the process is more time consuming than just basic, physical homogenization of tissue.\n\nGel Loading (0.5ug of each DNA was loaded in a volume of 25uL)\nLane 1. Hyperladder\nLane 2. R51 11\nLane 3. R51 01\nLane 4. R51 01 homogenized\nThe R51 11 sample looks perfect. The other two samples however, appear degraded, with the homogenized sample looking the worst. Interestingly, those are both from the same source tissue, possibly suggesting that the DNA in this particular gill sample is actually degraded and is independent of the preparation, since the R51 11 (Lane 2) and R51 01 (Lane 3) were prepared simultaneously and in the same way. The gel also seems to show that physically homogenizing the sample leads to greater degradation than performing the Proteinase K digestion."
  },
  {
    "objectID": "posts/2010/2010-04-02-bioanalyzer-total-mrna-and-post-fragmentation-solid-libraries-abalone-pools/index.html",
    "href": "posts/2010/2010-04-02-bioanalyzer-total-mrna-and-post-fragmentation-solid-libraries-abalone-pools/index.html",
    "title": "Bioanalyzer Total, mRNA and post-fragmentation SOLiD Libraries - Abalone pools",
    "section": "",
    "text": "0.5uL of fragmented mRNA from each library (combined with 0.5uL) was run on Agilent Bioanalyzer 2100 using RNA Pico chips/reagents according to Agilent’s protocol.\nResults:\nTotal RNA shows a single, distinct rRNA band, along with some low-molecular weight RNA (i.e. degraded) in both total RNA samples. mRNA samples exhibit the expected “smear” that spans a large range of molecular weights. Both mRNA samples also show residual rRNA bands, but their concentrations should be extremely low. Fragmented samples show the expected strong band of low-molecular weight RNA. The CE frag sample exhibits some larger banding, which is probably background signal (compare to the empty lane labelled “Sample 7”).\nWill proceed with rest of library procedure for both fragmented samples."
  },
  {
    "objectID": "posts/2010/2010-04-16-templated-bead-prep-solid-libraries-yellow-perch-wb-lake-trout-lean-and-sisco-and-herring-go-hws09-libraries/index.html",
    "href": "posts/2010/2010-04-16-templated-bead-prep-solid-libraries-yellow-perch-wb-lake-trout-lean-and-sisco-and-herring-go-hws09-libraries/index.html",
    "title": "Templated Bead Prep SOLiD Libraries - Yellow perch WB, lake trout Lean and Sisco, and herring G/O HWS09 libraries",
    "section": "",
    "text": "All libraries were prepped according to ABI’s “full-scale” bead prep protocol. Initial bead counts were performed using a hemocytometer in a 1:200 dilution:\nFormula for calculating bead counts:\nAverage hemo count x hemo volume x hemo squares x dilution x bead volume\nInitial Bead Counts\nWB: 111, 96, 90, 100 Average = 99.25 Count: 99.25 x 10 x 25 x 200 x 200 = 9.925 x 10^8 beads\nLean: 101, 100, 108, 108 Average = 104.25 Count: 104.25 x 10 x 25 x 200 x 200 = 1.0425 x 10^9 beads\nSisco: 142, 144, 120, 112 Average = 129.5 Count: 129.5 x 10 x 25 x 200 x 200 = 1.295 x 10^9 beads\nHPWS09: 112, 115, 105, 104 Average = 109 Count: 109 x 10 x 25 x 200 x 200 = 1.09 x 10^9 beads\nTemplated Bead Counts\nTemplated bead counts were performed using a hemocytometer with a 1:10 dilution:\nWB: 198, 186, 198, 175 Average = 189.25 Count: 189.25 x 10 x 25 x 10 x 400 = 1.8925 x 10^8 beads\nLean: 253, 259, 236, 244 Average = 248 Count: 248 x 10 x 25 x 10 x 400 = 2.48 x 10^8 beads\nSisco: 267, 241, 252, 255 Average = 253.75 Count: 253.75 x 10 x 25 x 10 x 400 = 2.5375 x 10^8 beads\nHPWS09: 193, 193, 172, 186 Average = 186 Count: 186 x 10 x 25 x 10 x 400 = 1.86 x 10^8 beads\nTemplated Bead Recovery: Final bead count divided by initial bead count x 100 = % recovery\nWB = 1.8925 x 10^8/9.925 x 10^8 x 100 = 19.07%\nLean = 2.48 x 10^8/1.0425 x 10^9 x 100 = 23.8%\nSisco = 2.5375 x 10^8/1.295 x 10^9 x 100 = 24.34%\nHPWS09 = 1.86 x 10^8/1.09 x 10^9 x 100 = 17.06%\nResults: Yields of templated beads look fabulous. Recoveries of templated beads are a bit on the high side (desired recoveries are between 5-15%, with 20% being the “cutoff” that Rhonda’s lab uses for runs. The Lean and Sisco samples cross this cutoff value. Will consult with Steven to see what how he wants to proceed (i.e. new ePCRs?). Beads stored @ 4C until ready for running on the SOLiD."
  },
  {
    "objectID": "posts/2010/2010-07-02-medip-sbwb-fragmented-gdna-continued-from-yesterday-2/index.html",
    "href": "posts/2010/2010-07-02-medip-sbwb-fragmented-gdna-continued-from-yesterday-2/index.html",
    "title": "MeDIP - SB/WB Fragmented gDNA (continued from yesterday)",
    "section": "",
    "text": "Continued MeDIP process from yesterday. Added 20uL of Protein A/G Plus Agarose (Santa Cruz Biotech) beads to each sample and continued incubation with rotation @ 4C for 2hrs. Pelleted the Protein A/G beads 3300g, 2mins, 4C.\nRemoved and saved supe (to retain unmethylated DNA). Washed beads with 1mL 1x MeDIP Buffer. Repeated two more times. Saved supe after each wash.\nResuspended beads in 250uL MeDIP Digestion Buffer (50mM Tris-HCl, pH=8.0, 10mM EDTA, pH=8.0, 0.5% SDS). Added 75ug of Proteinase K. Incubated 20hrs @ RT with end-over-end rotation.\nNote: The protocol we have says to incubate the Proteinase K digest @ 55C. However, we don’t have a means to do so, since we need a rocker/rotator to keep the agarose beads in suspension. According to various sources, Proteinase K retains >80% of it’s enzymatic activity between 20C-50C. So, I’ve allowed the digest to run longer (24hrs) than recommended (O/N)."
  },
  {
    "objectID": "posts/2010/2010-07-09-gdna-isolation-various-gigas-samples/index.html",
    "href": "posts/2010/2010-07-09-gdna-isolation-various-gigas-samples/index.html",
    "title": "gDNA Isolation - Various gigas samples",
    "section": "",
    "text": "Placed ~20mg fragments of tissue in 250uL DNAzol. Added 1.35uL of Proteinase K (Fermentas; 18.5mg/mL) to reach a final concentration of 100ug/mL. Incubated RT, O/N, end-over-end rotation. Will complete DNA isolation tomorrow.\nSample List:\nVt Gigas Live #3 Gill 24E (from 20080828; Tatyana’s notebook)\nGigas Control #2 Gill 24E (from 20080828; Tatyana’s notebook)\nNB-1209-10 (RNA Later)\nSB-1209-14 (RNA Later)\nWB-1209-09 (RNA Later)\n0629 gill 5aza\n0629 gonad 5aza\n0629 mantle 5aza"
  },
  {
    "objectID": "posts/2010/2010-07-01-medip-sbwb-fragmented-gdna-from-20100625/index.html",
    "href": "posts/2010/2010-07-01-medip-sbwb-fragmented-gdna-from-20100625/index.html",
    "title": "MeDIP - SB/WB Fragmented gDNA (from 20100625)",
    "section": "",
    "text": "After confirming proper fragmentation (~460bp average fragment size) via Bioanalyzer earlier today, began the MeDIP process. Brought fragmented DNA samples up to 350uL with TE. Heated samples @ 95C for 10mins, then incubated on ice 5mins. Added 100uL of 5x MeDIP Buffer (50mM Na2HPO4, 700mM NaCl, 0.25% Triton-X 100), 45uL of TE and 5uL (5ug) of anti-methyl cytidine antibody (Diagenode; 5-mC monoclonal antibody cl. b). Incubated O/N, 4C rotating."
  },
  {
    "objectID": "posts/2010/2010-09-08-rna-isolation-hard-clam-tissues-recd-from-rutgers-on-20100820/index.html",
    "href": "posts/2010/2010-09-08-rna-isolation-hard-clam-tissues-recd-from-rutgers-on-20100820/index.html",
    "title": "RNA Isolation - Hard Clam Tissues Rec’d from Rutgers on 20100820",
    "section": "",
    "text": "RNA was isolated from the following samples using TriReagent, according to protocol:\nMAX 1, 2, & 3\nCA 1, 2, & 3\nMA 1, 2, & 3\nSamples were resuspended in 50uL of 0.1% DEPC-H2O and spec’d:\n\nResults:\n260/280 ratios are decent for most of the samples, with MAX1 and MAX 2 being the exception. Both of these samples also have very poor 260/230 ratios. Out of curiosity, I will EtOH precipitate all samples to see if I can improve both the 260/280 and 260/230 ratios."
  },
  {
    "objectID": "posts/2010/2010-04-08-cdna-clean-up-bioanalyzer-for-solid-libraries-abalone-yellow-perch-lake-trout-herring/index.html",
    "href": "posts/2010/2010-04-08-cdna-clean-up-bioanalyzer-for-solid-libraries-abalone-yellow-perch-lake-trout-herring/index.html",
    "title": "cDNA clean up & Bioanalyzer for SOLiD Libraries - Abalone, Yellow Perch, Lake Trout, Herring",
    "section": "",
    "text": "Amplified cDNA was cleaned up using the Invitrogen PureLink Micro Kit, but was done so according to Ambion’s Whole Transcriptome Analysis Kit protocol and then spec’d.\n\nResults:\n0.5uL was removed from each sample and mixed with 0.5uL to run on DNA 1000 chips on the Bioanalyzer 2100. The slideshow below shows the electropherograms from each sample. Each sample (to be considered worthy of moving to the next stage) should have <20% of the sample in the 25-150bp range. All 8 samples exhibit this and their peaks look very good. Will proceed to ePCR/templated bead prep next week."
  },
  {
    "objectID": "posts/2010/2010-03-25-solid-library-prep-mrna-perch-lake-trout-herring-from-20100318-fragmentation/index.html",
    "href": "posts/2010/2010-03-25-solid-library-prep-mrna-perch-lake-trout-herring-from-20100318-fragmentation/index.html",
    "title": "SOLiD Library Prep - mRNA (perch, lake trout, herring from 20100318) Fragmentation",
    "section": "",
    "text": "Fragmented mRNA according to Ambion’s Whole Transcriptome Sequencing Kit. Cleaned up sample using Ribominus Concentration Module (Invitrogen) according to Ambion’s WTS Analysis Kit. Samples were eluted w/20uL of H2O and stored @ -80C. Will Bioanalyze and speedvac at a later date."
  },
  {
    "objectID": "posts/2010/2010-09-18-opticon-calibration/index.html",
    "href": "posts/2010/2010-09-18-opticon-calibration/index.html",
    "title": "Opticon Calibration",
    "section": "",
    "text": "Distributed 50uL of FAM calibration dye to wells. Ran out of dye!!\nLooking back at old purchasing logs, it turns out we need 2 orders of dye packs to have enough for a 96-well plate.\nWill cap existing plate with dye, wrap in foil and store @ -20C.\nOrdered an additional pack of dye (Cat# 10006046; not available online, must call BioRad to order). Will ship on Monday. Will finish calibration procedure on Tuesday (20100928). Ugh.\nResults:\nEmpty Plate:\n\nPlate with dye (presumably calibrated):\n\nAfter running the calibration protocol with the dye, all the wells should show consistent fluorescence levels. Clearly, they do not. Oddly enough, there appears to be a cyclical pattern across the wells of low -> high -> low fluorescence. The calibration protocol advises that if the wells do not exhibit consistent fluorescence across wells, then the plate should be read again. The graph above is the 2nd reading, which appears to be the same as the 1st. Conclusion is that the Opticon 2 is not working correctly and will contact BioRad for price quotes on repairs."
  },
  {
    "objectID": "posts/2010/2010-11-30-etoh-precipitations-hpaii-and-mspi-2nd-round-digests-from-20101124/index.html",
    "href": "posts/2010/2010-11-30-etoh-precipitations-hpaii-and-mspi-2nd-round-digests-from-20101124/index.html",
    "title": "EtOH Precipitations - HpaII and MspI 2nd Round Digests from 20101124",
    "section": "",
    "text": "Samples were EtOH precipitated, according to protocol. Samples were resuspended in 20uL of Qiagen’s EB and spec’d.\nSamples are labeled as Parent (P), #, tissue, enzyme (MspI = M, HpaII = H, Undigested = U)\nResults:\nSpreadsheet of spec values is here. Overall, poor recoveries from all of the digested samples, but decent recoveries from the undigested samples. The samples were passed to Mac who performed qPCR using two different primer sets. Please see her notebook for the results of the qPCR."
  },
  {
    "objectID": "posts/2010/2010-11-30-restriction-digestions-hpaii-and-mspi-on-macs-c-gigas-samples-round-1/index.html",
    "href": "posts/2010/2010-11-30-restriction-digestions-hpaii-and-mspi-on-macs-c-gigas-samples-round-1/index.html",
    "title": "Restriction Digestions - HpaII and MspI on Mac’s C.gigas Samples: Round 1",
    "section": "",
    "text": "1st of 2 rounds of digests were performed. Calculations are here. Samples were incubated 37C for 3hrs, heat inactivated @ 80C for 30mins and then stored @ -20C."
  },
  {
    "objectID": "posts/2010/2010-07-09-medip-sbwb-fragmented-gdna-etoh-precipitation-continued-from-20100702/index.html",
    "href": "posts/2010/2010-07-09-medip-sbwb-fragmented-gdna-etoh-precipitation-continued-from-20100702/index.html",
    "title": "MeDIP - SB/WB Fragmented gDNA EtOH precipitation (continued from 20100702)",
    "section": "",
    "text": "Finished EtOH precipitation of MeDIP gDNA. Samples were pelleted 16,000g, 4C, 30mins. Supe was discarded. Washed with 1mL 70% EtOH, pelleted 16,000g, 4C, 15mins. Supe discarded. MeDIP DNA was resuspended in 100uL of TE (pH = 8.5). Wash samples, containing unmethylated DNA, were resuspended/combined in a total of 100uL TE (pH = 8.5). Samples were spec’d:\n\nResults:\nR37: MeDIP DNA = 1.393ug recovery. This is ~13% of the input total gDNA (11.25ug) and is ~28% of the total DNA recovered in the procedure (4.935ug). Unmethylated DNA = 3.542ug total recovery. This is ~31% of the input total gDNA (11.25ug) and is ~72% of the total DNA recovered in the procedure (4.935ug). Total DNA recovery = ~44%.\nR51: MeDIP DNA = 1.256ug recovery. This is ~14% of the input total gDNA (8.75ug) and is ~23% of the total DNA recovered in the procedure (5.462ug). Unmethylated DNA = 4.206ug total recovery. This is ~48% of the input total gDNA (8.75ug) and is ~77% of the total DNA recovered in the procedure (5.462ug). Total DNA recovery = ~62%.\nThere definitely seemed to be a high degree of salt carryover from the procedure, despite the phenol:chloroform treatment and EtOH precipitation. As such, I believe this is the reason that the 260/230 ratios are so out of whack. Possibly explains why the 260/280 ratios for the MeDIP DNA are so high, too?\nThese results demonstrate what we can expect to recover from this procedure, as well as how much DNA gets lost during processing. MeDIP DNA and unmethylated DNA were stored @ -20C."
  },
  {
    "objectID": "posts/2010/2010-03-16-mrna-isolation-for-solid-perch-lake-trout-and-herring-total-rna/index.html",
    "href": "posts/2010/2010-03-16-mrna-isolation-for-solid-perch-lake-trout-and-herring-total-rna/index.html",
    "title": "mRNA Isolation for SOLiD - Perch, Lake Trout, and Herring total RNA",
    "section": "",
    "text": "Received pooled lean and siscowet RNA from Rick. Samples will be processed immediately for SOLiD fragment libraries. Two 1.5mL snap cap tubes labelled:\nL.T. 2ug muscle sisco pool\nL.T. 2ug muscle lean pool\nRNA was first precipitated according to the Ambion MicroPolyA Purist Kit protocol (0.1 vol 5M ammonium acetate, 1uL glycogen, 2.5 vols 100% EtOH). Samples were incubated @ -80C for 30mins. Samples were resusupended in 250uL nuclease-free H2O and spec’d.\n\nStarting quantities PRIOR to total RNA precipitation:\nPerch Samples:\nWB tRNA (WB tRNA ~12ug 24.5uL)\nPQ tRNA (PW tRNA ~12ug 21.88uL)\nCT tRNA (CT tRNA ~12ug 25uL)\nHerring:\n1 G/O HPWS09 (20ug)\nLake Trout:\nL.T. 20ug muscle sisco pool\nL.T. 20ug muscle lean pool\nRemoved 1uL of each sample, diluted to ~5ng/uL and stored @ -80C to run on the Bioanalyzer.\nUsed Ambion MicroPolyA Purist Kit according to protocol. Samples were treated twice to ensure elimination of rRNA from the samples. After second run through MicroPolyA Purist, samples were EtOH precipitated O/N @ -20C according to Ambion’s MicroPolyA Purist protocol."
  },
  {
    "objectID": "posts/2010/2010-04-06-reverse-transcription-solid-libraries-abalone-yellow-perch-lake-trout-herring/index.html",
    "href": "posts/2010/2010-04-06-reverse-transcription-solid-libraries-abalone-yellow-perch-lake-trout-herring/index.html",
    "title": "Reverse Transcription SOLiD Libraries - Abalone, Yellow Perch, Lake Trout, Herring",
    "section": "",
    "text": "Samples were speedvac’d to dryness and resuspended in 3uL of nuclease-free H2O. Samples were then reversed transcribed according to Ambion’s Whole Transcriptome Analysis Kit. RT master mix set up is here (top portion of sheet)."
  },
  {
    "objectID": "posts/2010/2010-12-14-qpcr-cox-qpcr-vibrio-exposure-response-check/index.html",
    "href": "posts/2010/2010-12-14-qpcr-cox-qpcr-vibrio-exposure-response-check/index.html",
    "title": "qPCR - COX qPCR Vibrio Exposure Response Check",
    "section": "",
    "text": "Used COX primers (SR IDs 1060, 1061) and cDNA from 20080327, which consisted of 7 control gigas gill and 7 vibrio-exposed (24hrs) gigas gill samples, labeled as C# and VE#, respectively. The experiment was a 24hr. exposure live Vibrio vulnificus, parahaemolyticus Cf = 2.055x10^11 (6.85x10^7 Vibrio cells/oyster). Note: Used a free sample of 2x Brilliant III Ultra Fast SYBR Green QPCR Master Mix (Stratagene) for this qPCR. Mixed components and set up cycling params according to the manufacturer’s recommendation for the BioRad CFX96.\nMaster mix calcs are here. Plate layout, cycling params, etc. can be see in the qPCR Report (see Results).\nResults:\n[ qPCR Report (PDF)(https://eagle.fish.washington.edu/Arabidopsis/Notebook%20Workup%20Files/20101213%20qPCR%20Report-01.pdf).\nPCR Miner analysis is here. There appears to be an increase in COX expression in samples exposed to Vibrio sp. (see graph below), however, I have not determined if the results are significant."
  },
  {
    "objectID": "posts/2010/2010-03-31-rna-precipitation-mrna-isolation-for-solid-libraries-pooled-abalone-total-rna-carmel-control-carmel-exposed/index.html",
    "href": "posts/2010/2010-03-31-rna-precipitation-mrna-isolation-for-solid-libraries-pooled-abalone-total-rna-carmel-control-carmel-exposed/index.html",
    "title": "RNA Precipitation & mRNA Isolation for SOLiD Libraries - Pooled abalone total RNA: Carmel control, Carmel exposed",
    "section": "",
    "text": "RNA of 8 samples from each group was pooled equally from each individual. RNA was precipitated according to Ambion’s MicroPolyA Purist Kit. Used 0.1 volumes of 3M NaAOc, pH=5.2, 2.5vols of 100% EtOH and incubated 30min @ -80C. Pelleted RNA 16,000g, 30mins. Washed pellet w/70% EtOH and pelleted RNA 16,000g, 15mins. Pellets were resuspended in 50uL nuclease-free H2O and spec’d:\n\nTotal RNA pools look really nice. ~45ug of total RNA in each sample.\nIsolated mRNA from each pool using Ambion’s MicroPolyA Purist Kit according to protocol. Samples were processed 2x as recommended by Ambion’s SOLiD Whole Transcriptome Analysis Kit. Final elution was 200uL of The RNA Storage Solution. Samples were spec’d:"
  },
  {
    "objectID": "posts/2010/2010-06-19-gdna-sonication-sbwb-gdna-pools-prep-for-medip-from-earlier-today/index.html",
    "href": "posts/2010/2010-06-19-gdna-sonication-sbwb-gdna-pools-prep-for-medip-from-earlier-today/index.html",
    "title": "gDNA Sonication - SB/WB gDNA pools (prep for MeDIP) from earlier today",
    "section": "",
    "text": "The two gDNA pools (SB and WB) were sonicated using a Covaris S2. Used the guidelines of the manufacturer (listed below) for shearing gDNA to a desired target size (500bp):\nDuty Cycle: 5%\nIntensity: 3\nCycels per Burst: 200\nTime (seconds): 90\nTemp (water bath): 4C\nPower Mode: Frequency Sweeping\nSample Volume: 120uL\nBuffer: TE\nDNA Mass: ~8ug\nStarting Material: >50kb\nTo be noted, the Covaris guidelines list the use of an “AFA Intensifier” tube, which I did not use (because we don’t have them).\nAfter shearing, ran 250ng of each pool on a 2% TAE agarose gel for fragmentation verification. Also ran 250ng of pre-sonication DNA from each pool as controls.\nResults:\n\nLane 1 - Hyperladder I\nLane 2 - R37, Un-sonicated\nLane 3 - R37, sonicated\nLane 4 - R51, Un-sonicated\nLane 5 - R51, sonicated\nSonication with the Covaris did NOT produce the desired fragmentation (500bp smear) in either sample, although the R37 sonicated samples shows a significantly greater degree of fragmentation than the R51 sonicated sample. Not sure how to explain this difference, other than the R51 sample has a greater amount of DNA. Additionally, the results could be explained by the fact that we did not use the AFA Intensifier listed in the Covaris guidelines…\nAm consulting with a person in Genome Sciences who has used a Covaris for DNA fragmentation in the past to see if the AFA Intensifiers are indeed necessary and, if so, we can use two of them. Hopefully have an answer soon and be able to proceed with additional fragmentation next week."
  },
  {
    "objectID": "posts/2010/2010-03-10-pcr-test-lexies-mercenaria-18s-contamination-issue/index.html",
    "href": "posts/2010/2010-03-10-pcr-test-lexies-mercenaria-18s-contamination-issue/index.html",
    "title": "PCR - Test Lexie’s Mercenaria 18s contamination issue",
    "section": "",
    "text": "Lexie’s PCR with this primer set and a pool of Mercenria cDNA has yielded contamination in all of her waters. Performed two sets of PCR: one with her existing primer working stocks and the other with a fresh aliquot of primer working stocks. Used my own reagents/water. PCR set up and cycling params are here. PCR ran O/N.\nResults:\n\nLane 1 - 100bp ladder\nLane 2 - H2O (Lexie’s primer stocks)\nLane 3 - H2O (Lexie’s primer stocks)\nLane 4 - cDNA (Lexie’s primer stocks)\nLane 5 - H2O (fresh primer stocks)\nLane 6 - H2O (fresh primer stocks)\nLane 7 - cDNA (fresh primer stocks)\nAll water samples look clean and there’s a nice bright band in the cDNA samples. Lexie’s contamination issue is probably a technique issue and not one of reagent contamination."
  },
  {
    "objectID": "posts/2010/2010-01-11-solid-epcr-herring-fragmented-cdna-library-2lhkod09/index.html",
    "href": "posts/2010/2010-01-11-solid-epcr-herring-fragmented-cdna-library-2lhkod09/index.html",
    "title": "SOLiD ePCR - Herring fragmented cDNA library: 2LHKOD09",
    "section": "",
    "text": "Using 1.5pM of starting template, based on success of the 3LHSITK09 bead prep (see 20100108).\nProcessed herring fragmented cDNA library 2LHKOD09 (76.1.ng/uL) according to the ABI “Templated Bead Preparation Guide” following the “full-scale” protocol. Made a 1:100 dilution (1uL library, 99uL 1x Low TE) = 761pg/uL. Mixed 23.7uL of this diluted sample with 76.3uL 1x Low TE to get a final concentration of 180pg/uL (1.5pM, according to ABI protocol). Oil phase used was previously prepared by Jesse (Seeb lab) 1/11/2010. This oil phase is stable for 2 months @ 4C.\nePCR was started and run O/N. The plate will be stored @ 4C until the two remaining libraries have been through ePCR. Then, all three libraries will be processed simulatneously."
  },
  {
    "objectID": "posts/2010/2010-04-01-rna-precipitation-and-fragmentation-for-solid-libraries-pooled-abalone-mrna-from-yesterday/index.html",
    "href": "posts/2010/2010-04-01-rna-precipitation-and-fragmentation-for-solid-libraries-pooled-abalone-mrna-from-yesterday/index.html",
    "title": "RNA Precipitation and Fragmentation for SOLiD Libraries - Pooled abalone mRNA (from yesterday)",
    "section": "",
    "text": "mRNA was precipitated according to Ambion’s MicroPolyA Purist Kit protocol. Added 0.1vols of ammonium acetate, 2.5vols of 100% EtOH and incubated 30mins @ -80C. Samples were pelleted, washed with 1mL 70% EtOH, pelleted, resuspended in 8uL of nuclease-free H2O and spec’d:\n\nAfter precipitation, samples were fragmented with RNase III according to the Ambion Whole Transcriptome Analysis Kit protocol and then cleaned up using the Invitrogen Ribominus Concentration Module, according to the Ambion Whole Transcriptome Analysis Kit protocol. 0.5uL of each sample was removed for analysis on the Bioanalyzer."
  },
  {
    "objectID": "posts/2010/2010-01-07-solid-epcr-herring-fragmented-cdna-library-3lhsitk09/index.html",
    "href": "posts/2010/2010-01-07-solid-epcr-herring-fragmented-cdna-library-3lhsitk09/index.html",
    "title": "SOLiD ePCR - Herring fragmented cDNA library: 3LHSITK09",
    "section": "",
    "text": "Due to low yield of templated beads (12x10^6) from the first run through (see SOLiD Bead Titration below), am repeating using 1.5pM of starting template (as opposed to 0.5pM used yesterday). It should be noted that there is NOT a linear relationship between the amount of starting template and the amount of enriched, templated beads one ends up with in this protocol. So, even though I am increasing the starting template by 3-fold, a 3-fold increase in the amount of enriched, templated beads is NOT expected (hopefully it’ll be more than that!).\nProcessed herring fragmented cDNA library 3LHSITK09 (88.ng/uL) according to the ABI “Templated Bead Preparation Guide” following the “full-scale” protocol. Made a 1:100 dilution (1uL library, 99uL 1x Low TE) = 885pg/uL. Mixed 20.3uL of this diluted sample with 79.7uL 1x Low TE to get a final concentration of 180pg/uL (1.5pM, according to ABI protocol). Oil phase used was previously prepared by Jesse (Seeb lab) in mid-December 2009. This oil phase is stable for 2 months @ 4C.\nePCR was started and run O/N. The rest of the procedure will be finished tomorrow."
  },
  {
    "objectID": "posts/2010/2010-05-03-qpcr-v-tubiashii-primers-test-vpt-a-and-vt-igs/index.html",
    "href": "posts/2010/2010-05-03-qpcr-v-tubiashii-primers-test-vpt-a-and-vt-igs/index.html",
    "title": "qPCR - V.tubiashii primers test (Vpt A and Vt IGS)",
    "section": "",
    "text": "Utilized to sets of primers obtained from the Friedman Lab: VptA (referred to as “Hasegawa”, even though the reference article calls the primers Vtp A) and Vt IGS (referred to as “Lee” primers, presumably from a published article). For template, used “RE22 DNA” that was given to me by Elene. Tube is dated 9/10/09 and has no indication of concentration. Performed qPCR on a set of 10-fold dilutions. Plate layout/qPCR set up is here, along with dilution series used.\nResults:\nThe VptA primer set generated a nice looking set of dilutions with appropriate spacing (~3.2 Ct/10-fold dilution). HOWEVER, the raw fluorescence signal is very low (only 0.4 units; good signal is usually 3-5-fold higher) AND the melting curve doesn’t look that great. The melting curve could look poor due to the low signal, since it doesn’t come up much higher than background levels.\nIt should be noted that the low fluorescence levels generated could simply be due to the amplicon size generated by these primers. The amplicon size is only 63bp. An amplicon of this size might not be able to incorporate significant amounts of dye to generate a “normal” level of fluorescence (1.25 - 2 units).\nThe Vt IGS primers failed to generate any product."
  },
  {
    "objectID": "posts/2010/2010-07-10-gdna-isolation-various-gigas-samples-continued-from-yesterday/index.html",
    "href": "posts/2010/2010-07-10-gdna-isolation-various-gigas-samples-continued-from-yesterday/index.html",
    "title": "gDNA Isolation - Various gigas samples (continued from yesterday)",
    "section": "",
    "text": "Pelleted residual tissue 10mins @ 10,000g @ RT. Transferred supe to new tubes. Precipitated DNA with 0.25mL 100% EtOH. Incubated 3mins @ RT. DNA was pelleted 5mins @ 5000g @ RT. Supe was removed, pellets were washed with 1mL 75% EtOH (x2). Supe was fully removed and the DNAs were resuspended in 300uL 8mM NaOH (made 7/9/10 SJW).\n1M HEPES (provided with DNAzol) was added at a 1:100 dilution to achieve a pH = 8.0. This was based on the DNAzol protocol calculations (For 1mL of 8mM NaOH, use 101uL of 0.1M HEPES = pH 8.0).\nSamples were spec’d on NanoDrop 1000. Used a sample with 8mM NaOH and 1M HEPES as a blank to match the pH = 8.0 of the samples.\nResults:\n\n260/280 ratios look good for all samples. Most of the samples have mediocre 260/230 ratios. Yields are excellent for all samples."
  },
  {
    "objectID": "posts/2010/2010-07-10-qpcr-hpaiimspi-digests-from-earlier-today/index.html",
    "href": "posts/2010/2010-07-10-qpcr-hpaiimspi-digests-from-earlier-today/index.html",
    "title": "qPCR - HpaII/MspI Digests from earlier today",
    "section": "",
    "text": "qPCR plate layout/setup is here.\nResults:"
  },
  {
    "objectID": "posts/2010/2010-07-01-bioanalyzer-fragmented-sbwb-gdna-from-20100625/index.html",
    "href": "posts/2010/2010-07-01-bioanalyzer-fragmented-sbwb-gdna-from-20100625/index.html",
    "title": "Bioanalyzer - Fragmented SB/WB gDNA (from 20100625)",
    "section": "",
    "text": "To gain a more quantitative assessment of the fragmentation from 20100625, I ran 1uL of each sample (~55ng, according to pre-fragmentation spec values) on the Agilent Bioanalyzer 2100, using the DNA 1000 kit, according to manufacturer’s protocol.\nResults:\nAvg. size of fragmentation is ~460bp for the two samples. Fragmentation size was determined by marking the same region on both sample’s electropherograms (see below).\nR37: Avg. size = 450bp (in Region 1, marked with blue lines in image below)\n\nR51: Avg. size = 468bp (in Region 1, marked with blue lines in image below)\n\nOverlay of R37 and R51 fragmentation. Note that both electropherograms are nearly identical (this is good)."
  },
  {
    "objectID": "posts/2010/2010-01-08-solid-bead-titration-herring-fragmented-cdna-library-3lhsitk09-continued-from-epcr-yesterday/index.html",
    "href": "posts/2010/2010-01-08-solid-bead-titration-herring-fragmented-cdna-library-3lhsitk09-continued-from-epcr-yesterday/index.html",
    "title": "SOLiD Bead Titration - Herring fragmented cDNA library 3LHSITK09 (CONTINUED from ePCR yesterday)",
    "section": "",
    "text": "Completed the remainder of the procedure for template bead titration, according to the ABI “Templated Bead Preparation Guide” following the “full-scale” protocol.\nTo see explanations of the various calculations below, see the “SOLiD Bead Titration - Herring fragmented cDNA library 3LHSITK09(CONTINUED from ePCR yesterday)” from 20100107.\nTemplated bead count after breaking emulsion, in a 1:200 dilution: 110, 129, 115, 105, 143, 113. Average = 119.2 beads/square\nRecovery: 119.2 beads/square x 10uL x 25 squares x 200 = 5.96x10^6 beads/uL\nTotal beads recovered: 5.96x10^6 beads/uL x 200uL = 1.19x10^9\nDesired # of beads is between 1-2 billion. I recovered 1.19 billion. This is in the desired range.\nFinal count of enriched, templated-beads: 194, 181, 161, 214. Average = 187.5 beads/square\nFinal recovery: 187.5 beads/square x 10uL x 25 squares x 10 = 4.6875x10^5 beads/uL\nTotal enriched, templated beads recovered: 4.6875x10^5 beads/uL x 400uL = 1.875x10^8 beads\nEnrichment efficiency percentage: 1.875x10^8 beads/1.19x10^9 x 100 = 15.8%\nBeads were stored @ 4C until more templated beads are generated.\nResults: This is excellent! Got desired recovery of beads after the ePCR and got an excellent yield of templated beads. Need 46 million for a section on an octet and got 188 million, plus the 12 million from yesterdays. These two samples will be pooled. Will now proceed with the remaining herring samples, using 1.5pM as the starting amount of template for each library."
  },
  {
    "objectID": "posts/2010/2010-10-13-qpcr-test-plate-for-opticon-2/index.html",
    "href": "posts/2010/2010-10-13-qpcr-test-plate-for-opticon-2/index.html",
    "title": "qPCR - Test Plate for Opticon 2",
    "section": "",
    "text": "Ran a full plate for testing well-to-well consistency (or, inconsistency!) of the Opticon 2, since it’s been behaving poorly lately. This will provide us with an idea of whether or not the oddities that we’ve been witnessing have any effect on our actual data.\nUsed C.gigas gDNA (DH15 from 20100519; 0.5128ug/uL) and IL17 Internal Fw/Rv primers (SR ID: 255, 256), which have previously produced an amplicon with gDNA. Master mix calcs/plate layout/cycling parameters/etc are here.\nDNA was combined in master mix so that all wells received ~100ng of gDNA.\nResults:"
  },
  {
    "objectID": "posts/2010/2010-01-11-qpcrs-macs-bbdh-cdna-from-20091223/index.html",
    "href": "posts/2010/2010-01-11-qpcrs-macs-bbdh-cdna-from-20091223/index.html",
    "title": "qPCRs - Mac’s BB/DH cDNA from 20091223",
    "section": "",
    "text": "GNRR2 and CALL primer sets used. These are duplicates based on initial differences seen between BB and DH expression. qPCR set up and plate layout is here.\nResults:\nqPCR Data File (Opticon): 20100111_180230.tad\nData workup: PROPS BB_DH Gene Expression Miner Workup\nSPI and CP17A primer sets used. These are duplicates based on initial differences seen between BB and DH expression. qPCR set up and plate layout is here.\nResults:\nqPCR Data File (Opticon): 20100111_141711.tad\nData workup: PROPS BB_DH Gene Expression Miner Workup\nEF1 primers in duplicate, since I had not done these primers yet. qPCR set up and plate layout is here.\nResults:\nqPCR Data File (Opticon): 20100111_102001.tad\nData workup: PROPS BB_DH Gene Expression Miner Workup"
  },
  {
    "objectID": "posts/2010/2010-10-20-received-hard-clam-samples-and-live-clams-from-mbl/index.html",
    "href": "posts/2010/2010-10-20-received-hard-clam-samples-and-live-clams-from-mbl/index.html",
    "title": "Received Hard Clam Samples and Live Clams from MBL",
    "section": "",
    "text": "Received 82 gill samples in RNA Later in 3 microfuge tube racks from MBL (Scott Lindell). Samples were catalogued, boxed (1 box) and stored at -80C.\nThe live clams were received in two bags one containing ~12 labelled MA4 and one containing ~12 labelled BX1. Clams were NOT counted and the quantity may be different. Clams were temporarily stored @ 4C."
  },
  {
    "objectID": "posts/2010/2010-01-13-solid-epcrs-herring-cdna-libraries/index.html",
    "href": "posts/2010/2010-01-13-solid-epcrs-herring-cdna-libraries/index.html",
    "title": "SOLiD ePCRs - Herring cDNA libraries",
    "section": "",
    "text": "Herring fragmented cDNA library: 4LHTOG09\nUsing 1.5pM of starting template, based on success of the 3LHSITK09 bead prep (see 20100108).\nProcessed herring fragmented cDNA library 4LHTOG09 (20.1.ng/uL) according to the ABI “Templated Bead Preparation Guide” following the “full-scale” protocol. Made a 1:100 dilution (1uL library, 99uL 1x Low TE) = 201pg/uL. Mixed 89.6uL of this diluted sample with 10.4uL 1x Low TE to get a final concentration of 180pg/uL (1.5pM, according to ABI protocol). Oil phase used was previously prepared by Jesse (Seeb lab) 1/11/2010. This oil phase is stable for 2 months @ 4C.\nePCR was run. The plate will be stored @ 4C until the two remaining libraries have been through ePCR. Then, all three libraries will be processed simulatneously.\n\n\n\n\n\n\n\n\n\n\n\nHerring fragmented cDNA library: 6LHPWS09\nUsing 1.5pM of starting template, based on success of the 3LHSITK09 bead prep (see 20100108).\nProcessed herring fragmented cDNA library 6LHPWS09 (51.4.ng/uL) according to the ABI “Templated Bead Preparation Guide” following the “full-scale” protocol. Made a 1:100 dilution (1uL library, 99uL 1x Low TE) = 541pg/uL. Mixed 35uL of this diluted sample with 65uL 1x Low TE to get a final concentration of 180pg/uL (1.5pM, according to ABI protocol). Oil phase used was previously prepared by Jesse (Seeb lab) 1/11/2010. This oil phase is stable for 2 months @ 4C.\nePCR was run. The plate will be stored @ 4C until the two remaining libraries have been through ePCR. Then, all three libraries will be processed simultaneously."
  },
  {
    "objectID": "posts/2010/2010-10-23-gdna-isolation-2/index.html",
    "href": "posts/2010/2010-10-23-gdna-isolation-2/index.html",
    "title": "gDNA Isolation",
    "section": "",
    "text": "Isolated gDNA from crab (unknown species), starfish exposed to RoundUp (unknown species) and gray whale blubber using Qiagen’s DNEasy Kit, according to manufacturer’s protocol. Tissue was incubated at 55C with Proteinase K for 1hr. gDNA was eluted with 100uL of Buffer AE and spec’d.\nResults:\n\nGray whale sample has virtually no DNA. Will try to precipitate the whale gDNA in order to obtain a more concentrated sample. The other two samples look good, with good yields and good OD260/280 ratios."
  },
  {
    "objectID": "posts/2010/2010-05-13-solid-templated-bead-prep-yellow-perch-ct-wb-and-lake-trout-lean-libraries-continued-from-yesterday/index.html",
    "href": "posts/2010/2010-05-13-solid-templated-bead-prep-yellow-perch-ct-wb-and-lake-trout-lean-libraries-continued-from-yesterday/index.html",
    "title": "SOLiD Templated Bead Prep - Yellow perch CT, WB and lake trout Lean libraries (continued from yesterday)",
    "section": "",
    "text": "Templated bead preparation was performed according to the “full scale” protocol.\nBead counts are calculated as follows:\nAvg bead count x # hemacytometer squares x volume in hemacytometer (uL) x dilution factor = beads/uL x suspension volume (uL) = total beads\nInitial Bead counts: (1:200 dilution)\nCT: 132, 133, 127, 136 Avg. = 132\nWB: 127, 128, 119, 126 Avg. = 125\nLean: 121, 114, 132, 109 Avg. = 119\nCT: 132 x 25 x 10 x 200 = 6.6x10^6 beads/uL x 200uL = 1.32x10^9 beads\nWB: 125 x 25 x 10 x 200 = 6.25x10^6 beads/uL x 200uL = 1.25x10^9 beads\nLean: 119 x 25 x 10 x 200 = 5.95x10^6 beads/uL x 200uL = 1.19x10^9 beads\nTemplated Bead counts (1:10 dilution)\nCT: 91, 80, 100, 78 Avg. = 87.25\nWB: 69, 70, 75, 65 Avg. = 69.75\nLean: 40, 52, 48, 46 Avg. = 46.5\nCT: 87.25 x 25 x 10 x 10 = 218125 beads/uL x 400uL = 8.7525x10^7 beads\nWB: 39.75 x 25 x 10 x 10 = 174375 beads/uL x 400uL = 6.975x10^7 beads\nLean: 46.5 x 25 x 10 x 10 = 116250 beads/uL x 400uL = 4.65x10^7 beads\nPercent Recovery Templated Beads\nCT: (8.7252x10^7 beads)/(1.32x10^9 beads) x 100 = 6.61%\nWB: (6.975x10^7 beads)/(1.25x10^9 beads) x 100 = 5.58%\nLean: (4.65x10^7 beads)/(1.19x10^9 beads) x 100 = 3.91%\nResults: Everything looks pretty darn good. One mild concern, however, is the yield from the the Lean library. An 8-well slide requires 41 million beads for a run. Additionally, I believe 15 million are needed for a WFA (quality check, pre-run). This means that the Lean prep is nearly 10 million beads short of what is necessary for a “complete” run of this sample. Will send the numbers to Rhonda and see what her opinion is and what she suggests to do. But, based on the percent recovery, all the samples should be really high quality (extremely few polyclonal beads)."
  },
  {
    "objectID": "posts/2010/2010-04-13-epcr-solid-libraries-yellow-perch-pq-wb-and-lake-trout-lean-libraries-from-20100408/index.html",
    "href": "posts/2010/2010-04-13-epcr-solid-libraries-yellow-perch-pq-wb-and-lake-trout-lean-libraries-from-20100408/index.html",
    "title": "ePCR SOLiD Libraries - Yellow perch PQ, WB and Lake Trout Lean libraries (from 20100408)",
    "section": "",
    "text": "ePCR was performed for the above three mentioned SOLiD libraries using 1.5pM (180 pg/uL) of cDNA, according to the ABI “full scale” ePCR protocol. ePCRs were stored @ 4C until ready for the emulsion breaking step.\nAmounts of cDNA used to make dilutions (in 1x Low TE Buffer) of 180pg/uL:\nPQ (20.77ng/uL): 4.33uL in 500uL\nWB (16.81ng/uL): 2.14uL in 200uL\nLean (53.49ng/uL): 1.68uL in 500uL"
  },
  {
    "objectID": "posts/2010/2010-12-24-solid-retrieved-solid-library-samples-from-ceg-from-20101213/index.html",
    "href": "posts/2010/2010-12-24-solid-retrieved-solid-library-samples-from-ceg-from-20101213/index.html",
    "title": "SOLiD - Retrieved SOLiD Library Samples from CEG from 20101213",
    "section": "",
    "text": "Retrieved the following SOLiD libraries from the CEG and stored in -80C in the “NGS Libraries” Box.\nCC SOLiD Library (20010408 13.8ng/uL)\nHerring 2L HKOD09 SOLiD Library (20091209 76.1ng/uL)\nHerring 3L HSITK09 SOLiD Library (20091209 88.5ng/uL)\nHerring 4L HTOG09 SOLiD Library (20091209 20.1ng/uL)\nHerring 6L HPWS09 SOLiD Library (20091209 51.4ng/uL)\nHPWS09 SOLiD Library (20010408 9.29ng/uL)\nPQ SOLid Library (20100408 20.77ng/uL)\nSisco SOLiD Library (20100408 42.29ng/uL)\nCE SOLiD Library (20100408 23.01ng/uL)"
  },
  {
    "objectID": "posts/2010/2010-06-26-gdna-sonication-sbwb-gdna-pools-prep-for-medip-from-20100618/index.html",
    "href": "posts/2010/2010-06-26-gdna-sonication-sbwb-gdna-pools-prep-for-medip-from-20100618/index.html",
    "title": "gDNA Sonication - SB/WB gDNA pools (prep for MeDIP) from 20100618",
    "section": "",
    "text": "The previous attempt at sonication (see 20100618) failed, likely due to no using the correct equipment (tubes and Covaris adapter). The two gDNA pools, which had previously been unsuccessfully fragmented on 20100618 (SB and WB) were sonicated using a Covaris S2. Used the guidelines of the manufacturer (listed below) for shearing gDNA to a desired target size (500bp):\nDuty Cycle: 5%\nIntensity: 3\nCycels per Burst: 200\nTime (seconds): 90\nTemp (water bath): 4C\nPower Mode: Frequency Sweeping\nSample Volume: 120uL\nBuffer: TE\nDNA Mass: ~8ug\nStarting Material: >50kb\nAFA Intensifier tubes and associated Covaris adapter.\nAfter shearing, ran 250ng of each pool on a 2% TAE agarose gel for fragmentation verification.\nResults:\n\nLane 1 - Hyperladder I\nLane 2 - R37\nLane 3 - R51\nLooking at this gel, the samples have been successfully fragmented and I would estimate have generated and average fragment size of ~400bp (going from bottom to top of the Hyperladder: 200bp, 400bp, 600bp, 800bp, 1000bp). So, this looks great! Can proceed with remainder of MeDIP procedure at any time.\nAdditionally, I will confirm a more accurate assessment of average fragment size by running these two samples on the Agilent Bioanalyzer."
  },
  {
    "objectID": "posts/2010/2010-11-25-restriction-digestions-hpaii-and-mspi-on-macs-c-gigas-samples-round-2/index.html",
    "href": "posts/2010/2010-11-25-restriction-digestions-hpaii-and-mspi-on-macs-c-gigas-samples-round-2/index.html",
    "title": "Restriction Digestions - HpaII and MspI on Mac’s C.gigas Samples: Round 2",
    "section": "",
    "text": "Continued with 2nd round of digestions from yesterday. All samples were resuspended in 25uL of H2O yesterday, so brought volume up to 44uL with H2O, added 5uL of appropriate 10X Buffer (HpaII = NEB Buffer #4, MspI = NEB Buffer #1), added 1uL of enzyme, incubated 37C for 3hrs. Heat-inactivated all samples @ -80C for 30 mins.\n\n\n\n\nPhenol:Chloroform Extractions\nRestriction digests  were mixed with equal volume (50uL) of phenol:chloroform:IAA (25:24:1) and centrifuged 16,000g for 5mins @ 4C. Aqueous phase was transferred to a clean tube and an equal volume (50uL) of chloroform was added. Samples were mixed and centrifuged 16,000g for 5mins @ 4C. Aqueous phase was transferred to clean tubes and stored @ -20C. Will EtOH precipitate and spec on Monday."
  },
  {
    "objectID": "posts/2011/2011-01-12-bacterial-dilutions-determination-of-colony-forming-units-from-gigas-bacterial-challenge-from-earlier-today/index.html",
    "href": "posts/2011/2011-01-12-bacterial-dilutions-determination-of-colony-forming-units-from-gigas-bacterial-challenge-from-earlier-today/index.html",
    "title": "Bacterial Dilutions - Determination of Colony Forming Units from Gigas Bacterial challenge (from earlier today)",
    "section": "",
    "text": "All dilutions were performed with 1x LB+ 1%NaCl. 100uL were plated of all dilutions (see below) on 1xLB+1%NaCL plates. Plates were incubated O/N @ 37C. Colonies will be counted tomorrow to determine CFU for each sample.\nPlated 100uL of:\nV.vulnificus, t=0, 1:1,000,000 and 1:10,000,000\nV.vulnificus H2O sample, t=1 & 3, 1:10,000 and 1:1,000,000\nV.tubiashii, t=0, 1:1,000,000\nControl H2O sample, t=1 & 3, Undiluted\nSamples tubes containing bacteria and dilutions were stored @ 4C.\n**_UPDATE 20110112**_:\nColony counts and calculations\nV.vulnificus 0hr = Both dilutions produced a total lawn of bacteria. Uncountable. Will plate higher dilutions, but this will now only be a rough estimate due to the time that has passed.\n—UPDATE—\nNew serial dilutions (90uL plated) of V.vulnificus 0hr were performed, down to 10^12. The only countable plate was the 10^12 dilution.\nV.vulnificus 0hr = 10^12 dilution x 410 CFU = 4.1x10^14 CFU/90uL = 4.56x10^12 CFU/uL x 8x10^6uL (8L H2O in oyster tank) = 3.64x10^19 CFU total in oyster tank/8L = 4.56x10^18 CFU/L\nV.vulnificus 1hr = 1:1,000,000 dilution x 48 CFU = 4.8x10^7 CFU/100uL = 4.8x10^5 CFU/uL x 8x10^6uL (8L H2O in oyster tank) = 3.84x10^12 CFU total in oyster tank/8L = 4.8x10^11 CFU/L\nV.vulnificus 3hr = 1:1,000,000 dilution x 23 CFU = 2.3x10^7 CFU/100uL = 2.3x10^5 CFU/uL x 8x10^6uL (8L H2O in oyster tank) = 1.84x10^12 CFU total in oyster tank/8L = 2.3x10^11 CFU/L\nControl H2O (no significant growth occurred O/N, just tiny colonies; continued incubation to allow colonies to increase in size for easier counting)\nControl H2O 1hr = Undiluted 146 CFU/100uL = 1.46 CFU/uL x 8x10^6uL (8L H2O in oyster tank) = 1.168x10^7 CFU total in oyster tank/8L = 1.46x10^6 CFU/L\nControl H2O 3hr = Undiluted 106 CFU/100uL = 1.06 CFU/uL x 8x10^6uL (8L H2O in oyster tank) = 8.48x10^6 CFU total in oyster tank/8L = 1.06x10^5 CFU/L\nV.tubiashii 0hr = 1:1,000,000 dilution x 31 CFU = 3.1x10^7 CFU/100uL = 3.1x10^5 CFU/uL x 5x10^4 (50mL total volume of bacteria) = 1.55x10^10 CFU total V.tubiashii"
  },
  {
    "objectID": "posts/2011/2011-01-12-gigas-bacterial-challenge-1hr-3hr-challenges-with-vibrio-vulnificus/index.html",
    "href": "posts/2011/2011-01-12-gigas-bacterial-challenge-1hr-3hr-challenges-with-vibrio-vulnificus/index.html",
    "title": "Gigas Bacterial Challenge - 1hr & 3hr Challenges with Vibrio vulnificus",
    "section": "",
    "text": "400mL O/N culture (1x LB+1% NaCl, 37C, 150RPM, 1L flask) of V.vulnificus (STRAIN??) and V.tubiashii (Strain: RE22) were pelleted (4300RPM, 25C, Sorvall ST-H750 rotor). Supe was removed and pellets were each resuspended in 50mL sea water. 1mL was taken from each to use for dilutions to determine colony forming units (CFU).\nTwo containers were set up with each containing 16 C.gigas, and air stone and 8L of sea water. The entire 50mL of V.vulnificus was added to one of the containers. 8 oysters were sampled (gill and mantle tissue) from each container at 1hr and 3hrs after the addition of V.vulnificus culture and immediately frozen on dry ice. Samples were stored @ -80C in the “Gigas Vibrio Exposure 1,3hrs 1/11/11” box. Additionally, 1mL samples of the water were taken at each time to determine CFU in the water.\nIn addition to the samples taken above, the following tissues were taken from 5 control oysters at the 3hr time point and treated/stored in the same fashion as the others, specifically for assessment of cyclooxygenase tissue distribution analysis: muscle, digestive gland/gonad (difficult to differentiate)\nAll oysters were measured. Morphometric data is here."
  },
  {
    "objectID": "posts/2011/2011-02-10-qpcr-test-young-lab-qpcr-calibration/index.html",
    "href": "posts/2011/2011-02-10-qpcr-test-young-lab-qpcr-calibration/index.html",
    "title": "qPCR - Test Young Lab qPCR Calibration",
    "section": "",
    "text": "This is a repeat of the two runs from yesterday, just to see if there is a correlation between the failed plates being the first of the day or not. Master mix calcs and cycling params are here (these calcs are from yesterday, but were used again for today).\nResults:\nAmplification in all wells. Still seeing ~3 cycle spread across the entire plate. Will work up all three successful sets of run data."
  },
  {
    "objectID": "posts/2011/2011-05-09-dnase-hard-clam-gill-rna-from-earlier-today/index.html",
    "href": "posts/2011/2011-05-09-dnase-hard-clam-gill-rna-from-earlier-today/index.html",
    "title": "DNase - Hard Clam Gill RNA (from earlier today)",
    "section": "",
    "text": "DNased 5ug of RNA from each sample with Ambion’s Turbo DNA-free Kit, according to the manufacturer’s rigorous protocol. Samples were spec’d and stored @ -80C in the “Hard Clam V.t. Experiment RNA” box.\nResults:\n\nDue to lack of a positive control (and lack of primers known to amplify gDNA), these DNased RNA samples will NOT be checked to verify elimination of gDNA carryover at this time. Will proceed with making cDNA for qPCR anyway."
  },
  {
    "objectID": "posts/2011/2011-10-07-pcr-purified-coxpgs-12-dna-from-earlier-today/index.html",
    "href": "posts/2011/2011-10-07-pcr-purified-coxpgs-12-dna-from-earlier-today/index.html",
    "title": "PCR - Purified COX/PGS 1/2 DNA from earlier today",
    "section": "",
    "text": "Ran PCR using primers Cg_COX1/2_qPCR_F, Cg_COX1_qPCR_R, Cg_COX2_454align1_R (SR IDs: 1192, 1191, 1190; respectively). Template was pooled cDNA from 20110311 of various C.gigas tissues. These reactions will verify (sort of) if we have both isoforms present in the PCR performed earlier today, prior to cloning. Master mix calcs and cycling params are here.\nResults:\n(http://eagle.fish.washington.edu/Arabidopsis/20111007-01.JPG)\nLane 1: Hyperladder I (Bioline)\nLane 2: COX1/PGS1 primer set\nLane 3: COX1/PGS1 primer set NTC\nLane 4: COX2/PGS2 primer set\nLane 5: COX2/PGS2 primer set NTC\nNTCs are clean for both primer sets. We see bands of the expected size for both primer sets. Additionally, we see lower expression in COX2/PGS2, as we observed in our previous qPCR reactions with these primer sets. Will clone the large fragment that was PCR’ed/purified from earlier today."
  },
  {
    "objectID": "posts/2011/2011-07-23-53-race-c-gigas-cox2pgs2-race-pcr/index.html",
    "href": "posts/2011/2011-07-23-53-race-c-gigas-cox2pgs2-race-pcr/index.html",
    "title": "5’/3’ RACE - C.gigas COX2/PGS2 RACE PCR",
    "section": "",
    "text": "Additional RACE using gene specific primers (SR IDs: 1347 & 1348) for C.gigas COX2/PGS2 according to Clontech’s SMARTer cDNA RACE Kit protocol. 3’/5’ RACE cDNA libraries are from 20080619. Master mix calcs and set up is here. Cycling params followed “Program 2” of the Clontech protocol and are as follows:\n25 cycles:\n\n94°C 30 sec\n68°C 30 sec\n72°C 3 min\n\nReactions were run with both primers on both libraries, just to ensure that in case there was any confusion in primer design. When finished, I will remove 2uL of the PCR reaction for use in a nested PCR reaction. Will run a gel with both sets of products, once the nested PCR is completed.\nResults:\n\nGel Layout:\nLane 1 - Hyperladder 1\nLanes 2-6 = 5’ RACE Library\nLane 2 - GSP1 (5’ RACE primer)\nLane 3 - GSP2 (3’ RACE primer)\nLane 4 - Neg. Control (no RACE primers)\nLane 5 - Neg. Control (GSP1, no Universal primer)\nLane 6 - Neg. Control (GSP2, no Universal primer)\nLane 7 - Empty\nLanes 8-12 = 3’ RACE Library\nLane 8 - GSP1 (5’ RACE primer)\nLane 9 - GSP2 (3’ RACE primer)\nLane 10 - Neg. Control (no RACE primers)\nLane 11 - Neg. Control (GSP1, no Universal primer)\nLane 12 - Neg. Control (GSP2, no Universal primer)\nAs has generally been the case, our primary RACE PCRs failed to produce any products. This is why I performed the nested PCR (described above) before viewing the results of this primary PCR."
  },
  {
    "objectID": "posts/2011/2011-07-26-cloning-c-gigas-cox2pgs2-53-race-products-from-earlier-today/index.html",
    "href": "posts/2011/2011-07-26-cloning-c-gigas-cox2pgs2-53-race-products-from-earlier-today/index.html",
    "title": "Cloning - C.gigas COX2/PGS2 5’/3’ RACE Products (from earlier today)",
    "section": "",
    "text": "The bands that were excised and purified earlier today were cloned in to pCR2.1 using the TOPO TA Cloning Kit (Invitrogen) according to the manufacturer’s protocol with the following changes: used 4uL of all PCR products, incubated ligation reactions for 15mins @ RT, incubated competent cells with ligation reactions for 15mins on ice.\nTwo volumes of each reaction were plated (50uL and 100uL) on Kan50 plates with X-gal (made 20010412 by SJW) and incubated @ 37C O/N.\nResults:\nAmple number of white colonies for all 4 sets of cloning reactions."
  },
  {
    "objectID": "posts/2011/2011-04-26-bacterial-cultures-colonies-selected-from-yesterdays-colony-pcrs/index.html",
    "href": "posts/2011/2011-04-26-bacterial-cultures-colonies-selected-from-yesterdays-colony-pcrs/index.html",
    "title": "Bacterial Cultures - Colonies Selected from Yesterday’s Colony PCRs",
    "section": "",
    "text": "Inoculated 5mL of 1x LB + Kan50 (made by Steven on 3/23/11). Incubated O/N at 37C, 250RPM. Will perform mini preps tomorrow. The following samples were selected:\n\nMM09 - #1, 2, 8\nMM11 660bp - #1, 2, 8\nMM10 2/8/11 - #1, 2\nMM04 1/19/11 - #2, 3\nMM11 3000bp - #3\nMM04 1500bp - #4\nMM06 1/19/11 - #1, 2\nMM04 550bp - #1, 2\nMM05 1/19/11 - #1, 2"
  },
  {
    "objectID": "posts/2011/2011-02-05-qpcr-test-young-lab-qpcr-calibration-2/index.html",
    "href": "posts/2011/2011-02-05-qpcr-test-young-lab-qpcr-calibration-2/index.html",
    "title": "qPCR - Test Young Lab qPCR Calibration",
    "section": "",
    "text": "Recently, the Young Lab’s ABI 7300 qPCR machine was calibrated. Steven asked me to run a plate and see how well the calibration worked. Ran a plate with C.gigas gDNA and Gigas 18s primers (SR ID: 156 and 157) that are known to amplify gDNA. [Master mix calcs are here (top half of page)(https://eagle.fish.washington.edu/Arabidopsis/Notebook%20Workup%20Files/20110204-01.jpg). Cycling params were as follows:\n\n95C - 10min\n\n40 Cycles of:\n\n95C - 15s\n55C - 30s\n72C - 30s\n\nMelt curve.\nResults:\nAbsolutely no amplification of any kind. However, I did use one of our conventional PCR plates and not one of the ABI “prism” plates. Additionally, when I removed the plate from the machine, the plate looked as though it had been vigorously shaken:\n\nWill repeat this qPCR with a proper ABI “prism” plate."
  },
  {
    "objectID": "posts/2011/2011-08-26-pcr-full-length-pgs1-pgs2-cdnas/index.html",
    "href": "posts/2011/2011-08-26-pcr-full-length-pgs1-pgs2-cdnas/index.html",
    "title": "PCR - Full-length PGS1 & PGS2 cDNAs",
    "section": "",
    "text": "Ran PCR to amplify full-length cDNAs of PGS1 & PGS2 (COX1 & COX2) using primers designed to anneal in the 5’/3’UTRs of each isoform. PGS1 primers = SRIDs: 1377, 1378. PGS2 primers = 1376, 1375. Master mix calcs and cycling params are here. cDNA was pooled cDNA made 20110311 from various tissues.\nPGS1 Expected Size = ~2300bp\nPGS2 Expected Size = ~2500bp\nResults:\n\nGel\nLane 1 - Hyperladder I (Bioline)\nLane 2 - PGS1\nLane 3 - PGS1 NTC\nLane 4 - PGS1 NTC\nLane 5 - PGS2\nLane 6 - PGS2 NTC\nLane 7 - PGS2 NTC\nPGS1 Results: PGS1 PCR produces a single band of the expected size (~2300bp), indicating that the two primers, which were designed to anneal in the 5’/3’UTRs of the gene and should be highly specific to just this isoform, work perfectly. The band was excised and stored @ -20C in “Sam’s Miscellaneous” box.\nPGS2 Results: PGS2 PCR didn’t produce any product. Will repeat with a lower annealing temp (50C instead of 55C)."
  },
  {
    "objectID": "posts/2011/2011-02-28-qpcr-check-dnased-rna-bb01-for-residual-gdna-from-earlier-today-2/index.html",
    "href": "posts/2011/2011-02-28-qpcr-check-dnased-rna-bb01-for-residual-gdna-from-earlier-today-2/index.html",
    "title": "qPCR - Check DNased RNA BB01 for Residual gDNA (from earlier today)",
    "section": "",
    "text": "Ran qPCR on DNased RNA from earlier today to verify removal of contaminating gDNA. Used C.gigas 18s primers (SR IDs: 156, 157). 0.75uL (~50ng) of DNased RNA was used for testing. This corresponds, roughly, to the amount of sample that would be carried through to qPCR analysis of cDNA, assuming 1ug of RNA was used to make the cDNA (cDNA = 1000ng RNA/25uL = 40ng/uL, 1uL of cDNA in 25uL qPCR reaction). Positive control sample was ~25ng BB16 gDNA (from 20090519). Master mix calcs are here. Plate layout, cycling params, etc can be found in the qPCR Report (see Results). RNA was stored @ -80C in “Sam’s -80C Box”.\nResults:\n[ qPCR Report (PDF)(https://eagle.fish.washington.edu/Arabidopsis/qPCR/Roberts%20Lab_2011-02-28%2013-04-32_CC009827.pdf)\n[ qPCR Data File (CFX96)(https://eagle.fish.washington.edu/Arabidopsis/qPCR/Roberts%20Lab_2011-02-28%2013-04-32_CC009827.pcrd)\nWell, this sucks. Still gDNA contamination. Will just start with original RNA again and discard this “DNased” sample."
  },
  {
    "objectID": "posts/2011/2011-04-22-colony-pcr-5race-colony-cox2-repeat-of-yesterdays-pcr/index.html",
    "href": "posts/2011/2011-04-22-colony-pcr-5race-colony-cox2-repeat-of-yesterdays-pcr/index.html",
    "title": "Colony PCR - 5’RACE Colony: COX2 (repeat of yesterday’s PCR)",
    "section": "",
    "text": "Repeated yesterday’s PCR on the re-streaked colony in order to run the product on a gel with a more appropriate ladder. See yesterday’s entry for all PCR info.\nResults:\n\nLane 1: Hyperladder I\nLane 2: colony PCR\nLane 3: NTC\nA band of nearly ~950bp is seen in the colony PCR, suggesting that the cloning reaction was successful. However, this does not match up with the expected size of ~1500bp seen on 20110407. Will sequence this regardless. Also, the gel on 20110407 may not have run properly (see image from that dat), which could possibly explain why we don’t see the “expected” size band of ~1500bp? Will inoculate a liquid culture for mini prep for eventual sequencing."
  },
  {
    "objectID": "posts/2011/2011-09-30-ethanol-precipitation-full-length-pgs1-cdna-from-20110921/index.html",
    "href": "posts/2011/2011-09-30-ethanol-precipitation-full-length-pgs1-cdna-from-20110921/index.html",
    "title": "Ethanol Precipitation - Full-length PGS1 cDNA (from 20110921)",
    "section": "",
    "text": "Performed an EtOH on gel-purified PCR products from 20110921. Briefly, added 0.1 vols of 3M sodium acetate (pH=5.2; 43uL), mixed and then added 2.5 vols of 100% EtOH (1182.5uL). Mixed, split into two tubes (due to high volume not fitting in a single tube) and incubated @ -80C O/N. Pelleted DNA 16,000g, 20mins, 4C. Discarded supe. Washed pellet w/ 1mL 70% EtOH. Pelleted DNA 16,000g, 15mins, 4C. Discarded supe. Resuspended both pellets in a TOTAL of 25uL Qiagen Buffer EB (10mM Tris-HCl) and spec’d.\nResults:\n\nNow have sufficient DNA for sequencing.\nWhat’s next?\nGenerate PCR product using primers that anneal OUTSIDE of each of the qPCR primers and then sequence those bands to ensure that the qPCR primers are actually annealing to two different isoforms."
  },
  {
    "objectID": "posts/2011/2011-03-21-qpcr-c-gigas-bbdh-cdna-for-props-hmgp-primers/index.html",
    "href": "posts/2011/2011-03-21-qpcr-c-gigas-bbdh-cdna-for-props-hmgp-primers/index.html",
    "title": "qPCR - C.gigas BB/DH cDNA for PROPS (HMGP primers)",
    "section": "",
    "text": "Performed qPCR using cDNA from 20110311. This was performed for 2 reps with HMGP (SR IDs:359 & 360). Master mix calcs are here. Plate layout, cycling params, etc can be found in the qPCR Report (see Results).\nResults:\nqPCR Report (PDF)\nqPCR Data File (CFX96)"
  },
  {
    "objectID": "posts/2011/2011-03-11-reverse-transcription-c-gigas-bbdh-dnased-rna-from-20090507-for-props/index.html",
    "href": "posts/2011/2011-03-11-reverse-transcription-c-gigas-bbdh-dnased-rna-from-20090507-for-props/index.html",
    "title": "Reverse Transcription - C.gigas BB/DH DNased RNA (from 20090507) for PROPS",
    "section": "",
    "text": "Performed RT on DNased RNA using Promega MMLV RT and Oligo dT according to manufacturer’s protocol, using 1ug of DNased RNA, but in a 50uL reaction. Due to large number of samples, cDNA was made in PCR plate. Plate layout and calcs are here."
  },
  {
    "objectID": "posts/2011/2011-03-01-qpcr-check-dnased-rna-bb01-for-residual-gdna-from-earlier-today/index.html",
    "href": "posts/2011/2011-03-01-qpcr-check-dnased-rna-bb01-for-residual-gdna-from-earlier-today/index.html",
    "title": "qPCR - Check DNased RNA BB01 for Residual gDNA (from earlier today)",
    "section": "",
    "text": "Ran qPCR on DNased RNA from earlier today to verify removal of contaminating gDNA. Used C.gigas 18s primers (SR IDs: 156, 157). 0.5uL (~40ng) of DNased RNA was used for testing. This corresponds, roughly, to the amount of sample that would be carried through to qPCR analysis of cDNA, assuming 1ug of RNA was used to make the cDNA (cDNA = 1000ng RNA/25uL = 40ng/uL, 1uL of cDNA in 25uL qPCR reaction). Positive control sample was ~25ng BB16 gDNA (from 20090519). Master mix calcs are here. Plate layout, cycling params, etc can be found in the qPCR Report (see Results). RNA was stored @ -80C in “Sam’s -80C Box”.\nResults:\n[ qPCR Report (PDF)(https://eagle.fish.washington.edu/Arabidopsis/qPCR/Roberts%20Lab_2011-03-01%2013-10-22_CC009827.pdf)\n[ qPCR Data File (CFX96)(https://eagle.fish.washington.edu/Arabidopsis/qPCR/Roberts%20Lab_2011-03-01%2013-10-22_CC009827.pcrd)\nResidual gDNA is present in the sample. So, it’s become apparent that it’s virtually impossible to rid the BB01 RNA of contaminating gDNA. Will discuss with Steven and Mac if it’s feasible to exclude this from the additional PROPS analysis that needs to be done and how this could potentially affect our data. Talked to Steven and, duh, we can just remove the previous BB01 data from our analysis. Will make new batch of cDNA from existing DNased RNA samples."
  },
  {
    "objectID": "posts/2011/2011-07-16-sequencing-pgs-hi-4-pgs2cox2/index.html",
    "href": "posts/2011/2011-07-16-sequencing-pgs-hi-4-pgs2cox2/index.html",
    "title": "Sequencing - PGS Hi 4 (PGS2/COX2)",
    "section": "",
    "text": "Sent plasmid prep to ASU (5uL of plasmid + 1uL of 10uM M13F/R). SJW01 = M13F, SJW02 = M13R.\nResults:\nSequencing looks great! Definitely have a portion of the second isoform of COX/PGS!! Here’s the result of the consensus BLASTed in GenBank>Nucleotide (others)>blastn:\n\nTop hit in the db is COX1/PGS1, and, clearly, there are differences between the two sequences confirming that we have the second isoform (COX2/PGS2). Will design more RACE primers in hopes of obtaining the full-length cDNA sequence."
  },
  {
    "objectID": "posts/2011/2011-05-11-reverse-transcription-hard-clam-gill-dnased-rna-from-20110509/index.html",
    "href": "posts/2011/2011-05-11-reverse-transcription-hard-clam-gill-dnased-rna-from-20110509/index.html",
    "title": "Reverse Transcription - Hard Clam Gill DNased RNA (from 20110509)",
    "section": "",
    "text": "Performed reverse transcription on DNased RNA from the hard clam vibrio tubiashii challenge experiment (see Dave’s Notebook 5/2/2011), following the Promega M-MLV RT protocol with ~1ug of DNAsed RNA. Master mix calcs are here. Reactions were done in a plate. cDNA was diluted 1:4 with H2O."
  },
  {
    "objectID": "posts/2011/2011-02-09-qpcr-test-young-lab-qpcr-calibration-repeat-2/index.html",
    "href": "posts/2011/2011-02-09-qpcr-test-young-lab-qpcr-calibration-repeat-2/index.html",
    "title": "qPCR - Test Young Lab qPCR Calibration (Repeat)",
    "section": "",
    "text": "This was repeated from earlier today due to the failure of the previous run, but had to use new gDNA since I ran out of the stock I had previously used. Master mix calcs and cycling params are here.\nResults:\nAmplification in all wells, however well E4 appears to have had some evaporation (and the effects can clearly be seen in the amplification plot below). Still getting ~3 cycle spread across the entire plate, which is disconcerting. Oddly, this is the second day where the 1st run completely failed, but the 2nd run was successful…"
  },
  {
    "objectID": "posts/2011/2011-05-09-rna-isolation-hard-clam-gill-tissue-from-vibrio-experiment-see-daves-notebook-522011/index.html",
    "href": "posts/2011/2011-05-09-rna-isolation-hard-clam-gill-tissue-from-vibrio-experiment-see-daves-notebook-522011/index.html",
    "title": "RNA Isolation - Hard Clam Gill Tissue from Vibrio Experiment (see Dave’s Notebook 5/2/2011)",
    "section": "",
    "text": "Isolated RNA in 1mL of Tri-Reagent according to the manufacturer’s protocol. Also, finished RNA isolation of samples that were started 20110506. Samples were resuspended in 50uL 0.1%DEPC-H2O and spec’d.\nResults:"
  },
  {
    "objectID": "posts/2011/2011-05-06-rna-isolation-hard-clam-gill-tissue-from-vibrio-experiment-see-daves-notebook-522011-2/index.html",
    "href": "posts/2011/2011-05-06-rna-isolation-hard-clam-gill-tissue-from-vibrio-experiment-see-daves-notebook-522011-2/index.html",
    "title": "RNA Isolation - Hard Clam Gill Tissue from Vibrio Experiment (see Dave’s Notebook 5/2/2011)",
    "section": "",
    "text": "Isolated RNA in 1mL of Tri-Reagent according to manufacturer’s protocol. Samples were precipitated with isopropanol and stored over the weekend @ -20C. Will conclude isolation on Monday. The samples isolated were:\nMA 1-11\nMA Vt 1-11"
  },
  {
    "objectID": "posts/2011/2011-03-10-solid-sequencing-submission/index.html",
    "href": "posts/2011/2011-03-10-solid-sequencing-submission/index.html",
    "title": "SOLiD Sequencing Submission",
    "section": "",
    "text": "Submitted the following 8 samples for SOLiD sequencing at HTGU:\n\n\n\n\n\nSB unmeth C.gigas\n\n\nC.gigas\n\n\ngill pool\n\n\ngDNA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSB meth C.gigas\n\n\nC.gigas\n\n\ngill pool\n\n\ngDNA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMA\n\n\nMercenaria mercenaria\n\n\ngill pool\n\n\npolyA(x2)\n\n\n\n\nBX\n\n\nMercenaria mercenaria\n\n\ngill pool\n\n\npolyA(x2)\n\n\n\n\nVt RE22\n\n\nVibrio tubiashii (RE22)\n\n\n\n\ngDNA\n\n\n\n\nVt STRAIN\n\n\nVibrio tubiashii (ATCC 19106)\n\n\n\n\ngDNA"
  },
  {
    "objectID": "posts/2011/2011-02-17-qpcr-check-dnased-rna-bb01-09-from-earlier-today/index.html",
    "href": "posts/2011/2011-02-17-qpcr-check-dnased-rna-bb01-09-from-earlier-today/index.html",
    "title": "qPCR - Check DNased RNA BB01 & 09 (from earlier today)",
    "section": "",
    "text": "Ran qPCR on DNased RNA from earlier today to verify that it was free of contaminating gDNA. Used C.gigas 18s primers (SR IDs: 156, 157). 0.5uL (50ng) of DNased RNA was used for testing. This corresponds, roughly, to the amount of sample that would be carried through to qPCR analysis of cDNA, assuming 1ug of RNA was used to make the cDNA (cDNA = 1000ng RNA/25uL = 40ng/uL, 1uL of cDNA in 25uL qPCR reaction). Positive control sample was ~25ng BB16 gDNA (from 20090519). Master mix calcs are here. Plate layout, cycling params, etc can be found in the qPCR Report (see Results). RNA was stored @ -80C in “Sam’s -80C Box”.\nResults:\n[ qPCR Report (PDF)(https://eagle.fish.washington.edu/Arabidopsis/qPCR/Roberts%20Lab_2011-02-17%2011-30-30_CC009827.pdf).\n[ qPCR Data file (CFX96)(https://eagle.fish.washington.edu/Arabidopsis/qPCR/Roberts%20Lab_2011-02-17%2011-30-30_CC009827.pcrd).\nThere is residual gDNA in the BB01 sample. Will EtOH precipitate and treat again.\nDNased BB09 was stored @ -80C in “Mac’s Gigas DNased RNA Box #1” (on the top shelf) with the rest of the PROPS DNased RNA."
  },
  {
    "objectID": "posts/2011/2011-02-05-qpcr-test-young-lab-qpcr-calibration-repeat-3/index.html",
    "href": "posts/2011/2011-02-05-qpcr-test-young-lab-qpcr-calibration-repeat-3/index.html",
    "title": "qPCR - Test Young Lab qPCR Calibration (Repeat)",
    "section": "",
    "text": "This is a repeat of an earlier run from today, but with a different qPCR plate. [Here’re master mix calcs (bottom half of page)(https://eagle.fish.washington.edu/Arabidopsis/Notebook%20Workup%20Files/20110204-01.jpg). Cycling params were as follows:\n\n95C - 10min\n\n40 Cycles of:\n\n95C - 15s\n55C - 30s\n72C - 1m\n\nMelt curve.\nResults:\nAll samples amplified and showed a proper dissociation curve. However, it does look like there’s a spread of ~3 Cts across the plate. This is not good, as this is the equivalent of ~10-fold difference in gene expression. Will repeat again and see if specific wells show the same relative differences in Cts."
  },
  {
    "objectID": "posts/2011/2011-02-09-pcr-new-c-gigas-cox-primers-for-sequencing-of-isoforms/index.html",
    "href": "posts/2011/2011-02-09-pcr-new-c-gigas-cox-primers-for-sequencing-of-isoforms/index.html",
    "title": "PCR - New C. gigas COX Primers for Sequencing of Isoforms",
    "section": "",
    "text": "Used new primers for obtaining bands for additional sequencing of both COX isoforms in C. gigas. Master mix calcs are here. Master mix shorthand (MM##) is described below:\nMM07 - Cg_COX_416_F (SR ID: 1193) + Cg_COX1_qPCR_R (SR ID: 1191) Expected band size (if no intron) = ~1540bp\nMM08 - Cg_COX_416_F (SR ID: 1193) + Cg_COX2_454align1_R (SR ID: 1190) Expected band size (if no intron) = ~1540bp\nMM09 - Cg_COX1/2_qPCR_F (SR ID: 1192) + Cg_COX1_qPCR_R (SR ID: 1191) Expected band size (if no intron) = ~225bp\nMM10 - Cg_COX1/2_qPCR_F (SR ID: 1192) + Cg_COX2_454align1_R (SR ID: 1190) Expected band size (if no intron) = ~225bp\nMM11 - Cg_COX_1519_F (SR ID: 1146) + Cg_COX2_454align1_R (SR ID: 1190) Expected band size (if no intron) = ~275bp\nMM12 - Cg_COX_982_F (SR ID: 1151) + Cg_COX2_454align1_R (SR ID: 1190) Expected band size (if no intron) = ~812bp\nResults:\n\nLadder is Hyperladder I from Bioline.\nMaster mixes are indicated underneath each group by the labels MM##. The order within each MM group (from left to right) is: template, NTC, NTC.\nAll bands boxed with green were purified using Millipore’s Ultrafree-DA spin columns. Samples were stored @ -20C in “Sam’s Misc. -20C Box”.\nMM07 - Fails to produce any bands of any size. Suggests the presence of intron(s) causing the size of the potential amplicon to exceed the capabilities of the polymerase under these cycling conditions.\nMM08 - Produces a band of ~400bp which is well below the expected 1540bp (if no introns) size. Due to the faintness of the band, the band was not excised. Will consult with Steven to see if he thinks it worth repeating to produce sufficient product for sequencing.\nMM09 - Produce a ~500bp band. The band was excised. This band size is ~275bp larger than the expected size of 225bp. This implies the presence of an intron in this region. This band size differs from that produced by MM10, which suggests that this primer set can be used for qPCR AND distinguish between the COX1 and COX2 isoforms.\nMM10 - Produced a ~700bp band. The band was excised. This band size is ~475bp larger than the expected size of 225bp. This implies the presence of an intron in this region. This band size differs from that produced by MM09, which suggests that this primer set can be used for qPCR AND distinguish between the COX1 and COX2 isoforms.\nMM11 - Produced multiple bands, of which two were excised; a ~3000bp band and a ~600bp band. These bands were excised solely based on their intensity and their immediate useability for sequencing. Will discuss with Steven on whether or not this should be repeated and the other bands excised for sequencing purposes. Both bands that were excised exceed the expected band size of ~275bp, suggesting the presence of multiple introns. Additionally, the presence of so many products suggests that the primers are not very specific, in regards to their target.\nMM12 - An extremely faint band of ~350bp can be seen, however, due to it’s faintness and it’s small size (expected size was ~812bp), the band was not excised. Will discuss with Steven to see if this warrants repeating to accumulate sufficient product for sequencing purposes. No amplification of any larger products suggests the presence of introns, causing the size of the potential amplicon to exceed the capabilities of the polymerase under these cycling conditions. This is also confirmed by the MM11 PCR results in which a 3000bp band was produced. Since the primer set in MM12 has an additional 600bp at the 5’ end, this has already exceeded the abilities of the polymerase, even if this addtional 600bp does NOT include an additional intron. However, it is curious that the MM12 primer set does not produce smaller, spurious PCR products as is seen in the MM11 primer set (these two primer sets both use the same forward primer)."
  },
  {
    "objectID": "posts/2011/2011-06-04-qpcr-c-gigas-gapdh-second-rep-on-v-vulnificus-exposure-cdna-from-20110311-and-standard-curves-for-cox1-cox2-gapdh/index.html",
    "href": "posts/2011/2011-06-04-qpcr-c-gigas-gapdh-second-rep-on-v-vulnificus-exposure-cdna-from-20110311-and-standard-curves-for-cox1-cox2-gapdh/index.html",
    "title": "qPCR - C.gigas GAPDH second rep on V.vulnificus exposure cDNA (from 20110311) and standard curves for COX1, COX2, GAPDH",
    "section": "",
    "text": "Ran a qPCR on all cDNA samples. Created a standard curve to possibly allow for use of the BioRad software for gene expression analysis. Standard curve was created from pooled cDNA (1uL from each individual sample). Master mix calcs are here.\n\n\nResults:\nqPCR Data File (BioRad CFX96)\nqPCR Report (PDF)\nStandard curves aren’t that good. Will not use them. Will analyze data using PCR Miner."
  },
  {
    "objectID": "posts/2011/2011-10-14-mini-preps-coxpgs-cloning-colonies-from-today/index.html",
    "href": "posts/2011/2011-10-14-mini-preps-coxpgs-cloning-colonies-from-today/index.html",
    "title": "Mini-preps - COX/PGS Cloning Colonies from today",
    "section": "",
    "text": "Selected 10 colonies (1-8, 18, 28) for mini-preps. Inoculated 5mL 1x LB + 50ug/mL of Kanamycin. Incubated O/N, 37C, 200RPM. 3mL of each culture were used for mini-preps. Used Qiagen kit. Samples were eluted w/30uL of EB."
  },
  {
    "objectID": "posts/2011/2011-06-01-qpcr-c-gigas-cox1-on-v-vulnificus-exposure-cdna-from-20110311/index.html",
    "href": "posts/2011/2011-06-01-qpcr-c-gigas-cox1-on-v-vulnificus-exposure-cdna-from-20110311/index.html",
    "title": "qPCR - C.gigas COX1 on V.vulnificus exposure cDNA (from 20110311)",
    "section": "",
    "text": "Ran a qPCR on all cDNA samples from the V.vulnificus exposure experiment from 20110111. Primers used were Cg_COX1/2_qPCR_F (SR ID: 1192) & Cg_COX1_qPCR_R (SR ID: 1191). Samples were run in duplicate. Master mix calcs are here. Plate layout, cycling params, etc., can be seen in the qPCR Report (see Results).\n\n\nResults:\nqPCR Data File (BioRad CFX96)\nqPCR Report (PDF)\nData looks good (e.g. the replicates are all very close, with the largest Cq Std. Deviation = 0.534), nothing in the NTCs, & the melt curves look good. Will eventually normalize the data and then perform a complete analysis."
  },
  {
    "objectID": "posts/2011/2011-05-23-qpcr-hard-clam-ngs-primer-checks/index.html",
    "href": "posts/2011/2011-05-23-qpcr-hard-clam-ngs-primer-checks/index.html",
    "title": "qPCR - Hard Clam NGS Primer Checks",
    "section": "",
    "text": "Ran a qPCR to evaluate a large batch of primers (40 sets) that were ordered per Steven, based off of the most recent SOLiD run (samples submitted 3/10/2011; see Dave’s notebook for more info). Pooled cDNA (2uL from each individual; from 20110511) was used. Master mix calcs are here. Plate layout, cycling params, etc. can be found in the qPCR Report (see Results). The list of primers tested is available in the Primer Database and consist of SR IDs 1233 - 1312. For brevity, samples were only labelled with the corresponding contig number.\nResults:\nqPCR Data File (BioRad CFX96)\nqPCR Report (PDF)\nSamples that produced good melt curves are listed here."
  },
  {
    "objectID": "posts/2011/2011-05-20-qpcr-emmas-new-3kdsqpcr-primers/index.html",
    "href": "posts/2011/2011-05-20-qpcr-emmas-new-3kdsqpcr-primers/index.html",
    "title": "qPCR - Emma’s New 3KDSqPCR Primers",
    "section": "",
    "text": "Due to previous contamination issues with Emma’s primers, Emma asked me to order new primers, reconstitute them and run a qPCR for her to see if we could eliminate her contamination issues with this primer set. cDNA template was supplied by Emma (from 2/2/11) and was from a C.gigas 3hr Vibrio vulnificus challenge. Samples were run in duplicate, as requested. Master mix calcs are here. Plate layout, cycling params, etc. can be found in the qPCR Report (see Results). Primer set used was:\nCg_3KDSqPCR_F/R (SR IDs: 1186, 1187)\nResults:\nqPCR Data File (BioRad CFX96)\nqPCR Report (PDF)\nThe negative controls (NTC) are negative, meaning they do not cross the threshold set by the BioRad software. However, there is clearly amplification in the NTCs, but they come up late enough that they do not cross the threshold and, thus, generate a Cq value. Additionally, the melt curve reveals peaks in the NTCs that are at the same melting temperature as the product produced in the cDNA qPCR reactions. This would potentially imply some sort of contamination, as Emma has experienced.\nHonestly, I do no think contamination is the problem. I believe that the “contamination” being seen in the NTCs is actually primer dimer. Increasing the annealing temperature (I’m not sure if Emma tried this during her troubleshooting) could potentially alleviate this issue. However, I’m not sure she’s amplifying the target that she wants to. Based on my analysis, I think she needs to re-design primers for her 3KDS target. Read my analysis and why I came to this conclusion below.\nIt seems unlikely that two independent people (and multiple primer stock replacements!) would have contamination, so I looked in to things a bit further.\nI BLASTed the primer sets (NCBI, blastn, est_others db, C.gigas only) and the BLAST results reveal the primers matching with a C.gigas EST sequence that would produce a band of only 63bp. Here’s a screen capture of the BLAST results:\n\nThis result does NOT agree with what is entered in our Primer Database. As entered in our sheet, the expected PCR product would be ~102bp. However, taking in to account the BLAST results, it would be difficult to distinguish the difference between primer dimers and PCR product in a melt curve analysis.\nEmma has previously run a conventional PCR with these primers and ran a gel (see below). At the time, it was thought to be contamination, but in retrospect (knowing the results of the qPCRs and the BLAST results) it seems likely that what she’s seeing in the negative controls was actually primer dimer, which was the same size of her PCR product (which she thought should be larger). Additionally, the gel was difficult to interpret because no ladder was run. A ladder might have revealed that her PCR product was half the size that she was expecting:"
  },
  {
    "objectID": "posts/2011/2011-10-15-sequencing-coxpgs-clones-from-yesterdaytoday/index.html",
    "href": "posts/2011/2011-10-15-sequencing-coxpgs-clones-from-yesterdaytoday/index.html",
    "title": "Sequencing - COX/PGS Clones from yesterday/today",
    "section": "",
    "text": "Samples were submitted for sequencing to the University of Washington HTGU, two times from each direction using vector M13F/R primers. See Sequence Log for plate layout."
  },
  {
    "objectID": "posts/2011/2011-07-28-bacterial-cultures-c-gigas-cox2pgs2-clones-from-yesterday/index.html",
    "href": "posts/2011/2011-07-28-bacterial-cultures-c-gigas-cox2pgs2-clones-from-yesterday/index.html",
    "title": "Bacterial Cultures - C.gigas COX2/PGS2 Clones (from yesterday)",
    "section": "",
    "text": "Inoculated 4 x 5mL 1xLB + Kan50 with a colony from each set of clones, incubated 37C, 200RPM, O/N. Will mini prep and send for sequencing tomorrow."
  },
  {
    "objectID": "posts/2011/2011-09-22-pcr-full-length-pgs1-cdna/index.html",
    "href": "posts/2011/2011-09-22-pcr-full-length-pgs1-cdna/index.html",
    "title": "PCR - Full-length PGS1 cDNA",
    "section": "",
    "text": "Still have insufficient quantities of DNA for sequencing. Master mix calcs and cycling params are here. Additionally, used some of the purified PCR product as template in one of the reactions, just for comparison purposes. cDNA template was pooled cDNA from 20110311 from various C.gigas tissues. Also, increased the amount of template 4-fold in an attempt to obtain higher yields of PCR products for sequencing.\nResults:\n\nLane 1: Hyperladder I (Bioline)\nLane 2: PCR 1 (cDNA template)\nLane 3: PCR 2 (cDNA template)\nLane 4: PCR 3 (PCR template)\nLane 5: Neg. Control\nBands were excised and will be purified using Ultra-free DA columns (Millipore). Also, it’s very clear that using the purified PCR product as template produced a much greater yield, although there appear to be some spurious, high-molecular weight banding/smearing."
  },
  {
    "objectID": "posts/2011/2011-07-08-clone-restreaking-pgs2-hilo-clones-from-20110421/index.html",
    "href": "posts/2011/2011-07-08-clone-restreaking-pgs2-hilo-clones-from-20110421/index.html",
    "title": "Clone Restreaking - PGS2 Hi/Lo Clones (from 20110421)",
    "section": "",
    "text": "Sequencing of the PGS2/COX2 clone failed (was empty vector). Restreaked bacterial clones on to a Kan50 plate (made 20110413 by SJW) from a plate that Caroline Storer had created from cloning colony selection on 20110421. Samples were labeled as PGS Lo 1 & 2 and PGS Hi 3 & 4. Additionally, there were red numbers on the plate associated with these four samples. They were 42 - 45, respectively. PGS Hi 4 (#45) was previously grown up and sequenced. This sample is what produced vector only sequence. Incubated O/N @ 37C. Hopefully we’ll bacteria is still viable and will have samples to grow up for miniprep, plamsid iso and sequencing.\nResults:\nLimited growth in all after O/N incubation. Will leave plate on bench over the weekend and hope to get more growth.\nAfter the weekend on the bench, have growth in all but PGS Lo 2. Will inoculate liquid cultures for plasmid preps."
  },
  {
    "objectID": "posts/2011/2011-04-28-received-live-hard-clams-from-scott-lindell/index.html",
    "href": "posts/2011/2011-04-28-received-live-hard-clams-from-scott-lindell/index.html",
    "title": "Received - Live Hard Clams From Scott Lindell",
    "section": "",
    "text": "Received two bags containing ~24 live clams (didn’t count) in each bag. One bag labeled as “Mashpee Control” and the other “BX Selected.” Clams were stored @ 4C by Steven."
  },
  {
    "objectID": "posts/2011/2011-02-25-qpcr-check-dnased-rna-bb01-for-residual-gdna-from-earlier-today-3/index.html",
    "href": "posts/2011/2011-02-25-qpcr-check-dnased-rna-bb01-for-residual-gdna-from-earlier-today-3/index.html",
    "title": "qPCR - Check DNased RNA BB01 for Residual gDNA (from earlier today)",
    "section": "",
    "text": "Ran qPCR on DNased RNA from earlier today to verify removal of contaminating gDNA. Used C.gigas 18s primers (SR IDs: 156, 157). 0.5uL (50ng) of DNased RNA was used for testing. This corresponds, roughly, to the amount of sample that would be carried through to qPCR analysis of cDNA, assuming 1ug of RNA was used to make the cDNA (cDNA = 1000ng RNA/25uL = 40ng/uL, 1uL of cDNA in 25uL qPCR reaction). Positive control sample was ~25ng BB16 gDNA (from 20090519). Master mix calcs are here. Plate layout, cycling params, etc can be found in the qPCR Report (see Results). RNA was stored @ -80C in “Sam’s -80C Box”.\nResults:\n[ qPCR Report (PDF)(https://eagle.fish.washington.edu/Arabidopsis/qPCR/Roberts%20Lab_2011-02-25%2011-53-02_CC009827.pdf)\n[ qPCR Data File (CFX96)(https://eagle.fish.washington.edu/Arabidopsis/qPCR/Roberts%20Lab_2011-02-25%2011-53-02_CC009827.pcrd)\nUgh. Still gDNA present in this sample. Hmmmm. Will consider starting from original RNA, but will precipitate this sample again and treat again to see if I can get rid of that cursed gDNA."
  },
  {
    "objectID": "posts/2011/2011-03-11-reverse-transcription-c-gigas-dnased-rna-from-20110131-from-v-vulnificus-exposure-tissues-from-20110111/index.html",
    "href": "posts/2011/2011-03-11-reverse-transcription-c-gigas-dnased-rna-from-20110131-from-v-vulnificus-exposure-tissues-from-20110111/index.html",
    "title": "Reverse Transcription - C.gigas DNased RNA (from 20110131) from V.vulnificus Exposure & Tissues (from 20110111)",
    "section": "",
    "text": "Performed RT on DNased RNA using Promega MMLV RT and Oligo dT according to manufacturer’s protocol, using 1ug of DNased RNA. Due to large number of samples, cDNA was made in PCR plate. Plate layout and calcs are here. cDNA was diluted 4-fold (to 100uL total volume) based on qPCR done by Emma on 20110202."
  },
  {
    "objectID": "posts/2011/2011-09-22-ethanol-precipitation-purified-pgs1-pcr-from-yesterday/index.html",
    "href": "posts/2011/2011-09-22-ethanol-precipitation-purified-pgs1-pcr-from-yesterday/index.html",
    "title": "Ethanol Precipitation - Purified PGS1 PCR from yesterday",
    "section": "",
    "text": "Added 0.1 vols of 3M sodium acetate (pH = 5.2; 38uL) and 2 vols of 100% EtOH (836uL). Incubated 30mins @ -20C. Pelleted DNA 16,000g, 15mins, 4C. Removed supe. Washed pellet w/1mL 70% EtOH. Pelleted DNA 16,000g, 15mins, 4C. Removed supe. Air-dried pellet. Resuspended in 50uL of Qiagen EB Buffer and spec’d.\nResults:\nInsufficient quantity of DNA for sequencing. Will re-run PCR, but will use some of this purified DNA as template to see if that helps increase yields."
  },
  {
    "objectID": "posts/2011/2011-09-21-pcr-full-length-pgs1-cdna-2/index.html",
    "href": "posts/2011/2011-09-21-pcr-full-length-pgs1-cdna-2/index.html",
    "title": "PCR - Full-length PGS1 cDNA",
    "section": "",
    "text": "Need more PCR product for sequencing. Repeated reaction from 20110825.\nResults:\n\nLane 1 - Hypperladder I (Bioline)\nLane 2 - PCR 1 & 2\nLane 3 - PCR 3 & 4\nLane 4 - PCR 5 & 6\nLane 5 - Neg. Control\nBands from lanes 2 - 4 were excised and purified with Ultra-free DA columns (Millipore) and spec’d. Concentration was extremely low (3.5ng/uL) and too dilute for sequencing. Will EtOH precipitate."
  },
  {
    "objectID": "posts/2011/2011-04-14-colony-pcr-5-race-colonies/index.html",
    "href": "posts/2011/2011-04-14-colony-pcr-5-race-colonies/index.html",
    "title": "Colony PCR - 5’ RACE Colonies",
    "section": "",
    "text": "Two light blue colonies (there were no white colonies) were picked, restreaked on a new Kan50 plate (no X-gal) and PCR’d.\nMaster Mix:\n2x Apex Red Master Mix - 37.5uL\n10uM M13 Forward - 3uL\n10uM M13 Reverse - 3uL\nH2O - 46.5\nAdded 25uL to each PCR tube.\nCycling Params:\n\n95C - 10mins\n\n40 cycles of:\n\n95C - 30s\n55C - 30s\n72C - 2mins\n\n1 cycle:\n\n72C - 10mins\n\nResults:\n\nThe two pale blue colonies do NOT contain our desired insert. Despite the presence of a larger, faint band (~950bp), that is far smaller than our 5’RACE insert size (~1500bp). And, clearly, the primary amplicon produced is ~250bp, which is the expected size for empty vector… Ladder is Hyperladder I (Bioline).\nWill need to re-do ligation reaction and will do so at the recommended volumes in the TOP TA (Invitrogen) protocol."
  },
  {
    "objectID": "posts/2011/2011-04-25-colony-pcr-colonies-from-cox1-genomic-cloning-from-20110411/index.html",
    "href": "posts/2011/2011-04-25-colony-pcr-colonies-from-cox1-genomic-cloning-from-20110411/index.html",
    "title": "Colony PCR - Colonies from COX1 Genomic Cloning (from 20110411)",
    "section": "",
    "text": "Ran colony PCR on various colonies produced from cloning on 20110411. All colonies were picked, re-streaked on Kan50 plate(s) and PCR’d. Master mix calcs are here. Cycling params:\n\n95C - 10mins\n\n40cycles of:\n\n95C - 30s\n55C - 30s\n72C - 3mins\n72C - 10mins\n\nResults:"
  },
  {
    "objectID": "posts/2011/2011-03-15-qpcr-c-gigas-cox1cox2-tissue-distribution/index.html",
    "href": "posts/2011/2011-03-15-qpcr-c-gigas-cox1cox2-tissue-distribution/index.html",
    "title": "qPCR - C.gigas COX1/COX2 Tissue Distribution",
    "section": "",
    "text": "Performed qPCR using pooled cDNA from 20110311. Pooled 2uL from each of the following samples groups: Dg 3hr C, Gill 1hr C, Gill 1hr E, Mantle 3hr C, and Muscle 3hr C. Master mix calcs are here. Plate layout, cycling params, etc can be found in the qPCR Report (see Results). Primers sets run were:\nEF1_qPCR_5’,3’ (SR IDs: 309, 310)\nCg_COX1/2_qPCR_F (SR ID: 1192) + Cg_COX1_qPCR_R (SR ID: 1191)- Target = COX1\nCg_COX1/2_qPCR_F (SR ID: 1192) + Cg_COX2_454align1_R (SR ID: 1190) - Target = COX2\nResults:\n[qPCR Report (PDF)(https://eagle.fish.washington.edu/Arabidopsis/qPCR/Roberts%20Lab_2011-03-15%2011-35-42_CC009827.pdf)\n[qPCR Data File (CFX96)(https://eagle.fish.washington.edu/Arabidopsis/qPCR/Roberts%20Lab_2011-03-15%2011-35-42_CC009827.pcrd)\n\nGraphs were generated using the BioRad CFX Manager v2.0 software. Expression was normalized to EF1. Also to note, gene efficiency was assumed as 100% by the software since no standard curve was run on the plate. As such, analysis of this data may not be exact.\nIt’s clear by examining the graphs that the primers being used to differentiate COX1 and COX2 (since they share a common primer: SRID 1192) are differentially expressed. This indicates that the primer sets are indeed amplifying different targets as hoped. This was the primary intention of this qPCR. However, we also now have an idea of tissue distribution of the two genes, as well as their response to V. vulnificus exposre after 1hr. Next step is to perform this qPCR on all the individuals from this experiment as well as the different tissues."
  },
  {
    "objectID": "posts/2011/2011-07-29-plasmid-isolation-sequencing-c-gigas-cox2pgs2-clones-from-yesterday/index.html",
    "href": "posts/2011/2011-07-29-plasmid-isolation-sequencing-c-gigas-cox2pgs2-clones-from-yesterday/index.html",
    "title": "Plasmid Isolation & Sequencing - C.gigas COX2/PGS2 Clones (from yesterday)",
    "section": "",
    "text": "Isolated plasmid DNA from 3mL of liquid cultures that were inoculated yesterday using Qiagen’s miniprep kit. DNA was eluted with 50uL of EB. DNA was prepped and sent for sequencing to ASU sequencing facility. Each clone was sequenced two times in each direction. Samples are as follows:\nName - Clone # Primer\n\nSJW01 - 1 M13F\nSJW02 - 1 M13F\nSJW03 - 1 M13R\nSJW04 - 1 M13R\nSJW05 - 2 M13F\nSJW06 - 2 M13F\nSJW07 - 2 M13R\nSJW08 - 2 M13R\nSJW09 - 3 M13F\nSJW10 - 3 M13F\nSJW11 - 3 M13R\nSJW12 - 3 M13R\nSJW13 - 4 M13F\nSJW14 - 4 M13F\nSJW15 - 4 M13R\nSJW16 - 4 M13R\n\n\n\nClone #s are as follows:\n1 - 5’ Library Top band\n2 - 5’ Library Mid band\n3 - 5’ Library Bottom band\n4 - 3’ Library band\nResults:\nSequencing results received 20110801. SJW15 and 16 apparently stop abruptly. The sequencing facility believes this to be caused by secondary structure of the template. Depending on how things align, I may consider using 7-daeza-GTP in a PCR reaction and re-sequencing this clone, as the 7-daeza-GTP helps relax secondary structure.\nSpoke with Steven and he suggested just designing new primers closer to each other and resubmit."
  },
  {
    "objectID": "posts/2011/2011-07-26-53-race-c-gigas-cox2pgs2-nested-race-pcr/index.html",
    "href": "posts/2011/2011-07-26-53-race-c-gigas-cox2pgs2-nested-race-pcr/index.html",
    "title": "5’/3’ RACE - C.gigas COX2/PGS2 Nested RACE PCR",
    "section": "",
    "text": "Performed nested RACE PCR on the RACE PCR products generated on 20110722 using the following nested primers: PGS2_ngspRACE_5’ (SR ID: 1350) and PGS2_ngspRACE_3’ (SR ID: 1349). Removed 2uL from each of the primary PCR reactions and brought up to 100uL in tricine EDTA (supplied in the Clontech SMARTer RACE cDNA Amplification Kit). Performed the nested RACE PCR according to the Clontech manual. Briefly, this is the same as the primary RACE PCR reaction, but using 5uL of the diluted primary PCR product and 1uL of the Nested Universal Primer (instead of 5uL of the 10X Universal Primer Mix). Master mix calcs and set up are here. Cycling params followed “Program 2” of the Clontech protocol, modified for nested primers, and are as follows:\n20 cycles:\n94C 30s\n68C 30s\n72C 3m\nResults:\n\nGel Layout:\nLane 1 - Hyperladder 1\nLanes 2-6 = 5’ RACE Library\nLane 2 - nGSP1 (5’ RACE primer)\nLane 3 - nGSP2 (3’ RACE primer)\nLane 4 - Neg. Control (no RACE primers)\nLane 5 - Neg. Control (nGSP1, no Universal primer)\nLane 6 - Neg. Control (nGSP2, no Universal primer)\nLane 7 - Empty\nLanes 8-12 = 3’ RACE Library\nLane 8 - nGSP1 (5’ RACE primer)\nLane 9 - nGSP2 (3’ RACE primer)\nLane 10 - Neg. Control (no RACE primers)\nLane 11 - Neg. Control (nGSP1, no Universal primer)\nLane 12 - Neg. Control (nGSP2, no Universal primer)\nFirst of all, we see the appropriate response of each primer only producing amplicons in their respective libraries (i.e. 5’ primer only works in 5’ RACE library). This simply confirms that the primers were designed correctly. Secondly, our negative controls are clean. Thirdly, we get distinct bands from both primers. The bands marked with blue arrows in the image above were excised and purified using Ultrafree DA spin columns (Millipore). These products will be used for cloning and eventual sequencing."
  },
  {
    "objectID": "posts/2011/2011-04-06-53-race-pcrs-cox2-sequence-on-5-3-race-libraries-from-20080619/index.html",
    "href": "posts/2011/2011-04-06-53-race-pcrs-cox2-sequence-on-5-3-race-libraries-from-20080619/index.html",
    "title": "5’/3’ RACE PCRs - COX2 Sequence on 5’ & 3’ RACE Libraries (from 20080619)",
    "section": "",
    "text": "Ran PCRs on both the 5’ & 3’ RACE libraries created 20080619 with a new COX2 gene-specifc (GSP) primer designed by Steven (CgPGSRACEsrGSP1; SR ID: 1208). Although this primer was designed to obtain additional 5’ sequence, it was used with both 5’ and 3’ libraries as a precaution in case it accidentally designed on the wrong strand. PCR rxn was set up according to the Clontech SMARTer RACE cDNA Amplification Kit. Master mix calcs are here. PCR cycling followed “Program 1” from the Clontech manual for 25 cycles.\nAfter PCR completion, 5uL were transferred to a clean tube and saved, in case this PCR didn’t work and a nested PCR would need to be performed. This is according to the Clontech protocol. Samples were run on a 1.2% agarose gel, as instructed in the Clontech manual.\nResults:\nNo bands of any kind in any sample, including the negative controls (gel not shown). Will perform nested PCR on both libraries in hopes of getting bands."
  },
  {
    "objectID": "posts/2011/2011-02-25-ethanol-precpitation-dnased-rna-bb01-from-earlier-today/index.html",
    "href": "posts/2011/2011-02-25-ethanol-precpitation-dnased-rna-bb01-from-earlier-today/index.html",
    "title": "Ethanol Precpitation - DNased RNA BB01 (from earlier today)",
    "section": "",
    "text": "Due to residual gDNA contamination, will EtOH precipitate in order to treat with DNase again. Add 0.5 vols 3M NaAOc (pH=\n5.2), 2.5 vols 100% EtOH, mixed and incubated @ -20C for 30mins. Pelleted RNA @ 16,000g, 4C 30mins. Washed RNA with 1mL 70% EtOH (2x due to fear of residual salts from DNase Buffer). Pelleted RNA @ 16,000g, 4C, 15mins. Resuspended RNA in 45uL nuclease-free H2O. Sample was stored @ -80C (in “Sam’s RNA Box #1) until it could be DNased again."
  },
  {
    "objectID": "posts/2011/2011-02-01-genomic-pcr-repeat-of-c-gigas-cox-genomic-pcr-from-20110118/index.html",
    "href": "posts/2011/2011-02-01-genomic-pcr-repeat-of-c-gigas-cox-genomic-pcr-from-20110118/index.html",
    "title": "Genomic PCR - Repeat of C.gigas COX genomic PCR from 20110118",
    "section": "",
    "text": "This was repeated to generate more PCR product for sequencing purposes. PCR master mix calcs and cycling params are here. Master mixes 04 and 05 (MM04 and MM05) were repeated to gain more PCR product from the faint 550bp & 1500bp bands(MM04) and 5000bp band (MM05).\nMM04 - Cg_COX_982_F (SR ID: 1151) + Cg_COX_1545_R (SR ID: 1148) Band size w/o intron = ~550bp\nMM05 - Cg_COX_982_F (SR ID: 1151) + Cg_COX_2138_R (SR ID: 1149) Band size w/o intron = ~1130bp\nResults:\nGel was run on 20110203\n\nSamples on the left portion of the gel are from the MM04 primer combo and those on the right are from the MM05. Boxed bands were excised, purified using Millipore Ultra DA-free spin columns and stored @ -20C in Sam’s “Misc. -20C Box.”\nInterestingly in the MM05 set, inconsistent, faint bands of ~400-500bp are visible. These were not visible the first time this PCR was conducted (see 20110118), but the exposure of the gel image wasn’t turned up as high as in this image. Due to their inconsistency and extremely low yield, these bands were not excised."
  },
  {
    "objectID": "posts/2011/2011-07-13-plasmid-isolation-miniprep-on-pgs-hi-4-colony-from-yesterday/index.html",
    "href": "posts/2011/2011-07-13-plasmid-isolation-miniprep-on-pgs-hi-4-colony-from-yesterday/index.html",
    "title": "Plasmid Isolation - Miniprep on PGS Hi 4 Colony from yesterday",
    "section": "",
    "text": "Plasmid was isolated from 3mL of liquid culture started yesterday using the Qiagen MiniPrep Kit, according to the manufacturer’s protocol. Will send off for sequencing."
  },
  {
    "objectID": "posts/2011/2011-04-25-bacterial-cultures-colonies-selected-by-steven-from-stevens-re-streaked-plate/index.html",
    "href": "posts/2011/2011-04-25-bacterial-cultures-colonies-selected-by-steven-from-stevens-re-streaked-plate/index.html",
    "title": "Bacterial Cultures - Colonies Selected by Steven from Steven’s Re-Streaked Plate",
    "section": "",
    "text": "Inoculated 5mL of 1x LB + Kan50 (made by Steven on 3/23/11). Incubated O/N @ 37C, 250RPM. Will perform mini preps tomorrow. The following samples were selected (red text on the plate):\n\n#9\n#10\n#13\n#43\n#45\n#49\n#56\n#58"
  },
  {
    "objectID": "posts/2011/2011-07-27-colony-pcrs-c-gigas-cox2pgs2-clones-from-yesterday/index.html",
    "href": "posts/2011/2011-07-27-colony-pcrs-c-gigas-cox2pgs2-clones-from-yesterday/index.html",
    "title": "Colony PCRs - C.gigas COX2/PGS2 Clones (from yesterday)",
    "section": "",
    "text": "Performed colony PCRs on the 4 sets of cloning reactions that were performed yesterday using the M13F/R vector primers. Colonies were picked, restreaked on a fresh LB Kan50 plates (made 20110726 by SJW) and PCR’d. Master mix calcs are here. Selected 8 white colonies from each cloning reaction for PCR. Restreaked plate was incubated @ 37C O/N.\nCycling Params:\n\n95C - 10m\n\n40cycles of:\n\n95C - 10s\n55C - 10s\n72C - 3m\n\nResults:\n\n\nHyperladder I is used as the ladder in both gels.\nCloning results look great (except Colony #1 in the 5’ Top Band didn’t produce a product). Will select a re-streaked colony from each set and inoculate liquid culture for mini prep and subsequent sequencing."
  },
  {
    "objectID": "posts/2011/2011-01-19-genomic-pcr-c-gigas-cyclooxygenase-cox-genomic-sequence/index.html",
    "href": "posts/2011/2011-01-19-genomic-pcr-c-gigas-cyclooxygenase-cox-genomic-sequence/index.html",
    "title": "Genomic PCR - C.gigas cyclooxygenase (COX) genomic sequence",
    "section": "",
    "text": "Attempt to obtain full genomic sequence for C.gigas COX. PCR set up/cycling params/etc are here. Primer set combinations(master mixes) are as follows:\nMM01 - Cg_COX_5’UTR_3_F (SR ID: 1150) + Cg_COX_1009_R (SR ID: 1147) Band size w/o intron = ~1000bp\nMM02 - “” + Cg_COX_1545_R (SR ID: 1148) Band size w/o intron = ~1540bp\nMM03 - “” + Cg_COX_2138_R (SR ID: 1149) Band size w/o intron = ~2135bp\nMM04 - Cg_COX_982_F (SR ID: 1151) + Cg_COX_1545_R (SR ID: 1148) Band size w/o intron = ~550bp\nMM05 - “” + Cg_COX_2138_R (SR ID: 1149) Band size w/o intron = ~1130bp\nMM06 - Cg_COX_1519_F (SR ID: 1146) + Cg_COX_2138_R (SR ID: 1149) Band size w/o intron = ~620bp\nResults:\n\nBioline Hyperladder I used for marker. Gel is loaded with template samples at the far left of each master mix group with two no template controls (NTC) in the remaining two wells of each master mix group. All NTCs on the gel are clean.\nAll bands surrounded by a green box were excised from the gel.\nMM01, MM02 and MM03 - The smallest expected band (i.e. no intron present) would have been 1000bp in MM01. Instead, we see faint banding of multiple sizes less than 1000bp in both MM01 and MM02. MM03 fails to produce any bands. This potentially suggests a couple of things. Firstly, the multiple banding produced in MM01 and MM02 suggests that the PCR conditions lead to some non-specific priming and should be optimized. Secondly, the fact that no bands were produced that are equal to or larger than the “no intron size” suggests that intron(s) may exist in the 5’ region of the COX gene and are large enough that the polymerase had insufficient time/ability to amplify.\nMM04 - Three distinct bands were produced: 2000bp, 1500bp and 550bp. The size of band that would have been produced had an intron NOT been present would have been ~550bp. A band of this size was produced in this PCR reaction. However, two additional bands were produced. The presence of these two larger bands lends additional evidence for the existence of multiple isoforms of COX (which is also supported by the fact that multiple isoforms of COX are known to exist in most other species). The 2000bp band was excised and purified with Millipore Ultra-free DA spin columns and stored @ -20C until a sequencing plate is readied.\nMM05 - A distinct band of ~5000bp was produced. This is significantly larger than the “no intron size” of ~1130bp, suggesting the presence of an intron. This band was excised, but not purified due to the low concentration of DNA in the gel. The gel slice was stored @ -20C until this PCR reaction could be repeated to accumulate sufficient product for sequencing.\nMM06 - A distinct band of ~2200bp was produced. This is significantly larger than the “no intron size” of ~620bp, suggesting the presence of an intron. The band was excised and purified with Millipore Ultra-free DA spin columns and stored @ -20C until a sequencing plate is readied.\nThe PCR reactions reveal the presence of intron(s) in the COX gene we’re investigating as well as providing evidence for the existence of multiple isoforms in C.gigas. Since the PCR products that have been excised for sequencing are so large, additional primers will need to be designed closer to the introns in order to generate smaller products that can be fully sequenced. Additionally, all reactions using the primer designed to anneal in the 5’UTR of COX (SR ID: 1150) failed to produce useful results. This is either due to poor performance of the primer under these reaction conditions or due to the presence of a large intron in the 5’ region of the gene. Additional reverse primers will be designed that anneal closer to the 5’ portion of the COX gene in hopes of characterizing the 5’ genomic sequence better.\nAfter speaking with Steven today about the potential existence/“discovery” of multiple isoforms, he decided to map the newly-released C.gigas 454 NGS data to the existing COX coding sequence in GenBank (FJ375303). The alignment is shown below.\n\nThe two 454 reads that map closest to the 5’ end of the COX coding sequence match up nearly perfectly, with periodic SNPs. The remaining 454 reads that map to the COX coding sequence are very different and provide very good evidence of a previously unidentified isoform of COX in C.gigas. Primers will be designed from both the existing COX sequence in GenBank (FJ375303) and the other potential isoform. These primers will likely be used in both qPCR and for sequencing purposes, in order to be able to distinguish and characterize both isoforms. Additionally, BLASTing will be performed with the sequences from both isoforms to evaluate how they match up with existing COX isoforms in other species."
  },
  {
    "objectID": "posts/2011/2011-03-04-3race-c-gigas-3race-for-cox2/index.html",
    "href": "posts/2011/2011-03-04-3race-c-gigas-3race-for-cox2/index.html",
    "title": "3’RACE - C.gigas 3’RACE for COX2",
    "section": "",
    "text": "Used Cg_COX2_3’RACE_short (SR ID: 1197) & Cg_COX2_3’RACE_long (SR ID: 1196) and the Clonetech SMART RACE cDNA Amplification Kit (unknown acquisition date) to attempt to acquire more 3’ sequence of the C.gigas COX2 isoform. Used Gigas 3’RACE cDNA (from 20080610).\nResults:\n\nGel Loading:\nLane 1: Hyperladder 1\nLane 2: empty\nLane 3: Cg_COX2_3’RACE_long\nLane 4: Cg_COX2_3’RACE_long NTC\nLane 5: empty\nLane 6: Cg_COX2_3’RACE_short\nLane 7: Cg_COX2_3’RACE_short NTC\nLane 8: Hyperladder 1\nNo products produced. This could be due to a large number of factors. The age of the cDNA (from 20080610) is well beyond what the Clontech manual says for storage term (6 months). Additionally, the Clontech polymerase used was nearly 6 years old. The kit (and its components) are of an unknown age and could factor in to the failure of this procedure. Also, the primers that were designed had less than ideal Tm, per the kit’s recommendations.\nMay need to sequence some previously purified potential COX2 fragments in order to obtain a more useable region of the gene for RACE."
  },
  {
    "objectID": "posts/2011/2011-10-07-pcr-region-outside-of-coxpgs-qpcr-primers/index.html",
    "href": "posts/2011/2011-10-07-pcr-region-outside-of-coxpgs-qpcr-primers/index.html",
    "title": "PCR - Region Outside of COX/PGS qPCR Primers",
    "section": "",
    "text": "Ran PCR using primers Cg_COX_982_F and Cg_COX_2138_R (SR IDs: 1149 & 1151, respectively). Template was pooled cDNA from 20110311 of various C.gigas tissues. These primers anneal 5’ and 3’ of where the qPCR primers for both COX1/PGS1 and COX2/PGS2 anneal. Master mix calcs and cycling params are here. Ran multiples of the same reaction to ensure sufficient product for use in cloning/PCR.\nResults:\n\nGel is loaded with Hyperladder I (Bioline) and 7 samples (no NTC; don’t ask). Band in each lane is of the expected size (~1200bp). Each band was excised and purified using Ultra-free DA columns (Millipore), according to protocol. Purified DNA will be used in a subsequent PCR using the qPCR primers for COX/PGS 1&2 BEFORE cloning this product for sequencing."
  },
  {
    "objectID": "posts/2011/2011-10-14-pcr-coxpgs-cloning-colony-screens-from-yesterday/index.html",
    "href": "posts/2011/2011-10-14-pcr-coxpgs-cloning-colony-screens-from-yesterday/index.html",
    "title": "PCR - COX/PGS Cloning Colony Screens from yesterday",
    "section": "",
    "text": "Performed PCR on 40 colonies using both qPCR primer sets to see if I could differentiate between which colonies potentially contained each isoform to reduce the amount of clones needed for sequencing. Master mix and cycling params are here. Primers used were:\nCg_COX1/2_qPCR_F (SR ID: 1192)\nCg_COX1_qPCR_R (SR ID: 1191)\nCg_COX2_454align1_R (SR ID: 1190)\nPositive controls for both primers set were also run. The positive control template was the purified PCR product from 20111006.\nResults:\n\n\nLadder is Hyperladder II (Bioline). Samples are loaded, left to right, as PGS1 and PGS2 on each colony (e.g. on the bottom gel image, under the “Colony 40” label is the PGS1 rxn on the left and the PGS2 rxn on the right).\nNearly every colony exhibits amplification using both primer sets, w/the PGS1 reaction producing a band of ~250bp and the PGS2 reaction producing a band of ~750bp. Colonies 18 and 28 are an exception to this and produced no band with the PGS2 primer set. NTCs were clean. The positive controls worked as expected, yielding a band of ~250bp for PGS1 and a band of ~250bp for PGS2.\nIt is confusing as to why the size of the PGS2 positive control is different than the product that was generated from the colony PCRs.\nWill select 10 colonies for mini-preps."
  },
  {
    "objectID": "posts/2011/2011-02-10-nanodrop1000-comparison-roberts-vs-young-lab-2/index.html",
    "href": "posts/2011/2011-02-10-nanodrop1000-comparison-roberts-vs-young-lab-2/index.html",
    "title": "NanoDrop1000 Comparison - Roberts vs. Young Lab",
    "section": "",
    "text": "Due to an apparent reduction in assay sensitivity for the Hematodidium qPCR assay, we have decided to determine if the spec readings of the plasmid DNA being used for the standard curves are accurate. Used C.gigas gDNA and the lambda DNA Standard (100ng/uL) included in the Quant-iT PicoGreen dsDNA Assay Kit (Invitrogen) that was marked as received 9/1/10. Tested both the Roberts Lab and Young Lab using these DNAs. At least 6 separate measurements were taken of each DNA on each machine. Samples were briefly mixed by flicking the tube 4-5 times prior to each measurement.\nResults:\nSpreadsheet containing absorbance data and calculations of average concentration and standard deviation for both DNA samples on both machines is here.\nA quick table of the results:\n\n\n\n\n\n\n\nRoberts Lab\n\n\nYoung Lab\n\n\n\n\n[Avg. gDNA] (ng/uL)\n\n\n45.656\n\n\n51.778\n\n\n\n\nStd Dev gDNA\n\n\n0.2377\n\n\n0.5825\n\n\n\n\n[Avg. lambda DNA] (ng/uL)\n\n\n76.01\n\n\n90.255\n\n\n\n\nStd Dev lambda DNA\n\n\n3.826\n\n\n0.9342\n\n\n\n\n\nThe first thing to notice is that the lambda DNA that has been used for standard curves does not have the expected concentration (100ng/uL) on either of the machines. It seems unlikely that BOTH NanoDrop1000s are incorrectly calibrated (which could be a possible explanation for why the lambda DNA is not matching the expected 100ng/uL). This is also supported by recent curves done on the Friedman Lab plate reader using this DNA by Lisa, Vanessa and Elene (data not shown). It’s also interesting to note that the lambda DNA also shows a greater standard deviation (on both machines) than the other DNA (gDNA) used in this test. This is surprising as one would expect a store-bought reagent to be of the highest quality, particularly since it is supposed to be used for DNA quantification. However, it should also be remembered that this DNA is over a year old and has never been aliquoted. As such, it has gone through an extremely high number of freeze/thaw cycles which could have an impact on the long-term quality of the DNA.\nThe second thing to notice is that the Roberts Lab and Young Lab machines provide different concentrations of each of the two DNAs. Unfortunately, due to the fact that the lambda DNA concentration is not as expected (100ng/uL) on either machine it is impossible to determine which machine is more accurate. However, it appears that the Young Lab NanoDrop1000, overall, is more consistently precise in its readings than the Roberts Lab NanoDrop1000. Of course, both machines do seem to be sufficiently precise that precision shouldn’t be a concern.\nI’ve notified Lisa of the potentially inaccurate readings of the lambda DNA. She has ordered a fresh set of DNA standards that will be used to test both machines to help assess their accuracy."
  },
  {
    "objectID": "posts/2011/2011-06-03-qpcr-c-gigas-18s-and-ef1a-on-v-vulnificus-exposure-cdna-from-20110311/index.html",
    "href": "posts/2011/2011-06-03-qpcr-c-gigas-18s-and-ef1a-on-v-vulnificus-exposure-cdna-from-20110311/index.html",
    "title": "qPCR - C.gigas 18s and EF1a on V.vulnificus exposure cDNA (from 20110311)",
    "section": "",
    "text": "Ran a qPCR on all cDNA samples from the V.vulnificus exposure experiment from 20110111. This qPCR was to test 2 of 4 potential normalizing genes to evaluate which genes show the least amount of effect from the treatments in this experiment. Primers for 18s used were Cg_18s_1644_F (SR ID: 1168), Cg_18s_1750_R (SR ID: 1169). Primers for EF1a used were EF1_qPCR_5’ (SR ID: 309), EF1_qPCR_3’ (SR ID: 310)Samples were run in duplicate. Master mix calcs are here. The master mix info is the same that was used earlier today, but with the primers noted above, not those listed on the calcs page. Plate layout, cycling params, etc., can be seen in the qPCR Report (see Results).\nResults:\nqPCR Data File (BioRad CFX96)\nqPCR Report (PDF)\n18s: Average Cq = 22.39, Standard Deviation = 0.905\nEF1a: Average Cq = 20.59, Standard Deviation = 0.658"
  },
  {
    "objectID": "posts/2011/2011-03-07-mrna-isolation-pooled-black-abalone-dg-rna-from-abalone-dg-exp-1/index.html",
    "href": "posts/2011/2011-03-07-mrna-isolation-pooled-black-abalone-dg-rna-from-abalone-dg-exp-1/index.html",
    "title": "mRNA Isolation - Pooled Black Abalone Dg RNA (from Abalone Dg Exp 1)",
    "section": "",
    "text": "mRNA was isolated for SOLiD sequencing by HTGU. Made two pools of San Nick RNA (Control and Exposed) using equal amounts (5ug) of each individual sample. Individual samples used can be found here. mRNA was isolated using Ambion’s Micro PolyAPurist Kit according to protocol. Procedure was performed two times on each pool and then EtOH precipitated. Samples were resuspended in 10uL of The RNA Storage Solution provided in the kit and spec’d on the Roberts Lab ND1000. Samples were stored @ -80C in the “Next Gen Sequencing Libraries” box.\nResults:\n\nYields are pretty good from both samples (~500ng). However, the OD260/280 values are rather poor."
  },
  {
    "objectID": "posts/2011/2011-10-13-cloning-purified-coxpgs-qpcr-fragment-from-20111006/index.html",
    "href": "posts/2011/2011-10-13-cloning-purified-coxpgs-qpcr-fragment-from-20111006/index.html",
    "title": "Cloning - Purified COX/PGS “qPCR Fragment” from 20111006",
    "section": "",
    "text": "Cloned the purified “qPCR Fragment” from 20111006 using the TOPO TA Cloning Kit (Invitrogen). Performed a half reaction (total volume = 3uL), using 1uL of purified PCR product. Incubated at RT for 20mins and then placed reaction on ice. Transformed chemically competent TOP 10 cells (Invitrogen) and heat shocked at 42C for 30s. Added 250uL of RT S.O.C. medium and incubated at 37C, 200RPM. Plated cells on pre-warmed Kan50+X-Gal plates (plates from 20110726; X-Gal added ~30mins before plating cells). Incubated plates O/N, 37C.\nResults:\nGood number of white colonies (>30). Will screen each colony with both qPCR primer sets to see if we can differentiate between the two COX/PGS isoforms in these clones."
  },
  {
    "objectID": "posts/2011/2011-01-25-rna-isolation-various-c-gigas-tissue-from-20110111/index.html",
    "href": "posts/2011/2011-01-25-rna-isolation-various-c-gigas-tissue-from-20110111/index.html",
    "title": "RNA Isolation - Various C.gigas Tissue from 20110111",
    "section": "",
    "text": "RNA was isolated in 1mL TriReagent, according to protocol. Samples were resuspended in 50uL 0.1% DEPC-H2O and spec’d. RNA was stored @ -80C in “Shellfish RNA Box #4\nResults:\n\n\nRNA looks OK. Not surprising, but mantle and Dg/Gonad tissues ended up with poor OD260/230 ratios. This has been observed in the past with these tissue types."
  },
  {
    "objectID": "posts/2011/2011-02-25-dnase-c-gigas-bb01-from-20110216/index.html",
    "href": "posts/2011/2011-02-25-dnase-c-gigas-bb01-from-20110216/index.html",
    "title": "DNase - C.gigas BB01 from 20110216",
    "section": "",
    "text": "Used EtOH precipitated BB01 RNA from 20110216 and followed Ambion’s “rigorous” protocol, utilizing a total of 2uL of DNAse. Briefly, samples were incubated @ 37C for 30mins, an additional 1uL of DNase was added to each sample, mixed and incubated for an additional 30mins @ 37C. After finishing protocol, samples were spec’d.\nResults:\n\nFirst reading had an air bubble and should be ignored. DNased RNA looks good, based on 260/280 ratios. As is usually the case for DNased RNA, the 260/230 ratios are on the low side. Will check DNased RNA for residual gDNA."
  },
  {
    "objectID": "posts/2011/2011-06-03-qpcr-c-gigas-actin-and-gapdh-on-v-vulnificus-exposure-cdna-from-20110311/index.html",
    "href": "posts/2011/2011-06-03-qpcr-c-gigas-actin-and-gapdh-on-v-vulnificus-exposure-cdna-from-20110311/index.html",
    "title": "qPCR - C.gigas actin and GAPDH on V.vulnificus exposure cDNA (from 20110311)",
    "section": "",
    "text": "Ran a qPCR on all cDNA samples from the V.vulnificus exposure experiment from 20110111. This qPCR was to test 2 of 4 potential normalizing genes to evaluate which genes show the least amount of effect from the treatments in this experiment. Primers for actin used were Cg_Actin_306_F (SR ID: 1170), Cg_Actin_408_R (SR ID: 1171). Samples were run in duplicate. Master mix calcs are here. The master mix info is the same that was used earlier today, but with the primers noted above, not those listed on the calcs page. Plate layout, cycling params, etc., can be seen in the qPCR Report (see Results).\nResults:\nqPCR Data File (BioRad CFX96)\nqPCR Report (PDF)\nActin: Average Cq = 20.21, Standard Deviation = 1.22\nGAPDH: Average Cq = 24.42, Standard Deviation = 0.519\nBased on the results from the 4 normalizing genes examined, I will use GAPDH as the normalizing gene due to it having the lowest standard deviation of the 4 normalizing genes. Will perform another qPCR to run a duplicate of GAPDH so that we have a second rep."
  },
  {
    "objectID": "posts/2011/2011-06-01-qpcr-c-gigas-cox2-on-v-vulnificus-exposure-cdna-from-20110311/index.html",
    "href": "posts/2011/2011-06-01-qpcr-c-gigas-cox2-on-v-vulnificus-exposure-cdna-from-20110311/index.html",
    "title": "qPCR - C.gigas COX2 on V.vulnificus exposure cDNA (from 20110311)",
    "section": "",
    "text": "Ran a qPCR on all cDNA samples from the V.vulnificus exposure experiment from 20110111. Primers used were Cg_COX1/2_qPCR_F (SR ID: 1192) & Cg_COX2_454align1_R (SR ID: 1190). Samples were run in duplicate. Master mix calcs are here. The master mix info is the same that was used earlier today, but with the primers noted above, not those listed on the calcs page. Plate layout, cycling params, etc., can be seen in the qPCR Report (see Results).\nResults:\nqPCR Data File (BioRad CFX96)\nqPCR Report (PDF)\nData looks good (e.g. the replicates are all very close, with the largest Cq Std. Deviation = 1.227, although this does appear to be an anomaly as the next highest Cq Std. Deviation in any of the reps is 0.633), nothing in the NTCs, & the melt curves look good. Will eventually normalize the data and then perform a complete analysis."
  },
  {
    "objectID": "posts/2011/2011-04-21-colony-pcr-5-race-colony-cox2/index.html",
    "href": "posts/2011/2011-04-21-colony-pcr-5-race-colony-cox2/index.html",
    "title": "Colony PCR - 5’ RACE Colony: COX2",
    "section": "",
    "text": "One white colony (marked with arrow in image linked) from the two plates from Steven’s cloning (from yesterday) was picked, restreaked on a new Kan50 plate (no X-gal) and PCR’d.\nMaster Mix:\n2x Apex Red Master Mix - 25uL\n10uM M13 Forward - 1uL\n10uM M13 Reverse - 1uL\nH2O - 23\nAdded 25uL to each PCR tube.\nCycling Params:\n\n95C - 10mins\n\n40 cycles of:\n\n95C - 30s\n55C - 30s\n72C - 2mins\n\n1 cycle:\n\n72C - 10mins\n\nResults:\n\nLane 1: Hyperladder IV\nLane 2: colony PCR\nLane 3: NTC\nTurns out the Hyperladder IV (this gel was run in the Friedman Lab) only goes up to 1000bp. So, the band we see in the colony PCR reaction could be close to the expected size if the insert is present (~1500bp). Although, we also see a band in the NTC. Will repeat this PCR and run on a gel with a more appropriate ladder…"
  },
  {
    "objectID": "posts/2011/2011-01-21-rna-isolation-various-c-gigas-tissue-from-20110111-3/index.html",
    "href": "posts/2011/2011-01-21-rna-isolation-various-c-gigas-tissue-from-20110111-3/index.html",
    "title": "RNA Isolation - Various C.gigas Tissue from 20110111",
    "section": "",
    "text": "RNA was isolated in 1mL TriReagent, according to protocol. Samples were resuspended in 50uL 0.1% DEPC-H2O and spec’d. RNA was stored @ -80C in “Shellfish RNA Box #4”.\nResults:\n\nAll gill RNA looks nearly perfect (based on 260/280 and 260/230 values). Muscle RNA is only OK (based on 260/280 and 260/230 values)."
  },
  {
    "objectID": "posts/2011/2011-02-28-dnase-c-gigas-bb01-from-20110225/index.html",
    "href": "posts/2011/2011-02-28-dnase-c-gigas-bb01-from-20110225/index.html",
    "title": "DNase - C.gigas BB01 from 20110225",
    "section": "",
    "text": "Used EtOH precipitated BB01 RNA from 20110225 and followed Ambion’s “rigorous” protocol, utilizing a total of 2uL of DNAse. Briefly, samples were incubated @ 37C for 30mins, an additional 1uL of DNase was added to each sample, mixed and incubated for an additional 30mins @ 37C. After finishing protocol, samples were spec’d.\nResults:\n\nRNA looks good, based on the OD260/280. As usual after DNasing, the OD260/230 is on the low side. Will check for residual gDNA via qPCR."
  },
  {
    "objectID": "posts/2011/2011-02-09-qpcr-test-young-lab-qpcr-calibration-repeat/index.html",
    "href": "posts/2011/2011-02-09-qpcr-test-young-lab-qpcr-calibration-repeat/index.html",
    "title": "qPCR - Test Young Lab qPCR Calibration (Repeat)",
    "section": "",
    "text": "This is a repeat of a run from 20110204. Here’re master mix calcs. This was being repeated to evaluate whether or not the relative differences in Ct values observed on 20110204 are consistent or not across the plate. Cycling params were as follows:\n\n95C - 10min\n\n40 Cycles of:\n\n95C - 15s\n55C - 30s\n72C - 1m\n\nMelt curve.\nResults:\nAbsolutely no amplification of any kind! Bizarre. Will repeat."
  },
  {
    "objectID": "posts/2011/2011-04-11-ligations-cox1cox2-pcr-products/index.html",
    "href": "posts/2011/2011-04-11-ligations-cox1cox2-pcr-products/index.html",
    "title": "Ligations - COX1/COX2 PCR Products",
    "section": "",
    "text": "Performed ligations/cloning on a variety of COX1 genomic and COX 5’ RACE products using the TOPO TA Cloning Kit (Invitrogen). Used 2uL of gel-purified PCR product in each cloning rxn, 2.5uL of H2O, 1uL of salt solution, and 0.5uL of the Invitrogen pCR2.1 vector. Incubated samples for 5mins at RT. Used 2uL of the cloning reaction to transform TOP10 chemically competent cells (Invitrogen), mixed very gently, incubated on ice for 5mins, heat shocked at 42C for 30s and immediately placed on ice. Added 250uL of SOC Medium and incubated tubes at 37C, 200RPM for 1hr. Plated 50uL of each transformation on LB+Kan plates (made by Steven on unknown date with unknown Kan concentration) containing 40uL of 40mg/mL X-gal. Incubated O/N at 37C. Remaining volume of transformed bacteria were stored @ 4C."
  },
  {
    "objectID": "posts/2011/2011-03-14-qpcr-c-gigas-bbdh-cdna-for-props/index.html",
    "href": "posts/2011/2011-03-14-qpcr-c-gigas-bbdh-cdna-for-props/index.html",
    "title": "qPCR - C.gigas BB/DH cDNA for PROPS",
    "section": "",
    "text": "Performed qPCR using cDNA from 20110311. This was performed for additional reps for TIMP3(BB) (SR IDs:1067 & 1106) and HMGP (SR IDs:359 & 360). Master mix calcs are here. Plate layout, cycling params, etc can be found in the qPCR Report (see Results).\nResults:\n[qPCR Report (PDF)(https://eagle.fish.washington.edu/Arabidopsis/qPCR/Roberts%20Lab_2011-03-14%2013-01-59_CC009827.pdf)\n[qPCR Data File (CFX96)(https://eagle.fish.washington.edu/Arabidopsis/qPCR/Roberts%20Lab_2011-03-14%2013-01-59_CC009827.pcrd)\nWill analyze with PCR Miner and incorporate with previous PCR rep done for PROPS with these two genes. Oddly, samples in wells B09 and H09 have weird melt curves. As such, these samples will be excluded from analysis."
  },
  {
    "objectID": "posts/2011/2011-03-01-dnase-c-gigas-bb01-props-rna-from-20090507/index.html",
    "href": "posts/2011/2011-03-01-dnase-c-gigas-bb01-props-rna-from-20090507/index.html",
    "title": "DNase - C.gigas BB01 (PROPS) RNA (from 20090507)",
    "section": "",
    "text": "Since the previous DNase treatment failed for this sample, will repeat but will start with less RNA (5ug instead of 10ug). Need more DNased RNA to finish repeating of PROPS. Some samples had insufficient quantities of DNased RNA remaining in BB01. Used 5ug of RNA and followed Ambion’s “rigorous” protocol, utilizing a total of 2uL of DNAse for each sample. Briefly, samples were incubated @ 37C for 30mins, an additional 1uL of DNase was added to each sample, mixed and incubated for an additional 30mins @ 37C. After finishing protocol, samples were spec’d.\nDNase Rxn Calcs:\nBB01 (1.824ug/uL): 5ug/1.824ug/uL = 2.74uL RNA + 42.26uL H2O (to 45uL) + 5uL 10X DNase Buffer = 50uL\nResults:\n\nRNA looks OK, based on OD260/280. Would like that value to be higher, though. OD260/230 is low, which is typical post-DNased treatment. Will check for residual gDNA via qPCR."
  },
  {
    "objectID": "posts/2011/2011-01-29-dnase-dnase-c-gigas-rna-from-20110120-20110121-and-20110124/index.html",
    "href": "posts/2011/2011-01-29-dnase-dnase-c-gigas-rna-from-20110120-20110121-and-20110124/index.html",
    "title": "DNase - DNase C.gigas RNA from 20110120, 20110121 and 20110124",
    "section": "",
    "text": "5ug of RNA was DNased using Ambion’s Turbo DNA-free kit, following the rigorous protocol (0.5uL of DNase for 30 mins then additional 0.5uL of DNase for 30mins). Calcs for DNase reactions are here. RNA was stored @ -80C in Shellfish RNA Boxes 4 and 5. Samples will be spec’d on Monday.\nResults:\n\nOverall, the RNA looks really good (based on OD 260/280 numbers). Not surprisingly, the OD 260/230 values for all samples dropped, likely due to the addition of the buffer (salts) used in the DNase reaction. Emma says she will check these samples for residual DNA.\n–UPDATE (20110131)– Emma checked all DNased RNA samples on 20110131 using C.gigas 18s primers (SR ID: ?). She has not listed the results of the whether or not all samples are clean or if some still have residual gDNA carryover.\n–UDPATE (20110201– Samples that appear to have residual gDNA carryover based on Emma’s qPCR on 20110131: Muscle C6, Gill 1hr C2 & E2."
  },
  {
    "objectID": "posts/2011/2011-08-05-sequencing-c-gigas-cox2pgs2-clone-4-from-20110728/index.html",
    "href": "posts/2011/2011-08-05-sequencing-c-gigas-cox2pgs2-clone-4-from-20110728/index.html",
    "title": "Sequencing - C.gigas COX2/PGS2 Clone #4 from 20110728",
    "section": "",
    "text": "Used new primers for sequencing (SR IDs: 1351 & 1352) clone #4. Sequenced clone two times in each direction. DNA and primers were sent for sequencing at ASU. Requested “High GC” treatment to help overcome the issue seen on 20110728.\nResults:\nSequencing results received 20110810. Initial analysis suggests that we managed to fully sequence this clone! Will try to assemble a full-length CDS for COX2/PGS2."
  },
  {
    "objectID": "posts/2011/2011-02-10-data-analysis-young-lab-abi-7300-calibration-checks/index.html",
    "href": "posts/2011/2011-02-10-data-analysis-young-lab-abi-7300-calibration-checks/index.html",
    "title": "Data Analysis - Young Lab ABI 7300 Calibration Checks",
    "section": "",
    "text": "All runs (3 runs were conducted) were created using a master mix containing C.gigas gDNA (either 50ng or 100ng), 1X Promega qPCR Master Mix, 0.2uM each of forward/reverse primers (18s; Roberts SR ID: 156, 157). The master mix was mixed well and 10uL were distributed in each well of ABI plates. Plates were sealed with ABI optical adhesive covers.\nIt should also be noted that this analysis was only done with a single primer set and was not tested on any other qPCR machines. This can easily be done if it is desired, however I think one of the issues still being observed with the machine is sample-independent (see Results section below).\nResults:\nHere’s an extremely quick and dirty analysis of what these qPCR runs have revealed (across the entire plate, 3 plates of data):\nAvg. Range of Cts Across Plates - 1.70\nAvg. Std. Deviation of Cts Across Plates - 0.352\nBased off of the graphs below (particularly the Ct vs Well Position plot), my conclusion is that the machine reads plates inaccurately in Rows A, B, C, F, G, & H. Rows D & E exhibit the most consistent well-to-well readings and, potentially, could be used for qPCR.\nThe entire work up (which includes a breakdown of each well position relative to each other) is here (Excel Workbook .xlsx). Below are screen captures of one of the three plates (as an example, since all looked the same) that were used for analysis of the amplification plots, melt curves and Ct vs Well Position and a quick description/assessment of what I have observed.\nThe amplification plot (below) clearly shows the type of spread in Cts across an entire plate that was observed in each run, as well as a large range in fluorescence detected (Rn) in each well.\n\nThe melt curve (below) reflects the large range of detected fluorescence seen in the amplification plot. Additionally, some wells exhibit small “bumps” between 75C and 80C. This provides more evidence for a problem with well-to-well consistency.\n\nA graph of Ct vs. Well Position (below) reveals some enlightening information. From looking at this plot, it’s clear that the machine reads from A1 to A12, then B1 to B12 (reads by row, not column) and so on. This plot reveals that most of the variation seen in Ct values occurs in the two rows closest to the edge of the plate, and within those rows, the middle wells’ Cts are more similar to the Cts observed throughout the rest of the plate."
  },
  {
    "objectID": "posts/2011/2011-07-12-bacterial-cultures-liquid-cultures-of-pgs2cox2-colonies-from-20110707/index.html",
    "href": "posts/2011/2011-07-12-bacterial-cultures-liquid-cultures-of-pgs2cox2-colonies-from-20110707/index.html",
    "title": "Bacterial Cultures - Liquid Cultures of PGS2/COX2 Colonies from 20110707",
    "section": "",
    "text": "Inoculated 5mL of 1xLB + Kan50 with re-streaked colonies from 20110707. Incubated O/N, 37C, 200RPM. Will isolated plasmids of those with inserts tomorrow."
  },
  {
    "objectID": "posts/2011/2011-05-08-primer-design-hard-clam-ngs-primers/index.html",
    "href": "posts/2011/2011-05-08-primer-design-hard-clam-ngs-primers/index.html",
    "title": "Primer Design - Hard Clam NGS Primers",
    "section": "",
    "text": "Designed primers for 40 PCR targets derived from the most recent SOLiD data by Steven(Evernote link) using BatchPrimer3. BatchPrimer3 results are here."
  },
  {
    "objectID": "posts/2011/2011-08-12-qpcr-c-gigas-v-vulnificus-exposure-cdna-from-20110311/index.html",
    "href": "posts/2011/2011-08-12-qpcr-c-gigas-v-vulnificus-exposure-cdna-from-20110311/index.html",
    "title": "qPCR - C.gigas V.vulnificus Exposure cDNA (from 20110311)",
    "section": "",
    "text": "Ran a qPCR using 3hr Vibrio vulnificus exposure cDNA from 20110311. Original experiment conducted on 20110111 with defensin primers (SR IDs: 1109 & 1070) and GAPDH (SR IDs: 1172 & 1173). Master mix calcs are here. Cycling params, plate layout, etc can be seen in the qPCR Report (see Results). This was performed to help Herschel.\nResults:\nqPCR Report (PDF)\nqPCR Data File (CFX96)\nInitial glance at data looks good. GAPDH exhibits highly consistent Cq values across all samples, controls and exposed. Although, there is slight amplification of something in the two water samples for GAPDH, the melt curve shows that this product has a different melting temperature than our intended target. As such, I believe the GAPDH data to be useable, since no other samples exhibit this smaller product. Defensin shows clean water sample and clean melt curves with a single peak. However, it seems like we may not see an effect on defensin expression in response to the Vibrio vulnificus exposure…"
  },
  {
    "objectID": "posts/2011/2011-01-22-rna-isolation-various-c-gigas-tissue-from-20110111-2/index.html",
    "href": "posts/2011/2011-01-22-rna-isolation-various-c-gigas-tissue-from-20110111-2/index.html",
    "title": "RNA Isolation - Various C.gigas Tissue from 20110111",
    "section": "",
    "text": "RNA was isolated in 1mL TriReagent, according to protocol. Samples were resuspended in 50uL 0.1% DEPC-H2O and spec’d. RNA was stored @ -80C in “Shellfish RNA Box #4”.\nResults:\n\nOverall, all RNA looks very good (based on 260/280 and 260/230 values)."
  },
  {
    "objectID": "posts/2011/2011-03-01-nanodrop1000-comparison-roberts-vs-young-lab/index.html",
    "href": "posts/2011/2011-03-01-nanodrop1000-comparison-roberts-vs-young-lab/index.html",
    "title": "NanoDrop1000 Comparison - Roberts vs. Young Lab",
    "section": "",
    "text": "A previous comparison was performed (see 20110209), but it was determined that the standard DNA being used to test the machines was old/degraded. Lisa ordered a new standard DNA dilutions series (Quant-iT dsDNA Kit; Invitrogen) and these DNAs were used. All DNAs were measured 5 times and were mixed by gently flicking between each measurement. A “blank” was measured between each different [DNA] and, if the reading was > + or - 1ng/uL, the machine was reblanked.\nResults:\nQuick assessment is that Graham’s NanoDrop1000 is more accurate than ours.\n[Here is a spreadsheet with averages, standard deviations and experimental error (%)(https://spreadsheets4.google.com/ccc?hl=en&key=tSqYT6UZDXFLvxIq0XmCzFw&authkey=CICJ1-wC&hl=en#gid=0). Below are the raw measurements from both machines.\nRoberts Lab ND100:\n\nYoung Lab ND1000:"
  },
  {
    "objectID": "posts/2011/2011-07-12-pcr-colony-pcr-on-restreaked-pgs2-clones-from-20110707/index.html",
    "href": "posts/2011/2011-07-12-pcr-colony-pcr-on-restreaked-pgs2-clones-from-20110707/index.html",
    "title": "PCR - Colony PCR on Restreaked PGS2 Clones from 20110707",
    "section": "",
    "text": "Ran a colony PCR at the same time that I inoculated liquid cultures, using M13 primers.\nCycling params:\n\n94C - 10m\n\n40 cycles of:\n\n94C - 1m\n50C - 1m\n72C - 2m\n\nResults:\n\nLane 1: Hyperladder I\nLane 2: PGS Lo 1\nLane 3: PGS Hi 3\nLane 4: PGS Hi 4\nLane 5: Neg. Control\nThe only colony with an insert is PGS Hi 4. Will run a plasmid prep. However, this is the same sample that was sent for sequencing that produced nothing but vector sequence…"
  },
  {
    "objectID": "posts/2011/2011-05-20-qpcr-lexies-qpx-temp-tissue-experiment-see-lexies-notebook-4262011/index.html",
    "href": "posts/2011/2011-05-20-qpcr-lexies-qpx-temp-tissue-experiment-see-lexies-notebook-4262011/index.html",
    "title": "qPCR - Lexie’s QPX Temp & Tissue Experiment (see Lexies Notebook 4/26/2011)",
    "section": "",
    "text": "Ran qPCR with Lexie’s cDNA samples from this experiment with the following primer sets in order to better evaluate her biological reps:\nQPX_SPB_F/R (SR ID: 387, 388)\nLABY_A/Y (SR ID: 116, 121)\nLABY was run as a potential normalizing gene. Master mix calcs are here. Plate layout, cycling params, etc. can be found in the qPCR Report (see Results). Samples were run in duplicate and were labeled according to what was written on the tops of Lexie’s cDNA tubes.\nResults:\nqPCR Data File (BioRad CFX96)\nqPCR Report (PDF)\nLABY primers worked, but the melt curves don’t look that good. I’ll let Lexie worry about the rest of the analysis."
  },
  {
    "objectID": "posts/2011/2011-09-15-pcr-full-length-pgs2-cdna/index.html",
    "href": "posts/2011/2011-09-15-pcr-full-length-pgs2-cdna/index.html",
    "title": "PCR - Full-length PGS2 cDNA",
    "section": "",
    "text": "Repeated PCR from 20110825 to attempt to amplify the full-length cDNA for PGS2 (COX2), however this time using a more robust polymerase (Amplitaq Gold) in hopes of getting results. Additionally, tried 3 different Mg2+ concentrations (1.5mM, 2.0mM, and 3.0mM). Master mix calcs and cycling params are here. cDNA was pooled cDNA made 20110311 from various tissues. PGS2 primers = 1376, 1375.\nPGS2 expected size = ~2500bp\n\n\nResults:\n\nLoading order doesn’t matter, as there are no bands. Ladder is Hyperladder I (Bioline). Will continue current sequence analysis and potentially design a new set of primers…"
  },
  {
    "objectID": "posts/2011/2011-04-26-mini-preps-liquid-cultures-from-yesterday/index.html",
    "href": "posts/2011/2011-04-26-mini-preps-liquid-cultures-from-yesterday/index.html",
    "title": "Mini Preps - Liquid Cultures from yesterday",
    "section": "",
    "text": "Mini prepped 3mLs of each culture, according to Qiagen protocol. Samples were eluted with 50uL of Buffer EB.\n\n#9\n#10\n#13\n#43\n#45\n#49\n#56\n#58"
  },
  {
    "objectID": "posts/2011/2011-04-07-53-race-pcrs-nested-pcrs-for-cox2-sequence/index.html",
    "href": "posts/2011/2011-04-07-53-race-pcrs-nested-pcrs-for-cox2-sequence/index.html",
    "title": "5’/3’ RACE PCRs - Nested PCRs for COX2 Sequence",
    "section": "",
    "text": "Due to the failure of the primary PCR on both 5’ and 3’ RACE cDNA libraries (from 20080619) yesterday, will perform nested PCR using a nested GSP designed by Steven (CgPGSRACEsrNGSP1; SR ID:1209). The 5uL of PCR reactions that were set aside yesterday were diluted to 250uL with tricine-EDTA (supplied with the Clontech SMARTer RACE cDNA Amplification Kit) as instructed in the Clontech manual. The master mix and tube layouts were exactly the same as yesterday’s, but instead of using 2.5uL of RACE cDNA library as template, I used 5uL of the diluted PCR reaction. Additionally, Universal Nested Primers were used instead of the Universal Primer Mix (both supplied in the kit). Cycling parameters followed “Program 2” from the Clontech manual for 25 cycles.\nEntire PCR rxns were run on a 1.2% gel, as instructed by the Clontech manual.\nResults:\n\nSo….. What we see here is a melted gel!\nBut! We also see a successful PCR! The first three lanes (excluding the Hyperladder I) are 5’ RACE rxn, followed by two different negative controls (the negative control in the last lane is the one we’re really concerned with and it’s totally clean). The next three lanes are the 3’ RACE rxn, followed by two different negative controls (the negative control in the last lane is the one we’re really concerned with and it’s totally clean). As hoped/expected, we got a nice, clear product in the 5’ RACE rxn.\nThe bright band (~1500bp) in the 5’ RACE rxn PCR was excised and purified using Millipore Ultrafree DA columns according to protocol. Will clone and sequence this product."
  },
  {
    "objectID": "posts/2011/2011-02-17-dnase-c-gigas-bbdh-props-rna-from-20090507/index.html",
    "href": "posts/2011/2011-02-17-dnase-c-gigas-bbdh-props-rna-from-20090507/index.html",
    "title": "DNase - C.gigas BB/DH (PROPS) RNA (from 20090507)",
    "section": "",
    "text": "Need more DNased RNA to finish repeating of PROPS. Some samples had insufficient quantities of DNased RNA remaining in BB01 and BB09. Used 10ug of each RNA and followed Ambion’s “rigorous” protocol, utilizing a total of 2uL of DNAse for each sample. Briefly, samples were incubated @ 37C for 30mins, an additional 1uL of DNase was added to each sample, mixed and incubated for an additional 30mins @ 37C. After finishing protocol, samples were spec’d.\nDNase Rxn Calcs:\nBB01 (1.824ug/uL): 10ug/1.824ug/uL = 5.48uL RNA + 39.52uL H2O (to 45uL) + 5uL 10X DNase Buffer = 50uL\nBB09 (0.506ug/uL): 10ug/0.506ug/uL = 19.77uL RNA + 25.23uL H2O (to 45uL) + 5uL 10X DNase Buffer = 50uL\nResults:\n\n260/280 values look great. 260/230 values look bad, but this is not unusual for samples post-DNase treatment."
  },
  {
    "objectID": "posts/2011/2011-02-17-ethanol-precipitation-dnased-rna-bb01-from-earlier-today/index.html",
    "href": "posts/2011/2011-02-17-ethanol-precipitation-dnased-rna-bb01-from-earlier-today/index.html",
    "title": "Ethanol Precipitation - DNased RNA BB01 (from earlier today)",
    "section": "",
    "text": "Due to residual gDNA contamination, will EtOH precipitate in order to treat with DNase again. Add 0.5 vols 3M NaAOc (pH = 5.2), 2.5 vols 100% EtOH, mixed and incubated @ -20C for 30mins. Pelleted RNA @ 16,000g, 4C 30mins. Washed RNA with 1mL 70% EtOH (2x due to fear of residual salts from DNase Buffer). Pelleted RNA @ 16,000g, 4C, 15mins. Resuspended RNA in 45uL nuclease-free H2O. Sample was stored @ -80C (in “Sam’s RNA Box #1) until it could be DNased again."
  },
  {
    "objectID": "posts/2011/2011-03-21-qpcr-c-gigas-bbdh-cdna-for-props-timp3bb-primers/index.html",
    "href": "posts/2011/2011-03-21-qpcr-c-gigas-bbdh-cdna-for-props-timp3bb-primers/index.html",
    "title": "qPCR - C.gigas BB/DH cDNA for PROPS (TIMP3(BB) primers)",
    "section": "",
    "text": "Performed qPCR using cDNA from 20110311. This was performed for 2 reps with TIMP3(BB) (SR IDs: 1067 & 1106). Master mix calcs are here. Plate layout, cycling params, etc. can be found in the qPCR Report (see Results).\nResults:\nqPCR Report (PDF)\nqPCR Data File (CFX96)"
  },
  {
    "objectID": "posts/2012/2012-01-13-rna-isolation-c-gigas-larvae-from-20110412-20110705/index.html",
    "href": "posts/2012/2012-01-13-rna-isolation-c-gigas-larvae-from-20110412-20110705/index.html",
    "title": "RNA Isolation - C.gigas Larvae from 20110412 & 20110705",
    "section": "",
    "text": "RNA was isolated from C.gigas larvae collected from Taylor Shellfish hatchery on the dates noted above. Samples were in RNA Later. RNA Later was removed. Attempted homogenization with a pestle proved futile, as a significant quantity of larvae were sticking to the pestle and were nearly impossible to wash off using TriReagent as a rinsing agent. Due to this, all samples were vortexed for 1min in 1mL of TriReagent. It should be noted that the TriReagent took on a cloudy appearance and even showed some separation into two layers upon letting the samples sit. This was not normal and I was immediately concerned about the high salt content from residual RNA Later. Samples were treated normally with the following changes:\n\nAqueous phase after chloroform treatment was clear, but grey in color. This is not necessarily unusual.\nAddition of isopropanol triggered immediate precipitation of a dark grey material.\n“Pelleting” of the RNA after the isopropanol precipitation resulted in a gooey grey material that did NOT pellet, and a clear supernatant. The grey goo was transferred to a clean tube. An additional 500uL of isopropanol was added to the clear supernatant of two samples (#140 & #142), as well as to the grey goo. The addition of isopropanol to the clear supe resulted in an immediate precipitation of white salt-like material. The isopropanol appeared to have no effect on the grey goo. All samples were stored @-20C in their existing conditions until 20120116.\nSince the two samples that were treated with an additional 500uL of isopropanol produced an excess of salt precipitation, I instead added 1mL of 70% EtOH to all the remaining samples; both the clear supernatants and the grey goo. The idea being that the higher water content in the 70% EtOH would help to keep the salts in solution, while precipitating the RNA. Samples were pelleted. All of the grey goo samples produced a white pellet. The grey goo seemed unchanged. Supernatants (including grey goos) were discarded and the resulting pellets from all samples were washed in this fashion were washed three more times.\nPellets were resuspended in 25uL of 0.1% DEPC-H2O and stored @ -80C until 20120123.\nSamples were spec’d on the Roberts’ Lab NanoDrop 1000.\n\nResults:\nSpreadsheet of OD readings is here.\nSince samples were split into two (clear supernatant and grey goo), they were kept separate through the remainder of the process. Sample names are appended with “-1” or “-2”. “-1” samples are grey goo samples and the “-2” samples are the clear supernatant samples.\nOverall, most of the grey goo samples appear to have produced the highest yields and highest quality of RNA, although this is not true for all of the samples."
  },
  {
    "objectID": "posts/2012/2012-11-28-qpcr-halley-cdna-check/index.html",
    "href": "posts/2012/2012-11-28-qpcr-halley-cdna-check/index.html",
    "title": "qPCR - Halley cDNA Check",
    "section": "",
    "text": "Ran qPCR on Halley’s cDNA to see if I could get them to work. She has been getting high levels of fluorescence at the initiation of the qPCR cycling that shouldn’t be there. Master mix calcs and plate layout can be seen here. http://eagle.fish.washington.edu/Arabidopsis/Notebook%20Workup%20Files/20121128%20qPCR%20Layout.jpg\nCycling params can be found in the qPCR Data File (see Results).\nResults:\nqPCR Data File (Opticon2)\nhttps://eagle.fish.washington.edu/Arabidopsis/qPCR/Opticon/Sam_20121128_111905.tad\n\nHigh levels of initial fluorescence are present in both sets of cDNA samples, while the NTC sample does not exhibit this behavior, suggesting the template is to blame. Have suggested to Halley to make new cDNA using the correct recipe, instead of the FISH441 recipe she had been using."
  },
  {
    "objectID": "posts/2012/2012-03-09-qpcr-daves-manila-calm-venerupis-philippinarum-dnased-rna-from-yesterday-and-20120302/index.html",
    "href": "posts/2012/2012-03-09-qpcr-daves-manila-calm-venerupis-philippinarum-dnased-rna-from-yesterday-and-20120302/index.html",
    "title": "qPCR - Dave’s Manila Calm (Venerupis philippinarum) DNased RNA from yesterday and 20120302",
    "section": "",
    "text": "Performed qPCR on all DNased RNA samples from this group (samples #1-48) using beta actin primers (SR IDs: 1379, 1380). 0.5uL of each DNased RNA was used, which was the equivalent of ~40ng, in order to simulate the amount of RNA present in the subsequent cDNA (1000ng of RNA in 25uL cDNA; use 1uL of cDNA in qPCR reaction). Master mix calcs are here. Plate layout, cycling params, etc., can be found in the qPCR Report (see Results). 0.5uL of total RNA from sample Vp gill 01 was used to serve as a positive control, since Dave has no existing V. phillippinarum cDNA.\nResults:\nqPCR Data File (CFX96)\nqPCR Report (PDF)\nAll samples are clean and are ready for reverse transcription.\nOf note, the overall fluorescence of the reactions was very low. As such, the default baseline analysis setting (linear) suggested that all samples had a Cq value because the baseline was incorrectly set an was NOT above background fluorescence levels. Changing the baseline analysis setting to “regression” resolved this. Also, it should be noted that one sample (#48) other than the positive control actually does show amplification and a corresponding melt curve. However, the melt curve peak is at a different temp than the positive control, suggesting that this is non-specific amplification in sample #48."
  },
  {
    "objectID": "posts/2012/2012-07-09-sample-submission-qpx-rna-and-dna-for-illumina-36bp-single-end-rnadnaseq/index.html",
    "href": "posts/2012/2012-07-09-sample-submission-qpx-rna-and-dna-for-illumina-36bp-single-end-rnadnaseq/index.html",
    "title": "Sample Submission - QPX RNA and DNA for Illumina 36bp single-end RNA/DNAseq",
    "section": "",
    "text": "Submitted samples to HTGU for Illumina sequencing."
  },
  {
    "objectID": "posts/2012/2012-02-09-reverse-transcription-c-gigas-larvae-dnased-rna-from-20120125/index.html",
    "href": "posts/2012/2012-02-09-reverse-transcription-c-gigas-larvae-dnased-rna-from-20120125/index.html",
    "title": "Reverse Transcription - C.gigas larvae DNased RNA (from 20120125)",
    "section": "",
    "text": "Performed reverse transcription on Dnased RNA from 20120125 using 175ng RNA from each sample. Also used random primers (instead of the usual Oligo dT primers) since these samples will also be used to analyze gene expression in Vibrio tubiashii. cDNA calcs are here."
  },
  {
    "objectID": "posts/2012/2012-10-16-received-oysters-from-taylor-shellfish/index.html",
    "href": "posts/2012/2012-10-16-received-oysters-from-taylor-shellfish/index.html",
    "title": "Received oysters from Taylor Shellfish.",
    "section": "",
    "text": "Photos of oysters are here:\n[gallery ids=“217,218,219,220,221,222,223,224”]\nBag labels and oyster quantities are below:\nHood Canal Dabob (Long Spit) 2012 Broodstock O. lurida PSRF - 42 oysters\nDabob Progeny (Long Spit) outplanted in Port Gamble Bay 8-20-2012 - ~97 oysters\nO. lurida 2012 Seed Fidalgo Bay PSRF - Too small to count; settled on old oyster shells\nO. lurida 2012 Broodstock Fidalgo Bay PSRF - 104 oysters\nAll oysters were put in our recirculating system in MAR 189 and held at 11C."
  },
  {
    "objectID": "posts/2012/2012-07-23-minipreps-emmas-illumina-library-cloning/index.html",
    "href": "posts/2012/2012-07-23-minipreps-emmas-illumina-library-cloning/index.html",
    "title": "Minipreps - Emma’s Illumina Library Cloning",
    "section": "",
    "text": "Performed plasmid isolation on 17 bacterial cultures Emma inoculated yesterday using the QIAprep Spin Mini Kit (Qiagen) using ~1.4mL of culture according to the manufacturer’s protocol. Plasmid DNA was eluted with 50uL of Buffer EB. Tubes were stored @ 4C in the refrigerator in FTR 213."
  },
  {
    "objectID": "posts/2012/2012-01-26-qpcr-dnased-rna-from-earlier-today/index.html",
    "href": "posts/2012/2012-01-26-qpcr-dnased-rna-from-earlier-today/index.html",
    "title": "qPCR - DNased RNA from earlier today",
    "section": "",
    "text": "Checked DNased RNA samples from earlier today for the presence of residual gDNA. Used C.gigas BB16 gDNA (from 20110201) diluted to ~7ng/uL as a positive control to match the dilution factor of the RNA that will be used in the reverse transcription reaction (175ng in 25uL = 7ng/uL). All samples were run in duplicate. Master mix calcs are here. Plate layout, cycling params, etc can be found in the qPCR Report (see Results).\nResults:\nqPCR Data (CFX96)\nqPCR Report (PDF)\nPositive control (in Green in qPCR Report) worked perfectly and showed excellent repeatability. The remainder of the samples (in Blue in qPCR Report) and the NTCs (in Red in qPCR Report) were extremely inconsistent with many having one replicate show late amplification, while the other replicate showed no amplification at all. Will have to repeat to get a more definitive assessment of residual gDNA content in these samples."
  },
  {
    "objectID": "posts/2012/2012-11-09-qpcr-manila-clam-larvae-cdna-from-august-2012-daves-notebook-3/index.html",
    "href": "posts/2012/2012-11-09-qpcr-manila-clam-larvae-cdna-from-august-2012-daves-notebook-3/index.html",
    "title": "qPCR - Manila Clam Larvae cDNA (from August 2012 - Dave’s Notebook)",
    "section": "",
    "text": "Ran qPCR on manila clam larvae cDNA that Dave made on 8/7/2012, using the sample sets from 7/29/2011 and 8/5/2011 of the OA manila clam experiment he ran.\nPrimers used:\nRp_Cathepsin_F/R2 (SR IDs: 1461, 1473)\nRp_EF1a_F/R2 (SR IDs: 1463, 1474)\nPrimers were verified to be in good working order by Dave on 4/1/2012 (see Dave’s notebook).\nMaster mix calcs are here. Cycling params can be found in the qPCR Data File (see Results). Plate layout and PCR Miner analysis can be found in the qPCR Raw Data file (see Results). All samples run in duplicate.\nResults:\nqPCR Data File(Opticon 2) http://eagle.fish.washington.edu/Arabidopsis/qPCR/Opticon/Sam_20121108_172259.tad\nqPCR Raw Dat and PCR Miner Analysis(Excel) http://eagle.fish.washington.edu/Arabidopsis/qPCR/Opticon/Sam_20121108_172259.xlsx\nReps look pretty good, although the 4C2 8.5.11 sample has consistently bad reps across all of today’s runs. Data will be shared with Steven for comparison to Dave’s Illumina data.\nAll data was normalized to EF1a expression from this run."
  },
  {
    "objectID": "posts/2012/2012-04-30-reverse-transcription-dnased-c-gigas-larval-rna-from-20120427/index.html",
    "href": "posts/2012/2012-04-30-reverse-transcription-dnased-c-gigas-larval-rna-from-20120427/index.html",
    "title": "Reverse Transcription - DNased C.gigas Larval RNA from 20120427",
    "section": "",
    "text": "Performed reverse transcription using random primers (Promega) diluted 1:100 (5ng/uL) with 175ng of DNased total RNA. Random primers were used because we will be targeting V.tubiashii RNA instead of eukaryotic RNA. Reverse transcription was performed with M-MLV Reverse Transcriptase (Promega) according to the manufacturer’s protocol. Calcs are here.\nCreated dilutions of all samples to 100ng/uL in a volume of 50uL in preparation for qPCR analysis. Calcs are here."
  },
  {
    "objectID": "posts/2012/2012-11-21-reverse-transcription-fish441-rna/index.html",
    "href": "posts/2012/2012-11-21-reverse-transcription-fish441-rna/index.html",
    "title": "Reverse Transcription - FISH441 RNA",
    "section": "",
    "text": "Reverse transcribed the class FISH441 RNA to cDNA. Followed protocol provided on the FISH441 Wiki page, NOT the usual Roberts Lab protocol, with some modifications.\nChanged total reaction volume to 50uL to accommodate volume of RNA, as well as low concentration of dNTPs that were to be used.\nRNA - 17.75uL\nOligo dT - 1.0uL\nSamples were heated at 70C for 5mins and placed immediately on ice.\nReaction buffer master mix calcs:\n5x MMLV Buffer - 10uL/rxn X 88 = 880uL\n2.5mM dNTPs - 10uL/rxn X 88 = 880uL\nM-MLV - 1uL/rxn X 88 = 88uL\nH2O - 9.25uL x 88 = 902uL\nAdded 31.25uL of the reaction buffer master mix to each well of RNA/Oligo dT. Reaction was run at 42C for 1hr, followed by 70C for 3mins. Samples were stored @ -20C in Rm. 209."
  },
  {
    "objectID": "posts/2012/2012-01-26-dnase-c-gigas-rna-from-20120124/index.html",
    "href": "posts/2012/2012-01-26-dnase-c-gigas-rna-from-20120124/index.html",
    "title": "DNAse - C.gigas RNA from 20120124",
    "section": "",
    "text": "5ug of each RNA was DNased using Ambion’s Turbo DNA-free Kit, according to the rigorous protocol and spec’d on Roberts Lab NanoDrop 1000. RNA volume calcs are here.\nResults:\n\nDNased RNA looks fine. Low OD260/280 ratios, but this is often seen after DNase treatment and particularly with low [RNA]. Will perform qPCR to assess gDNA removal."
  },
  {
    "objectID": "posts/2012/2012-01-25-rna-isolation-c-gigas-larvae-from-20110412-20110705-continued-from-20120112/index.html",
    "href": "posts/2012/2012-01-25-rna-isolation-c-gigas-larvae-from-20110412-20110705-continued-from-20120112/index.html",
    "title": "RNA Isolation - C.gigas Larvae from 20110412 & 20110705 (Continued from 20120112)",
    "section": "",
    "text": "All of the RNA samples were re-combined with their respective counterparts and subject to a standard EtOH precipitation (0.1 volumes of 3M NaOAc, pH = 5.2, 2.5 volumes 100% EtOH; incubated -80C 1hr; pelleted; washed with 1mL 70% EtOH; pelleted). Pellets were washed two additional times (for a total of three washes) with 70% EtOH. RNA was resuspended in 50uL of 0.1% DEPC-H2O and spec’d on the Roberts Lab NanoDrop 1000.\nResults:\n\nYields for the 4/12/2011 samples were all lower than the yields for the 7/5/2011 samples. However, the RNA quality (based on OD260/280 ratios) looks pretty good for both groups of RNA. RNA will be treated with DNase before reverse transcription."
  },
  {
    "objectID": "posts/2012/2012-03-23-dna-extraction-taylor-water-filter-samples-from-2011/index.html",
    "href": "posts/2012/2012-03-23-dna-extraction-taylor-water-filter-samples-from-2011/index.html",
    "title": "DNA Extraction - Taylor Water Filter Samples from 2011",
    "section": "",
    "text": "Extracted DNA from the following water filter samples using the Qiagen DNeasy Blood & Tissue Kit:\n\n158\n200\n279\n313\n341\n410\n433\n503\n551\n604\n\nFilters were cut into ~13 pieces and placed in 1.5mL snap cap tubes containing 50uL of Proteinase K and 400uL of Buffer AL. Samples were incubated O/N @ 56C. Tubes were spun @ 16,000g @ RT for 2mins. 400uL of 100% EtOH was added to each tube and vortexed. Tubes were spun @ 16,000g @ RT for 2mins. Supe was transferred to Qiagen column. Qiagen protocol was followed from this point on. Samples were eluted with 100uL of Buffer AE and stored @ 4C."
  },
  {
    "objectID": "posts/2012/2012-03-24-qpcr-taylor-water-filter-dna-extracts-from-yesterday/index.html",
    "href": "posts/2012/2012-03-24-qpcr-taylor-water-filter-dna-extracts-from-yesterday/index.html",
    "title": "qPCR - Taylor Water Filter DNA Extracts from Yesterday",
    "section": "",
    "text": "Ran qPCR on the Taylor water filter DNA extracts from yesterday using V.tubiashii 16s primers (SR IDs: 455, 456). Used RE22 DNA as a positive control, provided by Elene. Master mix calcs are here. All samples were run in duplicate. Plate layout, cycling params, etc can be found in the qPCR Report (see Results).\nResults:\nqPCR Data File (CFX96)\nqPCR Report (PDF)\nAll samples amplified, including the negative controls. Negative controls exhibited very weak, late amplification. Additionally, many of the samples have a “shoulder” or apparent double-peak present in the melt curves. Will repeat to see if I can eliminate amplification in negative control samples."
  },
  {
    "objectID": "posts/2012/2012-02-09-qpcr-cdna-from-earlier-today/index.html",
    "href": "posts/2012/2012-02-09-qpcr-cdna-from-earlier-today/index.html",
    "title": "qPCR - cDNA from earlier today",
    "section": "",
    "text": "Performed qPCR on all 12 samples. Used Cg_EF1aF/R2 (SR IDs: 1410 & 1412) for one set of qPCRs and Vtub_16s_F/R (SR IDs: 455 & 456) for the other set of qPCRs. Used pooled C.gigas cDNA (from 20110311) and RE22 DNA (provided by Elene) as positive controls for C.gigas and V.tubiashii, respectively. C.gigas gDNA (7ng of BB16 from 20110201) was used as a negative control for EF1a. Master mix calcs are here. Plate layout, cycling params, etc can be found in the qPCR Report (see Results). All samples were run in duplicate.\nResults:\nqPCR Data File (CFX96)\nqPCR Report (PDF)\nC.gigas EF1a - Positive control amplified. Negative control and no template control were all clean (i.e. no amplification detected). The majority of samples had amplification, however two samples had no amplification at all (samples 132 & 136).\nV.tubiashii 16s - Positive control amplified. No template controls exhibited amplification in both replicates. All samples exhibited amplifcation, however nearly all of the melt curves have multiple peaks present, suggesting that more than one target is being amplified. I suspect this is due to residual gDNA, but this fails to explain the amplification in the no template controls which also exhibited dual peaks in the melt curves.\nSpoke with Steven and he suggested to skip troubleshooting the V. tubiashii 16s for now and proceed with trying to qPCR some additional V.tubiashii genes. Will talk with Elene to see if/which additional genes she has primers for."
  },
  {
    "objectID": "posts/2012/2012-03-02-rna-isolation-daves-manila-clam-venerupis-philippinarum-gill-samples-1-24/index.html",
    "href": "posts/2012/2012-03-02-rna-isolation-daves-manila-clam-venerupis-philippinarum-gill-samples-1-24/index.html",
    "title": "RNA Isolation - Dave’s Manila Clam (Venerupis philippinarum) Gill Samples (#1-24)",
    "section": "",
    "text": "Isolated RNA from Manila Clam gill samples provided by Dave according to protocol. Samples were resuspended in 0.1%-DEPC H2O and spec’d on the Roberts Lab NanoDrop1000. Samples were stored @ -80C in Dave’s box that the tissue was initially stored in.\nResults:\n\nOverall, RNA quality is very good, as well as yields."
  },
  {
    "objectID": "posts/2012/2012-04-27-rna-isolation-c-gigas-larvae-from-taylor-summer-2011/index.html",
    "href": "posts/2012/2012-04-27-rna-isolation-c-gigas-larvae-from-taylor-summer-2011/index.html",
    "title": "RNA Isolation - C.gigas Larvae from Taylor Summer 2011",
    "section": "",
    "text": "Samples had been stored in RNA Later (Ambion). Samples were pelleted and the RNA Later supe removed. Samples were washed (2x) with 1mL TE (pH = 8.0) to remove excess salt resulting from the RNA Later. Samples were split, roughly equally, into two separate tubes. Samples were pelleted and the supe removed. One tube from each sample was set aside for gDNA isolation using DNAzol (MRC). The other tube was vortexed vigorously in TriReagent (MRC) and the then treated according to protocol. Samples were resuspended in 100uL of 0.1% DEPC-H2O and spec’d on the Roberts Lab NanoDrop 1000.\nResults:\n\nOverall, the samples look really good. Some samples (280, 434 & 605) required re-specing after the NanoDrop was reblanked in order to get a reading without an error message. They will be DNased and then reverse transcribed."
  },
  {
    "objectID": "posts/2012/2012-07-11-illumina-rnaseq-library-construction-32-c-gigas-individuals/index.html",
    "href": "posts/2012/2012-07-11-illumina-rnaseq-library-construction-32-c-gigas-individuals/index.html",
    "title": "Illumina RNAseq Library Construction - 32 C.gigas Individuals",
    "section": "",
    "text": "Took heat-fragmented RNA provided by Emma (see Emma’s Notebook, 7/3/2011) and proceeded to make first strand cDNA, as described in the Eli Meyer protocol for Illumina HiSeq. Master mix calcs are here. Samples were stored @ -20C after the reverse transcription and library construction will be continued tomorrow."
  },
  {
    "objectID": "posts/2012/2012-07-11-oligo-reconstitution-illumina-rnaseq-library-oligos-and-barcodes/index.html",
    "href": "posts/2012/2012-07-11-oligo-reconstitution-illumina-rnaseq-library-oligos-and-barcodes/index.html",
    "title": "Oligo Reconstitution - Illumina RNAseq Library Oligos and Barcodes",
    "section": "",
    "text": "Reconstituted all of the oligos and barcodes for library construction in TE (pH = 8.0) to a final concentration of 100uM. Created 10uM working stocks of all oligos and barcodes. All samples (stocks and working stocks) are stored @ -80C in their own box (Illumina Library Oligos & Barcodes) due to the fact that one of the oligos is an RNA oligo and requires storage at -80C."
  },
  {
    "objectID": "posts/2012/2012-05-01-qpcr-detection-of-v-tubiashii-presence-and-expression-using-vtpa-primers-in-dnacdna-from-yesterday/index.html",
    "href": "posts/2012/2012-05-01-qpcr-detection-of-v-tubiashii-presence-and-expression-using-vtpa-primers-in-dnacdna-from-yesterday/index.html",
    "title": "qPCR - Detection of V.tubiashii Presence and Expression Using VtpA Primers in DNA/cDNA from yesterday",
    "section": "",
    "text": "Ran qPCR with VtpA primers on cDNA and DNA (from yesterday) of C.gigas larvae to see levels of V.tubiashii compared to their water filter samples (see 20120326). Master mix calcs are here. Plate layout, cycling params, etc can be seen in the qPCR Report (see Results). Used 1uL of cDNA and 100ng (1uL) of DNA as template.\nAll samples were run in duplicate.\nResults:\nqPCR Data File (CFX96) qPCR Report (PDF)\nNo detectable levels of expression (or, no expression at all) in any of the cDNA samples.\nBelow I’ve put together a very rough comparison of larvae levels, based off of the the standard curve. I have NOT done the full back calculations!! This is data straight out of the qPCR machine, using the standard curve. Due to the large range, I’ve graphed the data on a logarithmic scale so all the data is visible on the graph."
  },
  {
    "objectID": "posts/2012/2012-03-03-dnase-daves-manila-clam-venerupis-philippinarum-gill-rna-from-yesterday/index.html",
    "href": "posts/2012/2012-03-03-dnase-daves-manila-clam-venerupis-philippinarum-gill-rna-from-yesterday/index.html",
    "title": "DNase - Dave’s Manila Clam (Venerupis philippinarum) Gill RNA from Yesterday",
    "section": "",
    "text": "DNased RNA using Ambion’s Turbo DNA-free Kit following the “routine” protocol. 5ug of total RNA from each sample was treated in 50uL reactions. Samples will be spec’d on Monday with the Roberts Lab NanoDrop 1000."
  },
  {
    "objectID": "posts/2012/2012-10-10-qpcr-opticon-test/index.html",
    "href": "posts/2012/2012-10-10-qpcr-opticon-test/index.html",
    "title": "qPCR - Opticon Test",
    "section": "",
    "text": "Ran qPCR to test uniformity of Opticon 2, after it was serviced on 20120926.\nResults:\nqPCR Data File (Opticon 2): Sam_20121010_115249.tad"
  },
  {
    "objectID": "posts/2012/2012-03-08-rna-isolation-daves-manila-clam-venerupis-philippinarum-gill-samples-25-48/index.html",
    "href": "posts/2012/2012-03-08-rna-isolation-daves-manila-clam-venerupis-philippinarum-gill-samples-25-48/index.html",
    "title": "RNA Isolation - Dave’s Manila Clam (Venerupis philippinarum) Gill Samples (#25-48)",
    "section": "",
    "text": "Isolated RNA from Manila Clam gill samples provided by Dave, according to protocol. Samples were resuspended in 0.1%-DEPC H2O and spec’d on the Roberts Lab NanoDrop1000. Samples were stored @ -80C in Dave’s box that the tissue was initially stored in.\nResults:\n\nAll samples look great with excellent yields and great 260/280 values. Will proceed with DNasing. (Note: Sample #42 appears twice because the first reading had an air bubble and, as such, should be discarded.)\nDNased RNA using Ambion’s Turbo DNA-free Kit following the “routine” protocol. 5ug of total RNA from each sample was treated in 50uL reactions. Samples will be spec’d on Monday with the Roberts Lab NanoDrop 1000.\nResults:"
  },
  {
    "objectID": "posts/2012/2012-07-06-qpx-sample-pooling-for-illumina-sequencing/index.html",
    "href": "posts/2012/2012-07-06-qpx-sample-pooling-for-illumina-sequencing/index.html",
    "title": "QPX Sample Pooling for Illumina Sequencing",
    "section": "",
    "text": "Pooling volumes/quantities for QPX RNA/DNA-seq: 20120705 Oly larvae and QPX HiSeq Calcs"
  },
  {
    "objectID": "posts/2012/2012-07-10-chloroform-clean-up-lexies-qpx-rna-from-20110504/index.html",
    "href": "posts/2012/2012-07-10-chloroform-clean-up-lexies-qpx-rna-from-20110504/index.html",
    "title": "Chloroform Clean Up - Lexie’s QPX RNA from 20110504",
    "section": "",
    "text": "After submission of QPX samples to HTGU for Illumina library prep yesterday, I was notified that there was insufficient RNA for the QPX RNA samples. I checked the source RNA on the Roberts Lab NanoDrop1000 and determined that they had high phenol contamination (large peak at 270nm), which results in a large exaggeration in the OD260 absorbance (NanoDrop1000 report[JPEG]; notice terrible OD260/280 ratios; did not save screen shot of absorbance peaks.). As such, the concentrations that Lexie had listed in her notebook for these samples are highly inaccurate and highly inflated. To remove the phenol, I brought all of her QPX RNA samples from 20110504 up to ~200uL with 0.1%DEPC-H2O, added 200uL of chloroform, vortexed for 30s, spun at 12,500g RT for 15mins, and transferred aqueous phase to new tube. Then performed an ethanol precipitation on the aqueous phase. Added 0.1 vols of 3.0M sodium acetate (pH = 5.2), 2.5 vols of 100% EtOH, mixed and incubated at -20C for 1hr. Pelleted RNA by spinning at 16,000g 4C for 15mins.\nResults:\n\nAs suspected, most of these samples have absolutely no RNA in them. However, the samples that do (the “Control” samples), look great! Pooled 2ug each of the RT Control a & b samples and pooled 2ug each of the 10C Control a & b samples (which are ATCC). Calculations are here. Will take them down to HTGU tomorrow to replace the bad samples that were provided yesterday."
  },
  {
    "objectID": "posts/2012/2012-11-09-qpcr-manila-clam-larvae-cdna-from-august-2012-daves-notebook-2/index.html",
    "href": "posts/2012/2012-11-09-qpcr-manila-clam-larvae-cdna-from-august-2012-daves-notebook-2/index.html",
    "title": "qPCR - Manila Clam Larvae cDNA (from August 2012 - Dave’s Notebook)",
    "section": "",
    "text": "Ran qPCR on manila clam larvae cDNA that Dave made on 8/7/2012, using the sample sets from 7/29/2011 and 8/5/2011 of the OA manila clam experiment he ran.\nPrimers used:\nRp_Calmodulin_F/R2 (SR IDs: 1449, 1467)\nRp_Crumbs_F/R (SR IDs: 1477, 1476)\nPrimers were verified to be in good working order by Dave on 4/1/2012 (see Dave’s notebook).\nMaster mix calcs are here. Cycling params can be found in the qPCR Data File (see Results). Plate layout and PCR Miner analysis can be found in the qPCR Raw Data file (see Results). All samples run in duplicate.\nResults:\nqPCR Data File(Opticon 2) http://eagle.fish.washington.edu/Arabidopsis/qPCR/Opticon/Sam_20121108_161738.tad\nqPCR Raw Data and PCR Miner Analysis (Excel) http://eagle.fish.washington.edu/Arabidopsis/qPCR/Opticon/Sam_20121108_161738.xlsx\nReps look pretty good, although the 4C2 8.5.11 sample has consistently bad reps across all of today’s runs. Data will be shared with Steven for comparison to Dave’s Illumina data. All data was normalized to EF1a expression from later today."
  },
  {
    "objectID": "posts/2012/2012-03-13-reverse-transcription-daves-manila-clam-venerupis-philippinarum-dnased-rna-from-20120307-and-20120302/index.html",
    "href": "posts/2012/2012-03-13-reverse-transcription-daves-manila-clam-venerupis-philippinarum-dnased-rna-from-20120307-and-20120302/index.html",
    "title": "Reverse Transcription - Dave’s Manila Clam (Venerupis philippinarum) DNased RNA from 20120307 and 20120302",
    "section": "",
    "text": "Performed reverse transcription on 1.5ug of DNased RNA in a 75uL reaction, using oligo dT primers. All reagents were scaled appropriately (based on Promega’s M-MLV RT protocol). Samples were prepared in a plate and stored @ -20C. Plate layout and all reverse transcription calcs are here:"
  },
  {
    "objectID": "posts/2012/2012-11-08-qpcr-manila-clam-larvae-cdna-from-august-2012-daves-notebook/index.html",
    "href": "posts/2012/2012-11-08-qpcr-manila-clam-larvae-cdna-from-august-2012-daves-notebook/index.html",
    "title": "qPCR - Manila Clam Larvae cDNA (from August 2012 - Dave’s Notebook)",
    "section": "",
    "text": "Ran qPCR on manila clam larvae cDNA that Dave made on 8/7/2012, using the sample sets from 7/29/2011 and 8/5/2011 of the OA manila clam experiment he ran.\nPrimers used:\nRp_GPX3_F/R2 (SR IDs: 1453, 1469)\nRp_HSP90_F2/R2 (SR Ids: 1457, 1471)\nPrimers were verified to be in good working order by Dave on 4/1/2012 (see Dave’s notebook).\nMaster mix calcs are here. Cycling params can be found in the qPCR Data File (see Results). Plate layout and PCR Miner analysis can be found in the qPCR Raw Data file (see Results). All samples run in duplicate.\nResults:\nqPCR Data File(Opticon 2) http://eagle.fish.washington.edu/Arabidopsis/qPCR/Opticon/Sam_20121108_150936.tad\nqPCR Raw Data and PCR Miner Analysis(Excel) http://eagle.fish.washington.edu/Arabidopsis/qPCR/Opticon/Sam_20121108_150936.xlsx\nReps look pretty good, although the 4C2 8.5.11 sample has consistently bad reps across all of today’s runs. Data will be shared with Steven for comparison to Dave’s Illumina data.\nAll data was normalized to EF1a expression from later today."
  },
  {
    "objectID": "posts/2012/2012-04-28-dnase-treatment-c-gigas-larvae-rna-from-yesterday/index.html",
    "href": "posts/2012/2012-04-28-dnase-treatment-c-gigas-larvae-rna-from-yesterday/index.html",
    "title": "DNase Treatment - C.gigas Larvae RNA from yesterday",
    "section": "",
    "text": "Treated 5ug of total RNA (in a 50uL rxn) using Turbo DNA-free (Ambion) according to the “Standard” protocol. Samples were spec’d on the Roberts Lab NanoDrop 1000.\nResults:\n\nAll samples look good, both quality and quantity-wise. Will check for residual gDNA in these samples via qPCR."
  },
  {
    "objectID": "posts/2012/2012-10-26-qpcr-dnased-manila-clam-larvae-rna-from-august-2012-daves-notebook/index.html",
    "href": "posts/2012/2012-10-26-qpcr-dnased-manila-clam-larvae-rna-from-august-2012-daves-notebook/index.html",
    "title": "qPCR - DNased Manila Clam Larvae RNA (from August 2012 - Dave’s Notebook)",
    "section": "",
    "text": "Performed qPCR on Dave’s manila clam larvae DNased RNA from August 2012 using EF1a primers (SR IDs: 1463, 1474).\nMaster mix calcs are here. https://docs.google.com/spreadsheet/ccc?key=0AmS_90rPaQMzdHc5amwzZzdDa1d0VXQzLVU0WkFTc0E\nPlate layout, cycling params, etc can be found in the qPCR Report (see Results).\nPositive control was pooled cDNA taken from Dave’s cDNA plate on 8/7/2012.\nResults:\nqPCR Data File(CFX96) http://eagle.fish.washington.edu/Arabidopsis/qPCR/CFX96/Roberts%20Lab_2012-10-26%2010-48-07_CC009827.pcrd\nqPCR Report(PDF) http://eagle.fish.washington.edu/Arabidopsis/qPCR/CFX96/Roberts%20Lab_2012-10-26%2010-48-07_CC009827.pdf\nHere’s a quick Google Spreadsheet summary highlighting samples that came up positive/negative.\nhttps://docs.google.com/spreadsheet/ccc?key=0AmS_90rPaQMzdFFHb3YwWE01UG00TnY3OWo2cWx2UVE\nApproximately half of the samples (~27) came up positive for still having gDNA in them.\nThere are three pCO2 treatments: 1000ppm, 750ppm, and 400ppm. There are six sampling dates: 7/29/2011, 8/2/2011, 8/9/2011, 8/12/2011. Currently, it is unknown when the Day 0 samples were collected. Have emailed Dave for deets.\nThere are only two dates (7/29/2011 and 8/5/2011) that have a full set of samples (i.e. 1000ppm, 750ppm and 400ppm) that exhibit DNA-free RNA. Will discuss with Steven on how to proceed.\nUPDATE 20121031 - Dave emailed and indicated the experimented started on 7/27/2011. Additionally, the two sample sets that are complete are Day 2 and Day 7. Discussing with Steven, we have decided to run a few genes and see how the expression levels compare to the NGS data analysis for these samples. If the qPCR data supports the NGS data, then that information will be relayed to the BMC Genomics reviewers in response to their critiques. A copy of the manuscript is here(may not be publicly viewable). https://docs.google.com/document/d/1Ii1lODz2oThiyxZtHBblUEdzyhIVq92n8jkEjhkuuts/edit"
  },
  {
    "objectID": "posts/2012/2012-02-10-qpcr-cdna-from-20120208/index.html",
    "href": "posts/2012/2012-02-10-qpcr-cdna-from-20120208/index.html",
    "title": "qPCR - cDNA from 20120208",
    "section": "",
    "text": "Performed qPCR on all 12 samples. Used the following primers, provided by Elene, to detect V.tubiashii expression:\n\nrseA_F/R\nVtpA_F/R\nVtpR_F/R\n\nUsed RE22 DNA (provided by Elene) as a positive control. Master mix calcs are the same as yesterday’s qPCR, but using the primers mentioned above. Plate layout, cycling params, etc. can be found in the qPCR Report (see Results). All samples were run in duplicate.\nResults:\nqPCR Data File (CFX96)\nqPCR Report (PDF)\nPositive control worked in all primer sets. All no template controls were clean for all primer sets.\nOnly one sample (#411) produced any amplification. Amplification was detected in the vtpA primer set (mean Cq = 38.06). However, there was also amplification detected in one of the two replicates for sample #411 in the rseA primer set (Cq = 39.09)."
  },
  {
    "objectID": "posts/2012/2012-03-24-qpcr-repeat-of-qpcr-from-earlier-today/index.html",
    "href": "posts/2012/2012-03-24-qpcr-repeat-of-qpcr-from-earlier-today/index.html",
    "title": "qPCR - Repeat of qPCR from Earlier Today",
    "section": "",
    "text": "Repeated exactly what was done earlier today due to apparent contamination in negative controls.\nResults:\nqPCR Date File (CFX96)\nqPCR Report (PDF)\n\n\nEssentially the same results as the previous run. No template controls do amplify, but EXTREMELY weak and late. Melt curve analysis shows that the signals for the no template controls don’t cross the threshold set by the software.\nHowever, I just looked back at the qPCR results from 20120208 where I used these V. tubiashii 16s primers and realized I got the same results from the cDNA (double-peaks in melt curves and amplification in the no template controls)!! So, I suspect that this primer set isn’t that useful. Will have to examine other sets of V. tubiashii 16s primers to use. Will discuss with Steven."
  },
  {
    "objectID": "posts/2012/2012-04-27-gdna-isolation-c-gigas-larvae-from-taylor-summer-2011/index.html",
    "href": "posts/2012/2012-04-27-gdna-isolation-c-gigas-larvae-from-taylor-summer-2011/index.html",
    "title": "gDNA Isolation - C.gigas Larvae from Taylor Summer 2011",
    "section": "",
    "text": "Samples that had been split from earlier today (see the RNA Isolation below) were resuspended in 1mL of DNAzol (MRC). 100ug of Proteinase K (Fermentas) was added to each sample. Samples were incubated at RT, O/N on a rotator. On 20120427 samples were pelleted 10mins, 10,000g, and supe transferred to fresh tube. DNA was precipitated with 0.5mL of 100% EtOH, mixed gently and pelleted 5mins, 5000g. Supe was discarded, pellets were washed with 1mL 75% EtOH, re-pelleted at same speed as previous step, supe discarded and pellets were resuspended in NanoPure H2O. Samples were spec’d on the Roberts Lab NanoDrop1000.\nResults:\nReport on the NanoDrop software wouldn’t display, so I’ve entered the concentration of each sample in the table below.\n\n\n\n\n\nSampleID\n\n\nng/uL\n\n\n\n\n201\n\n\n1364\n\n\n\n\n280\n\n\n131.7\n\n\n\n\n314\n\n\n710.3\n\n\n\n\n342\n\n\n539.4\n\n\n\n\n434\n\n\n274.4\n\n\n\n\n552\n\n\n334.8\n\n\n\n\n605\n\n\n369.7"
  },
  {
    "objectID": "posts/2012/2012-03-27-qpcr-taylor-water-filter-dna-extracts-from-20120322/index.html",
    "href": "posts/2012/2012-03-27-qpcr-taylor-water-filter-dna-extracts-from-20120322/index.html",
    "title": "qPCR - Taylor Water Filter DNA Extracts from 20120322 - Sam White",
    "section": "",
    "text": "Ran qPCR on the Taylor water filter DNA extracts from 20120322 using V.tubiashii VtpA primers (provide by Elene; no SR ID?) instead of 16s primers, which failed to produce acceptable results in the melt curves (see 20120323). Additionally, Elene has a standard curve for V. tubiashii (from 1/12/2011) based off of CFUs/mL, which will allow us to quantify theoretical number of V.tubiashii CFUs present in each sample.\nMaster mix calcs are here. Plate layout, cycling params, etc. can be found in the qPCR Report (see Results).\nResults:\nqPCR Date File (CFX96)\nqPCR Report (PDF)\nOverall, the run looks excellent. Both negative controls and no template controls are clean. Since I was able to use a standard curve, I determined CFUs of V.tubiashii in each sample, as follows:\nMean CFUs per qPCR reaction / template volume per qPCR reaction x filter extraction elution volume (100uL) = total CFUs on water filter.\nTotal CFUs on filter / filtered water volume = CFUs per mL in Taylor tanks\n158 - 16500 copies/2uL = 8250 copies/uL x 100uL = 825000 copies on water filter/1000mL = 825 copies/mL\n200 - 5700 copies/2uL = 2850 copies/uL x 100uL = 285000 copies on water filter/1000mL = 285 copies/mL\n279 - 325000 copies/2uL = 162500 copies/uL x 100uL = 16250000 copies on water filter/1000mL = 16250 copies/mL\n313 - 152 copies/2uL = 76 copies/uL x 100uL = 7600 copies on water filter/1000mL = 7.6 copies/mL\n341 - 124000/2uL = 62000 copies/uL x 100uL = 6200000 copies on water filter/1000mL = 6200 copies/mL\n410 - 132000/2uL = 66000 copies/uL x 100uL = 6600000 copies on water filter/1000mL = 6600 copies/mL\n433 - 63700/2uL = 31850 copies/uL x 100uL = 3185000 copies on water filter/1000mL = 3185 copies/mL\n503 - 110/2uL = 55 copies/uL x 100uL = 5500 copies on water filter/1000mL = 5.5 copies/mL\n551 - 2000/2uL = 1000 copies/uL x 100uL = 100000 copies on water filter/1000mL = 100 copies/mL\n604 - 272/2uL = 136 copies/uL x 100uL = 13600 copies on water filter/1000mL = 13.6 copies/mL\nSample #410 was from the only tank that exhibited mortalities and was the only group of oyster larvae that showed any expression from the V.tubiashii genes (see DATE)."
  },
  {
    "objectID": "posts/2012/2012-04-28-qpcr-check-dnased-rna-from-earlier-today-for-residual-gdna/index.html",
    "href": "posts/2012/2012-04-28-qpcr-check-dnased-rna-from-earlier-today-for-residual-gdna/index.html",
    "title": "qPCR - Check DNased RNA from Earlier Today for Residual gDNA",
    "section": "",
    "text": "Ran qPCR using V.tubiashii VtpA primers (from Elene; no SR ID). Used 0.5uL of each DNased RNA sample, which equals ~40ng of RNA, which would be the equivalent amount of RNA that would end up in a qPCR rxn after cDNA has been made (using 1uL of cDNA). Used the filter DNA extraction from samples #279 from DATE as a positive control. Master mix calcs are here. Plate layout, cycling params, etc. can be found in the qPCR Report (see Results).\nResults:\nqPCR Data File (CFX96)\nqPCR Report (PDF)\nAll samples showed up negative, except for the positive control. Will proceed with making cDNA on Monday."
  },
  {
    "objectID": "posts/2013/2013-02-13-reverse-transcription-herring-rna-from-20091026/index.html",
    "href": "posts/2013/2013-02-13-reverse-transcription-herring-rna-from-20091026/index.html",
    "title": "Reverse Transcription - Herring RNA from 20091026",
    "section": "",
    "text": "Performed an RT reaction on pooled herring gonad and liver mRNA from 20091026 for James Raymond at the UNLV. A single RT reaction was performed using 12.75uL (208ng) of the pooled gonad mRNA and 5uL (132.5ng) of the pooled liver RNA, according to our default MMLV (Promega) protocol. After reaction was completed, sample was stored @ -20C and then shipped to James Raymond on 20130214."
  },
  {
    "objectID": "posts/2013/2013-04-08-pcr-hexokinase-and-partial-exon-1/index.html",
    "href": "posts/2013/2013-04-08-pcr-hexokinase-and-partial-exon-1/index.html",
    "title": "PCR - Hexokinase and Partial Exon #1",
    "section": "",
    "text": "Performed PCR using newly designed primers to amplify the C. gigas hexokinase “promoter” (-2059bp from start) along with a portion of the first exon.\nPrimers used were Cg_Hk_Prom_pBAD_-2059 (SRID: 1518) and Cg_HK_Exon1_R (SRID: 1520).\nTemplate used was C.gigas gDNA BB15 (from 20090519; 0.4216ug/uL). Master mix calcs are here. Cycling params are the same used on 20130227.\nSamples were run in duplicate.\nResults:\n\nLane 1: Hyperladder II (Bioline)\nLanes 2-3: C.gigas gDNA\nLanes 4-5: NTCs\nWe see a band of >2000bp (that’s the maximum on the molecular weight marker). The bands from each replicate were excised, purified using Ultrafree-DA columns (Millipore) and stored at 4C."
  },
  {
    "objectID": "posts/2013/2013-09-19-pcr-lake-trout-c1q-3/index.html",
    "href": "posts/2013/2013-09-19-pcr-lake-trout-c1q-3/index.html",
    "title": "PCR - Lake Trout C1q",
    "section": "",
    "text": "Ran PCR on lake trout DNA and lake trout bisulfite-converted DNA. Used primers SRIDs: 1551 and 1552. DNA was isolated by Caroline Storer on 4/4/2011 and bisulfite converted on 4/7/2011. Master mix and cycling params are here:\nhttps://eagle.fish.washington.edu/Arabidopsis/Notebook%20Workup%20Files/20130919-01.jpg\nSamples:\nLake Trout Lean_6 Liver\nLake Trout Lean_7 Liver\nLake Trout Siscowet_6 Liver\nLake Trout Siscowet_7 Liver\nBisulfite converted DNA from the four samples listed above.\nResults:\n\nLane 1: Hyperladder II (Bioline)\nLane 2: Lean6\nLane 3: Lean6 BS\nLane 4: Lean7\nLane 5: Lean7 BS\nLane 6: Siscowet6\nLane 7: Siscowet6 BS\nLane 8: Siscowet7\nLane 9: Siscowet7 BS\nAll the non-BS converted samples amplified as expected, producing a band of ~560bp. However, none of the BS-converted DNA produced any amplification. It is likely an issue with the primer sequences and the resulting conversion of the gDNA.\nWill look at Caroline Storer’s notebook entries for her work on this and try to evaluate what has already been done."
  },
  {
    "objectID": "posts/2013/2013-11-26-gylcogen-carboyhydrate-assays-emmas-c-gigas-whole-body-samples-continued-from-yesterday/index.html",
    "href": "posts/2013/2013-11-26-gylcogen-carboyhydrate-assays-emmas-c-gigas-whole-body-samples-continued-from-yesterday/index.html",
    "title": "Gylcogen & Carboyhydrate Assays - Emma’s C.gigas Whole Body Samples (continued from yesterday)",
    "section": "",
    "text": "Samples from yesterday were centrifuged 30mins, 4000g, 4C (fixed angle rotor).\nSupernatant was removed and pellets were dried (inverted tubes for 30mins).\nPellets were resuspended in 200uL H2O and stored @ -20C.\nData spreadsheet is here: 20131125 - Oyster Glycogen Assay"
  },
  {
    "objectID": "posts/2013/2013-10-28-pcr-lake-trout-c1q/index.html",
    "href": "posts/2013/2013-10-28-pcr-lake-trout-c1q/index.html",
    "title": "PCR - Lake Trout C1q",
    "section": "",
    "text": "Repeated PCR from 20130919, but with a newly designed reverse primer. Primers were designed using MethPrimer (SR IDs: 1553, 1555). Primers were designed using MethPrimer:\nResults:\nNo amplification of any samples BS-treated or non-treated."
  },
  {
    "objectID": "posts/2013/2013-12-07-gylcogen-assay-emmas-c-gigas-whole-body-samples-continued-from-yesterday/index.html",
    "href": "posts/2013/2013-12-07-gylcogen-assay-emmas-c-gigas-whole-body-samples-continued-from-yesterday/index.html",
    "title": "Gylcogen Assay - Emma’s C.gigas Whole Body Samples (continued from yesterday)",
    "section": "",
    "text": "Samples from yesterday were centrifuged 30mins, 4000g, 4C (fixed angle rotor).\nSupernatant was removed and pellets were dried (inverted tubes for 30mins).\nPellets were resuspended in 200uL H2O.\nData spreadsheet is here: 20131125 - Oyster Glycogen Assay"
  },
  {
    "objectID": "posts/2013/2013-03-14-pcr-hexokinase-promoter-and-cds-repeat-from-20130227/index.html",
    "href": "posts/2013/2013-03-14-pcr-hexokinase-promoter-and-cds-repeat-from-20130227/index.html",
    "title": "PCR - Hexokinase Promoter and CDS (repeat from 20130227)",
    "section": "",
    "text": "Performed a repeat of the failed PCR from 20130227, but used a pool of cDNA (made from 20110311 C.gigas cDNA) instead of a single sample and changed the annealing temp to 50C.\nResults:\nSame exact results as 20130227; nothing. As such, didn’t take gel image. Will retry one more time using a long-distance polymerase, along with varying [MgCl2].\nUPDATE 20130318: Doh! When talking about this at lab meeting today, I realized I’m trying to amplify the promoter (a genomic sequence) using cDNA! Will re-design primers and develop new cloning strategy for this!"
  },
  {
    "objectID": "posts/2013/2013-12-06-gylcogen-assay-emmas-c-gigas-whole-body-samples/index.html",
    "href": "posts/2013/2013-12-06-gylcogen-assay-emmas-c-gigas-whole-body-samples/index.html",
    "title": "Gylcogen Assay - Emma’s C.gigas Whole Body Samples",
    "section": "",
    "text": "Finally located the remaining half of Emma’s samples. These had already been freeze dried AND pulverized! So, I just had to weigh out ~half of each sample for the glycogen assay.\nGlycogen Assay:\nSamples were placed in 3mL of 15% trichloracetic acid (TCA), vortexed and incubated for 1hr @ 4C.\nSamples were spun 10mins, 3,000g, at 4C (in bucket rotor).\n500uL of supernatant was transferred to 4mL of 100% EtOH, vortexed and incubated O/N @ 4C.\nWill continue processing tomorrow.\nData spreadsheet is here: 20131125 - Oyster Glycogen Assay"
  },
  {
    "objectID": "posts/2013/2013-10-10-pcr-lake-trout-c1q-2/index.html",
    "href": "posts/2013/2013-10-10-pcr-lake-trout-c1q-2/index.html",
    "title": "PCR - Lake Trout C1q",
    "section": "",
    "text": "Repeated PCR from 20130919, but with a newly designed set of primers that targets the desired region of C1q for sequencing (SR IDs: 1553, 1554). Primers were designed in Geneious.\nResults:\nNo amplification of any samples BS-treated or non-treated."
  },
  {
    "objectID": "posts/2013/2013-04-09-pcr-hexokinase-partial-cds/index.html",
    "href": "posts/2013/2013-04-09-pcr-hexokinase-partial-cds/index.html",
    "title": "PCR - Hexokinase Partial CDS",
    "section": "",
    "text": "Performed PCR using the primers CG_HK_CDS_2132-2158 (SRID: 1521) and Cg_Hk_CDS_3’_no_stop (SRID: 1519) on pooled C.gigas cDNA (from DATE).\nMaster mix calcs and cycling params are here.\nSamples were run in duplicate.\nResults:\n\nNo amplification of any kind. Time for some troubleshooting…"
  },
  {
    "objectID": "posts/2013/2013-11-25-gylcogen-and-carboyhydrate-assays-emmas-c-gigas-whole-body-samples/index.html",
    "href": "posts/2013/2013-11-25-gylcogen-and-carboyhydrate-assays-emmas-c-gigas-whole-body-samples/index.html",
    "title": "Gylcogen and Carboyhydrate Assays - Emma’s C.gigas Whole Body Samples",
    "section": "",
    "text": "Samples were previously freeze dried overnight and stored @ -20C. To maximize sample homogeneity and, thus, increase accuracy of both assays, all samples were mechanically pulverized in their existing tubes. Approximately half of each sample was weighed and used for the glycogen assay. The remainder of each sample was stored @ -20C.\nGlycogen Assay:\nSamples were placed in 3mL of 15% trichloracetic acid (TCA), vortexed and incubated for 1hr @ 4C.\nSamples were spun 10mins, 3,000g, at 4C (in bucket rotor).\n500uL of supernatant was transferred to 4mL of 100% EtOH, vortexed and incubated O/N @ 4C.\nWill continue processing tomorrow.\nData spreadsheet is here: 20131125 - Oyster Glycogen Assay"
  },
  {
    "objectID": "posts/2013/2013-02-27-pcr-hexokinase-promoter-and-cds/index.html",
    "href": "posts/2013/2013-02-27-pcr-hexokinase-promoter-and-cds/index.html",
    "title": "PCR - Hexokinase Promoter and CDS",
    "section": "",
    "text": "Performed PCR to amplify the C.gigas hexokinase (ACCESSION#) promoter region (-2059bp) and the CDS without the stop codon. Elimination of the stop codon allows for subsequent cloning into the pBAD-TOPO expression vector, which will incorporate the V5 epitope tag sequence. This tag will be used to distinguish between endogenous hexokinase expression and expression generated from our hexokinase construct.\nUsed hexokinase primers (SR IDs: 1518, 1519).\nMaster mix calcs and cycling params are here.\nResults:\n\nLadder: Hyperladder II (Bioline)\nNo amplification in sample or no-template control. Will re-do with lower annealing temp (50C)."
  },
  {
    "objectID": "posts/2014/2014-02-12-dna-isolation-geoduck-3/index.html",
    "href": "posts/2014/2014-02-12-dna-isolation-geoduck-3/index.html",
    "title": "DNA Isolation - Geoduck",
    "section": "",
    "text": "Isolated gDNA from 6 geoduck siphon samples provided by Brent using the Qiagen DNeasy Spin Kit. Samples were as follows:\n\nLangley 006\nLangley 007\nLangley 008\nLangley 009\nGeoduck 01\nGeoduck 02\n\nThe Langley samples were fixed in ethanol in 2006. Geoduck 01/02 were fresh geoduck siphon samples, taken from two live, juvenile geoduck (the rest of the bodies were frozen at -80C).\nThe samples were processed according to the Qiagen protocol (but utilized an overnight incubation at 56C with Proteinase K), eluted in 100uL of Buffer AE and spec’d on a NanoDrop1000.\nResults:\n\nThe person who needs these samples (Axa) needs at least 25ug of DNA. The two fresh samples (Geoduck 01 and Geoduck 02) yielded more than sufficient quantities of DNA. The Langley (i.e. ethanol-fixed) samples did not yield sufficient DNA and I will need to isolate additional DNA from these samples."
  },
  {
    "objectID": "posts/2014/2014-10-23-dna-quantification-oly-oyster-gdna-01-for-rad-sequencing-from-20141014/index.html",
    "href": "posts/2014/2014-10-23-dna-quantification-oly-oyster-gdna-01-for-rad-sequencing-from-20141014/index.html",
    "title": "DNA Quantification - Oly Oyster gDNA-01 for RAD Sequencing (from 20141014)",
    "section": "",
    "text": "Quantified the gDNA isolated 20141014 using the Quant-iT dsDNA Broad Range kit (Life Technologies).\nUsed half the recommended volume of buffer (100uL instead of 200uL), as well as half the recommended volume of dye (5uL instead of 10uL). Prepared a master mix of the buffer/dye solution, containing a 1:200 dilution of the dye:\nBuffer: 14745uL\nDye: 75\n100uL of the solution was added to the appropriate wells in two 96 well, black plates with a multichannel pipette.\n5uL of each standard was added to the designated wells (see the plate layout in the Results below). Standards were run in duplicate.\n5uL of each samples was added to the designated wells.\nSamples were quantified using a plate reader.\nResults:\nRaw fluorescence was collected and an equation for the standard curve was determined for each plate. Concentrations were calculated from that equation (see linked spreadsheet below).\nConcentrations of each sample in their corresponding locations in the Oly Oyster gDNA-01 plate are here: 20141022-OlyRADdnaConcentrations\nAdditionally, the volumes needed for 500ng of each sample the required starting amount for the RAD sequencing protocol) are also on the spreadsheet linked above."
  },
  {
    "objectID": "posts/2014/2014-04-04-dna-gel-claires-c-gigas-female-gonad-and-macs-c-gigas-gonad/index.html",
    "href": "posts/2014/2014-04-04-dna-gel-claires-c-gigas-female-gonad-and-macs-c-gigas-gonad/index.html",
    "title": "DNA gel - Claire’s C.gigas Female Gonad and Mac’s C.gigas Gonad",
    "section": "",
    "text": "Ran out 2uL of Clair’es C.gigas female gonad gDNA (from 20140328) and Mac’s C.gigas gonad gDNA (from 20140402) for quality assessment. Both samples had been isolated using Qiagen’s Blood & Tissue DNeasy Kit. 2uL of each sample was run on a 0.8% 1x TBE gel.\nResults:\n\nLoading:\nLane 1 - Hyperladder 1 (Bioline)\nLane 2 - Claire’s gDNA\nLane 3 - mac’s gDNA\nBoth samples show an extremely high amount of smearing. Additionally, both samples have definitive bands that correspond to ~1300bp and ~850bp."
  },
  {
    "objectID": "posts/2014/2014-11-26-gel-sheared-gdna/index.html",
    "href": "posts/2014/2014-11-26-gel-sheared-gdna/index.html",
    "title": "Gel - Sheared gDNA",
    "section": "",
    "text": "Ran ~250ng (out of 3000ng, according to Claire) of LSU C.virginica oil spill gDNA on a gel that was previously sheared by Claire to verify that shearing was successful.\nRan unsheared side-by-side with sheared gDNA for comparison.\nNote: HB16 and NB3 did not have any unsheared gDNA left in their tubes, so nothing was run on a gel.\nResults:\n\nLadder used: O’GeneRuler 100bp Ladder (ThermoFisher)\nWell, it’s rather obvious that the initial shearing did NOT work. Will re-shear the samples.\nUPDATE: Looking at the Biorupter (Diagenode) manual, it turns out that shearing samples in a 1.5mL tube (in which these were sheared) requires a minimum volume of 100uL. All the samples were far below this minimum volume. Additionally, the recommendations in the manual to reach the target size range are significantly longer (30 - 40 cycles) than what was applied (4 cycles). The combination of these two factors are likely the reason that shearing didn’t take place."
  },
  {
    "objectID": "posts/2014/2014-11-17-rad-sequencing-oly-oyster-gdna-01-rad-library-from-20141110/index.html",
    "href": "posts/2014/2014-11-17-rad-sequencing-oly-oyster-gdna-01-rad-library-from-20141110/index.html",
    "title": "RAD Sequencing - Oly Oyster gDNA-01 RAD Library (from 20141110)",
    "section": "",
    "text": "Prepared 10nM of the library in total volume of 20uL of Buffer EB (Qiagen) + 0.1% Tween-20, according the University of Oregon’s Genomic’s Core:\nhttps://gcf.uoregon.edu/home/services\nBased on a calculator provided by their site, 10nM was equivalent to 2.93ng/uL. Diluted 3.13uL of the library (18.7ng/uL) in 16.87uL of Buffer EB + Tween 20.\nShipped FedEx Standard Overnight on wet ice for 100bp single end Illumina sequencing."
  },
  {
    "objectID": "posts/2014/2014-04-16-dna-isolation-test-sample/index.html",
    "href": "posts/2014/2014-04-16-dna-isolation-test-sample/index.html",
    "title": "DNA Isolation - Test Sample",
    "section": "",
    "text": "Due to the recent poor quality gDNA that has been isolated from C.gigas gonad, I decided to do a quick test using TE for DNA pellet resuspension in hopes that old Buffer EB (Qiagen) or old nuclease-free H2O (Promega) are to blame for the apparent, rapid degradation that I’ve experienced.\nIsolated gDNA from a C.gigas female gonad sample (EV2 141 go) provided by Mac. Isolated gDNA using DNazol (Molecular Research Center):\n\nIncubated ~25mg of tissue O/N @ RT in 500uL of DNazol + 100ug/mL Proteniase K (2.7uL of 18.5mg/mL Fermentas stock) on rotator.\nAdded additional 500uL of DNazol and briefly disrupted remaining tissue with a few pipette strokes.\nPelleted debris by spinning 10mins, 10,000g @ RT.\nTransferred supe to new tube and repeated Steps 3 & 4 one time.\nAdded 500uL of 100% EtOH; mixed by inversion.\n\nNOTE: Despite initial appearance of white cloudy appearance after EtOH addition, cloudiness dispersed upon inversion and no visible DNA strands were present\n\nPelleted DNA by spinning 5000g 5mins @ RT.\nRemoved supe and washed pellet with 1mL of a 70% DNazol+30% EtOH solution.\nRemoved supe and washed pellet with 1mL 70% EtOH.\nRepeated Step 8 two times.\nDiscarded supe, quick spun tube to pool residual EtOH. Removed all residual EtOH.\nResuspended in 200uL of TE (pH = 8.0) and incubated at RT for 5mins.\nPelleted insoluble material 12,000g 10mins @ RT.\nTransferred supe to clean tube.\nSpec’d on NanoDrop1000.\nRan ~500ng on 1.0% agaroase 1x modified TAE gel to evaluate integrity.\n\nResults:\n\n\n\n260/280 value looks excellent, but, as always seems to be the case with DNazol/TriReagent, the 260/230 value looks crappy. Will investigate gDNA integrity on agarose gel.\n\nGel Loading:\nLane 1 - Hyperladder I (Bioline)\nLane 2 - EV2 141 go C.gigas female gonad gDNA\nWell, look at that! A nice, clear, high molecular weight band! It looks like my Buffer EB and/or nuclease-free water are is contaminated. Have discarded both. Will re-isolated Claire and Mac’s gDNA."
  },
  {
    "objectID": "posts/2014/2014-11-27-methylated-dna-enrichment-mbd-lsu-c-virginica-oil-spill-gdna-2/index.html",
    "href": "posts/2014/2014-11-27-methylated-dna-enrichment-mbd-lsu-c-virginica-oil-spill-gdna-2/index.html",
    "title": "Methylated DNA Enrichment (MBD) - LSU C.virginica Oil Spill gDNA",
    "section": "",
    "text": "Enrichment was performed using the MethylMiner Methylated DNA Enrichment Kit (Invitrogen) according to the manufacturer’s protocol with the following changes:\n\nUsed 25uL of Dynabeads M-280 (10uL/ug of input DNA) and 15uL of MBD-Biotin Protein (7uL/ug of input DNA).\nFollowed the corresponding instructions for the volumes listed above and for quantities of input DNA > 1ug - 10ug\nA single elution with 2000mM NaCl was performed\nEtOH precipitation: Samples were incubated over the long weekend at -80C."
  },
  {
    "objectID": "posts/2014/2014-10-30-dna-allocation-oly-oyster-gdna-01-for-rad-sequencing-from-20141022/index.html",
    "href": "posts/2014/2014-10-30-dna-allocation-oly-oyster-gdna-01-for-rad-sequencing-from-20141022/index.html",
    "title": "DNA Allocation - Oly Oyster gDNA-01 for RAD Sequencing (from 20141022)",
    "section": "",
    "text": "Transferred 500ng of gDNA from each sample to a 96-well, low-profile, non-skirted PCR plate (sample layout matches that of the layout of the source gDNA plate) and air-dried the samples over night.\nCalculations for volumes is here: 20141022-OlyRADdnaConcentrations"
  },
  {
    "objectID": "posts/2014/2014-09-24-dna-isolation-c-gigas-larvae-from-katie-latterhos/index.html",
    "href": "posts/2014/2014-09-24-dna-isolation-c-gigas-larvae-from-katie-latterhos/index.html",
    "title": "DNA Isolation - C.gigas Larvae from Katie Latterhos",
    "section": "",
    "text": "Since the previous isolation attempt was unsuccessful (see 20140922), we’re trying a slightly different approach than yesterday.\nToday, I will pellet the samples, remove the RNA Later and then proceed with the Quick-gDNA MicroPrep Kit (ZymoResearch) according to the manufacturer’s protocol for Cell Suspensions and Proteinase K Digested Samples.\nIsolated gDNA from two C.gigas larvae samples from Katie Latterhos:\nB1 400 D6\nB6 D00\nPelleted the samples at 10,000g, 5mins, RT. Although no pellets were visible in either sample, the B1 400 D6 sample did have visible cells/debris at the top of the RNA Later after spinning! So, I recovered that portion of the sample for use in the DNA isolation. The B6 D00 sample had no visible debris, nor pellets, so the RNA Later supernatant was removed and discarded.\nBoth samples were then processed with the Quick-gDNA MicroPrep Kit (ZymoResearch) according to the manufacturer’s protocol for Cell Suspensions and Proteinase K Digested Samples.\nSamples were eluted with 10uL of elution buffer and spec’d on a NanoDrop1000 (ThermoFisher). The 2uL used for each sample were recovered from the NanoDrop.\nResults:\nNote: The B1 400 D6 sample was spec’d twice, due to an error message on the NanoDrop when spec’ing it the first time. Thus, the second entry for B1 400 D6 is the correct value.\n\nAlthough the B1 400 D6 sample actually yielded gDNA today, the yield is far too low for use in RAD sequencing (need 500ng; B1 400 D6 yielded only ~260ng). Additionally, the quality of the DNA isolated is horrible (OD 260/280 = 0.81).\nThe B6 D00 did not yield any DNA.\nWill let Steven know and see how he wants to proceed."
  },
  {
    "objectID": "posts/2014/2014-12-03-etoh-precipitation-lsu-c-virginica-oil-spill-mbd-continued-from-20141126/index.html",
    "href": "posts/2014/2014-12-03-etoh-precipitation-lsu-c-virginica-oil-spill-mbd-continued-from-20141126/index.html",
    "title": "EtOH Precipitation - LSU C.virginica Oil Spill MBD Continued (from 20141126)",
    "section": "",
    "text": "Precipitation was continued according to the MethylMiner Methylated DNA Enrichment Kit (Invitrogen). Since I will need sample volumes of 24uL for the subsequent bisulfite conversion, I resuspended the samples in 29uL of water (will use 2.5uL x 2 reps for quantification).\nSamples to be quantified:\nNC = non-captured (i.e. non-methylated)\nE = eluted (i.e. methylated)\n\nHB2 NC\nHB5 NC\nHB16 NC\nHB30 NC\nNB3 NC\nNB6 NC\nNB11 NC\nNB21 NC\nHB2 E\nHB5 E\nHB16 E\nHB30 E\nNB3 E\nNB6 E\nNB11 E\nNB21 E\nControl NC\nControl E\n\nSamples were quantified using the Quant-IT BS Kit (Invitrogen) with a plate reader (BioTek). All samples were run in duplicate. Used 2.5uL of each sample for quantification.\nSamples were stored in @ -20C (FTR 209) in the bisulfite seq box created by Claire for this project.\nResults:\n20141202_LSU_Virginica_MBD:\nhttps://docs.google.com/spreadsheets/d/1NrrVmYsUQcstnrt4583mYN2PeVav54luyFvVUEkcjWE/edit?usp=sharing"
  },
  {
    "objectID": "posts/2014/2014-12-19-bisulfite-ngs-library-prep-lsu-c-virginica-oil-spill-mbd-bisulfite-dna-and-emmas-c-gigas-larvae-oa-bisulfite-dna-continued-from-yesterday/index.html",
    "href": "posts/2014/2014-12-19-bisulfite-ngs-library-prep-lsu-c-virginica-oil-spill-mbd-bisulfite-dna-and-emmas-c-gigas-larvae-oa-bisulfite-dna-continued-from-yesterday/index.html",
    "title": "Bisulfite NGS Library Prep - LSU C.virginica Oil Spill MBD Bisulfite DNA and Emma’s C.gigas Larvae OA Bisulfite DNA (continued from yesterday)",
    "section": "",
    "text": "Continued library prep from yesterday. Set up Library Amplification according to the protocol. The samples received the following Barcode Indices:\n\nHB2 - 1 (ATCACG)\nHB5 - 2 (CGATGT)\nHB16 - 3 (TTAGGC)\nHB30 - 4 (TGACCA)\nNB3 - 5 (ACAGTG)\nNB6 - 6 (GCCAAT)\nNB11 - 7 (CAGATC)\nNB21 - 12 (CTTGTA)\n1A1 - 2 (CGATGT)\n1A2 - 1 (ATCACG)\n6A1 - 4 (TGACCA)\n6A2 - 5 (ACAGTG)\n103B1 - 6 (GCCAAT)\n103B2 - 7 (CAGATC)\n105A4 - 12 (CTTGTA)\n105A5 - 11 (GGCTAC)\n\nDue to differences in input DNA quantities, samples were run with different numbers of thermal cycles.\n13 thermal cycles were run for the following samples:\n\n1A1\n105A4\n105A5\n\n22 thermal cycles were run for the following samples:\n\nHB2\nHB5\nHB16\nHB30\nNB3\nNB6\nNB11\nNB21\n1A2\n6A1\n6A2\n103B1\n103B2\n\nSamples were quantified with 1uL of each sample using the Quant-iT dsDNA BR Kit (Invitrogen). Used 5uL of each standard and standards were run in duplicate.\nResults:"
  },
  {
    "objectID": "posts/2014/2014-04-10-dna-isolation-claires-c-gigas-female-gonad-and-macs-c-gigas-gonad/index.html",
    "href": "posts/2014/2014-04-10-dna-isolation-claires-c-gigas-female-gonad-and-macs-c-gigas-gonad/index.html",
    "title": "DNA Isolation - Claire’s C.gigas Female Gonad and Mac’s C.gigas Gonad",
    "section": "",
    "text": "Due to the poor quality DNA yielded by the DNeasy Kit (Qiagen; see 20140404), I am re-isolating these samples using DNazol (Molecular Research Center). Weighed tissue from each frozen sample:\nClaire’s (Female DNA; 5/6/2013) - 0.022g\nMac’s (EV2 9.g) - 0.017g\nIncubated samples in 500uL of DNazol + 100ug/mL Proteinase K (2.7uL of 18.5mg/mL stock) O/N at RT on rotator. An additional 500uL of DNazol was added, mixed by pipetting to break up remaining tissues clumps. Manufacturer’s protocol was followed, substituting the first EtOH wash with a wash of 70% DNazol, 30% 100% EtOH. Samples were resuspended in 100uL Buffer EB (Qiagen) and spec’d on a NanoDrop1000.\nNOTE: Mac’s sample seemed to get “chunky”/cloudy during the precipitation portion of the procedure. Claire’s remained clear. Although not noted, Mac’s sample behaved in a similar fashion when adding Buffer AL to the sample when using the Qiagen DNeasy Blood & Tissue Kit. Finally, Mac has previously mentioned this behavior to me as well.\nResults:\n\n\nSuprisingly high yields from Mac’s sample.\nBoth samples exhibit poor 260/230 ratios and high absorbance at 230nm is evident in both samples. Mac’s sample may benefit from\nRan ~600ng of each sample on a 0.8% 1x modified TAE agarose gel to visually assess sample quality.\n\n\n\nGel Loading (from left to right):\n\nHyperladder II (Bioline)\nClaire’s Female DNA\nMac’s gonad (EV2 9.go)\n\nI knew the ladder was of little use due to high molecular weight of gDNA, but it still serves as a bit of a reference. Highest molecular weight band is 2000bp.\nClaire’s sample looks pretty good, in relation to the lack of smearing. A single, high molecular weight band is present (albeit, faint) with almost no smearing. However, I’m disappointed by the lack of definition in the band. I fully expected a sharper, more defined band.\nMac’s sample shows a high molecular weight band and significant smearing. Smearing could be indicative of either DNA degradation or high amounts of RNA carryover. If the latter, could explain the high yield.\nWill attempt to clean up both samples (RNase and/or do a chloroform clean up)."
  },
  {
    "objectID": "posts/2014/2014-04-10-rna-isolation-sea-star-coelomocytes-from-colleen/index.html",
    "href": "posts/2014/2014-04-10-rna-isolation-sea-star-coelomocytes-from-colleen/index.html",
    "title": "RNA Isolation - Sea Star Coelomocytes (from Colleen)",
    "section": "",
    "text": "Isolated RNA from two samples stored in RNAlater that had either no visible pellet or a minutely visible pellet:\n\nControl P26\nFilt. Inj. P8\n\nSamples were spun 5000g, 20mins @ RT. Supe was removed, being sure to leave behind any debris that failed to pellet. Samples were homogenized in 1mL of TriReagent by pipetting/vortexing. RNA was then isolated using the Direct-zol RNA Miniprep Kit (ZymoResearch). RNA was eluted from the column with 25uL of 0.1%DEPC-treated H2O and spec’d on a NanoDrop1000.\nResults:\n\n\nRNA quality looks very good, as do the yields. I’m very surprised I got anything close to 1ug out of either sample!\nHowever, it should be noted that neither of these samples has been DNased and, as such, the yields seen above may potentially include residual gDNA carryover which would artificially inflate the yields seen above. Will DNase the samples to see how yields are affected (if at all)."
  },
  {
    "objectID": "posts/2014/2014-09-23-dna-isolation-c-gigas-larvae-from-katie-latterhos-and-emma/index.html",
    "href": "posts/2014/2014-09-23-dna-isolation-c-gigas-larvae-from-katie-latterhos-and-emma/index.html",
    "title": "DNA Isolation - C.gigas Larvae from Katie Latterhos and Emma",
    "section": "",
    "text": "Isolated gDNA from two C.gigas larvae samples (stored in RNA Later) from Katie Latterhos:\nB4 400 D05\nB6 400 D03\nand two samples from Emma:\n280E\n380E\nEmma’s samples were in her -80C box (in rack #2): C.gigas larvae - NOAA O.A. September 2010 Emma\nNote: No visible larvae present in either of Katie Latterhos samples. Easily visible larvae in each of Emma’s samples.\nDNA was isolated using the Quick-gDNA MicroPrep Kit (ZymoResearch) according to the manufacturer’s protocol for Cell Suspensions and Proteinase K Digested Samples.\nSamples were eluted with 10uL of elution buffer and spec’d on a NanoDrop1000 (ThermoFisher). The 2uL used for each sample were recovered from the NanoDrop.\nResults:\n\nNot surprisingly, the samples from Katie Latterhos yielded, essentially, no gDNA. Will discuss with Steven.\nUPDATE 20141030\nSteven sent me this screen cap of Emma’s notebook so we could track where the samples originated from"
  },
  {
    "objectID": "posts/2014/2014-04-25-ethanol-precipitation-colleens-sea-star-coelomycete-rna-from-yesterday/index.html",
    "href": "posts/2014/2014-04-25-ethanol-precipitation-colleens-sea-star-coelomycete-rna-from-yesterday/index.html",
    "title": "Ethanol Precipitation - Colleen’s Sea Star Coelomycete RNA from Yesterday",
    "section": "",
    "text": "Performed an EtOH precipitation on the sea start RNA due to some residual column resin (?) in the tubes after elution.\nAdded 0.1 volumes of 3M sodium acetate (pH=5.2; 10uL), 1uL glycogen (Ambion stock 5mg/mL), 2.5 volumes of ice cold 100% EtOH (275uL). Vortexed and incubated O/N at -20C.\nPelleted RNA 16,000g, 30mins @ 4C.\nDiscarded supe.\nWashed pellet 70% EtOH.\nPelleted RNA 16,000g, 15mins @ 4C.\nRepeated wash and spin.\nRemoved supe, resuspended RNA in 50uL of 0.1%DEPC-treated H2O and spec’d on NanoDrop1000.\nSamples were stored in Shellfish RNA Box #5.\nResults:\n\nWell, overall, the RNA looks immensely better than yesterday. However, as expected, there has been some slight loss with all the additional manipulations. As such, yields are low (although, they were initially low, too). However, I think most of the samples will be usable, albeit bordering on the minimum amount of total RNA needed (200ng) at the Cornell sequencing facility…"
  },
  {
    "objectID": "posts/2014/2014-10-15-dna-isolation-olympia-oyster-populations-for-rad-sequencing/index.html",
    "href": "posts/2014/2014-10-15-dna-isolation-olympia-oyster-populations-for-rad-sequencing/index.html",
    "title": "DNA Isolation - Olympia Oyster Populations for RAD Sequencing",
    "section": "",
    "text": "Olympia oysters from three different Puget Sound locations/populations (HL, NF, and SN) were collected and stored @ -80C on 8/29/2103.\nWe removed whole bodies from 32 oysters (randomly selected; ~5 -10mm “diameter” shells) from each population and placed them into a 96 well DNeasy Blood & Tissue Kit (Qiagen). DNA was prepared/isolated according to the manufacturer’s protocol.\nDNA was eluted once with 200uL of Buffer AE and stored @ 4C.\nPlate is called: Oly Oyster gDNA-01\nPlate layout can be found here: 20141022-OlyRADdnaConcentrations\nUPDATE 20141017\nSteven ran the samples out on a gel for quality assessment. His notebook entry can be seen here:\nGel layout info and image of gel 1 of 2: https://sr320.tumblr.com/post/100245499294\nImages of gel 2 of 2: https://sr320.tumblr.com/post/100231194034\nThe samples are all heavily smeared, suggesting heavy degradation. Will compare Qiagen kit with DNazol on some of the samples from 8/29/2013, as well as samples more recently collected/frozen."
  },
  {
    "objectID": "posts/2014/2014-09-04-pcr-macs-bisulfite-treated-dna/index.html",
    "href": "posts/2014/2014-09-04-pcr-macs-bisulfite-treated-dna/index.html",
    "title": "PCR - Mac’s Bisulfite-Treated DNA",
    "section": "",
    "text": "Realized that the PCR performed on 20140828 used the incorrect forward primer! As such, am repeating as before, but with the correct forward primer:\nCgBS_733_26796F (SRID: 1597)\nNOTE: Nothing left of sample EV2.28 bisulfite, so this was not run.\nResults:\n\nLadder - O’GeneRuler 100bp Ladder (ThermoFisher)\nSamples are loaded in numerical order from left to right, with a NTC sample before the second ladder.\nAll samples ran at ~275bp, which is larger than the previous gels. Confirmed with Mac that this gel looks correct. Will contact Cassie at Fred Hutchinson to go forward with PyroMark sequencing of these products.\nEvidently, it would seem that Mac (and I) used the incorrect primer set when performing this PCR most recently. Doh!"
  },
  {
    "objectID": "posts/2014/2014-02-13-dna-isolation-geoduck-2/index.html",
    "href": "posts/2014/2014-02-13-dna-isolation-geoduck-2/index.html",
    "title": "DNA Isolation - Geoduck",
    "section": "",
    "text": "Since yesterday’s DNA isolation failed to yield sufficient quantity of DNA from the ethanol-fixed samples, I isolated additional DNA from the same samples.\nIsolated gDNA from 6 geoduck siphon samples provided by Brent using the Qiagen DNeasy Spin Kit. Samples were as follows:\n\nLangley 006\nLangley 007\nLangley 008\nLangley 009\n\nThe Langley samples were fixed in ethanol in 2006. Geoduck 01/02 were fresh geoduck siphon samples, taken from two live, juvenile geoduck (the rest of the bodies were frozen at -80C).\nThe samples were processed according to the Qiagen protocol (but utilized an overnight incubation at 56C with Proteinase K), eluted in 50uL of Buffer AE, combined with the corresponding DNA from yesterday, mixed throughly and spec’d on a NanoDrop1000.\nResults:\n\nNow have sufficient quantity of DNA for all four of these samples. Will contact Axa (the person who this DNA is intended for) to see if he requires a specific concentration/volume."
  },
  {
    "objectID": "posts/2014/2014-03-28-dna-isolation-c-gigas-female-gonads-from-frozen/index.html",
    "href": "posts/2014/2014-03-28-dna-isolation-c-gigas-female-gonads-from-frozen/index.html",
    "title": "DNA Isolation - C.gigas Female Gonads (from frozen)",
    "section": "",
    "text": "Isolated gDNA from Claire’s “Female DNA” (from 05/16/2013) using the Qiagen Blood & Tissue DNeasy Kit according to the manufacturer’s protocol, with the following changes:\n\nIncubated sample in Buffer ATL + Proteinase K @ 56C for 3hrs. Vortexed once each hour.\nEluted with 100uL of Buffer AE.\n\nResults:\n\nExcellent yield and quality is good, although both the 260/280 and 260/230 ratios are on the high side. However, these high values could be an artifact of the high sample concentration (this is a common “issue” with the NanoDrop)."
  },
  {
    "objectID": "posts/2014/2014-12-17-bisulfite-conversion-lsu-c-virginica-oil-spill-mbd-dna-and-emmas-c-gigas-larvae-oa-dna/index.html",
    "href": "posts/2014/2014-12-17-bisulfite-conversion-lsu-c-virginica-oil-spill-mbd-dna-and-emmas-c-gigas-larvae-oa-dna/index.html",
    "title": "Bisulfite Conversion - LSU C.virginica Oil Spill MBD DNA and Emma’s C.gigas Larvae OA DNA",
    "section": "",
    "text": "Performed bisulfite conversion on MBD DNA samples from LSU C.virginica oil spill samples (see 201411202 and 20141126) and Emma’s C.gigas larvae OA DNA samples (see 20141121) with the Methylamp DNA Modification Kit (Epigentek).\nAdded 4uL of H2O to each of Emma’s DNA samples to bring them up to 24uL.\nSamples were processed according to the manufacturer’s protocol.\nSamples were eluted with 10uL of Solution R6 and stored @ -20C."
  },
  {
    "objectID": "posts/2014/2014-05-14-sample-submission-colleen-sea-star-pycnopodia-coelomycete-rna-for-illumina-sequencing/index.html",
    "href": "posts/2014/2014-05-14-sample-submission-colleen-sea-star-pycnopodia-coelomycete-rna-for-illumina-sequencing/index.html",
    "title": "Sample Submission - Colleen Sea Star (Pycnopodia) Coelomycete RNA for Illumina Sequencing",
    "section": "",
    "text": "Sent the following samples (in their entirety) to Cornell for Illumina HiSeq 100bp paired-end sequencing:\n\nCF26 (V_CF26)\nCF34 (V_CF34)\nCF71 (V_CF71)\nCF2 (HK_CF2)\nCF35 (HK_CF35)\nCF70 (HK_CF70)"
  },
  {
    "objectID": "posts/2014/2014-11-06-dna-shearing-oly-oyster-gdna-rad-p1-adapters-from-20141105/index.html",
    "href": "posts/2014/2014-11-06-dna-shearing-oly-oyster-gdna-rad-p1-adapters-from-20141105/index.html",
    "title": "DNA Shearing & Size Selection - Oly Oyster gDNA RAD P1 Adapters (from 20141105)",
    "section": "",
    "text": "Pooled “low quality” samples and pooled “high quality” samples separately (in 1.5mL snap cap tubes) prior to shearing to improve chances of getting similar DNA size ranges.\nSamples were selected based on the gels run by Steven on Oct. 17, 2014: https://sr320.tumblr.com/\nLow quality samples (5uL from each):\nAll rows, columns 1 -9\nHigher quality samples (5uL from each):\nAll rows, columns 10 -12\nSheared each samples with the following cycling protocols on the Biorupter Plus (Diagenode):\nLow\n\n3 cycles of:\n30 seconds on\n59 seconds off\n\nHigh\n4 cycles of:\n\n30 seconds on\n59 seconds off\n\nRan a subset of sheared gDNA (5uL from each pool) on gel to verify final size range:\n\nGel loading:\nLane 1 - O’GeneRuler 100bp Ladder (ThermoFisher)\nLane 2 - Low quality\nLane 3 - Higher quality\nI neglected to run a set of un-sheared DNA.\nBoth samples appear to have an average size of 200 - 400bp.\nAfter confirming satisfactory shearing, the two samples were combined and run on a 1% agarose low TAE gel (stained with EtBr) for size selection.\nO’GeneRuler 100bp Ladder (ThermoFisher)\n\nO’GeneRuler 100bp Ladder (ThermoFisher)\n\nSize range of sheared DNA from 300 - 500bp was excised from gel.\nGel fragment weighed 254mg.\nPurified using MiniElute Gel Extraction Kit (Qiagen).\nAdded three volumes (762uL) of Buffer QG to gel slice.\nIncubated ~10mins on rotator until gel slice was fully dissolved.\nAdded one gel slice volume (254uL) of isopropanol; inverted multiple times to mix.\nAdded 700uL to MiniElute column; spun max speed (~16,000g) 1min; discarded flow-through.\nAdded remainder of sample to MiniElute column; spun max speed (~16,000g) 1min; discarded flow-through.\nAdded 500uL of Buffer QG to MiniElute column; spun max speed (~16,000g) 1min; discarded flow-through.\nAdded 750uL of Buffer PE to MiniElute column; incubated @ RT for 5mins; spun max speed (~16,000g) 1min; discarded flow-through.\nSpun MinElute column spun max speed (~16,000g) 1min; transferred column to clean 2.0mL tube.\nAdded 50uL of Buffer EB to column, incubated @ RT for 5mins and spun max speed (~16,000g) 1min; discarded column.\nStored sample @ 4C."
  },
  {
    "objectID": "posts/2014/2014-08-29-pcr-macs-bisulfite-treated-dna-2/index.html",
    "href": "posts/2014/2014-08-29-pcr-macs-bisulfite-treated-dna-2/index.html",
    "title": "PCR - Mac’s Bisulfite-Treated DNA",
    "section": "",
    "text": "Per Mac’s request, ran a PCR on a set of bisulfite-treated DNA (in her gDNA 2014 box in small -20C):\n\nEV2.16 bisulfite\nEV2.20 bisulfite\nEV2.22 bisulfite\nEV2.24 bisulfite\nEV2.28 bisulfite\nEV2.29 bisulfite\nEV2.32 bisulfite\nEV2.33 bisulfite\n\nDNA needed to be diluted. Diluted according to this sheet provided by Mac:\nhttps://eagle.fish.washington.edu/bivalvia/070914bisulfite.pdf\nNOTE: EV2.28 didn’t have sufficient DNA left to prepare the dilution according to Mac’s sheet. Instead, the remaining volume ofEv2.28 bisulfite DNA (0.5uL) was diluted in a total volume of 2.5uL to maintain the same dilution ratio.\nMaster mix calcs are here: 20140828 - PCR Mac Bisulfite Samples\nPrimers used were:\nCgBS_733_26796Seq (SRID: 1598)\nCgBS_733_26796R_5’biotin (SRID: 1596)\nCycling params:\n\n\n95C - 10mins\n\n\n94C - 30s\n\n\n56C - 30s\n\n\n72C - 30s\n\n\nRepeat steps 2 - 5 44 more times\n\n\n72C - 10mins\n\n\nResults:\n\nLadder used is O’GeneRuler 100bp DNA Ladder (ThermoFisher).\nAccording to Mac, the expected band size is ~300bp. However, all samples are running at ~150bp. Mac is confused and does not know what to do.\nUPDATE 20140902 - Realized I used the wrong forward primer! Will repeat PCR with correct primer. Wonder if Mac did the same thing…"
  },
  {
    "objectID": "posts/2014/2014-04-24-rna-clean-up-colleens-sea-star-coelomycete-rna-from-20140416/index.html",
    "href": "posts/2014/2014-04-24-rna-clean-up-colleens-sea-star-coelomycete-rna-from-20140416/index.html",
    "title": "RNA Clean Up - Colleen’s Sea Star Coelomycete RNA from 20140416",
    "section": "",
    "text": "Zymoresearch support suggested putting the samples through another set of columns to help clean up the apparent phenol carryover that was seen (absorbance peak shifted to 270nm) in the initial isolation of these samples.\nAdded 500uL of TriReagent to each sample and vortexed. Then, proceeded with the remainder of the protocol (excluding the DNase step). Eluted with 50uL of 0.1% DEPC-treated H2O and spec’d on NanoDrop1000.\nResults:\n\n\n\n\nAbsolutely horrible!! I can’t even begin to fathom what has happened here. The samples run with the sample kit all worked so well; why did this whole thing have to be jacked up with the actual samples??!!\nWell, I’ll do a second elution using 50uL of 0.1%DEPC-treated H2O and spec. Let’s see if that helps….\n\nOK, I didn’t even bother spec-ing all the samples because I noticed that the elution tubes had pellets in them! When I mix the tube prior to spec-ing (which is my normal behavior), I get the top absorbance spectra that is virtually useless. When I don’t mix the samples (thus, not disturbing the pellet), I get a more “realistic” spectra, but I can’t tell if I can trust it or not. I have contacted Zymoresearch support for more help with this…\nIt’s tempting to simply proceed with an EtOH precipitation, but I’m a bit concerned that the pellet in the tubes is resin from the column and that it might still bind some of the RNA. However, I guess the pellet is already in the elution solution, so the RNA should be soluble and, theoretically, not be able to bind to any residual resin…"
  },
  {
    "objectID": "posts/2014/2014-05-29-rna-seq-sea-star-data-download/index.html",
    "href": "posts/2014/2014-05-29-rna-seq-sea-star-data-download/index.html",
    "title": "RNA-Seq - Sea Star Data Download",
    "section": "",
    "text": "Received RNA-seq data from Cornell. They provided a convenient download script for retrieving all the data files at one time (a bash script containing a series of wget commands with each individual file’s URL), which is faster/easier than performing individual wget commands for each individual file and faster/easier then using the Synology “Download Station” app when so many URLs are involved.\nHere’s the script (download.sh) that was provided:\n[code lang=text] #!/bin/bash wget -q -c -O 3291_5903_10007_H94MGADXX_V_CF71_ATCACG_R2.fastq.gz https://cbsuapps.tc.cornell.edu/Sequencing/showseqfile.aspx?mode=http&cntrl=1160641846&refid=17091 wget -q -c -O 3291_5903_10007_H94MGADXX_V_CF71_ATCACG_R1.fastq.gz https://cbsuapps.tc.cornell.edu/Sequencing/showseqfile.aspx?mode=http&cntrl=505010539&refid=17092 wget -q -c -O 3291_5903_10008_H94MGADXX_V_CF34_CGATGT_R1.fastq.gz https://cbsuapps.tc.cornell.edu/Sequencing/showseqfile.aspx?mode=http&cntrl=636513375&refid=17093 wget -q -c -O 3291_5903_10008_H94MGADXX_V_CF34_CGATGT_R2.fastq.gz https://cbsuapps.tc.cornell.edu/Sequencing/showseqfile.aspx?mode=http&cntrl=1472734408&refid=17094 wget -q -c -O 3291_5903_10009_H94MGADXX_V_CF26_TTAGGC_R2.fastq.gz https://cbsuapps.tc.cornell.edu/Sequencing/showseqfile.aspx?mode=http&cntrl=948605937&refid=17095 wget -q -c -O 3291_5903_10009_H94MGADXX_V_CF26_TTAGGC_R1.fastq.gz https://cbsuapps.tc.cornell.edu/Sequencing/showseqfile.aspx?mode=http&cntrl=1810346594&refid=17096 wget -q -c -O 3291_5903_10010_H94MGADXX_HK_CF2_TGACCA_R2.fastq.gz https://cbsuapps.tc.cornell.edu/Sequencing/showseqfile.aspx?mode=http&cntrl=424477466&refid=17097 wget -q -c -O 3291_5903_10010_H94MGADXX_HK_CF2_TGACCA_R1.fastq.gz https://cbsuapps.tc.cornell.edu/Sequencing/showseqfile.aspx?mode=http&cntrl=630586816&refid=17098 wget -q -c -O 3291_5903_10011_H94MGADXX_HK_CF35_ACAGTG_R1.fastq.gz https://cbsuapps.tc.cornell.edu/Sequencing/showseqfile.aspx?mode=http&cntrl=1392201335&refid=17099 wget -q -c -O 3291_5903_10011_H94MGADXX_HK_CF35_ACAGTG_R2.fastq.gz https://cbsuapps.tc.cornell.edu/Sequencing/showseqfile.aspx?mode=http&cntrl=1598310685&refid=17100 wget -q -c -O 3291_5903_10012_H94MGADXX_HK_CF70_GCCAAT_R1.fastq.gz https://cbsuapps.tc.cornell.edu/Sequencing/showseqfile.aspx?mode=http&cntrl=868072864&refid=17101 wget -q -c -O 3291_5903_10012_H94MGADXX_HK_CF70_GCCAAT_R2.fastq.gz https://cbsuapps.tc.cornell.edu/Sequencing/showseqfile.aspx?mode=http&cntrl=1074182214&refid=17102 [/code]\nThis is a bash script. However, for the most direct method of downloading these on our Synology server, we need the script to be an ash script. So, just modify the first line of the script to say “#!/bin/ash” instead of “#!/bin/bash”. Then, I placed the script in the target directory for our files, SSH’d into our Synology (Eagle), changed to the directory where I placed our script (Eagle/web/whale/SeaStarRNASeq) and then ran the script (./download.sh)."
  },
  {
    "objectID": "posts/2014/2014-11-05-ligation-illumina-p1-adapters-for-oly-oyster-gdna-01-rad-sequencing-from-20141031/index.html",
    "href": "posts/2014/2014-11-05-ligation-illumina-p1-adapters-for-oly-oyster-gdna-01-rad-sequencing-from-20141031/index.html",
    "title": "Ligation - Illumina P1 Adapters for Oly Oyster gDNA-01 RAD Sequencing (from 20141031)",
    "section": "",
    "text": "Made 25nM working stock from the 100nM stock adapter plate provided by Carita. Added 2uL of each adapter to corresponding well of SbfI digested DNA (e.g. DNA plate well A1 got the P1 adapter from well A1 in the adapter plate).\nCreated master mix of the ligation components and added 3uL to each well of SbfI-digested Oly gDNA.\nMaster mix calcs are here: 20141105 - Oly Oyster gDNA-01 Adapter Ligation\nIncubated @20C for 60mins. Deactivated ligase @65C for 30mins. Stored @ 4C.\nAdapter plate layout and sequences can be found here: 96_SbfI_RAD_adapter_sequences"
  },
  {
    "objectID": "posts/2014/2014-04-02-rna-isolation-sea-star-coelomocytes-provided-by-colleen-burge-2/index.html",
    "href": "posts/2014/2014-04-02-rna-isolation-sea-star-coelomocytes-provided-by-colleen-burge-2/index.html",
    "title": "RNA Isolation - Sea Star Coelomocytes (provided by Colleen Burge)",
    "section": "",
    "text": "Tried another method of RNA Isolation for comparison with regular TriReagent method.\nUsed the Direct-zol RNA MiniPrep Kit (Zymo Research) on the following samples stored in RNAlater:\n\nP6 Control\nP16 Filt. Inj.\n\nPelleted samples in RNAlater by spinning 5000g, 10mins @ RT. Removed RNAlater, lysed pellets in 1mL TriReagent. Split each sample equally into two tubes (500uL in each tube). Added equal volumes of 100% ethanol to each tube and vortexed. Transferred samples to spin columns and followe manufacturer’s protocol. Eluted with 25uL of nuclease-free H2O (provided in kit). Spec’d on NanoDrop1000.\nResults:\n\nRNA quality is very good (based on 260/280 ratios). This turned out much better than the previous attmpt using the basic TriReagent method. However, the previous attempt (see 20140401) may have been compromised by me being too aggressive when collecting the aqueous phase. Knowing how little sample was present, I may have been overzealous in trying to gather too much of the aqueous phase, leading to the phenol carryover that was evident.\nRegardless, these columns seem to do an excellent job of eliminating even salt carryover, as we frequently see high absorbance at 230nm with marine samples; particularly those stored in RNAlater."
  },
  {
    "objectID": "posts/2014/2014-03-14-dna-quality-check-yanouks-oyster-gdna/index.html",
    "href": "posts/2014/2014-03-14-dna-quality-check-yanouks-oyster-gdna/index.html",
    "title": "DNA Quality Check - Yanouk’s Oyster gDNA",
    "section": "",
    "text": "We’ve had some Illumina sequencing issues with Yanouk’s samples, so I ran the samples out on a 0.8% agarose gel to evaluate the levels of degradation. Loaded 2uL of each sample. Did not load equal quantities of gDNA, due to the lack of available gDNA in the samples we submitted for Illumina sequencing. Added 2uL of H2O to samples 37 & 38 in hopes of having sufficient DNA for visualization on the gel.\nSee Sam’s Notebook 20131004 for sample concentrations.\nResults:\n\nFirst lane is Hyperladder II (Bioline). Highest molecular weight of the ladder is 2kb.\nSample numbers are listed above each lane.\nAll samples show a significant amount of smearing, but all still have an identifiable high molecular weight band. Will show to Steven and discuss options for re-sequencing."
  },
  {
    "objectID": "posts/2014/2014-04-14-phenol-chloroform-dna-clean-up-mac-and-claires-samples-from-20140410/index.html",
    "href": "posts/2014/2014-04-14-phenol-chloroform-dna-clean-up-mac-and-claires-samples-from-20140410/index.html",
    "title": "Phenol-Chloroform DNA Clean Up - Mac and Claire’s Samples (from 20140410)",
    "section": "",
    "text": "Due to low 260/230 values and Mac’s smeary sample, performed a phenol-chloroform DNA cleanup on the samples isolated 20140410.\n\nBrought volume of each sample to 200uL with Buffer EB (Qiagen).\nAdded an equal volume (200uL) of 25:24:1 Phenol/Chloroform:Isoamyl alcohol.\nMixed on rotator for 20mins @ RT.\nSeparated aqueous/organic phases by spinning at 12,000g 5mins @ RT.\nTransferred aqueous phase to new tube. Repeated steps 2-4 until samples exhibited no more interphase. Combined aqueous phases in to a single tube for each of the two samples.\nAdded and equal volume of chloroform (170uL).\nMixed on rotator for 20mins @ RT.\nSeparated aqueous/organic phases by spinning at 12,000g 5mins @ RT.\nTransferred aqueous phase to new tube.\n\nPerformed an ethanol precipitation on each sample.\n\nAdded 0.1 volumes of 5M sodium acetate (pH = 5.2).\nAdded 2 volumes of ice cold 100% EtOH.\nIncubated 20mins @ -20C.\nPelleted DNA by spinning 16,000g, 20mins @ 4C.\nDiscarded supe and washed pellets with 1mL 70% EtOH.\nPelleted DNA by spinning 16,000g, 5mins @ 4C.\nRepeated steps 5-6 one time.\nRemoved all supernatant and resuspended in 100uL of nuclease-free H2O.\nSpec’d on NanoDrop1000.\n\nNOTE: Mac’s sample exhibited the same chunky/cloudiness upon addition of 100% EtOH that has been seen previously by both her and myself…\nResults:\n\n\nSo, the clean up seemed to work wonders on the 260/230 values. Not surprisingly, Mac’s sample didn’t clean up nearly as nicely as Claire’s, based on my observations of the odd behavior during EtOH precipitation.\nAnd, despite the nice, clean looking peaks, the 260/280 ratios are actually WORSE than the original isolation. Will run on gel for a further assessment of quality/integrity.\nLoaded 5uL of each sample (~600ng) on a 1.0% agarose, 1x modified TAE gel stained with ethidium bromide.\n\nGel Layout:\nLane 1 - Hyperladder I (Bioline)\nLane 2 - Claire’s CgF gonad sample\nLane 3 - Mac’s gonad sample\nUsed Hyperladder I this time, which has a high molecular weight band of 10kb and a low molecular weight band of 200bp.\nWell, this totally sucks. Both samples appear to consist of nothing but 150-200bp fragments. Is something actually degrading these samples? The Buffer EB I used during the initial extraction is certainly old. Possible source of degradation? Ugh. Maybe I’ll try this again, but resuspend in TE…"
  },
  {
    "objectID": "posts/2014/2014-12-23-bisulfite-ngs-library-lsu-c-virginica-oil-spill-mbd-bisulfite-dna-sequencing-submission/index.html",
    "href": "posts/2014/2014-12-23-bisulfite-ngs-library-lsu-c-virginica-oil-spill-mbd-bisulfite-dna-sequencing-submission/index.html",
    "title": "Bisulfite NGS Library - LSU C.virginica Oil Spill MBD Bisulfite DNA Sequencing Submission",
    "section": "",
    "text": "Combined the following libraries in equal quantities (17ng each) to create a single, multiplexed sample for sequencing (LSU_Oil_01):\n\nHB2 – 1 (ATCACG)\nHB16 – 3 (TTAGGC)\nHB30 – 4 (TGACCA)\nNB3 – 5 (ACAGTG)\nNB6 – 6 (GCCAAT)\nNB11 – 7 (CAGATC)\n\nQuantified pooled libraries using the Quant-iT dsDNA BR Kit (Invitrogen) with a FLx800 plate reader (BioTek). Used 1μL of the pooled sample, run in duplicate. Used 1uL of standards, run in duplicate.\nResults:\npooled libraries = 6.575ng/μL\nWill submit to University of Oregon Genomics Core Facility for 100bp, single end Illumina HiSeq2500 sequencing. They need 10nM of sample. For a library with average size range of 300-400bp, this requires a sample volume of 20uL with a concentration of 2.28ng/μL in a solution of 0.1% Tween20 in Buffer EB (Qiagen).\nCombined 6.94μL of pooled libraries with 13.06 of 0.1% Tween20/EB solution.\nSubmitted sample LSU_Oil_01 to University of Oregon Genomics Core Facility via O/N FedEx on dry ice. Sample was assigned order # 2112."
  },
  {
    "objectID": "posts/2014/2014-11-26-dna-shearing-lsu-c-virginica-oil-spill-gdna/index.html",
    "href": "posts/2014/2014-11-26-dna-shearing-lsu-c-virginica-oil-spill-gdna/index.html",
    "title": "DNA Shearing - LSU C.virginica Oil Spill gDNA",
    "section": "",
    "text": "Used the remainder of the “sheared” samples (see today’s earlier entry; ~2750ng). Brought the volumes up to 80uL and transferred to 0.5mL snap cap tubes. The volume of 80uL was selected because it’s above the minimum volume required for shearing in 0.5mL tubes (10uL according to the Biorupter 300 manual) and the MethylMiner Kit (Invitrogen) requires the input DNA volume to be <= 80uL.\nDNA was sheared with the following parameters:\nLow power\n30 cycles of:\n30s on\n30s off\nTarget average fragment size is ~350bp.\nSee tomorrow (20141127) for the gel."
  },
  {
    "objectID": "posts/2014/2014-05-08-rna-isolation-colleen-sea-star-pycnopodia-coelomycete-sample/index.html",
    "href": "posts/2014/2014-05-08-rna-isolation-colleen-sea-star-pycnopodia-coelomycete-sample/index.html",
    "title": "RNA Isolation - Colleen Sea Star (Pycnopodia) Coelomycete Sample",
    "section": "",
    "text": "Apparently the Bio26 sample provided on 20140428 was incorrect. Instead, the sample should have been CF26.\nSamples were initially flash frozen and then stored @ -80C (no preservatives used). No visible cells/tissue in all samples, except Bio 26. Samples were homogenized in 1mL TriReagent. Used the Direct-zol RNA MiniPrep Kit (ZymoResearch) according to the manufacturer’s protocol (including on-column DNase I procedure) for the remainder of the isolation. Eluted with 50uL of 0.1%DEPC-treated H2O and spec’d on NanoDrop1000.\nSamples were stored in Shellfish RNA Box #5.\nResults:\n\nYield and quality look great. Will pass info on to Steven and Colleen for decision on which samples to sequence.\nUPDATE 20140514 - Sample sent to Cornell for Illumina RNA-seq on 20140514"
  },
  {
    "objectID": "posts/2014/2014-12-18-bisulfite-ngs-library-prep-lsu-c-virginica-oil-spill-bisulfite-dna-and-emmas-c-gigas-larvae-oa-bisulfite-dna/index.html",
    "href": "posts/2014/2014-12-18-bisulfite-ngs-library-prep-lsu-c-virginica-oil-spill-bisulfite-dna-and-emmas-c-gigas-larvae-oa-bisulfite-dna/index.html",
    "title": "Bisulfite NGS Library Prep - LSU C.virginica Oil Spill Bisulfite DNA and Emma’s C.gigas Larvae OA Bisulfite DNA",
    "section": "",
    "text": "Constructed next generation libraries (Illumina) using the bisulfite-treated DNA from yesterday using the EpiNext Post-Bisulfite DNA Library Preparation Kit - Illumina (Epigentek). Samples were processed according to the manufacturer’s protocol up to Section 8 (Library Amplification) with the following changes:\n\nSkipped Section 7.1 (recommended to do so in the protocol due to low quantity of input DNA)\n\nSamples were stored O/N @ -20C.\ndA Tailing Master Mix\n10x Tailing Buffer 1.5uL x 17.6 = 26.4uL\nKlenow 1uL x 17.6 = 17.6uL\nH2O 0.5uL x 17.6 = 8.8uL\nAdd 3uL of master mix to each sample\nAdaptor Ligation\n2x Ligation Buffer 17uL x 17.6 - 299.2uL\nT4 DNA Ligase 1uL x 17.6uL = 17.6uL\nAdaptors 1uL x 17.6 = 17.6uL\nAdded 19uL of master mix to each sample\ndsDNA Conversion Master Mix\n5x Conversion Buffer 4uL x 17.6 = 70.4uL\nC.P. 2uL x 17.6 = 35.2uL\nH2O 3uL x 18.6 = 52.8uL\nAdd 9uL of master mix to each sample\nEnd Repair\n10x Buffer 2uL x 17.6 = 35.2uL\nEnzyme 1uL x 17.6 = 17.6uL\nH2O 5uL x 17.6 = 88uL\nAdded 8uL of master mix to each sample"
  },
  {
    "objectID": "posts/2014/2014-05-27-rna-isolation-jessicas-geoduck-larval-stages/index.html",
    "href": "posts/2014/2014-05-27-rna-isolation-jessicas-geoduck-larval-stages/index.html",
    "title": "RNA Isolation - Jessica’s Geoduck Larval Stages",
    "section": "",
    "text": "Isolated RNA from the following samples provided by Jessica Blanchette (stored in RNA later):\n\nTrocophore 1 (T1)\nTrocophore 2 (T2)\nVeliger 1 (V1)\nVeliger 2 (V2)\nSettlers Interphase 1 (S1)\nSettlers Interphase 2 (S2)\n\nThe tocophore and veliger larval stages are neutrally bouyant (i.e. will not pellet when centrifuged). In order to separate them from the RNA Later, I used a fine mesh (don’t know mesh size; bag was labeled “Unknown”) as a “guard” between the pipette tip and the larvae. Removed RNA Later from those two groups in this fashion. However, a significant portion of the larvae in these tubes adhered to the outside of the mesh. I left the mesh “guard” in the tube, added 1mL of TriReagent and vortexed. The mesh quickly dissolved in the TriReagent, creating a milky white mix.\nFor the settlers samples, there was a such a large pellet already in the existing tubes, I just took ~75uL of this material, transferred to a clean tube and added 1mL of TriReagent. However, most of the debris that I transferred dissolved extremely quickly. I was expecting there to more insoluble “debris”, because marine bivalve larval shells generally don’t readily dissolve in the presence of TriReagent. So, I suspect that much of the settlers samples is not really geoduck larvae.\nDue to time constraints, stored all samples O/N @-80C in TriReagent.\nSamples were thawed and RNA was isolated, and DNased, using the Direct-zol RNA Miniprep Kit (ZymoResearch), eluted with 50uL of 0.1% DEPC-treated H2O, and spec’d on the NanoDrop1000.\nPrior to isolation, sample V1 showed a clear phase separation that none of the other samples exhibited. Sample V1 had a pink, goopy layer on top of a clear, low-viscosity layer. All other samples retained the uniform pink coloration imparted by the TriReagent. Additionally, after addition of the EtOH in the procedure to sample V1, a large amount of white precipitate formed and settled to the bottom of the tube. This did not happen in any other samples.\nSamples were stored @ -80C in “Shellfish RNA Box #5”\nResults:\n\nOverall, the yields are relatively low, as expected. Virtually all of the samples have poor OD260/280 values. Although not shown, there was a consistent shift in peak absorbance from 260nm towards 270nm, leading to the poor OD260/280 values."
  },
  {
    "objectID": "posts/2014/2014-11-21-dna-isolation-c-gigas-larvae-from-emma-oa-experiments/index.html",
    "href": "posts/2014/2014-11-21-dna-isolation-c-gigas-larvae-from-emma-oa-experiments/index.html",
    "title": "DNA Isolation - C.gigas Larvae from Emma OA Experiments",
    "section": "",
    "text": "Isolated gDNA using DNazol from the following larval samples for potential MBD selection and bisulfite sequencing:\n\n\nAdded 500uL of DNAzol to each tube, transferred to 1.5mL tube and homogenized with disposable pestles\nAdded additional 500uL DNAzol to each homogenized sample and mixed by inversion.\nIncubated 10mins at RT\nPelleted debris by spinning 10,000g, 10mins, @ RT\nTransferred supes to new tubes\nAdded 500uL of 100% EtOH to each; mixed by inversion; incubated 10mins @ RT\nPelleted DNA by spinning 5,000g, 4mins, @ RT\nDiscarded supes\nWashed DNA with 1mL 70% DNAzol/30% EtOH solution\nSpun 1000g, 1min, @ RT\nDiscard supes\nWashed DNA with 1mL 75% EtOH\nSpun 1000g, 1min, @ RT\nDiscarded supes\nSpun 1000g, 1min, @ RT\nRemoved residual EtOH with pipette; air dried samples for 5mins @ RT\nAdded 20uL of Trish-HCl (pH = 8.0) to each sample; incubated 10mins @ RT; flicked tubes to help dissolve\nSpun 12,000g, 10mins, @ RT\nTransferred supes to new tubes\nSpec’d on NanoDrop 1000 (ThermoFisher) and recovered solution from each sample due to limited sample volume\n\nResults:"
  },
  {
    "objectID": "posts/2014/2014-12-11-dna-isolation-claires-c-gigas-female-gonad-for-illumina-bisulfite-sequencing/index.html",
    "href": "posts/2014/2014-12-11-dna-isolation-claires-c-gigas-female-gonad-for-illumina-bisulfite-sequencing/index.html",
    "title": "DNA Isolation - Claire’s C.gigas Female Gonad for Illumina Bisulfite Sequencing",
    "section": "",
    "text": "Due to poor “tag counts” from the initial sequencing (DATE) and the re-sequencing (20131127) of this sample, the HTGU facility has concluded that the library is probably at fault. They will make a new library and do a quality control run on the new library. However, they have insufficient gDNA left to make a new library.\nIsolated gDNA from Claire’s sample following the DNAzol protocol.\nTransferred ~300uL of female C.gigas gonad from the source tube (ethanol-preserved) to a clean tube. Pelleted gonadal material by spinning 10,000g, 30seconds, @ RT. Decanted residual ethanol. Resuspended tissue in 500uL of DNAzol + 100ug of Proteinase K (Fermentas; 18.5mg/mL). Incubated on a rotator for ~6hrs. Proceeded according to DNAzol protocol. Resuspended final pellet in 100uL of Elution Buffer (Qiagen; EB). After resuspension, pelleted remaining debris 16,000g, 30seconds, @ RT. Transferred supernatant to clean tube and quantified on NanoDrop 1000.\nCgF - 403.2ng/uL\nWill bring tube to sequencing facility tomorrow morning."
  },
  {
    "objectID": "posts/2014/2014-02-18-dna-precipitation-geoduck-dna-from-20140213/index.html",
    "href": "posts/2014/2014-02-18-dna-precipitation-geoduck-dna-from-20140213/index.html",
    "title": "DNA Precipitation - Geoduck DNA from 20140213",
    "section": "",
    "text": "After speaking with Axa regarding the DNA concentrations, he would like the DNA from the ethanol-fixed tissue to be more concentrated, and he wants them in ddH2O instead of Buffer AE (from the Qiagen DNeasy Kit). So, I preformed a standard ethanol precipitation. Added 0.1 volumes of 3M sodium acetate (pH = 5.2) [15uL], 2.5 volumes of 100% ethanol [412.5uL] and incubated @ -20C over the weekend.\nPelleted DNA by spinning 16,000g, 15mins @ 4C. Discarded supe, washed pellets with 1mL 70% ethanol and re-pelleted the DNA. Performed a second wash with 70% EtOH, pelleted DNA, discarded supe, resuspended DNA in 75uL of NanoPure H2O, and spec’d on NanoDrop1000.\nResults:\nWill spec when I re-isolate DNA from “fresh” geoduck samples for coordinating Axa’s DNA sequencing project with our potential RNA-seq project. See 20140219."
  },
  {
    "objectID": "posts/2014/2014-04-01-rna-isolation-sea-star-coelomocytes-provided-by-colleen-burge/index.html",
    "href": "posts/2014/2014-04-01-rna-isolation-sea-star-coelomocytes-provided-by-colleen-burge/index.html",
    "title": "RNA Isolation - Sea Star Coelomocytes (provided by Colleen Burge)",
    "section": "",
    "text": "Isolated RNA from the following samples (stored in RNAlater):\nP18 Control 3/17/14\nP10 Filt. Inj. 3/17/14\nThese were “trial” RNA isolation runs to determine what yields we could expect from samples of this nature.\nBoth samples had very small tissue/cell pellets. Tubes were spun @ 5000g for 10mins at RT to ensure all cells were pelleted. RNAlater was removed and pellets were lysed using 1000uL of TriReagent, supplemented with 8uL of PolyAcryl carrier. PolyAcryl Carrier was used to enhance RNA recovery from such small starting materials. Remainder of procedure followed manufacturer’s protocol. RNA was resuspended in 20uL of 0.1% DEPC-H2O and spec’d on a NandoDrop1000.\nResults:\n\n\n\n\nAs can be seen by the absorbance spectrum plots (top image), there is clear phenol contamination (indicated by shift of absorbance peak to 270nm, instead of the peak being at 260nm). Additionally, there’re large peaks at 230nm in each of the two samples, suggesting other contamination (high residual salts, ethanol?). Additionally, the 260/280 ratios are subpar for RNA quality (i.e. <1.9). However, these ratios could be skewed by the the residual phenol present in both samples. I may perform an ethanol precipitation on these just to see if I can get them cleaned up.\nYields for both samples are very promising."
  },
  {
    "objectID": "posts/2014/2014-04-01-dna-isolation-mackenzies-c-gigas-gonad-sample/index.html",
    "href": "posts/2014/2014-04-01-dna-isolation-mackenzies-c-gigas-gonad-sample/index.html",
    "title": "DNA Isolation - Mackenzie’s C.gigas Gonad Sample",
    "section": "",
    "text": "Mac’s been having some difficulty getting good quality gDNA from some of her gonad samples, so she asked me to give it a shot.\nIsolated DNA from 10mg (0.010g) of C.gigas gonad tissue using the Qiagen Blood & Tissue DNeasy Kit, with the following changes:\n\nIncubated sample in Buffer ATL + Proteinase K @ 56C for 3hrs\nEluted sample in 100uL of Buffer AE.\n\nSpec’d on NanoDrop1000.\nResults:\n\nDNA looks good, both 260/280 ratio and yield. The 260/230 ratio isn’t perfect, but it’s much better than what Mac was seeing. After showing her this, she’s decided to have me isolate DNA from the rest of her samples."
  },
  {
    "objectID": "posts/2014/2014-11-10-dna-quantification-oly-oyster-gdna-01-rad-library/index.html",
    "href": "posts/2014/2014-11-10-dna-quantification-oly-oyster-gdna-01-rad-library/index.html",
    "title": "DNA Quantification - Oly Oyster gDNA-01 RAD Library",
    "section": "",
    "text": "Quantified the library using the Quant-It BR Kit (Life Technologies) according to the manufacturer’s protocol. Only used 1uL of the RAD library due to the small volume (15uL).\nRAD library concentration (ng/uL): 18.688\nNeed to submit 5nM of the library for sequencing.\nAverage size = ~500bp (400bp extracted from gel + 100bp of adapters)\nMolar concentration of the RAD library is 56.63nM.\nCalcs are here: 20141110 - Oly Oyster gDNA-01 RAD Library Calcs"
  },
  {
    "objectID": "posts/2014/2014-04-25-dna-isolation-claires-c-gigas-female-gonad/index.html",
    "href": "posts/2014/2014-04-25-dna-isolation-claires-c-gigas-female-gonad/index.html",
    "title": "DNA Isolation - Claire’s C.gigas Female Gonad",
    "section": "",
    "text": "Trying this sample again(!!), but will now use TE for pellet resuspension to prevent sample degradation. Incubated sample RT on rotator in 500uL of DNazol + 2.7uL of Proteinase K (Fermentas; Stock 18.5mg/mL) for 5hrs. Added additional 500uL of DNazol, mixed gently and followed DNazol manufacturer’s protocol. Performed first pellet was with 70% DNazol/ 30% EtOH solution. Resuspended pellet in 200uL of TE and spec’d on NanoDrop1000.\nResults:\n\nYield is good. 260/280 value is good. 260/230 value is poor. Will run on gel to evaluate integrity.\nLoaded 10uL (~830ng) on 1.0% agarose 1x modified TAE gel stained with EtBr.\n\nGel Loading Guide:\nLane 1 - Hyperladder I (Bioline)\nLane 2 - C.gigas female gonad gDNA (CgF)\nWell, this certainly looks much better than previous preparations, in that there is an obvious high molecular weight band present (previously, this had been absent). The low molecular weight bands/smears are possibly RNA carryover and/or degraded DNA. Will discuss with Steven and then, most likely, bring downtown for Illumina sequencing.\nUPDATE 20140508: Downtown sequencing facility says there’s only ~800ng of DNA! This is a far cry from the minimum amount needed for sequencing (6ug). Looking at the gel above and comparing sample band intensity to the ladder band intensities suggests that the downtown sequencing facility is correct. I loaded 10uL of DNA on the gel and the intensity of the high molecular weight band is similar to the 400bp band intensity. This corresponds to 40ng of DNA. That means the CgF gDNA band is 40ng/10uL = 4ng/uL. I resuspended the gDNA pellet in 200uL of TE, so 200uL x 4ng/uL = 800ng; exactly what the sequencing facility says they measured…\nI’m not entirely sure what is happening here. Until very recently, there were almost never such egregious differences between the NanoDrop measurements and what they were measuring downtown at the sequencing facility. It seems as though they have changed the way they quantify samples (possibly using an Agilent Bioanalyzer instead of the Life Technologies Qubit fluorometer?), but this doesn’t mean their measurements are incorrect. However, I’m starting to suspect that the reason the initial sequencing of this sample was due to an overestimation of the quantity of input DNA (since I believe they were still using the fluorometer back then).\nAs such, it’s become clear that C.gigas gonad samples seem to yield poor quantities of gDNA, relative to the amount of input material. Additionally, there may be insufficient sample left to generate a useable quantity of gDNA to complete this resequencing effort."
  },
  {
    "objectID": "posts/2014/2014-04-16-rna-isolation-colleens-sea-star-coelomycetes-samples/index.html",
    "href": "posts/2014/2014-04-16-rna-isolation-colleens-sea-star-coelomycetes-samples/index.html",
    "title": "RNA Isolation - Colleens’ Sea Star Coelomycetes Samples",
    "section": "",
    "text": "Isolated RNA from the following samples stored in RNAlater:\n\nTH52 3.28.14 c-fluid\nTH54 3.28.14 c-fluid\nCH55 3.28.14 c-fluid\nCH56 3.28.14 c-fluid\nCH57 3.28.14 c-fluid\nTH65 3.28.14 c-fluid\nTH66 3.28.14 c-fluid\nTH67 3.28.14 c-fluid\n\nSpun samples 5000g, 20mins @ RT to pellet any cells. Discarded supe. Resuspended cells/debris in 1mL TriReagent. Disrupted cells by pipetting and vortexting. RNA was isolated using the Direct-zol RNA Miniprep Kit (ZymoResearch). RNA was DNase treated on-column, as described in the manufacturer’s protocol, using DNase I. RNA was eluted from the columns using 25uL of nuclease-free H2O and spec’d on a NanoDrop1000.\nResults:\n\n\n\n\nSo, this is disheartening. Overall, the RNA looks pretty crappy; poor 260/280 ratios and a general shift in absorbance to 270nm. Plus, the yields aren’t that great. Maybe RNA left on the column and/or some sort of contaminant pushing these readings out of whack?\nI will perform another elution on the columns with 50uL of nuclease-free H2O and spec that elution set:\n\nThere’s still a shift in the peak absorbance in most samples to 270nm… I’m going to combine the two sets of elutions and spec:\n\n\nAlthough the 260/280 values are significantly better, there’s still this persistent shift of peak absorbance to 270nm. I contacted technical support for the kit and they say the absorbance shift is indicative of phenol contamination. They have advised that I add a volume of TriReagent to the RNA and re-run it through a new set of columns, following the entire RNA isolation protocol."
  },
  {
    "objectID": "posts/2014/2014-05-16-dna-isolation-mackenzies-c-gigas-ee2-gonad-samples/index.html",
    "href": "posts/2014/2014-05-16-dna-isolation-mackenzies-c-gigas-ee2-gonad-samples/index.html",
    "title": "DNA Isolation - Mackenzie’s C.gigas EE2 Gonad Samples",
    "section": "",
    "text": "Isolated DNA from the following samples, provided by Mackenzie:\n\nEE2v2, 22.go\nEE2v2, 20.go\nEE2v2, 28.go\nEE2v2, 29.go\nEE2v2, 16.go\nEE2v2, 32.go\nEE2v2, 24.go\nEE2v2, 33.go\n\nSamples were suspended in 500uL of DNazol (Molecular Research Center), 5uL of PolyAcryl Carrier (Molecular Research Center), 2.75uL Proteinase K (Fermentas; 18.5mg/mL stock), briefly vortexed and incubated 24hrs at RT on rotator. Samples were briefly vortexed and insoluble material was pelleted 10,000g, 10mins, RT. Supe was transferred to fresh tube, mixed with 250uL of 100% EtOH, incubated at RT 5mins, and DNA was pelleted by spinning samples 5,000g, 5mins, RT. Supe was discarded, pellets washed with 1mL of 70% DNazol/30% EtOH solution. Supe was discarded and pellets were washed with 1mL 70% EtOH. Pellets were stored @ -20C under 95% EtOH over the weekend. Supe was discarded and pellets were washed with 70% EtOH. This step was repeated 2 more times. Supe was discarded and pellets were resuspended in Low TE Buffer, spec’d on NanoDrop1000 and run on a gel (10uL of each sample).\nResults:\n\nYields look good and OD260/280 values look excellent. Most of the OD260/230 values aren’t good, but they rarely are.\n\nGel Loading:\nLane 1 - Hyperladder I (Bioline)\nLane 2 - EV2 16.go\nLane 3 - EV2 20.go\nLane 4 - EV2 22.go\nLane 5 - EV2 24.go\nLane 6 - EV2 28.go\nLane 7 - EV2 29.go\nLane 8 - EV2 32.go\nLane 9 - EV2 33.go\nLane10- Hyperladder I (Bioline)\nAll samples (excluding EV2 22.go) look pretty good, with minimal smearing. All samples exhibit low molecular weight smear which is either degraded DNA or residual RNA carryover. EV2 22.go had very little tissue, so yields were expected to be extremely low. However, I was anticipating to be able to visualize it on the gel (loaded 10uL = ~90ug)."
  },
  {
    "objectID": "posts/2014/2014-10-31-restriction-digest-oly-oyster-gdna-01-for-rad-sequencing-from-20141029/index.html",
    "href": "posts/2014/2014-10-31-restriction-digest-oly-oyster-gdna-01-for-rad-sequencing-from-20141029/index.html",
    "title": "Restriction Digest - Oly Oyster gDNA-01 for RAD Sequencing (from 20141029)",
    "section": "",
    "text": "Samples required two days of drying for all samples to fully dry down.\nReconstituted all samples in 20uL of PCR H2O.\nPerformed restriction digests:\n\nIncubated at 37C for 90mins and then inactivated enzyme @ 80C for 20mins. Incubation was done in thermal cycler using heated lid. Plate was stored @ -20C."
  },
  {
    "objectID": "posts/2014/2014-02-19-dna-isolation-geoduck/index.html",
    "href": "posts/2014/2014-02-19-dna-isolation-geoduck/index.html",
    "title": "DNA Isolation - Geoduck",
    "section": "",
    "text": "Isolated additional geoduck gDNA from the two fresh (now frozen) geoduck’s that Brent provided me with on 20140212 so that we can potentially isolate RNA from the same geoducks to tie in with the DNA Illumina sequencing that Axa will be conducting. Isolated DNA using the DNeasy Blood & Tissue Kit (Qiagen) according to the manufacturer’s protocol (incubated minced siphon tissue at 56C for 3hrs). Eluted with 75uL of ddH2O and spec’d on NanoDrop1000.\nNote: Initial specs were too low for Axa’s requirements (50uL, >= 500ng/uL). SpeedVac’d samples to concentrate, brought volume to 55uL and then spec’d on NanoDrop1000.\nResults:\n\nSamples look good. Will send Axa 50uL of all samples, excluding GD01 since that sample is below his desired concentration AND I believe he probably doesn’t want to wait for this DNA any longer."
  },
  {
    "objectID": "posts/2014/2014-11-07-library-prep-oly-oyster-gdna-01-rad/index.html",
    "href": "posts/2014/2014-11-07-library-prep-oly-oyster-gdna-01-rad/index.html",
    "title": "Library Prep - Oly Oyster gDNA-01 RAD",
    "section": "",
    "text": "Used gel-purified, size-selected DNA from yesterday to prepare the RAD library using the Kappa LTP Kit:\nhttps://eagle.fish.washington.edu/trilobite/Sites_genefish_100112/Steven/Commercial%20Protocols/KAPA_Biosystems%20-%20KAPA_LTP_Library_Preparation_Kit_TDS.pdf\nThe protocol was followed with the following changes:\n\nSection 8\n\nSkipped entirely\n\nSection 9.1\n\nUsed 10uL of library DNA (instead of 20uL)\nUsed 1uL of mixed primer set (instead of 5uL)\n\nSection 9.2\n\nPerformed 12 cycles of PCR protocol. This was Carita’s recommendation and experience with using the Kappa LTP Kit for RAD library construction.\nSample was eluted from the AMPure beads with 15uL of Buffer EB (Qiagen) and stored @ -20C."
  },
  {
    "objectID": "posts/2014/2014-09-27-package-received-package-from-jerome-lapeyre-from-lsu/index.html",
    "href": "posts/2014/2014-09-27-package-received-package-from-jerome-lapeyre-from-lsu/index.html",
    "title": "Package - Received Package from Jerome LaPeyre from LSU",
    "section": "",
    "text": "Oyster (C.virginica) gill samples exposed to “no oil” and “highest level of oil.” Samples were stored in Rack #2 in the -80C. Images of the box label and included paperwork below."
  },
  {
    "objectID": "posts/2014/2014-04-04-cloned-hard-drive-windows-xp-opticon-computer-aquacul8/index.html",
    "href": "posts/2014/2014-04-04-cloned-hard-drive-windows-xp-opticon-computer-aquacul8/index.html",
    "title": "Cloned Hard Drive - Windows XP Opticon Computer (Aquacul8)",
    "section": "",
    "text": "Cloned the XP hard drive of the computer hooked up to the Opticon qPCR machine using Macrium Reflect Free. Verified that the clone is bootable and operates correctly. Will store one of the hard drives."
  },
  {
    "objectID": "posts/2014/2014-11-24-rna-seq-c-gigas-total-rna-from-claires-prepost-heat-shock/index.html",
    "href": "posts/2014/2014-11-24-rna-seq-c-gigas-total-rna-from-claires-prepost-heat-shock/index.html",
    "title": "RNA Seq - C.gigas Total RNA from Claire’s Pre/Post Heat Shock",
    "section": "",
    "text": "Shipped (dry ice) ~15ug of total RNA from each of the following samples to Genewiz, Inc for high throughput transcriptomic sequencing (Illumina HiSeq2500, 100bp, single end).\n\n2M - 33uL\n4M - 41uL\n6M - 15.6uL\n2M HS - 15uL\n4M HS - 12.2uL\n6M HS - 15.2uL\n\nHere’s Claire’s notebook entry on their isolation and quantification:\nhttps://claireeolson.blogspot.com/2014/10/rna-extractions.html"
  },
  {
    "objectID": "posts/2014/2014-04-28-rna-isolation-colleen-sea-star-pycnopodia-coelomycete-samples/index.html",
    "href": "posts/2014/2014-04-28-rna-isolation-colleen-sea-star-pycnopodia-coelomycete-samples/index.html",
    "title": "RNA Isolation - Colleen Sea Star (Pycnopodia) Coelomycete Samples",
    "section": "",
    "text": "Isolated RNA from the following samples (provided by Colleen Burge):\n\nBio 26 (a LARGE amount of tissue/debris in this sample!)\nCF 2\nCF 3\nCF 17\nCF 34\nCF 35\nCF 70\nCF 71\n\nSamples were initially flash frozen and then stored @ -80C (no preservatives used). No visible cells/tissue in all samples, except Bio 26. Samples were homogenized in 1mL TriReagent. Used the Direct-zol RNA MiniPrep Kit (ZymoResearch) according to the manufacturer’s protocol (including on-column DNase I procedure) for the remainder of the isolation. Eluted with 50uL of 0.1%DEPC-treated H2O and spec’d on NanoDrop1000.\nSamples were stored in Shellfish RNA Box #5.\nResults:\n\nSamples CF 3 and CF 17 likely have insufficient total RNA for sequencing at Cornell (200ng minimum required).\nUPDATE 20140514 - CF2, CF34, CF35, CF70, CF71 sent to Cornell for Illumina RNA-seq on 20140514"
  },
  {
    "objectID": "posts/2015/2015-01-09-dna-isolation-c-gigas-larvae-from-2011-noaa-oa-experiment/index.html",
    "href": "posts/2015/2015-01-09-dna-isolation-c-gigas-larvae-from-2011-noaa-oa-experiment/index.html",
    "title": "DNA Isolation - C.gigas larvae from 2011 NOAA OA Experiment",
    "section": "",
    "text": "SAMPLE ID\n\n\nDATE\n\n\nTREATMENT (ppm)\n\n\n\n\n\n\n\n\n6B5\n\n\n20110513\n\n\n400\n\n\n5,000\n\n\n\n\n1B2\n\n\n20110513\n\n\n1000\n\n\n5,000\n\n\n\n\n6B2\n\n\n20110513\n\n\n400\n\n\n10,000\n\n\n\n\n1B1\n\n\n20110513\n\n\n1000\n\n\n10,000\n\n\n\n\n1B1\n\n\n20110519\n\n\n1000\n\n\nNA\n\n\n\n\n1B2\n\n\n20110519\n\n\n1000\n\n\nNA\n\n\n\n\n6B2\n\n\n20110519\n\n\n400\n\n\nNA\n\n\n\n\n6B1\n\n\n20110519\n\n\n400\n\n\nNA\nSome tubes contained a high quantity of algae, based on quantity of material in tube and overall green color.\nSamples 1B1 & 1B2 from 20110519 have excessive quantities of algae.\nSamples 6B1 & 6B1 from 20110519 have a fair amount of algae.\nSee pic:\n[caption id=“” align=“alignnone” width=“676”] Sample tubes after brief spin, prior to DNA isolation.[/caption]\nPrior to isolation, samples were briefly spun (12,000g, 15s @ RT). Supernatants were discarded."
  },
  {
    "objectID": "posts/2015/2015-01-09-dna-isolation-c-gigas-larvae-from-2011-noaa-oa-experiment/index.html#dna-isolation",
    "href": "posts/2015/2015-01-09-dna-isolation-c-gigas-larvae-from-2011-noaa-oa-experiment/index.html#dna-isolation",
    "title": "DNA Isolation - C.gigas larvae from 2011 NOAA OA Experiment",
    "section": "DNA Isolation",
    "text": "DNA Isolation\nDNA was isolated using the DNeasy Blood & Tissue Kit (Qiagen).\nSamples were resuspended in 180uL of Buffer AL and 20uL of Proteinase K. Samples were mixed by vortexing and incubated @ 56C O/N.\nThe manufacturer’s protocol (Purification of Total DNA from Animal Tissues (Spin-Column Protocol)) was followed.\nDue to low quantities of starting tissue, samples were eluted with 200μL of Buffer EB to maximize DNA recovery."
  },
  {
    "objectID": "posts/2015/2015-01-09-dna-isolation-c-gigas-larvae-from-2011-noaa-oa-experiment/index.html#dna-quantification",
    "href": "posts/2015/2015-01-09-dna-isolation-c-gigas-larvae-from-2011-noaa-oa-experiment/index.html#dna-quantification",
    "title": "DNA Isolation - C.gigas larvae from 2011 NOAA OA Experiment",
    "section": "DNA Quantification",
    "text": "DNA Quantification\nSamples were prepared for quantification via fluorescence using the Quant-iT DNA BR Kit (Life Technologies/Invitrogen). The manufacturer’s protocol was altered to use 5μL of sample and 5μL of standards (instead of 10μL) in each well. All samples/standards were run in duplicate and read on a FLx800 plate reader (BioTek).\nMean fluorescence of the standards were plotted with a best-fit line. The resulting equation from the best-fit line was used to determine sample concentrations from their mean fluorescence.\n\nResults:\n\nCalcs and resulting quantities are here:\nhttps://docs.google.com/spreadsheets/d/1e7EF05akWeBtO7Xz0UWXhIzRlkVU5HA_rjCE3c4SPEw/edit?usp=sharing\n``\nAll samples have yields great enough to proceed with shearing and bisulfite conversion.\nSamples 1B1 and 1B2 from 20110519 have extremely large yields.  This is not surprising, considering the amount of algae present in the source tubes.  Will process only 500ng from each sample."
  },
  {
    "objectID": "posts/2015/2015-01-09-dna-isolation-c-gigas-larvae-from-2011-noaa-oa-experiment/index.html#dna-shearing",
    "href": "posts/2015/2015-01-09-dna-isolation-c-gigas-larvae-from-2011-noaa-oa-experiment/index.html#dna-shearing",
    "title": "DNA Isolation - C.gigas larvae from 2011 NOAA OA Experiment",
    "section": "DNA Shearing",
    "text": "DNA Shearing\nAdjusted volume of all samples to 190μL using Buffer EB (Qiagen) in 1.5mL snap-cap tubes.\nSamples were sonicated/sheared in the Bioruptor (Diagenode) with the following cycling protocol:\n25 cycles of:\n30s on\n30s off\nCycling params were adjusted from the last time I performed this, since I felt the final sheared size was a bit on the small size.\nAfter shearing, samples were stored @ 4C until I could SpeedVac them to reduce their volumes, as the bisulfite treatment step requires volumes < 24uL."
  },
  {
    "objectID": "posts/2015/2015-09-19-uninterruptible-power-supplies-ups/index.html",
    "href": "posts/2015/2015-09-19-uninterruptible-power-supplies-ups/index.html",
    "title": "Uninterruptible Power Supplies (UPS)",
    "section": "",
    "text": "A new UPS we installed this week for our qPCR machine (Opticon2 - BioRad) to handle power surges and power outages doesn’t seem to be working properly. With the qPCR machine (and computer and NanoDrop1000) plugged into the “battery” outlets on the UPS, this is what happens when the Opticon goes through a heating cycle:\n[caption id=“” align=“alignnone” width=“727”](http://eagle.fish.washington.edu/Arabidopsis/20150918_opticon_ups_battery.jpg) The UPS becomes overloaded when the Opticon is in a heating cycle.[/caption]\nAnd, sometimes, that results in triggering a fault, shutting everything off in the middle of a qPCR run:\n[caption id=“” align=“alignnone” width=“733”](http://eagle.fish.washington.edu/Arabidopsis/20150918_opticon_surge_fault.jpg) Fault message indicating unit overload.[/caption]\nThis is supremely lame because having a battery backup is a great way to prevent the qPCR machine from shutting off when a power outage occurs!\nI switched the Opticon (and computer and NanoDrop1000) to the outlets that are solely for surge protection. Check out what happens when I run the qPCR machine now:\n[caption id=“” align=“alignnone” width=“738”](http://eagle.fish.washington.edu/Arabidopsis/20150918_opticon2_ups_surge.jpg) Opticon plugged in to surge protection outlet while in heating cycle. Notice that output load is 0%.[/caption]\nSo, I guess we’ll settle for at least having the surge protection aspect of things.\nWhile handling this UPS issue, I realized that the two Synology servers we have possess a built-in UPS monitor. So, I connected the USB cables to/from each of the UPS that each server is plugged into and enabled UPS shutdown in the Synology Diskstation Management (DSM):\n[caption id=“” align=“alignnone” width=“744”](http://eagle.fish.washington.edu/Arabidopsis/20150918_eagle_ups.jpg) Eagle[/caption]\n[caption id=“” align=“alignnone” width=“754”](http://eagle.fish.washington.edu/Arabidopsis/20150918_owl_ups.jpg) Owl[/caption]\nNow, both Synology units will enter Safe Mode when the UPS they’re connected to reaches a low battery status. This will help minimize data loss/corruption during the next extended power outage we experience."
  },
  {
    "objectID": "posts/2015/2015-04-22-bioanalyzer-submission-geoduck-rna-from-histology-blocks/index.html",
    "href": "posts/2015/2015-04-22-bioanalyzer-submission-geoduck-rna-from-histology-blocks/index.html",
    "title": "Bioanalyzer Submission - Geoduck Gonad RNA from Histology Blocks",
    "section": "",
    "text": "Submitted 3μL (~75ng) of RNA from each of the two gonad samples isolated from foot tissue embedded in paraffin histology blocks 20150408 (to assess quality of RNA) to Jesse Tsai at University of Washington Department of Environmental and Occupational Health Science Functional Genomics Laboratory:\n\nGeoduck Block 34\nGeoduck Block 42\n\nJesse will determine if the samples should be run on the RNA Pico or the RNA Nano chips."
  },
  {
    "objectID": "posts/2015/2015-10-06-sample-submission-additional-geoduck-gdna-for-genome-sequencing-bgi/index.html",
    "href": "posts/2015/2015-10-06-sample-submission-additional-geoduck-gdna-for-genome-sequencing-bgi/index.html",
    "title": "Sample Submission - Additional Geoduck gDNA for Genome Sequencing @ BGI",
    "section": "",
    "text": "Previous shipment of gDNA proved to be of insufficient quantity when assessed by BGI, so needed to isolate more.\nShipped the pooled gDNA we’ve been accumulating to BGI to contine the geoduck genome sequencing project.\nSample was shipped on dry ice with the appropriate paperwork required by BGI (sample declaration letter).\nAssigned BGI Lot: 1510071003"
  },
  {
    "objectID": "posts/2015/2015-10-22-dna-isolations-fidalgo-2sn-reciprocal-transplants-final-samplings/index.html",
    "href": "posts/2015/2015-10-22-dna-isolations-fidalgo-2sn-reciprocal-transplants-final-samplings/index.html",
    "title": "DNA Isolations - Fidalgo 2SN Reciprocal Transplants Final Samplings",
    "section": "",
    "text": "The remaining Olympia oysters from Jake Heare’s reciprocal transplant experiment have been retrieved from field sites and are awaiting sampling. The oysters have been stored in the cold room (temp?) for 6 days so far.\nSampling scheme is as follows:\n\nAssign unique number to oysters\nPhotograph with ruler for future shell measurements\nWeigh oysters\nDissect ctenidia for DNA isolation\nDissect & discard viscera (e.g. digestive gland and gonad)\nWeigh remaining body\nPreserve remaining body in RNAlater\nWeigh empty shells\n\nMrunmayee photographed & initiated dissections of oysters #3 - 8. I took over for oyster #9 -14.\nAll oyster data is here (Google Sheet): Oly reciprocal final sampling\nDNA was isolated using the E.Z.N.A. Mollusc Kit (Omega Biotek) according to the manufacturer’s protocol with the following changes:\n\nNo optional steps were performed\nCtenidia tissue was lysed for 3hrs @ 60C\nSingle elution of 50μL\n\nSamples were stored @ -20C in: Oly gDNA Oly Reciprocal Transplant Final Sampling Box #1."
  },
  {
    "objectID": "posts/2015/2015-05-15-dnase-treatment-jakes-o-lurida-ctenidia-rna-1hr-heat-shock-from-20150506/index.html",
    "href": "posts/2015/2015-05-15-dnase-treatment-jakes-o-lurida-ctenidia-rna-1hr-heat-shock-from-20150506/index.html",
    "title": "DNase Treatment - Jake’s O.lurida Ctenidia RNA (1hr Heat Shock) from 20150506",
    "section": "",
    "text": "Since the O.lurida RNA I isolated on 20150506 showed residual gDNA via qPCR, I treated 1.5μg of RNA from each sample using the Turbo DNA-free Kit (Ambion/Life Technologies), following the “rigorous” protocol.\nBriefly:\n\n50μL reactions were carried out in 0.5mL tubes\nadded 1μL of DNase to each tube\nincubated 30mins @ 37C\nadded additional 1μL of DNased\nincubated 30mins @ 37C\nadded 0.2 vols (10.2μL) of DNase Inactivation Reagent\nincubated and mixed for 2mins @ RT\ntransferred 50μL of supe to sterile 1.5mL snap cap tubes\nspec’d on Roberts Lab NanoDrop1000\n\nSamples were stored @ -80C in Shellfish RNA Box #5 and Box #6.\nDNase reaction calcs: 20150514_Jake_Oly_1hr_HS_DNase_calcs\nResults:\nGoogle Spreadsheet: 20150514_DNased_RNA_Jake_Oly_1hr_HS_ODs\n(http://eagle.fish.washington.edu/Arabidopsis/20150514_DNased_RNA_Jake_oly_1hr_HS_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150514_DNased_RNA_Jake_oly_1hr_HS_plots_01.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150514_DNased_RNA_Jake_oly_1hr_HS_plots_02.JPG)\nAll samples look pretty good except for HT1 8 (RNA concentration is ridiculously high!) and NT1 8 (RNA concentration is way below expected). Will check for residual gDNA via qPCR."
  },
  {
    "objectID": "posts/2015/2015-05-22-bioinformatics-trimmomaticfastqc-on-c-gigas-larvae-oa-ngs-data-2/index.html",
    "href": "posts/2015/2015-05-22-bioinformatics-trimmomaticfastqc-on-c-gigas-larvae-oa-ngs-data-2/index.html",
    "title": "Bioinformatics – Trimmomatic/FASTQC on C.gigas Larvae OA NGS Data",
    "section": "",
    "text": "Previously trimmed the first 39 bases of sequence from reads from the BS-Seq data in an attempt to improve our ability to map the reads back to the C.gigas genome. However, Mac (and Steven) noticed that the last ~10 bases of all the reads showed a steady increase in the %G, suggesting some sort of bias (maybe adaptor??):\n(http://eagle.fish.washington.edu/Arabidopsis/20150506_trimmed_2212_lane2_CTTGTA_L002_R1_001_fastqc/Images/per_base_sequence_content.png)\nAlthough I didn’t mention this previously, the figure above also shows an odd “waves” pattern that repeats in all bases except for G. Not sure what to think of that…\nQuick summary of actions taken (specifics are available in Jupyter notebook below):\n\nTrim first 39 bases from all reads in all raw sequencing files.\nTrim last 10 bases from all reads in raw sequencing files\nConcatenate the two sets of reads (400ppm and 1000ppm treatments) into single FASTQ files for Steven to work with.\n\nRaw sequencing files:\n\n2212_lane2_CTTGTA_L002_R1_001.fastq.gz\n2212_lane2_CTTGTA_L002_R1_002.fastq.gz\n2212_lane2_CTTGTA_L002_R1_003.fastq.gz\n2212_lane2_CTTGTA_L002_R1_004.fastq.gz\n2212_lane2_GCCAAT_L002_R1_001.fastq.gz\n2212_lane2_GCCAAT_L002_R1_002.fastq.gz\n2212_lane2_GCCAAT_L002_R1_003.fastq.gz\n2212_lane2_GCCAAT_L002_R1_004.fastq.gz\n2212_lane2_GCCAAT_L002_R1_005.fastq.gz\n2212_lane2_GCCAAT_L002_R1_006.fastq.gz\n\nNotebook Viewer: 20150521_Cgigas_larvae_OA_Trimmomatic_FASTQC\nJupyter (IPython) notebook: 20150521_Cgigas_larvae_OA_Trimmomatic_FASTQC.ipynb\n\n\n\nOutput files\nTrimmed, concatenated FASTQ files 20150521_trimmed_2212_lane2_400ppm_GCCAAT.fastq.gz 20150521_trimmed_2212_lane2_1000ppm_CTTGTA.fastq.gz\nFASTQC files 20150521_trimmed_2212_lane2_400ppm_GCCAAT_fastqc.html 20150521_trimmed_2212_lane2_400ppm_GCCAAT_fastqc.zip\n20150521_trimmed_2212_lane2_1000ppm_CTTGTA_fastqc.html 20150521_trimmed_2212_lane2_1000ppm_CTTGTA_fastqc.zip\nExample of FASTQC analysis pre-trim:\n(http://eagle.fish.washington.edu/Arabidopsis/20150414_trimmed_2212_lane2_CTTGTA_L002_R1_001_fastqc/Images/per_base_sequence_content.png)\nExample FASTQC post-trim (from 400ppm data):\n(http://eagle.fish.washington.edu/Arabidopsis/20150521_trimmed_2212_lane2_400ppm_GCCAAT_fastqc/Images/per_base_sequence_content.png)\nTrimming has removed the intended bad stuff (inconsistent sequence in the first 39 bases and rise in %G in the last 10 bases). Sequences are ready for further analysis for Steven.\nHowever, we still see the “waves” pattern with the T, A and C. Additionally, we still don’t know what caused the weird inconsistencies, nor what sequence is contained therein that might be leading to that. Will contact the sequencing facility to see if they have any insight."
  },
  {
    "objectID": "posts/2015/2015-07-02-goals-july-2015/index.html",
    "href": "posts/2015/2015-07-02-goals-july-2015/index.html",
    "title": "GOALS - July 2015",
    "section": "",
    "text": "Before we check out this month’s goals, let’s have a quick review of last month’s goals and which, if any, I was able to accomplish:\n\n\n From June 2015:\n\nGeoduck Reproductive Development Transcriptomics\nDone. Data from this was received 20150629.\n\n\nBS-Seq Illumina Data Assembly/Mapping – C.gigas larvae OA\nLittle progress. No response from Univ. of Oregon. However, it seems that Mac has been having a similar issue with libraries constructed using Epigentek kits. She has contacted Illumina and Epigentek for help.\n\n\nGeoduck & Olympia Oyster Genome Sequencing\nNo progress. Purchasing personnel (both departmental and university) appear to have had difficulty contacting BGI. I have put both purchasing personnel in contact with the BGI rep (Frank Hu), so things are starting to progress. Still not certain why they were unable to accomplish this.\n\n\nMiscellany\nGoal(s):\n\nMigrate Wikispaces notebook to this notebook\nAdd to GitHub code pages\nFlesh out/create README files on server(s)\nLab cleanup tasks\nAssist on Jonathan’s Capstone project\nEstablish go-to location for lab personnel questions\nTeach Unix shell at Software Carpentry\n\nStatus:\n\nMigrate Wikispaces notebook to this notebook – Minimal progress\nAdd to GitHub code pages – Updated “Commercial Protocols”, improved wget command for offline notebook backups\nFlesh out/create README files on server(s) – Some progress, but mostly on the notebook backups and newly received transcriptomic data. No progress on older directories.\nLab cleanup tasks – Partial progress. Autoclaved multiple bags of old autoclave trash.\nAssist on Jonathan’s Capstone project – Improved my time management working with Jonathan, but his sequencing results are a bit odd and he needs guidance on how to manipulate, and comprehend, what the data means.\nSuccessfully taught both the shell and GitHub at Software Carpentry.\n\n\n\n\n\nO.lurida RNA Isolation and Reverse Transcription\nNeed to isolate RNA from a set of Jake’s mechanically-stressed oyster tissue. Need to clarify with Steven if we want the 1hr post-mechanically stressed to “match” with the 1hr heat shock samples that were previously processed, or if we want the 24hr post-mechanically stressed samples.\n\n\nMiscellany\nNeed to address short-falls from the EH&S annual lab inspection. Most are minor, easily addressed issues and won’t take much time (e.g. print lab safety signs in color). The various computer tasks still stand: notebook migration from Wikispaces to this notebook, transitioning lab resources from Wikispaces to GitHub, creating/updating “readme” files for directories on our servers, etc. Lab organization goals: improve -80C organization and create an online inventory of the -80C, establish an online inventory of lab supply locations (i.e. thermometers can be found in FTR209, Drawer #02), general clean up."
  },
  {
    "objectID": "posts/2015/2015-01-23-library-cleanup-lsu-c-virginica-mbd-bs-library/index.html",
    "href": "posts/2015/2015-01-23-library-cleanup-lsu-c-virginica-mbd-bs-library/index.html",
    "title": "Library Cleanup - LSU C.virginica MBD BS Library",
    "section": "",
    "text": "I was contacted by the sequencing facility at the University of Oregon regarding a sample quality issue with our library.  As evidenced by the electropherogram below, there is a great deal of adaptor primer dimer (the peak at 128bp):\n(http://eagle.fish.washington.edu/Arabidopsis/20150120_LSUoilNGSlibraryBioanalyzer.png)\nThis is a problem because such a high quantity of adaptor sequence will result in the majority of reads coming off the Illumina being just adaptor sequences.\nWith the remainder of the library sample prepared earlier, I performed the recommended clean up procedure for removing adaptor sequences in the EpiNext Post-Bisulfite DNA Library Preparation Kit – Illumina (Epigentek).    Briefly:\n\nBrought sample volume up to 20uL with NanoPure H2O (added 9.99uL)\nAdded equal volume of MQ Beads\nWashed beads 3x w/80% EtOH\nEluted DNA w/12uL Buffer EB (Qiagen)\n\nAfter clean up, quantified the sample via fluorescence using the Quant-iT DNA BR Kit (Life Technologies/Invitrogen).  Used 1uL of the sample and the standards.  All standards were run in duplicate and read on a FLx800 plate reader (BioTek).\nResults are here: 20150122 - LSU_virginicaMBDlibraryCleanup\nLibrary concentration = 2.46ng/uL\nBrought the entire sample up to 20uL with Buffer EB (Qiagen) and a final concentration of 0.1% Tween-20 (required by the sequencing facility).\nSent sample to the University of Oregon to replace our previous submission."
  },
  {
    "objectID": "posts/2015/2015-03-04-dna-quantification-claires-c-gigas-sheared-dna/index.html",
    "href": "posts/2015/2015-03-04-dna-quantification-claires-c-gigas-sheared-dna/index.html",
    "title": "DNA Quantification - Claire’s C.gigas Sheared DNA",
    "section": "",
    "text": "In an attempt to obtain the most accurate measurement of Claire’s sheared, heat shock mantle DNA, I quantified the samples using a third method: fluorescence.\nSamples were quantified using the Quant-It DNA BR Kit (Life Technologies/Invitrogen) according the manufacturer’s protocol. Standards were run in triplicate. Due to low sample volumes, only 1μL of each sample was used and was not replicated.\nPlate was read on a Perkin Elmer plate reader using the Wallac software. The plate was measured three times, with each well measured for a one second duration on each read.\nResults:\nSpreadsheet: 20150303_gigasHSshearedDNApico\nComparison of NanoDrop1000, Bioanalyzer, and fluorescence measurements:\n\n\n\n\n\nSample\n\n\nNanoDrop (ng/μL)\n\n\nBioanalyzer (ng/μL)\n\n\nFluorescence (ng/μL)\n\n\n\n\n2M sheared\n\n\n48.03\n\n\n16.28\n\n\n4.91\n\n\n\n\n4M sheared\n\n\n190.96\n\n\n58.52\n\n\n48.10\n\n\n\n\n6M sheared\n\n\n141.56\n\n\n42.98\n\n\n28.42\n\n\n\n\n2MHS sheared\n\n\n221.93\n\n\n32.45\n\n\n13.48\n\n\n\n\n4MHS sheared\n\n\n257.48\n\n\n43.82\n\n\n11.75\n\n\n\n\n6MHS sheared\n\n\n202.02\n\n\n51.12\n\n\n8.97\n\n\n\n\n\nNot entirely surprising, but the fluorescence method is clearly the most conservative measurement of the three methods. However, I do find the difference between the Bioanalyzer and fluorescence measurements very surprising. I suspected the Bioanalyzer would underestimate the concentrations because I actively selected which peak regions to measure, possibly leaving out some aspect of the sample.\nRegardless, will use the most conservative measurements (fluorescence) for decision making.\nWith our yields, we have insufficient DNA to conduct MeDIP and then subsequent bisulfite conversion and library prep on our own. The recovery from the MeDIP will result in too little input DNA for bisulfite conversion and, in turn, library prep.\nHowever, we do have sufficient quantities of starting DNA (>200ng) for Epigentek’s MeDIP Methyl-seq. I have contacted Epigentek to see if their procedure includes bisulfite conversion after MeDIP (which the website workflow suggests that it does not)."
  },
  {
    "objectID": "posts/2015/2015-10-01-goals-october-2015/index.html",
    "href": "posts/2015/2015-10-01-goals-october-2015/index.html",
    "title": "Goals - October 2015",
    "section": "",
    "text": "I’d review last month’s goals, but I completely forgot to post them!\nHowever, I did accomplish the two most important goals that I needed to get done last month:\n\nPrep Olympia oyster (Ostrea lurida) gDNA for genome sequencing\nPrep geoduck (Panopea generosa) gDNA for genome sequencing\n\nFor this month, I’m looking at tackling the following:\n\nPrep RAD libraries to assess viability of the process on degraded Olympia oyster gDNA\nImplement lab safety changes to be in compliance\nEstablish an “onboarding” (that’s fancy corporate speak) guide for getting new lab members up-to-speed\nContinue working on a revamped primer database that will be a single resource (currently, it’s split in two spreadsheets and is not easily manageable/searchable)"
  },
  {
    "objectID": "posts/2015/2015-10-05-gdna-isolation-geoduck-adductor-muscle/index.html",
    "href": "posts/2015/2015-10-05-gdna-isolation-geoduck-adductor-muscle/index.html",
    "title": "gDNA Isolation - Geoduck Adductor Muscle",
    "section": "",
    "text": "My isolation on Friday didn’t yield a sufficient quantity of gDNA for the additional DNA needed for the geoduck genome sequencing project. Used two adductor muscles (Box 1) samples collected by Brent & Steven on 20150811.\nTissue weights:\n\nGeoduck adductor 1: 433mg (gone)\nGeoduck adductor 2: 457.4mg (gone)\n\nSamples were isolated using DNAzol (Molecular Research Center) according to the manufacturer’s protocol, with the following adjustments:\n\nTissues homogenized in 750μL of DNAzol with disposable mortar/pestle tubes using 10 pestle strokes\nAfter homogenization, topped off tubes to 960μL with DNAzol, added 40μL RNAse A (100mg/mL) and incubated @ RT for 15mins.\nPerformed optional centrifugation step (10,000g, 10mins @ RT)\nInitial pellet wash was performed using a 70%/30% DNAzol/EtOH\nPellets were resuspended Buffer EB (Qiagen)\nInsoluble material was pelleted (12,000g, 10mins @ RT) and supe transferred to new tubes\n\nNOTE: Both samples produced a stark white, “cottony” precipitate after the addition of the ethanol. This precipitate was transferred to a clean tube and processed in the same fashion.\nResuspension volumes\nAdductor 1:  200μL\nAdductor 2: 50μL\nAdductor 1 & 2 fluff: 500μL each\nSpec’d on Roberts Lab NanoDrop1000.\nResults:\n(http://eagle.fish.washington.edu/Arabidopsis/20151005_gDNA_geoduck_ODs_01.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20151005_gDNA_geoduck_plots_01.JPG)\nNOTE: The sample labeled “gDNA geoduck adductor 1” is actually adductor 2. The sample labeled “gDNA geoduck adductor 1{1} is actually adductor 1. However, this is probably moot since these two samples will be pooled shortly.\nI’m not going to speculate why there’re weird peaks at 240nm…\nThe two “fluff” samples aren’t good (extremely high 260/280 ratios, very low 260/230 ratios, and weird peak at 240nm). Not sure what the fluff is that precipitated out with the EtOH addition. Will discard them.\nThe two normal samples look fine. Will use them for pooling.\nYields\nAdductor 1: 52.2μg\nAdductor 2: 8.25μg"
  },
  {
    "objectID": "posts/2015/2015-04-14-sequence-data-analysis-lsu-c-virginica-oil-spill-mbd-bs-seq-data/index.html",
    "href": "posts/2015/2015-04-14-sequence-data-analysis-lsu-c-virginica-oil-spill-mbd-bs-seq-data/index.html",
    "title": "Sequence Data Analysis - LSU C.virginica Oil Spill MBD BS-Seq Data",
    "section": "",
    "text": "Performed some rudimentary data analysis on the new, demultiplexed data downloaded earlier today:\n2112_lane1_ACAGTG_L001_R1_001.fastq.gz 2112_lane1_ACAGTG_L001_R1_002.fastq.gz 2112_lane1_ATCACG_L001_R1_001.fastq.gz 2112_lane1_ATCACG_L001_R1_002.fastq.gz 2112_lane1_ATCACG_L001_R1_003.fastq.gz 2112_lane1_CAGATC_L001_R1_001.fastq.gz 2112_lane1_CAGATC_L001_R1_002.fastq.gz 2112_lane1_CAGATC_L001_R1_003.fastq.gz 2112_lane1_GCCAAT_L001_R1_001.fastq.gz 2112_lane1_GCCAAT_L001_R1_002.fastq.gz 2112_lane1_TGACCA_L001_R1_001.fastq.gz 2112_lane1_TTAGGC_L001_R1_001.fastq.gz 2112_lane1_TTAGGC_L001_R1_002.fastq.gz\nCompared total amount of data (in gigabytes) generated from each index. The commands below send the output of the ‘ls -l’ command to awk. Awk sums the file sizes, found in the 5th field ($5) of the ‘ls -l’ command, then prints the sum, divided by 1024^3 to convert from bytes to gigabytes.\nIndex: ACAGTG\n$ls -l 2112_lane1_AC* | awk '{sum += $5} END {print sum/1024/1024/1024}' 1.49652\nIndex: ATCACG\n$ls -l 2112_lane1_AT* | awk '{sum += $5} END {print sum/1024/1024/1024}' 3.02269\nIndex: CAGATC\n$ls -l 2112_lane1_CA* | awk '{sum += $5} END {print sum/1024/1024/1024}' 3.49797\nIndex: GCCAAT\n$ls -l 2112_lane1_GC* | awk '{sum += $5} END {print sum/1024/1024/1024}' 2.21379\nIndex: TGACCA\n$ls -l 2112_lane1_TG* | awk '{sum += $5} END {print sum/1024/1024/1024}' 0.687374\nIndex: TTAGGC\n$ls -l 2112_lane1_TT* | awk '{sum += $5} END {print sum/1024/1024/1024}' 2.28902\nRan FASTQC on the following files downloaded earlier today. The FASTQC command is below. This command runs FASTQC in a for loop over any files that begin with “2212_lane2_C” or “2212_lane2_G” and outputs the analyses to the Arabidopsis folder on Eagle:\n$for file in /Volumes/nightingales/C_virginica/2112_lane1_[ATCG]*; do fastqc \"$file\" --outdir=/Volumes/Eagle/Arabidopsis/; done\nFrom within the Eagle/Arabidopsis folder, I renamed the FASTQC output files to prepend today’s date:\n$for file in 2112_lane1_[ATCG]*; do mv \"$file\" \"20150413_$file\"; done\nThen, I unzipped the .zip files generated by FASTQC in order to have access to the images, to eliminate the need for screen shots for display in this notebook entry:\n$for file in 20150413_2112_lane1_[ATCG]*.zip; do unzip \"$file\"; done\nThe unzip output retained the old naming scheme, so I renamed the unzipped folders:\n$for file in 2112_lane1_[ATCG]*; do mv \"$file\" \"20150413_$file\"; done\nThe FASTQC results are linked below:\n20150413_2112_lane1_ACAGTG_L001_R1_001_fastqc.html 20150413_2112_lane1_ACAGTG_L001_R1_002_fastqc.html 20150413_2112_lane1_ATCACG_L001_R1_001_fastqc.html 20150413_2112_lane1_ATCACG_L001_R1_002_fastqc.html 20150413_2112_lane1_ATCACG_L001_R1_003_fastqc.html 20150413_2112_lane1_CAGATC_L001_R1_001_fastqc.html 20150413_2112_lane1_CAGATC_L001_R1_002_fastqc.html 20150413_2112_lane1_CAGATC_L001_R1_003_fastqc.html 20150413_2112_lane1_GCCAAT_L001_R1_001_fastqc.html 20150413_2112_lane1_GCCAAT_L001_R1_002_fastqc.html 20150413_2112_lane1_TGACCA_L001_R1_001_fastqc.html 20150413_2112_lane1_TTAGGC_L001_R1_001_fastqc.html 20150413_2112_lane1_TTAGGC_L001_R1_002_fastqc.html"
  },
  {
    "objectID": "posts/2015/2015-12-10-sample-submission-2brad-libraries-for-genewiz/index.html",
    "href": "posts/2015/2015-12-10-sample-submission-2brad-libraries-for-genewiz/index.html",
    "title": "Sample Submission - 2bRAD Libraries for Genewiz",
    "section": "",
    "text": "Pooled the libraries into a single sample for sequencing on Illumina HiSeq2500 by Genewiz.\nHere’s the list of samples that were pooled:\n\n\n\n\nSAMPLE NAME\n\nLIBRARY NAMES\n\nINDEX 1 (i7)\n\n\nLENGTH (bp)\n\nINDEX 2 (i5)\n\n\nLENGTH\n\n\n\nSJW_Oly_2bRAD\n\nOly RAD 02\n\nCGTGAT\n\n\n6\n\nATGCAT\n\n\n6\n\n\n\nSJW_Oly_2bRAD\n\nOly RAD 03\n\nACATCG\n\n\n6\n\nATGCAT\n\n\n6\n\n\n\nSJW_Oly_2bRAD\n\nOly RAD 04\n\nGCCTAA\n\n\n6\n\nATGCAT\n\n\n6\n\n\n\nSJW_Oly_2bRAD\n\nOly RAD 06\n\nTGGTCA\n\n\n6\n\nATGCAT\n\n\n6\n\n\n\nSJW_Oly_2bRAD\n\nOly RAD 07\n\nCACTGT\n\n\n6\n\nATGCAT\n\n\n6\n\n\n\nSJW_Oly_2bRAD\n\nOly RAD 08\n\nATTGGC\n\n\n6\n\nATGCAT\n\n\n6\n\n\n\nSJW_Oly_2bRAD\n\nOly RAD 14\n\nGATCTG\n\n\n6\n\nATGCAT\n\n\n6\n\n\n\nSJW_Oly_2bRAD\n\nOly RAD 17\n\nTCAAGT\n\n\n6\n\nATGCAT\n\n\n6\n\n\n\nSJW_Oly_2bRAD\n\nOly RAD 23\n\nCTGATC\n\n\n6\n\nATGCAT\n\n\n6\n\n\n\nSJW_Oly_2bRAD\n\nOly RAD 30\n\nAAGCTA\n\n\n6\n\nATGCAT\n\n\n6\n\n\n\n\n\nCombined 40ng of all samples, except Oly RAD 30. Used only 20ng of Oly RAD 30 because it was the only sample that produced a single peak in qPCR melt curve analysis (i.e. no primer dimer). As such, it’s a rough assumption that the qPCR quantitation of all the other samples is twice as high as they should be due to the contribution of primer dimer amplification.\nCalculations for pooling can be seen here (Google Sheet): 20151117_RAD_qPCR_data\nThe full list of samples (and the individual samples/libraries/indexes) submitted to Genewiz for this project by Katherine Silliman & me can be seen here (Google Sheet): White_BS1511196_R2_barcodes"
  },
  {
    "objectID": "posts/2015/2015-12-22-illumina-methylation-library-construction-olyc-gigas-bisulfite-treated-dna/index.html",
    "href": "posts/2015/2015-12-22-illumina-methylation-library-construction-olyc-gigas-bisulfite-treated-dna/index.html",
    "title": "Illumina Methylation Library Construction - Oly/C.gigas Bisulfite-treated DNA",
    "section": "",
    "text": "Took the bisulfite-treated DNA from 20151218 and made Illumina libraries using the [TruSeq DNA Methylation Library Kit (Illumina)(https://github.com/sr320/LabDocs/blob/master/protocols/Commercial_Protocols/Illumina_truseq-dna-methylation-library-prep-guide-15066014-a.pdf).\nQuantified the completed libraries using the Qubit 3.0 dsDNA BR Kit (ThermoFisher).\nEvaluated the DNA with the Bioanalyzer 2100 (Agilent) using the DNA 12000 assay. Illumina recommended using the High Sensitivity assay, but we don’t have access to that so I figured I’d just give the DNA 12000 assay a go.\n\n\n\n\n\nSampleName\n\n\nIndexNumber\n\n\nBarCode\n\n\n\n\n1NF11\n\n\n1\n\n\nATCACG\n\n\n\n\n1NF15\n\n\n2\n\n\nCGATGT\n\n\n\n\n1NF16\n\n\n3\n\n\nTTAGGC\n\n\n\n\n1NF17\n\n\n4\n\n\nTGACCA\n\n\n\n\n2NF5\n\n\n5\n\n\nACAGTG\n\n\n\n\n2NF6\n\n\n6\n\n\nGCCAAT\n\n\n\n\n2NF7\n\n\n7\n\n\nCAGATC\n\n\n\n\n2NF8\n\n\n8\n\n\nACTTGA\n\n\n\n\nM2\n\n\n9\n\n\nGATCAG\n\n\n\n\nM3\n\n\n10\n\n\nTAGCTT\n\n\n\n\nNF2_6\n\n\n11\n\n\nGGCTAC\n\n\n\n\nNF_18\n\n\n12\n\n\nCTTGTA\n\n\n\n\n\nResults:\nLibrary Quantification (Google Sheet): 20151221_quantification_illumina_methylation_libraries\n\n\n\n\n**Test Name**\n\n**Concentration (ng/μL)\n**\n\n\n\n1NF11\n\nOut of range\n\n\n\n1NF15\n\n\n2.14\n\n\n\n1NF16\n\n\n2.74\n\n\n\n1NF17\n\n\n2.64\n\n\n\n2NF5\n\n\n2.92\n\n\n\n2NF6\n\nOut of range\n\n\n\n2NF7\n\n\n2.42\n\n\n\n2NF8\n\n\n2.56\n\n\n\nM2\n\nOut of range\n\n\n\nM3\n\n\n2.1\n\n\n\nNF2_6\n\n\n2.38\n\n\n\nNF2_18\n\nOut of range\n\n\n\n\n\nI used the Qubit’s BR (broad range) kit because I wasn’t sure what concentrations to expect. I need to use the high sensitivity kit to get a better evaluation of all the samples’ concentrations.\nBioanalyzer Data File (Bioanalyzer 2100): 2100_20expert_DNA_2012000_DE72902486_2015-12-21_16-58-43.xad\n(http://eagle.fish.washington.edu/Arabidopsis/20151221_bioanalyzer_illumina_methylation_libraries.jpg)\nHa! Well, looks like you definitely need to use the DNA High Sensitivty assay for the Bioanalyzer to pick up anything. Although, I guess you can see a slight hump in most of the samples at the appropriate sizes (~300bp); you just have to squint. ;)"
  },
  {
    "objectID": "posts/2015/2015-09-17-dna-isolation-olympia-oyster-whole-body/index.html",
    "href": "posts/2015/2015-09-17-dna-isolation-olympia-oyster-whole-body/index.html",
    "title": "DNA Isolation - Olympia oyster whole body",
    "section": "",
    "text": "Continued the extractions that Steven began yesterday and this morning using the E.Z.N.A. Mollusc DNA Kit (Omega Bio-Tek) after the RNase treatment @ 70C.\n\nSamples were cooled to RT (~10mins)\nAdded 300μL of 100% EtOH to each (equivalent to the volume of aqueous phase Steven recovered from each sample)\nFollowed manufacturer’s protocol\nEluted all samples with 50μL of Elution Buffer\nSpec’d on Roberts Lab NanoDrop1000\n\nResults:\n(http://eagle.fish.washington.edu/Arabidopsis/20150916_gDNA_Oly_RAD_ODs_01.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150916_gDNA_Oly_RAD_ODs_02.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150916_gDNA_Oly_RAD_plots_01.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150916_gDNA_Oly_RAD_plots_02.JPG)\nDNA looks absolutely pristine and has amazing yields.\nWill check gDNA integrity via agarose gel tomorrow.\nData has been entered into the master spreadsheet for this project: Ostrea lurida Project Master Tissue Sample List"
  },
  {
    "objectID": "posts/2015/2015-11-17-qpcr-oly-rad-seq-library-quantification/index.html",
    "href": "posts/2015/2015-11-17-qpcr-oly-rad-seq-library-quantification/index.html",
    "title": "qPCR - Oly RAD-Seq Library Quantification",
    "section": "",
    "text": "The final step before sequencing these 2bRAD libraries is to quantify them. Used the KAPA Illumina Quantification Kit (KAPA Biosystems) according to the manufacturer’s protocol.\nMade 1:4 dilutions of each library to use as template.\nRan all samples, including standards, in triplicate on the Roberts Lab Opticon2 (BioRad).\nPlate set up and master mix can be found here: 20151116_qPCR_plate_layout_Oly_RAD.JPG\nResults:\nqPCR Data File (TAD): Sam_20151116_144718.tad\nThe take home messages from this qPCR are this:\n\nThe amplification plots that are pushed up against the left side of the graph (essentially at ~ cycle 1) are all of the libraries. A 1:4 dilution was insufficient to have the libraries amplify within the range of the standard curve.\nAll libraries except one (Oly RAD Library 30) have detectable levels of primer dimer. This confounds library quantification (because both the intended PCR product and the primer dimers contribute to the fluorescence accumulation), as well as potentially interfering with the subsequent Illumina sequencing (primer dimers will be sequenced and contain no insert sequence).\n\nWill repeat the qPCR with more appropriately diluted libraries.\nSee the info below for more deets on this run.\nDefault analysis settings need to be adjusted to account for how early the standard curve comes up. Otherwise, the Opticon software sets the baseline incorrectly:\n(http://eagle.fish.washington.edu/Arabidopsis/201501116_RAD_qPCR_01.png)\nThe KAPA Quantification Kit indicates that the baseline calculations need to be extended to cycles 1 through 3. This allows the software to set the baseline threshold correctly:\n(http://eagle.fish.washington.edu/Arabidopsis/201501116_RAD_qPCR_02.png)\nMelt curve analysis of the standard curve shows the expected profile - slight hump leading into the peak:\n(http://eagle.fish.washington.edu/Arabidopsis/201501116_RAD_qPCR_std_melt.png)\nMelt curve analysis of the libraries. Dual peaks indicate primer dimer contamination:\n(http://eagle.fish.washington.edu/Arabidopsis/201501116_RAD_qPCR_library_melt_01.png)\nMelt curve analysis of Oly RAD Library 30. Shows the desired single peak, suggesting library is free of primer dimers:\n(http://eagle.fish.washington.edu/Arabidopsis/201501116_RAD_qPCR_library_melt_02.png)"
  },
  {
    "objectID": "posts/2015/2015-10-29-restriction-digest-oly-gdna-for-rad-seq-walfi-3/index.html",
    "href": "posts/2015/2015-10-29-restriction-digest-oly-gdna-for-rad-seq-walfi-3/index.html",
    "title": "Restriction Digest – Oly gDNA for RAD-seq w/AlfI",
    "section": "",
    "text": "The previous attempt at making these RAD libraries failed during the prep-scale PCR, likely due to a discrepancy in the version of the Meyer Lab protocol I was following, so I have to start at the beginning to try to make these libraries again.\nSince the input DNA is so degraded, I’ve repeated this using 9μg of input DNA (instead of the recommended 1.2μg). This should increase the number of available cleavage sites for AlfI, thus improving the number of available ligation sites for the adaptors.\nUsed a subset (10 samples) from the Ostrea lurida gDNA isolated 20150916 to prepare RAD libraries.\nFollowed the 2bRAD protocol (PDF) developed by Eli Meyer’s lab.\nPrepared 9.0μg of each of the following samples in a volume of 9.5μL:\nGoogle Sheet: 20151028_RADseq_DNA_calcs\nPrepared master mix for restriction enzyme reaction:\n\n\n\n\n\nREAGENT\n\n\nSINGLE REACTION (μL)\n\n\nx11\n\n\n\n\nDNA\n\n\n9.5\n\n\nNA\n\n\n\n\n10x Buffer R\n\n\n1.2μL\n\n\n13.2μL\n\n\n\n\n150μM SAM\n\n\n0.8μL\n\n\n8.8μL\n\n\n\n\nAlfI\n\n\n0.5μL\n\n\n5.5μL\n\n\n\n\n\nCombined 2.5μL of the master mix with 9.5μL of each DNA sample in 0.5mL snap cap tubes. Incubated @ 37C O/N in thermal cycler (PTC-200; no heated lid)."
  },
  {
    "objectID": "posts/2015/2015-09-15-genomic-dna-isolation-geoduck-adductor-muscle-foot-2/index.html",
    "href": "posts/2015/2015-09-15-genomic-dna-isolation-geoduck-adductor-muscle-foot-2/index.html",
    "title": "Genomic DNA Isolation - Geoduck Adductor Muscle & Foot",
    "section": "",
    "text": "Previously isolated gDNA from these tissues on 20150828. However, found out after the isolations that BGI needs >73μg of gDNA for the genome sequencing project, which is significantly more than I obtained previously.\nIsolated gDNA from Panopea generosa (geoduck) adductor muscle & foot samples collected by Brent & Steven on 20150811 using the DNAzol (Molecular Research Center) according to the manufacturer’s protocol, with the following adjustments:\n\n58.8mg of adductor muscle 1\n84.0mg of adductor muscle 2\n70.3mg of foot 1\n95.1mg of foot 2\nTissues homogenized in 750μL of DNAzol with disposable mortar/pestle tubes using 10 pestle strokes\nAfter homogenization, topped off tubes to 1000μL with DNAzol and incubated @ RT for 10mins.\nPerformed optional centrifugation step (10,000g, 10mins @ RT)\nInitial pellet wash was performed using a 70%/30% DNAzol/EtOH\nPellets were resuspended in 200μL of Buffer EB (Qiagen)\nInsoluble material was pelleted (12,000g, 10mins @ RT) and supe transferred to new tubes\n\nSpec’d on Roberts Lab NanoDrop1000 (ThermoFisher) and stored temporarily at 4C to avoid freeze-thawing before sending off for sequencing next week.\nResults:\n(http://eagle.fish.washington.edu/Arabidopsis/20150914_gDNA_geoduck_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150914_gDNA_geoduck_plots.JPG)\nThere was a great deal of insoluble material from the get-go that was carried through the entire isolation.\nOverall, the 260/280 ratios look pretty good, but the 260/230 ratios are just trash. As can be seen in the plots above, there is clearly significant absorbance in the 230 - 250nm, suggesting some contaminant carryover (phenol/salt). Oddly, the side-by-side isolations from two different collections of the same tissue type yielded drastically different quantities of gDNA than each other.\nWill evaluate gDNA integrity on agarose gel.\nTotal yield from this isolation is still far below the minimum quantity of gDNA needed for the sequencing project. Will need to perform another round of gDNA isolation."
  },
  {
    "objectID": "posts/2015/2015-06-30-rnaseq-data-receipt-geoduck-gonad-rna-100bp-pe-illumina/index.html",
    "href": "posts/2015/2015-06-30-rnaseq-data-receipt-geoduck-gonad-rna-100bp-pe-illumina/index.html",
    "title": "RNAseq Data Receipt - Geoduck Gonad RNA 100bp PE Illumina",
    "section": "",
    "text": "Received notification that the samples sent on 20150601 for RNAseq were completed.\nDownloaded the following files from the GENEWIZ servers using FileZilla FTP and stored them on our server (owl/web/nightingales/P_generosa):\nGeo_Pool_F_GGCTAC_L006_R1_001.fastq.gz Geo_Pool_F_GGCTAC_L006_R2_001.fastq.gz Geo_Pool_M_CTTGTA_L006_R1_001.fastq.gz Geo_Pool_M_CTTGTA_L006_R2_001.fastq.gz\nGenerated md5 checksums for each file:\n<code>$for i in *; do md5 $i >> checksums.md5; done</code>\nMade a readme.md file for the directory."
  },
  {
    "objectID": "posts/2015/2015-10-06-agarose-gel-geoduck-olympia-oyster-gdna/index.html",
    "href": "posts/2015/2015-10-06-agarose-gel-geoduck-olympia-oyster-gdna/index.html",
    "title": "Agarose Gel - Geoduck & Olympia Oyster gDNA",
    "section": "",
    "text": "Needed to assess the integrity of the newest gDNA isolated for the two genome sequencing projects: Geoduck gDNA from earlier today and Olympia oyster gDNA from 20151002.\nAlso needed to assess the integrity of the gDNA of ethanol-preserved Olympia oyster mantle tissue from Jake’s reciprocal transplant experiment, isolated on 20151002: samples NF1A & SN49A.\nRan samples on a 0.8% agarose, 1X modified TAE gel.\nLoaded 1μL (~300ng) of the geoduck, Oly and NF1A samples.\nLoaded 2μL (~100ng) of the SN49A sample.\nUsed 5μL of ladder.\nResults:\n(https://raw.githubusercontent.com/sr320/LabDocs/master/protocols/Commercial_Protocols/ThermoFisher_OgeneRuler_DNA_Ladder_Mix_F100439.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/20151005_gDNA_gel_annotated.jpg)\nGenome Sequencing Samples\nThe geoduck and the Oly samples look good. Intact, high molecular weight band. My only concern is the noticeable difference in band intensities between these two. Both samples should be ~300ng/μL, based on the NanoDrop1000 readings. However, it’s evident that the concentrations of these two samples differ greatly. Additionally, we can use the ladder to gauge the concentrations of the samples, since I loaded 0.5μg of the ladder, which is the quantity referenced on the ladder guide above.\nIt would appear that the geoduck sample concentration is closer to 60ng/μL (band intensity is similar to that of the 500, 1000, & 3000bp markers), as opposed to the 292ng/μL that the NanoDrop1000 indicated.\nThe Oly sample appears to have even less and appears less intense than the lowest concentration bands on the marker (16.0ng/μL). That’s not even remotely close to the 331ng/μL measured by the NanoDrop1000.\nIt’s difficult to say why this might be, as both samples were RNased and neither of them show extensive smearing (both of those factors would contribute to inflated spec readings).\nRegardless, will ship them off to BGI to supplement the previous gDNA for this project.\nEthanol-Preserved Samples\nBoth samples show extensive smearing and no high molecular weight band, indicating they are both completely degraded. This is a very bad result for this project, as the tissue in this group is/was a bit of grasping at straws to obtain some intact DNA to use for the RAD-seq that we intend to pursue."
  },
  {
    "objectID": "posts/2015/2015-05-07-rna-isolation-jakes-o-lurida-ctenidia-control-from-20150422/index.html",
    "href": "posts/2015/2015-05-07-rna-isolation-jakes-o-lurida-ctenidia-control-from-20150422/index.html",
    "title": "RNA Isolation – Jake’s O. lurida Ctenidia Control from 20150422",
    "section": "",
    "text": "Isolated RNA from Jake’s Olympia oyster ctenidia, controls, collected on 20150422. Samples had been homogenized and stored @ -80C.\nThe following sample tubes (heat-shocked oyster ctenidia) were removed from -80C and thawed at RT:\n\n 42215 HC 1\n 42215 HC 2\n42215 HC 3\n42215 HC 4\n42215 HC 5\n42215 HC 6\n42215 HC 7\n42215 HC 8\n42215 NC 1\n42215 NC 2\n42215 NC 3\n42215 NC 4\n42215 NC 5\n42215 NC 6\n42215 NC 7\n42215 NC 8\n42215 SC 1\n42215 SC 2\n42215 SC 3\n42215 SC 4\n42215 SC 5\n42215 SC 6\n42215 SC 7\n42215 SC 8\n\nNOTE: 0.1% DEPC-H2O used throughout this procedure was prepared on 7/15/2010 by me.\nAccording to Jake’s notebook entry, the samples should have been previously homogenized in RNAzol RT (Molecular Research Center; MRC). However, none of the samples showed evidence of being homogenized:\n(http://eagle.fish.washington.edu/Arabidopsis/Pics/20150507_Jake_Oly_tissue_RNAzol.JPG)\nProcedure:\nSamples were homogenized with disposable pestle in their respective tubes and vortexed.\nAdded 400μL of 0.1% DEPC-H2O to each sample and vortexed 15s.\nIncubated samples 15mins at RT.\nCentrifuged tubes 15mins at RT @ 16,000g.\n750μL of the supe was transferred to a clean tube, added equal volume of isopropanol (750μL), mixed by inversion (20 times), and incubated at RT for 15mins.\nCentrifuged 12,000g for 10mins.\nDiscarded supe.\nWashed pellets with 500μL of 75% EtOH (made with 0.1% DEPC-H2O) and centrifuged 4,000g for 3mins at RT. Repeated one time.\nRemoved EtOH and resuspended in 100μL of 0.1% DEPC-H2O. Most samples required vortexing to dissolve pellet.\nSample tubes were transferred to ice, quantified on the Roberts Lab NanoDrop1000, and stored @ -80C in their original box, pictured:\n(http://eagle.fish.washington.edu/Arabidopsis/Pics/20150507_Jake_Oly_RNA_box.JPG)\nResults:\n(http://eagle.fish.washington.edu/Arabidopsis/20150507_Jake_oly_control_RNA_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150507_Jake_oly_control_RNA_plots-01.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150507_Jake_oly_control_RNA_plots-02.JPG)\nGoogle Spreadsheet with absorbance data: 20150507_Jake_Oly_control_RNA_ODs\nExcellent yields and pretty solid 260/280 ratios (>1.85). Interestingly, the 260/230 ratios aren’t so great (compared to yesterday’s isolations). I suspect that the reason for this is that there appeared to be more starting tissue in these samples than yesterday’s. The greater quantity of tissue explains the higher yields and could be tied to the decrease in the 260/230 ratios…\nAnyway, things look good. Next step will be to check for gDNA carryover in these samples and yesterday’s samples."
  },
  {
    "objectID": "posts/2015/2015-01-28-bisuflite-ngs-library-prep-c-gigas-larvae-oa-bisulfite-library-quantification/index.html",
    "href": "posts/2015/2015-01-28-bisuflite-ngs-library-prep-c-gigas-larvae-oa-bisulfite-library-quantification/index.html",
    "title": "Bisuflite NGS Library Prep – C.gigas larvae OA bisulfite library quantification",
    "section": "",
    "text": "The two completed BS Illumina libraries (400ppm and 1000ppm) were quantified via fluorescence using the Quant-iT DNA BR Kit (Life Technologies/Invitrogen).  Used 1uL of  each sample and the standards.  All standards were run in triplicate.  Due to limited sample, the two libraries were only processed singularly, without replication.  Fluorescence was measured on a FLx800 plate reader (BioTek).\nResults:\nThe standard curve, raw fluorescence, and calculated concentrations (as determined by the Gen5 (BioTek) software) can be seen here: 20150128_CgigasOA_BSlibrraryQuants_OluridaLibraryQuants\nThe standard curve was excellent, exhibiting a R² value = 0.999\n\n\n\n\n\nSample\n\n\nConcentration (ng/uL)\n\n\n\n\n400ppm\n\n\n10.592\n\n\n\n\n1000ppm\n\n\n0.0\n\n\n\n\n\nThe 400ppm library looks great, with a good yield.\nThe 1000ppm library appears to have no measurable quantity of DNA in it.  This is surprising, and disconcerting, as both samples were processed in parallel.  As such, there should be virtually no difference between them, in regards to the library construction process and subsequent yields.\nTo verify that this wasn’t a pipetting error on my part, I re-quantified the 1000ppm library (in duplicate) and still no detectable DNA.\nWill repeat the bisulfite conversion and library construction process on the 1000ppm sample in order to generate a usable library for sequencing."
  },
  {
    "objectID": "posts/2015/2015-10-02-pcr-oly-rad-seq-test-scale-pcr-2/index.html",
    "href": "posts/2015/2015-10-02-pcr-oly-rad-seq-test-scale-pcr-2/index.html",
    "title": "PCR - Oly RAD-seq Test-scale PCR",
    "section": "",
    "text": "Yesterday’s test scale PCR failed to produce any bands in any samples (expected size of ~166bp). This is not particularly surprising, due to the level of degradation in these samples. As such, repeated the test scale PCR, but increased the number of cycles.\nFollowing the Meyer Lab 2bRAD protocol.\nI ran PCR reactions on a the same subset of samples as yesterday (Sample #: 4, 7, 14, & 30).\nPCR reactions were set up on ice in 0.5mL PCR tubes.\n\n\n\n\n\nREAGENT\n\n\nSINGLE REACTION (μL)\n\n\nx4.4\n\n\n\n\nTemplate\n\n\n8\n\n\nNA\n\n\n\n\nNanoPure H2O\n\n\n1\n\n\n4.4\n\n\n\n\ndNTPs (1mM)\n\n\n4\n\n\n17.6\n\n\n\n\nILL-LIB1 (10μM)\n\n\n0.4\n\n\n1.76\n\n\n\n\nILL-LIB2 (10μM)\n\n\n0.4\n\n\n1.76\n\n\n\n\nILL-HT1 (1μM)\n\n\n1\n\n\n4.4\n\n\n\n\nILL-BC1 (1μM)\n\n\n1\n\n\n4.4\n\n\n\n\n5x Q5 Reaction Buffer\n\n\n4\n\n\n17.6\n\n\n\n\nQ5 DNA Polymerase\n\n\n0.2\n\n\n0.88\n\n\n\n\nTOTAL\n\n\n20\n\n\n52.8\n\n\n\n\n\nCombined 12μL of master mix with 8μL of the ligation reaction from yesterday.\nCycling was performed on a PTC-200 (MJ Research) with a heated lid:\n\n\n\n\n\nSTEP\n\n\nTEMP (C)\n\n\nTIME (s)\n\n\n\n\nInitial Denaturation\n\n\n\n98\n\n\n\n\n30\n\n\n\n\n\n42 cycles\n\n\n\n98\n60\n72\n\n\n\n\n5\n20\n10\n\n\n\n\n\n\nWe’re following the “1/4 reduced representation” aspect of the protocol. As such, 5μL of each reaction was pulled immediately after the extension (72C - machine was paused) of cycles 27, 32, 37, & 42 in order to determine the ideal number of cycles to use. Also ran the ligation reactions (labelled “ligations” on the gel below) of two samples (samples #: 14 & 30) as a pre-PCR comparison.\nThese samples were run on a 1x modified TAE 2% agarose gel (w/EtBr).\nResults:\n(https://raw.githubusercontent.com/sr320/LabDocs/master/protocols/Commercial_Protocols/ThermoFisher_OgeneRuler_DNA_Ladder_Mix_F100439.jpg)\nNOTE: Today’s gel image was taken with a proper gel imager (yesterday’s gel image was captured with my phone). The 27 cycles appears similar to yesterday’s results, even though the bands are not visible on yesterdays’ gel, due to limitations of the phone’s camera sensitivity.\nThere are a number of bands visible on this gel.\nThe green arrow on the image identifies what I believe to be the proper size band (~160bp). This band is present in all four cycling groups and at similar intensities across cycling groups.\nThe two lower molecular weight bands are very likely primer dimers. The Meyer Lab Protocol indicates that primer dimers will likely be present at ~70bp, ~90bp, & ~133bp.\nSince we’ve been following along with Katherine Silliman’s 2bRAD progress, here’s an image of her test scale PCR to compare to ours:\n[caption id=“” align=“alignnone” width=“571”](https://marinegenes.files.wordpress.com/2015/09/9_22_15.jpg) Katherine’s test scale PCR. Notice how much more prominent her bands are in all cycle groups, compared to my gel above.[/caption]\nSince this is my first foray into RAD-seq QC, I’m not certain whether or not our test scale PCRs indicate any level of success. I will consult with Katherine and Steven about what they think. Since we’re on a timeline, and we’re just testing the viability of this whole process, I suspect Steven will have me proceed and see how things turnout."
  },
  {
    "objectID": "posts/2015/2015-08-11-ssofast-evagreen-supermix-aliquots-2/index.html",
    "href": "posts/2015/2015-08-11-ssofast-evagreen-supermix-aliquots-2/index.html",
    "title": "SsoFast EvaGreen Supermix Aliquots",
    "section": "",
    "text": "Prepared sterile, ~1.5mL aliquots of SsoFast EvaGreen Supermix (received 20150810) in 2.0mL screw cap tubes. All aliquots were dated and stored @ -20C in the “PCR Supplies” box.\nBioRad Lot#: 730003517"
  },
  {
    "objectID": "posts/2015/2015-06-25-sample-submission-olympia-oyster-pcrs-sanger-sequencing-2/index.html",
    "href": "posts/2015/2015-06-25-sample-submission-olympia-oyster-pcrs-sanger-sequencing-2/index.html",
    "title": "Sample Submission – Olympia oyster PCRs Sanger Sequencing",
    "section": "",
    "text": "Submitted a plate of purified PCR products (PCR products prepared by Jake on 20150623) that Jake set up yesterday, to the UW High-Throughput Genomics Center for Sanger sequencing.\nPlate layout is here (Google Sheet): sequence_log\nOrder #:112442"
  },
  {
    "objectID": "posts/2015/2015-03-16-truseq-adaptor-counts-lsu-c-virginica-oil-spill-sequences/index.html",
    "href": "posts/2015/2015-03-16-truseq-adaptor-counts-lsu-c-virginica-oil-spill-sequences/index.html",
    "title": "TruSeq Adaptor Counts – LSU C.virginica Oil Spill Sequences",
    "section": "",
    "text": "Initial analysis, comparing barcode identification methods, revealed the following info about demultiplexing on untrimmed sequences:\n\nUsing grep:\nlong barcodes: Found in ~12% of all reads\nshort barcodes: Found in ~25% of all reads\n\n\nUsing fastx_barcode_splitter:\nlong barcodes, beginning of line: Found in ~15% of all reads\nlong barcodes, end of line: Found in < 0.008% of all reads (yes, that is actually percentage)\nshort barcodes, beginning of line: Found in ~1.3% of all reads\nshort barcodes, end of line: Found in ~2.7% of all reads\nDecided to determine what percentage of the sequences in this FASTQ file have just the beginning of the adaptor sequence (up to the 6bp barcode/index):\nGATCGGAAGAGCACACGTCTGAACTCCAGTCAC\nThis was done to see if the numbers increased without the barcode index (i.e. see if majority of sequences are being generated from “empty” adaptors lacking barcodes).\nThe analysis was performed in a Jupyter (IPython) notebook and the notebook is linked, and embedded, below.\nNBViewer: 20150316_LSU_OilSpill_Adapter_ID.ipynb\n\n\nResults:\nUsing grep:\n15% of the sequences match\nThat’s about 3% more than when the adaptor and barcode are searched as one sequence.\nUsing fastx_barcode_splitter:\nbeginning of line - 17% match\nend of line - 0.06% match\nThe beginning of line matches are ~2% higher than when the adaptor and barcode are searched as one sequence.\nWill contact Univ. of Oregon to see if they can shed any light and/or help with the demultiplexing dilemma we have here. Lots of sequence, but how did it get generated if adaptors aren’t present on all of the reads?"
  },
  {
    "objectID": "posts/2015/2015-12-22-sample-submission-bs-seq-library-pool-to-genewiz/index.html",
    "href": "posts/2015/2015-12-22-sample-submission-bs-seq-library-pool-to-genewiz/index.html",
    "title": "Sample Submission - BS-seq Library Pool to Genewiz",
    "section": "",
    "text": "Pooled 10ng of each of the libraries prepared yesterday with [TruSeq DNA Methylation Library Kit (Illumina)(https://github.com/sr320/LabDocs/blob/master/protocols/Commercial_Protocols/Illumina_truseq-dna-methylation-library-prep-guide-15066014-a.pdf) for sequencing at Genewiz.\n\n\n\n\n**SAMPLE**\n\n**VOLUME FOR 10ng (μL)**\n\n\n\n1NF11\n\n4.13\n\n\n\n1NF15\n\n5.32\n\n\n\n1NF16\n\n3.65\n\n\n\n1NF17\n\n3.94\n\n\n\n2NF4\n\n3.68\n\n\n\n2NF5\n\n4.10\n\n\n\n2NF6\n\n4.20\n\n\n\n2NF7\n\n5.32\n\n\n\nM2\n\n4.59\n\n\n\nM3\n\n3.91\n\n\n\nNF2_6\n\n4.00\n\n\n\nNF_18\n\n3.76\n\n\n\n\n\nSamples were sent to Genewiz on dry ice via standard overnight FedEx."
  },
  {
    "objectID": "posts/2015/2015-05-04-blast-c-gigas-larvae-oa-illumina-data-against-genbank-nt-db/index.html",
    "href": "posts/2015/2015-05-04-blast-c-gigas-larvae-oa-illumina-data-against-genbank-nt-db/index.html",
    "title": "BLAST - C.gigas Larvae OA Illumina Data Against GenBank nt DB",
    "section": "",
    "text": "In an attempt to figure out what’s going on with the Illumina data we recently received for these samples, I BLASTed the 400ppm data set that had previously been de-novo assembled by Steven: EmmaBS400.fa.\nJupyter (IPython) Notebook : 20150501_Cgigas_larvae_OA_BLASTn_nt.ipynb\nNotebook Viewer : 20150501_Cgigas_larvae_OA_BLASTn_nt\n\n\nResults:\nBLASTn Output File: 20150501_nt_blastn.tab\nBLAST e-vals <= 0.001: 20150501_Cgigas_larvae_OA_blastn_evals_0.001.txt\nUnique BLAST Species: 20150501_Cgigas_larvae_OA_unique_blastn_evals.txt\nFirstly, since this library was bisulfite converted, we know that matching won’t be as robust as we’d normally see.\nHowever, the BLAST matches for this are terrible.\nOnly 0.65% of the BLAST matches (e-value <0.001) are to Crassostrea gigas. Yep, you read that correctly: 0.65%.\nIt’s nearly 40-fold less than the top species: Dictyostelium discoideum (a slime mold)\nIt’s 30-fold less than the next species: Danio rerio (zebra fish)\nThen it’s followed up by human and mouse.\nI think I will need to contact the Univ. of Oregon sequencing facility to see what their thoughts on this data is, because it’s not even remotely close to what we should be seeing, even with the bisulfite conversion…"
  },
  {
    "objectID": "posts/2015/2015-11-23-dna-quantification-mbd-enriched-olympia-oyster-dna/index.html",
    "href": "posts/2015/2015-11-23-dna-quantification-mbd-enriched-olympia-oyster-dna/index.html",
    "title": "DNA Quantification - MBD-enriched Olympia oyster DNA",
    "section": "",
    "text": "Quantified the MBD enriched samples prepped over the last two days: MBD enrichment, EtOH precipiation.\nSamples were quantified using the QuantIT dsDNA BR Kit (Invitrogen) according to the manufacturer’s protocol.\nStandards were run in triplicate, samples were run in duplicate.\n96-well black (opaque) plate was used.\nFluorescence was measured on the Seeb Lab’s Victor 1420 plate reader (Perkin Elmer).\nResults:\nGoogle Sheet: 20151123_MBD_libraries_quantification\nStandard curve looked good - R² = 0.999\nMBD recovery ranged from ~250 - 600ng.\nMBD percent recoveries ranged from ~2 - 20%. Input DNA quantities were taken from Katherine’s numbers (Google Sheet): Silliman-DNA-Samples\nWill contact services about getting bisulfite Illumina sequencing performed."
  },
  {
    "objectID": "posts/2015/2015-10-13-pcr-oly-rad-seq-prep-scale-pcr/index.html",
    "href": "posts/2015/2015-10-13-pcr-oly-rad-seq-prep-scale-pcr/index.html",
    "title": "PCR - Oly RAD-seq Prep Scale PCR",
    "section": "",
    "text": "Continuing with the RAD-seq library prep. Following the Meyer Lab 2bRAD protocol.\nAfter determining the minimum number of PCR cycles to run to generate a visible, 166bp band on a gel yesterday, ran a full library “prep scale” PCR.\n\n\n\n\n\nREAGENT\n\n\nSINGLE REACTION (μL)\n\n\nx11\n\n\n\n\nTemplate\n\n\n40\n\n\nNA\n\n\n\n\nILL-HT1 (1μM)\n\n\n5\n\n\nNA\n\n\n\n\nILL-BC# (1μM)\n\n\n5\n\n\nNA\n\n\n\n\nNanoPure H2O\n\n\n5\n\n\n55\n\n\n\n\ndNTPs (10mM)\n\n\n20\n\n\n220\n\n\n\n\nILL-LIB1 (10μM)\n\n\n2\n\n\n22\n\n\n\n\nILL-LIB2 (10μM)\n\n\n2\n\n\n22\n\n\n\n\n5x Q5 Reaction Buffer\n\n\n20\n\n\n220\n\n\n\n\nQ5 DNA Polymerase\n\n\n1\n\n\n11\n\n\n\n\nTOTAL\n\n\n100\n\n\n550\n\n\n\n\n\nCombined the following for PCR reactions:\n\n50μL PCR master mix\n40μL ligation mix\n5μL of ILL-HT1 (1μM)\n5μL of ILL-BC# (1μM) - The barcode number and the respective sample are listed below.\n\nNOTE: Samples 02, 03, & 04 did not have 40μL of the ligation reaction left (only 32μL) due to additional usage in the test scale PCR yesterday. Supplemented those three reactions with 8μL of H2O to bring them to 100μL.\n\n\n\n\n\nSAMPLE\n\n\nBARCODE\n\n\nSEQUENCE\n\n\n\n\nOly RAD 02\n\n\n 1\n\n\n CGTGAT\n\n\n\n\nOly RAD 03\n\n\n 2\n\n\n ACATCG\n\n\n\n\nOly RAD 04\n\n\n 3\n\n\n GCCTAA\n\n\n\n\nOly RAD 06\n\n\n 4\n\n\n TGGTCA\n\n\n\n\nOly RAD 07\n\n\n 5\n\n\n CACTGT\n\n\n\n\nOly RAD 08\n\n\n 6\n\n\n ATTGGC\n\n\n\n\nOly RAD 14\n\n\n 7\n\n\n GATCTG\n\n\n\n\nOly RAD 17\n\n\n 8\n\n\n TCAAGT\n\n\n\n\nOly RAD 23\n\n\n 9\n\n\n CTGATC\n\n\n\n\nOly RAD 30\n\n\n10\n\n\nAAGCTA\n\n\n\n\n\nCycling was performed on a PTC-200 (MJ Research) with a heated lid:\n\n\n\n\n\nSTEP\n\n\nTEMP (C)\n\n\nTIME (s)\n\n\n\n\nInitial Denaturation\n\n\n\n98\n\n\n\n\n30\n\n\n\n\n\n12 cycles\n\n\n\n98\n60\n72\n\n\n\n\n5\n20\n10\n\n\n\n\n\n\nAfter cycling, added 16μL of 6x loading dye to each sample.\nDue to limitations in available comb sizes and inability to combine combs to make larger well sizes, only loaded 58μL of samples in each well on this gel. Will load remainder on a second gel and combine after PCR products are purified.\nResults:\n(https://raw.githubusercontent.com/sr320/LabDocs/master/protocols/Commercial_Protocols/ThermoFisher_OgeneRuler_DNA_Ladder_Mix_F100439.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/20151013_gel_Oly_RAD_prep_scale_PCR.jpg)\nWell, this is lame. There are absolutely no PCR products on this gel. In fact, this just looks like big smears of degraded DNA. I was expecting an amplicon of ~166bp to cut out of the gel. Based off of the test scale PCR from yesterday, everything should have been hunky dory. Not really sure what to think about this…"
  },
  {
    "objectID": "posts/2015/2015-12-17-agarose-gel-oly-gdna-for-bs-seq-libraries/index.html",
    "href": "posts/2015/2015-12-17-agarose-gel-oly-gdna-for-bs-seq-libraries/index.html",
    "title": "Agarose Gel - Oly gDNA for BS-seq Libraries",
    "section": "",
    "text": "Ran 1μL of each sample from yesterday’s DNA isolation on a 0.8% agarose, low-TAE gel, stained with ethidium bromide.\nResults:\n(https://raw.githubusercontent.com/sr320/LabDocs/master/protocols/Commercial_Protocols/ThermoFisher_OgeneRuler_DNA_Ladder_Mix_F100439.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/20151217_gel_Oly_gDNA.jpg)\nSince I didn’t load equal quantities of DNA, the intensities across the various samples is highly variable.\nThose samples with high degree of smearing are also those with the highest concentrations. Thus, one would expect to be able to visualize a greater range of DNA sizes in a gel (because more DNA is present). Notice the samples with nice, high molecular weight bands and little smearing (1NF16, 1NF17). These are less than half the concentrations of all the samples that exhibit extensive smearing (2NF3, 2NF8, 1NF12). So, I think all samples will be fine for proceeding with bisulfite conversion and subsequent library construction.\nHowever, I should re-run this gel using equalized DNA quantities for all samples…"
  },
  {
    "objectID": "posts/2015/2015-07-31-sample-submission-olympia-oyster-pcrs-sanger-sequencing-3/index.html",
    "href": "posts/2015/2015-07-31-sample-submission-olympia-oyster-pcrs-sanger-sequencing-3/index.html",
    "title": "Sample Submission – Olympia oyster PCRs Sanger Sequencing",
    "section": "",
    "text": "Submitted a plate of purified PCR products (PCR products prepared by Jake on 20150625) that Jake set up 20150625, to the UW High-Throughput Genomics Center for Sanger sequencing.\nPlate layout is here (Google Sheet): sequence_log\nOrder #:112582"
  },
  {
    "objectID": "posts/2015/2015-05-01-goals-may-2015/index.html",
    "href": "posts/2015/2015-05-01-goals-may-2015/index.html",
    "title": "Goals - May 2015",
    "section": "",
    "text": "Here are the things I plan to tackle throughout the month of May:\n\nGeoduck Reproductive Development Transcriptomics\nMy primary goal for this project is to successfully isolate RNA from the remaining, troublesome paraffin blocks that have yet to yield any usable RNA. The next approach to obtain usable quantities of RNA is to directly gouge tissue from the blocks instead of sectioning the blocks (as recommended in the PAXgene Tissue RNA Kit protocol). Hopefully this approach will eliminate excess paraffin, while increasing the amount of input tissue. Once I have RNA from the entire suite of samples, I’ll check the RNA integrity via Bioanalyzer and then we’ll decide on a facility to use for high-throughput sequencing.\n\n\nBS-Seq Illumina Data Assembly/Mapping\nCurrently, there are two projects that we have performed BS-Seq with (Crassostrea gigas larvae OA (2011) bisulfite sequencing and LSU C.virginica Oil Spill MBD BS Sequencing) and we’re struggling to align sequences to the C.gigas genome. Granted, the LSU samples are C.virginica, but the C.gigas larvae libraries are not aligning to the C.gigas genome via standard BLASTn or using a dedicated bisulfite mapper (e.g. BS-Map). I’m currently BLASTing a de-novo assembly of the C.gigas larvae OA 400ppm sequencing that Steven made against the NCBI nt DB in an attempt to assess the taxonomic distribution of the sequences we received back. I’ll also try using a different bisulfite mapper, bismark, that Mackenzie Gavery has previously used and has had better results with than BS-Map.\n\n\nC.gigas Heat Stress MeDIP/BS-Seq\nAs part of Claire’s project, there’s still some BS-Seq data that would be nice to have to complement the data she generated via microarray. It would be nice to make a decision about how to proceed with the samples. However, part of our decision on how to proceed is governed by the results we get from the two projects above. Why do those two projects impact the decision(s) regarding this project? They impact this project because in the two projects above, we produced our own BS-Seq libraries. This is extremely cost effective. However, if we can’t obtain usable data from doing the library preps in-house, then that means we have to use an external service provider. Using an external company to do this is significantly more expensive. Additionally, not all companies can perform bisulfite treatment, which limits our choices (and, in turn, pricing options) on where to go for sequencing.\n\n\nMiscellany\nWhen I have some down time, I’ll continue working on migrating my Wikispaces notebook to this notebook. I only have one year left to go and it’d be great is all my notebook entries were here so they’d all be tagged/categorized and, thus, be more searchable. I’d also like to work on adding README files to our plethora of electronic data folders. Having these in place will greatly facilitate the ability of people to quickly and more easily figure out what these folders contain, file formats within those folders, etc. I also have a few computing tips/tricks that I’d like to add to our Github “Code” page. Oh, although this isn’t really lab related, I was asked to teach the Unix shell lesson (or, at least, part of it) at the next Software Carpentry Workshop that Ben Marwick is setting up at UW in early June. So, I’m thinking that I’ll try to incorporate some of the data handling stuff I’ve been tackling in lab in to the lesson I end up teaching. Additionally, going through the Software Carpentry materials will help reinforce some of the “fundamental” tasks that I can do with the shell (like find, cut and grep).\nIn the lab, I plan on sealing up our nearly overflowing “Broken Glass” box and establishing a new one. I need to autoclave, and dispose of, a couple of very full biohazard bags. I’m also going to vow that I will get Jonathan to finally obtain a successful PCR from his sea pen RNA."
  },
  {
    "objectID": "posts/2015/2015-08-19-rad-seq-library-prep-reagents/index.html",
    "href": "posts/2015/2015-08-19-rad-seq-library-prep-reagents/index.html",
    "title": "RAD-Seq Library Prep Reagents",
    "section": "",
    "text": "A box with the above title was established in the -20C in FTR 209 containing the following:\n\nThermo Scientific AlfI: ER1801\nNEB T4 DNA ligase, 50 μL: M0202S\nNEB 10 mM ATP, 1 mL: P0756S\nPromega dNTPs (10 mM each): U1511\nNEB Q5 Taq Polymerase, 100 units: M0491S\n\nOligos (100μL each in TE pH=8.0; barcode sequences are in bold)\nAdaptor 1 5ILL-NR: CTACACGACGCTCTTCCGATCTNR\nAnti-ILL: AGATCGGAAGAGC(InvdT)\nAdaptor 2 3ILL-NR: CAGACGTGTGCTCTTCCGATCTNR\nILL-Lib1: AATGATACGGCGACCACCGA\nILL-Lib2: CAAGCAGAAGACGGCATACGA\nILL-HT1: AATGATACGGCGACCACCGAGATCTACACATGCATACACTCTTTCCCTACACGACGCTCTTCCGATCT\nILL-HT2:AATGATACGGCGACCACCGAGATCTACACCGTACGACACTCTTTCCCTACACGACGCTCTTCCGATCT\nILL-BC1: CAAGCAGAAGACGGCATACGAGATCGTGATGTGACTGGAGTTCAGACGTGTGCTCTTCCGATC"
  },
  {
    "objectID": "posts/2015/2015-09-16-agarose-gel-geoduck-gdna-integrity-check/index.html",
    "href": "posts/2015/2015-09-16-agarose-gel-geoduck-gdna-integrity-check/index.html",
    "title": "Agarose Gel – Geoduck gDNA Integrity Check",
    "section": "",
    "text": "Ran 0.8% agarose 1x modified TAE gel stained with EtBr to assess the integrity of geoduck gDNA isolated earlier today.\nRan ~500ng of each sample:\nGeoduck adductor muscle 1: 4μL\nResults:\n(https://raw.githubusercontent.com/sr320/LabDocs/master/protocols/Commercial_Protocols/ThermoFisher_OgeneRuler_DNA_Ladder_Mix_F100439.jpg)\nThe gDNA looks really good with a prominent high molecular weight band and little smearing.\nWill proceed with pooling all accumulated geoduck gDNA for this project."
  },
  {
    "objectID": "posts/2015/2015-11-30-data-storage-synology-dx513/index.html",
    "href": "posts/2015/2015-11-30-data-storage-synology-dx513/index.html",
    "title": "Data Storage - Synology DX513",
    "section": "",
    "text": "Running a bit low on storage on Owl (Synology DS1812+) and we will be receiving a ton of data in the next few months, so we purchased a Synology DX513. It’s an expansion unit designed specifically for seamlessly expanding our existing storage volume on Owl.\nInstalled 5 x 8TB Seagate HDDs and connected to Owl with the supplied eSATA cable.\nNow, we just need to wait (possibly days) for the full expansion to be completed.\n(http://eagle.fish.washington.edu/Arabidopsis/20151130_synology_expansion_owl.jpg)"
  },
  {
    "objectID": "posts/2015/2015-09-21-sample-submission-olympia-oyster-gdna-for-genome-sequencing-bgi/index.html",
    "href": "posts/2015/2015-09-21-sample-submission-olympia-oyster-gdna-for-genome-sequencing-bgi/index.html",
    "title": "Sample Submission - Olympia Oyster gDNA for Genome Sequencing @ BGI",
    "section": "",
    "text": "Shipped the pooled gDNA we’ve been accumulating to BGI to initiate the Olympia oyster genome sequencing project.\nSample was shipped on dry ice with the appropriate paperwork required by BGI (sample declaration letter).\nAssigned BGI Lot: 1509191001"
  },
  {
    "objectID": "posts/2015/2015-06-01-goals-june-2015/index.html",
    "href": "posts/2015/2015-06-01-goals-june-2015/index.html",
    "title": "Goals - June 2015",
    "section": "",
    "text": "Before we check out this month’s goals, let’s have a quick review of last month’s goals and which, if any, I was able to accomplish.\n\n\nFrom May 2015:\n\nGeoduck Reproductive Development Transcriptomics\nGoal(s): Isolate RNA from geoduck histology blocks\nStatus: Accomplished!\n\n\nBS-Seq Illumina Data Assembly/Mapping\nGoal(s): Glean additional info about this data set and our ability/inability to create our own BS-seq libraries.\nStatus: Still a mystery. Currently reaching out to Doug Turnbull at the Univ. of Oregon Genomics Core Facility to see if he can provide any insight as to why our data looks the way it does, which might help us figure out why we’re having such difficulty mapping our reads to the C.gigas genome…\n\n\nC.gigas Heat Stress MeDIP/BS-Seq\nGoal(s): BS-seq Claire’s samples.\nStatus: Untouched. Is dependent upon whether or not we can successfully create our own high-throughput sequencing libraries (see above).\n\n\nMiscellany\nGoal(s):\n\nMigrate Wikispaces notebook to this notebook\nAdd to GitHub code pages\nFlesh out/create README files on server(s)\nLab cleanup tasks\nAssist on Jonathan’s Capstone project\n\nStatus:\n\nMigrate Wikispaces notebook to this notebook - Minimal progress\nAdd to GitHub code pages - Updated “Commercial Protocols”, added wget command for offline notebook backups\nFlesh out/create README files on server(s) - No progress\nLab cleanup tasks - No progress\nAssist on Jonathan’s Capstone project - Things still not working. Had Jonathan isolate gDNA for proper testing of primers.\n\n\n\n\n\nGeoduck Reproductive Development Transcriptomics\nThis project is progressing relatively smoothly. Finished RNA isolations from all samples and checked their qualities via Bioanalyzer. Steven and Brent selected samples of males and females to pool for RNA-seq. Goal is to have these two pools sent off to GENEWIZ, Inc. for RNA-seq. Currently awaiting a quote adjustment as well as an answer regarding sample quantity requirements. Hope to have these sent off later today and data back by the end of the month. This data will be used alongside proteomics data that Emma is currently generating.\n\n\nBS-Seq Illumina Data Assembly/Mapping - C.gigas larvae OA\nThe troubleshooting for the data from these “homemade” libraries continues. We’ve tried various approaches to trimming the data, but Steven’s mapping attempts are still not yielding great results. I’ve contacted Univ. of Oregon Genomics Core Facility to see if they can provide insight, but haven’t gotten a response. Will hit them up again to see if I can get a response (and some help).\n\n\nGeoduck & Olympia Oyster Genome Sequencing\nWe have quotes from BGI Americas for genome sequencing for both of these organisms. Currently, we’re awaiting for funding to be processed, but expect it to be available this month. Hope to send out samples this month.\n\n\nC.gigas Heat Stress MeDIP/BS-Seq\nThis is still dependent upon our ability to make our own BS-seq libraries. Until, then, this project will likely be on the back burner for awhile.\n\n\nMiscellany\nI’d like to continue to contribute to our GitHub code repository with various command line tips and tricks. Additionally, I do need to actually spend some time creating/updating README files for our servers. We have a ton of folders that need some sort of descriptor file in them so users know what to expect to find in those folders. Additionally, we have a ton of data that needs descriptions and/or links to the projects from which the data was generated to serve as a means for people to know how/why/from what the data was generated. This has been done for newer data sets, but there’s a tremendous amount of data sets that have no information about them available in the README files. Also along the data management front, I’d like to tackle a bit of a reorganization, particularly re-establishing the go-to resource for lab members to find “stuff.” For example, Jake recently needed to know where/if we had some software and had to ask about it. Better organization on our part would eliminate him wasting time trying to track down this sort of thing. Part of the organizational issue is that we’ve partially transitioned over to using GitHub instead of Wikispaces. However, the transition hasn’t been fully realized/implemented and the result is fragmentation and confusion on where to find lab info. Oh, one last “digital” note. I’ll be teaching the Unix Shell lesson at Software Carpentry on June 25 - 26, so I have to get prepped for that (not on work time, of course).\nIn the lab, I still need to tackle some lab cleanup tasks that I neglected to deal with last month (autoclaving, glass disposal). Additionally, I need to continue helping Jonathan with his Capstone project, but I need to manage my time with him better."
  },
  {
    "objectID": "posts/2015/2015-04-13-sequence-data-lsu-c-virginica-oil-spill-mbd-bs-seq-demultiplexed/index.html",
    "href": "posts/2015/2015-04-13-sequence-data-lsu-c-virginica-oil-spill-mbd-bs-seq-demultiplexed/index.html",
    "title": "Sequence Data - LSU C.virginica Oil Spill MBD BS-Seq Demultiplexed",
    "section": "",
    "text": "I had previously contacted Doug Turnbull at the Univ. of Oregon Genomics Core Facility for help demultiplexing this data, as it was initially returned to us as a single data set with “no index” (i.e. barcode) set for any of the libraries that were sequenced. As it turns out, when multiplexed libraries are sequenced using the Illumina platform, an index read step needs to be “enabled” on the machine for sequencing. Otherwise, the machine does not perform the index read step (since it wouldn’t be necessary for a single library). Surprisingly, the sample submission form for the Univ. of Oregon Genomics Core Facility  doesn’t request any information regarding whether or not a submitted sample has been multiplexed. However, by default, they enable the index read step on all sequencing runs. I provided them with the barcodes and they demultiplexed them after the fact.\nI downloaded the new, demultiplexed files to Owl/nightingales/C_virginica:\nlane1_ACAGTG_L001_R1_001.fastq.gz lane1_ACAGTG_L001_R1_002.fastq.gz lane1_ATCACG_L001_R1_001.fastq.gz lane1_ATCACG_L001_R1_002.fastq.gz lane1_ATCACG_L001_R1_003.fastq.gz lane1_CAGATC_L001_R1_001.fastq.gz lane1_CAGATC_L001_R1_002.fastq.gz lane1_CAGATC_L001_R1_003.fastq.gz lane1_GCCAAT_L001_R1_001.fastq.gz lane1_GCCAAT_L001_R1_002.fastq.gz lane1_TGACCA_L001_R1_001.fastq.gz lane1_TTAGGC_L001_R1_001.fastq.gz lane1_TTAGGC_L001_R1_002.fastq.gz\nNotice that the file names now contain the corresponding index!\nRenamed the files, to append the order number to the beginning of the file names:\n$for file in lane1*; do mv \"$file\" \"2112_$file\"; done\nNew file names:\n2112_lane1_ACAGTG_L001_R1_001.fastq.gz 2112_lane1_ACAGTG_L001_R1_002.fastq.gz 2112_lane1_ATCACG_L001_R1_001.fastq.gz 2112_lane1_ATCACG_L001_R1_002.fastq.gz 2112_lane1_ATCACG_L001_R1_003.fastq.gz 2112_lane1_CAGATC_L001_R1_001.fastq.gz 2112_lane1_CAGATC_L001_R1_002.fastq.gz 2112_lane1_CAGATC_L001_R1_003.fastq.gz 2112_lane1_GCCAAT_L001_R1_001.fastq.gz 2112_lane1_GCCAAT_L001_R1_002.fastq.gz 2112_lane1_TGACCA_L001_R1_001.fastq.gz 2112_lane1_TTAGGC_L001_R1_001.fastq.gz 2112_lane1_TTAGGC_L001_R1_002.fastq.gz\nUpdated the checksums.md5 file to include the new files (the command is written to exclude the previously downloaded files that are named “2112_lane1_NoIndex_”; the [^N] regex excludes any files that have a capital ‘N’ at that position in the file name):\n$for file in 2112_lane1_[^N]*; do md5 \"$file\" >> checksums.md5; done\nUpdated the readme.md file to reflect the addition of these new files."
  },
  {
    "objectID": "posts/2015/2015-11-30-sample-submission-oly-oyster-bay-tissues-for-gbs/index.html",
    "href": "posts/2015/2015-11-30-sample-submission-oly-oyster-bay-tissues-for-gbs/index.html",
    "title": "Sample Submission - Oly Oyster Bay Tissues for GBS",
    "section": "",
    "text": "Sent Olympia oyster tissue samples to BGI for genotype-by-sequencing (GBS). Tissues were shipped FedEx standard overnight on dry ice.\nTissues were collected by Brent, Steven & Jake on 20151124 and were frozen @ -80C.\n36 samples from each of the three populations were collected. Only 32 samples from each population (total 96 samples) will be sequenced, but wanted to send extras from each population in case any were of poor quality.\nSample submission sheet is here (Google Sheet): 20151130_BGI_GBS_tissue_submission\n(http://eagle.fish.washington.edu/Arabidopsis/20151130_oly_tissue_gbs_bgi.JPG)"
  },
  {
    "objectID": "posts/2015/2015-11-05-dna-quantification-quality-assessment-oly-2sn-gdna/index.html",
    "href": "posts/2015/2015-11-05-dna-quantification-quality-assessment-oly-2sn-gdna/index.html",
    "title": "DNA Quantification & Quality Assessment - Oly 2SN gDNA",
    "section": "",
    "text": "Comparison of three different approaches to using the E.Z.N.A. Mollusc Kit:\n\nFresh isolations by me\nFresh isolations by Mrunmayee\nIsolations from tissue frozen in buffer by me\n\nResults:\nBioanalyzer Data File (XAD file): 2100 expert_DNA 12000_DE72902486_2015-11-04_15-06-32.xad\n(http://eagle.fish.washington.edu/Arabidopsis/20151104_gDNA_oly_2SN_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20151104_gDNA_oly_2SN_plots.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/Bioanalyzer%20Data/20151104_bioanalyzer_electropherograms.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/Bioanalyzer%20Data/20151104_bioanalyzer_gels.jpg)\nThere’s a LOT going on here. Will update this entry tomorrow with more info."
  },
  {
    "objectID": "posts/2015/2015-10-23-troubleshooting-oly-rad-seq/index.html",
    "href": "posts/2015/2015-10-23-troubleshooting-oly-rad-seq/index.html",
    "title": "Troubleshooting - Oly RAD-seq",
    "section": "",
    "text": "Oddly, it turns out that Katherine’s version of the Meyer Lab 2bRAD protocol differed from what I had download. To add to the confusion, both protocols have the same file name. Here’s what I’m talking about:\n(http://eagle.fish.washington.edu/Arabidopsis/20151023_2bRAD_protocol_conflict.jpg)\nThe file on the left is the one I was using and the one on the right is the file Katherine is using (NOTE: The file name’s aren’t exact because they were saved to the same directory and the numbers in the parentheses were appended to the file name automatically)\nI’ve updated our copy of the protocol in our GitHub account. However, Katherine informed me that she’s just been pulling up the Meyer Lab page to reference the protocol. So, it’s possible they made a change to the file after I initially downloaded it, but the change wasn’t indicated in the file name.\nhttps://people.oregonstate.edu/~meyere/docs/\nHowever, when discussing with Katherine, she made a good point and said she just scaled up the test-scale PCR. Since the test-scale PCR was successful, she didn’t see a need to make any changes.\nWill try this procedure again with the correct protocol; probably by scaling up the test-scale PCR."
  },
  {
    "objectID": "posts/2015/2015-05-15-qpcr-jakes-o-lurida-ctenidia-dnased-rna-control-samples/index.html",
    "href": "posts/2015/2015-05-15-qpcr-jakes-o-lurida-ctenidia-dnased-rna-control-samples/index.html",
    "title": "qPCR – Jake’s O.lurida ctenidia DNased RNA (Control Samples)",
    "section": "",
    "text": "Ran qPCR on DNased RNA from earlier today to assess whether there was any residual gDNA after the DNase treatment with Oly_Actin_F/R primers (SR IDs: 1505, 1504).\nUsed 1μL from all templates.\nAll samples were run in duplicate.\nPositive control was HL1 O.lurida DNA isolated by Jake on 20150323.\nCycling params:\n\n95C – 2.5mins\n40 cycles of:\n\n95C – 10s\n60C – 20s\n\nMelt curve\n\nMaster mix calcs are here: 20150514_qPCR_Oly_DNased_RNA\nqPCR Plate Layout: 20150514_qPCR_plate_Jake_Oly_Control_RNA\nResults:\nqPCR Data File (Opticon): Sam_20150514_153529.tad\nqPCR Report (Google Spreadsheet): 20150514_qPCR_Report_Jake_Oly_DNased_Control_RNA\nPositive control comes up around cycle ~21.\nNo amplification in the no template controls.\nFour wells of the DNased RNA samples exhibit amplification (B5, C10, C12, D3), however each respective replicate does not. Will re-test these four samples (NC1, SC1, SC2, SC4).\n\nAmplification Plots\n(http://eagle.fish.washington.edu/Arabidopsis/20150514_qPCR_Amp_DNased_RNA_Jake_Oly_controls.JPG)\n\n\nMelt Curves\n(http://eagle.fish.washington.edu/Arabidopsis/20150514_qPCR_Melt_DNased_RNA_Jake_Oly_controls.JPG)"
  },
  {
    "objectID": "posts/2015/2015-11-25-dna-isolation-geoduck-adductor-muscle-gdna/index.html",
    "href": "posts/2015/2015-11-25-dna-isolation-geoduck-adductor-muscle-gdna/index.html",
    "title": "DNA Isolation - Geoduck Adductor Muscle gDNA",
    "section": "",
    "text": "Since we still don’t have sufficient gDNA for the full scope of the genome sequencing, I isolated more gDNA.\nIsolated gDNA from 257mg adductor muscle tissue collected by Steven & Brent on 20150811.\nTissue was thoroughly minced with a clean razor blade and then processed with the E.Z.N.A. Mollusc Kit (Omega BioTek) with the following changes:\n\nDoubled solution volumes for steps before sample was loaded on columns\nSample was split equally in two tubes prior to addition of 100% EtOH\nAll mixing was done by shaking - no vortexing! Done this way to, hopefully, maintain gDNA integrity\nElution volume = 50μL\nElution was repeated using the initial elution to maximize recovery while maintaining low sample volume.\nThe two preps were pooled - final volume = 79μL\n\nDNA was quantified using two methods: NanoDrop1000 & QuantIT dsDNA BR Kit\nFor the Quant-IT kit, the samples were quantified using the QuantIT dsDNA BR Kit (Invitrogen) according to the manufacturer’s protocol.\nStandards were run in triplicate, samples were run in duplicate.\n96-well black (opaque) plate was used.\nFluorescence was measured on the Seeb Lab’s Victor 1420 plate reader (Perkin Elmer).\nResults:\n\n\n\n\n\nMETHOD\n\n\nCONCENTRATION (ng/μL)\n\n\nVOLUME (μL)\n\n\nYIELD (ng)\n\n\n\n\nNanoDrop1000\n\n\n54.93\n\n\n79\n\n\n4,339\n\n\n\n\nQuant-IT\n\n\n34.52\n\n\n79\n\n\n2,727\n\n\n\n\n\nThe NanoDrop1000 overestimates the concentration of the sample by 1.6x!\nRegardless, the yield isn’t all that great, which has generally been the case for all of the geoduck gDNA isolations I’ve performed. It would probably be prudent to try isolating gDNA from a different tissue to see if yields improve…\nWill evaluate gDNA quality on a gel.\nFluorescence (Google Sheet): 20151124_geoduck_oly_gDNA_quants\nNanoDrop1000 Measurements and Plots\n(http://eagle.fish.washington.edu/Arabidopsis/20151124_gDNA_geoduck_oly_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20151124_gDNA_geoduck_oly_plots.JPG)"
  },
  {
    "objectID": "posts/2015/2015-10-05-dna-quantification-pooled-geoduck-gdna/index.html",
    "href": "posts/2015/2015-10-05-dna-quantification-pooled-geoduck-gdna/index.html",
    "title": "DNA Quantification - Pooled geoduck gDNA",
    "section": "",
    "text": "Pooled the gDNA samples from earlier today & from 20151002.\nThe pooled volume = 260μL\nQuantified on the Roberts Lab NanoDrop1000.\nResults:\n(http://eagle.fish.washington.edu/Arabidopsis/20151005_gDNA_geoduck_pool_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20151005_gDNA_geoduck_pool_plots.JPG)\nBesides the weird peak at 240nm, everything looks great - perfect 260/280 & 260/230 ratios.\nYield = 75.92μg\nThis gDNA has been RNase treated, so the concentration should be semi-accurate. Regardless, even if there’s a discrepancy of 50%, this should provide enough additional DNA for BGI to work with.\nWill run on gel to evaluate integrity and then send to BGI."
  },
  {
    "objectID": "posts/2015/2015-11-25-samples-received-oly-tissue-dna-from-katherine-silliman/index.html",
    "href": "posts/2015/2015-11-25-samples-received-oly-tissue-dna-from-katherine-silliman/index.html",
    "title": "Samples Received - Oly Tissue & DNA from Katherine Silliman",
    "section": "",
    "text": "Samples were stored @ -20C in FTR 209.\n(http://eagle.fish.washington.edu/Arabidopsis/20151125_oly_samples_silliman.JPG)"
  },
  {
    "objectID": "posts/2015/2015-01-27-bisuflite-ngs-library-c-gigas-larvae-oa-bisulfite-dna/index.html",
    "href": "posts/2015/2015-01-27-bisuflite-ngs-library-c-gigas-larvae-oa-bisulfite-dna/index.html",
    "title": "Bisuflite NGS Library Prep - C.gigas larvae OA bisulfite DNA",
    "section": "",
    "text": "The two pooled bisulfite-treated DNA samples (400ppm and 1000ppm) from 20150114 were used to prepare bisulfite Illumina libraries with [EpiNext Post-Bisulfite DNA Library Preparation Kit (Illumina) (Epigentek)(https://github.com/sr320/LabDocs/blob/master/protocols/Commercial_Protocols/Epigentek_PostBisulfiteIlluminaLibraryPrep_P-1055.pdf).  Changes to the manufacturer’s protocol:\n\nSamples were transferred to 1.5mL snap cap tubes for all magnetic bead steps in order to fit in our tube magnets.\nStopped after End Repair step (prior to magnetic bead clean up).  Samples stored @ -20C"
  },
  {
    "objectID": "posts/2015/2015-11-25-dna-isolation-olympia-oyster-outer-mantle-gdna-2/index.html",
    "href": "posts/2015/2015-11-25-dna-isolation-olympia-oyster-outer-mantle-gdna-2/index.html",
    "title": "DNA Isolation - Olympia Oyster Outer Mantle gDNA",
    "section": "",
    "text": "Isolated additional gDNA for the genome sequencing. To try to improve the quality (260/280 & 260/230 ratios) of the gDNA, I added a chloroform step after the initial tissue homogenization.\nUsed 123mg of Ostrea lurida outer mantle collected by Brent & Steven on 20150812.\n\nHomogenized in 500μL of DNAzol.\nAdded additional 500μL of DNAzol.\nCentrifuged 12,000g, 10mins, @ RT.\nSplit supernatant equally into two tubes.\nAdded 500μL of chloroform and mixed moderately fast by hand.\nCentrifuged 12,000g, 10mins, RT.\nCombined aqueous phases from both tubes in a clean tube.\nAdded 500μL of 100% EtOH and mixed by inversion.\nSpooled precipitated gDNA and transferred to clean tube.\nPerformed 3 washes w/70% EtOH.\nDried pellet 3mins.\nResuspended in 200μL of Buffer EB (Qiagen).\nCentrifuged 10,000g, 5mins, RT to pellet insoluble material.\nTransferred supe to clean tube.\n\nDNA was quantified using two methods: NanoDrop1000 & Qubit 3.0 (ThermoFisher).\nFor the Qubit, the samples were quantified using the Qubit dsDNA BR reagents (Invitrogen) according to the manufacturer’s protocol and used 1μL of sample for measurement.\nResults:\nQubit Data (Google Sheet): 20151125_qubit_gDNA_geoduck_oly_quants\n\n\n\n\n\nMETHOD\n\n\nCONCENTRATION (ng/μL)\n\n\nTOTAL (μg)\n\n\n\n\nQubit\n\n\n137\n\n\n27.4\n\n\n\n\nNanoDrop1000\n\n\n295\n\n\n59.0\n\n\n\n\n\nYield is solid. We should finally have sufficient quantities of gDNA to allow for BGI to proceed with the rest of the genome sequencing! Will run sample on gel to evaluate integrity and then send off to BGI.\nThe NanoDrop & Qubit numbers still aren’t close (as expected).\nThe addition of the chloroform step definitely helped improve the 260/280 OD ratio (see below). However, the addition of that step had no noticeable impact on the 260/230 OD ratios, which is a bit disappointing.\nNanoDrop Absorbance Values & Plots\n(http://eagle.fish.washington.edu/Arabidopsis/20151125_gDNA_geoduck_oly_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20151125_gDNA_geoduck_oly_plots.JPG)"
  },
  {
    "objectID": "posts/2015/2015-11-25-phenol-chloroform-dna-cleanup-olympia-oyster-gdna/index.html",
    "href": "posts/2015/2015-11-25-phenol-chloroform-dna-cleanup-olympia-oyster-gdna/index.html",
    "title": "Phenol-Chloroform DNA Cleanup - Olympia Oyster gDNA",
    "section": "",
    "text": "The gDNA I extracted on 20151104 didn’t look great on the NanoDrop so I decided to perform a phenol-chloroform cleanup to see if I could improve the NanoDrop1000 absorbance spectrum and, in turn, the quality of the gDNA.\n\nAdded an equal volume (500μL) of phenol:chloroform:isoamyl alcohol (25:24:1) to the DNA\nMixed by hand - moderate shaking\nCentrifuged 2mins, 10,000g, RT\nTransferred aqueous phase to clean tube and discarded interphase & organic phase\nAdded an equal volume (380μL) of chlforoform:isoamyl alcohol (24:1)\nMixed by hand - moderate shaking\nCentrifuged 2mins, 10,000g, RT\nTransferred aqueous phase (320μL) to clean tube\nAdded 0.1vols (32μL) of 3M sodium acetate (pH = 5.2)\nAdded 2vols (640μL) of 100% EtOH\nMixed by inversion\nIncubated @ -20C, 1hr (probably not necessary since gDNA clearly precipitated out as soon as I mixed the sample)\nPelleted DNA by centrifuging 15mins, 12,000g, RT\nDiscarded supe\nWashed pellet with 1000μL cold (-20C) 70% EtOH\nCentrifuged 5mins, 12,000g, RT\nDiscarded supe\nRepeated was steps three more times\nResuspended pellet in 100μL of Buffer EB (Qiagen)\n\nDNA was quantified using two methods: NanoDrop1000 & QuantIT dsDNA BR Kit\nFor the Quant-IT kit, the samples were quantified using the QuantIT dsDNA BR Kit (Invitrogen) according to the manufacturer’s protocol.\nStandards were run in triplicate, samples were run in duplicate.\n96-well black (opaque) plate was used.\nFluorescence was measured on the Seeb Lab’s Victor 1420 plate reader (Perkin Elmer).\nResults:\n\n\n\n\n\nMETHOD\n\n\nCONCENTRATION (ng/μL)\n\n\nVOLUME (μL)\n\n\nYIELD (ng)\n\n\n\n\nNanoDrop1000\n\n\n547.15\n\n\n200\n\n\n109,430\n\n\n\n\nQuant-IT\n\n\n74.26\n\n\n200\n\n\n14,851\n\n\n\n\n\nThe NanoDrop1000 overestimates the concentration of the sample by 7.4x! That’s really insane!\nRegardless, this is a solid yield (using yield from Quant-IT) and, when combined with the other Ostrea lurida gDNA that I isolated today, should push the total amount of gDNA submitted to BGI over the required threshold.\nWill evaluate gDNA quality on a gel.\nFluorescence (Google Sheet): 20151124_geoduck_oly_gDNA_quants\nNanoDrop1000 Measurements and Plots\nThe clean up seems to have worked well, as the absorbance spectrum is much improved and nearly mirrors that of the Oly gDNA isolated with the Mollusc Kit.\n(http://eagle.fish.washington.edu/Arabidopsis/20151124_gDNA_geoduck_oly_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20151124_gDNA_geoduck_oly_plots.JPG)"
  },
  {
    "objectID": "posts/2015/2015-07-27-dnase-treatment-o-lurida-ctenidia-1hr-post-mechanical-stress-rna/index.html",
    "href": "posts/2015/2015-07-27-dnase-treatment-o-lurida-ctenidia-1hr-post-mechanical-stress-rna/index.html",
    "title": "DNase Treatment - O.lurida Ctenidia 1hr Post-Mechanical Stress RNA",
    "section": "",
    "text": "Quantified the RNA I isolated from Jake’s samples on 20150715 and 20150710 using the Roberts Lab NanoDrop1000 (ThermoFisher).\n(http://eagle.fish.washington.edu/Arabidopsis/20150727_Oly_ctenidia_RNA_mech_stress_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150727_Oly_ctenidia_RNA_mech_stress_plots_01.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150727_Oly_ctenidia_RNA_mech_stress_plots_02.JPG)\nOverall, the yields are good. The 260/280 ratios are mediocre. Will proceed with DNase treatment.\nDNased 1.5ug of RNA from each sample using the Turbo DNA-free Kit (Ambion/Life Technologies), following the “rigorous” protocol.\nBriefly:\n\n50μL reactions were carried out in 0.5mL tubes\nadded 1μL of DNase to each tube\nincubated 30mins @ 37C\nadded additional 1μL of DNased\nincubated 30mins @ 37C\nadded 0.2 vols (10.2μL) of DNase Inactivation Reagent\nincubated and mixed for 2mins @ RT\nspun 1.5mins, 10,000g @ RT\ntransferred 50μL of supe to sterile 1.5mL snap cap tubes\nspec’d on Roberts Lab NanoDrop1000\n\nSamples were stored @ -80C in Shellfish RNA Box #6. Will quantify at a later date.\nDNase reaction calcs: 20150727_Jake_Oly_mech_stress_DNase_calcs"
  },
  {
    "objectID": "posts/2015/2015-12-17-dna-isolation-oly-gdna-for-bs-seq/index.html",
    "href": "posts/2015/2015-12-17-dna-isolation-oly-gdna-for-bs-seq/index.html",
    "title": "DNA Isolation - Oly gDNA for BS-seq",
    "section": "",
    "text": "Need DNA to prep our own libraries for bisulfite-treated high-throughput sequencing (BS-seq).\nIsolated gDNA from the following tissue samples stored in RNAlater (tissue was not weighed) using DNAzol:\n\n\n\n\n2NF1\n\n\n\n2NF2\n\n\n\n2NF3\n\n\n\n2NF4\n\n\n\n2NF5\n\n\n\n2NF6\n\n\n\n2NF7\n\n\n\n2NF8\n\n\n\n1NF11\n\n\n\n1NF12\n\n\n\n1NF13\n\n\n\n1NF14\n\n\n\n1NF15\n\n\n\n1NF16\n\n\n\n1NF17\n\n\n\n1NF18\n\n\n\n\n\nThe sample coding breaks down as follows (see the project wiki for a full explanation):\n2NF#\n2 = Oysters outplanted in Fidalgo Bay\nNF = Broodstock originated in Fidalgo Bay\n\n= Sample number\n1NF#\n1 = Oysters outplanted in Oyster Bay\nNF = Broodstock originated in Fidalgo Bay\n\n\n= Sample number\nDNA was isolated in the following manner:\n\nHomogenized tissues in 500μL of DNAzol (Molecular Research Center; MRC).\nAdded additional 500μL of DNAzol.\nAdded 10μL of RNase A (10mg/mL, ThermoFisher); incubated 10mins @ RT.\nAdded 300μL of chloroform and mixed moderately fast by hand.\nIncubated 5mins @ RT.\nCentrifuged 12,000g, 10mins, RT.\nTransferred aqueous phase to clean tube.\nAdded 500μL of 100% EtOH and mixed by inversion.\nPelleted DNA 5,000g, 5mins @ RT.\nPerformed 3 washes w/70% EtOH.\nDried pellet 3mins.\nResuspended in 100μL of Buffer EB (Qiagen).\nCentrifuged 12,000g, 10mins, RT to pellet insoluble material.\nTransferred supe to clean tube.\n\nThe samples were quantified using the Qubit dsDNA BR reagents (Invitrogen) according to the manufacturer’s protocol and used 1μL of sample for measurement.\nResults:\nQubit data (Google Sheet): 20151216_Oly_gDNA_qubit_quants\n\n\n\n\n**SAMPLE**\n\n\nCONCENTRATION (ng/μL)\n\n\n\n2NF1\n\n\n76.4\n\n\n\n2NF2\n\n\n175\n\n\n\n2NF3\n\n\n690\n\n\n\n2NF4\n\n\n11.7\n\n\n\n2NF5\n\n\n142\n\n\n\n2NF6\n\n\n244\n\n\n\n2NF7\n\n\n25\n\n\n\n2NF8\n\n\n456\n\n\n\n1NF11\n\n\n182\n\n\n\n1NF12\n\n\n432\n\n\n\n1NF13\n\n\n155\n\n\n\n1NF14\n\n\n21\n\n\n\n1NF15\n\n\n244\n\n\n\n1NF16\n\n\n112\n\n\n\n1NF17\n\n\n25.2\n\n\n\n1NF18\n\n\n278\n\n\n\n\n\nWill run samples on gel tomorrow to evaluate gDNA integrity."
  },
  {
    "objectID": "posts/2015/2015-04-27-rna-isolation-geoduck-gonad-in-paraffin-histology-blocks-2/index.html",
    "href": "posts/2015/2015-04-27-rna-isolation-geoduck-gonad-in-paraffin-histology-blocks-2/index.html",
    "title": "RNA Isolation – Geoduck Gonad in Paraffin Histology Blocks",
    "section": "",
    "text": "UPDATE 20150528: The RNA isolated in this notebook entry may have been consolidated on 20150528.\nLast week’s RNA isolation failed for more than half of the samples I processed. I will re-isolate RNA from the following samples:\n\n02\n03\n04\n07\n08\n09\n35\n38\n46\n65\n67\n68\n\nIMPORTANT:\n\nI prepared fresh Buffer TR1 + β-mercaptoethanol (β-ME).\nI used aliquots of DNase prepared on 20150408.\n\nFive 5μm sections were taken from each block. A new blade was used for each block.\nSamples were then processed with the PAXgene Tissue RNA Kit in two groups of six.\nIsolated RNA according to the PAXgene Tissue RNA Kit protocol with the following alterations:\n\n“Max speed” spins were performed at 19,000g.\nTissue disruption was performed with the Disruptor Genie @ 45C for 15mins.\nShaking incubation step was performed with Disruptor Genie\nSamples were eluted with 40μL of Buffer TR4, incubated @ 65C for 5mins, immediately placed on ice and quantified on the Roberts Lab NanoDrop1000.\n\nResults:\n(http://eagle.fish.washington.edu/Arabidopsis/20150427_geoduck_gonad_DNased_RNA_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150427_geoduck_gonad_DNased_RNA_plots.JPG)\nWell, these results are very consistent with the data from the last isolation performed on these samples. This fact suggests that the problem lies with the tissue samples and not the isolation (since the isolation has been performed two separate times on these same samples and the results have come out virtually identical both times).\nAll samples with concentrations < 5ng/μL were discarded. The remaining samples were stored @ -80C in Shellfish RNA Box #5:\n\n35\n38\n65\n67\n\nWill discuss with Steven, look at Grace’s notebook to review the preservation process for these samples, and review the PAXgene Tissue RNA Kit to see if it will accommodate a greater number of microtome sections to use for isolation."
  },
  {
    "objectID": "posts/2015/2015-07-16-rna-isolation-o-lurida-ctenidia-1hr-post-mechanical-stress-2/index.html",
    "href": "posts/2015/2015-07-16-rna-isolation-o-lurida-ctenidia-1hr-post-mechanical-stress-2/index.html",
    "title": "RNA Isolation – O.lurida Ctenidia 1hr Post-Mechanical Stress",
    "section": "",
    "text": "Isolated RNA from [Jake’s Ostrea lurida ctenidia samples that had been subjected to mechanical stress (from 20150422)(https://heareresearch.blogspot.com/2015/04/4-22-2015-heatmechanical-shock.html).\nDespite the indication in this notebook, the samples had not been previously homogenized in RNAzol RT. I thawed the samples, homogenized them and followed the RNAzol RT protocol for total RNA isolation. Here’s the list of samples:\n\n42215 HM1 1\n42215 HM1 2\n42215 HM1 3\n42215 HM1 4\n42215 HM1 5\n42215 HM1 6\n42215 HM1 7\n42215 HM1 8\n42215 SM1 1\n42215 SM1 2\n42215 SM1 3\n42215 SM1 4\n42215 SM1 5\n42215 SM1 6\n42215 SM1 7\n42215 SM1 8\n\nRNA was resuspended in 50μL of 0.1%DEPC-H2O and stored @ -80C in the original box they came from."
  },
  {
    "objectID": "posts/2015/2015-06-16-gel-purification-olympia-oyster-and-sea-pen-pcrs/index.html",
    "href": "posts/2015/2015-06-16-gel-purification-olympia-oyster-and-sea-pen-pcrs/index.html",
    "title": "Gel Purification - Olympia Oyster and Sea Pen PCRs",
    "section": "",
    "text": "Purified DNA from the remaining PCR bands excised by Jake on 20150609 and 20150610, as well as Jonathan’s sea pen PCRs from 20150604, using Ultrafree-DA spin columns (Millipore). Transferred gel pieces from storage tubes (1.5mL snap cap tubes) to spin columns. Spun 10,000g, 5mins @ RT. Transferred purified DNA back to original storage tubes. See the sequence_log (Google Sheet) for a full list of the samples and the sequencing plates layouts. Purified DNA was stored @ 4C O/N. Will prepare and submit plates for Sanger sequencing tomorrow."
  },
  {
    "objectID": "posts/2015/2015-11-14-dna-quality-assessment-geoduck-oly-oly-2sn/index.html",
    "href": "posts/2015/2015-11-14-dna-quality-assessment-geoduck-oly-oly-2sn/index.html",
    "title": "DNA Quality Assessment - Geoduck, Oly & Oly 2SN",
    "section": "",
    "text": "I recently ran gDNA isolated for geoduck and Olympia oyster genome sequencing, as well as gDNA isolated from the Olympia oyster reciprocal transplant experiment out on a Bioanalyzer (Agilent) using the DNA 12000 chips. The results from the chip were a bit confusing and difficult to assess exactly what was going on with the DNA.\nSo, I ran 5μL of each of those samples on a 0.8% agarose 1x modified TAE gel w/EtBr to get a better look at how the samples actually looked.\nResults:\n(https://raw.githubusercontent.com/sr320/LabDocs/master/protocols/Commercial_Protocols/ThermoFisher_OgeneRuler_DNA_Ladder_Mix_F100439.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/20151113_gel_gDNA.png)\nBoth the geoduck and the Olympia oyster samples for genome sequencing show intact, high molecular weight bands with some smearing (i.e. degradation). The oly sample looks a bit funky, most likely due to a gel anomaly. I’ll quantify these using a dye-based method for a more accurate quantification before sending off to BGI.\nThe Fidalgo 2SN samples all have intact, high molecular weight bands, but most of the samples show extensive smearing (i.e. degradation). However, sample 2SN 35 has no visible DNA at all.\nHere’s a table highlighting the differences between the Fidalgo gDNA samples:\n\n\n\n\n\nSample\n\n\nFresh/Frozen\n\n\nIsolator\n\n\n\n\n10\n\n\nFresh\n\n\nSam\n\n\n\n\n11\n\n\nFresh\n\n\nSam\n\n\n\n\n12\n\n\nFresh\n\n\nSam\n\n\n\n\n20\n\n\nFresh\n\n\nMrunmayee\n\n\n\n\n21\n\n\nFresh\n\n\nMrunmayee\n\n\n\n\n22\n\n\nFresh\n\n\nMrunmayee\n\n\n\n\n32\n\n\nFrozen\n\n\nSam\n\n\n\n\n33\n\n\nFrozen\n\n\nSam\n\n\n\n\n34\n\n\nFrozen\n\n\nSam\n\n\n\n\n35\n\n\nFrozen\n\n\nSam\n\n\n\n\n\nThe fresh ctenidia samples were isolated by me on 20151021 and by Mrunmayee on 20151023. The frozen ctenidia samples were isolated by me on 20151103.\nIt’s interesting to note that Mrunmayee’s isolations appear to exhibit the least amount of degradation. Besides her handling the samples, the primary difference is that her samples were incubated in the buffer/Pro K solution O/N @ 37C, while my fresh samples were incubated @ 60C for 3hrs and my frozen samples were incubated @ 60C for 1hr. Overall, though, the frozen samples look the worst.\nFinally, it’s also interesting to see that the two samples isolated using DNazol (geoduck and Olympia oyster genome samples) migrate more slowly than the remaining Olympia oyster samples which were isolated with the E.Z.N.A. Mollusc Kit."
  },
  {
    "objectID": "posts/2015/2015-10-30-adaptor-ligation-oly-alfi-digested-gdna-for-rad-seq-3/index.html",
    "href": "posts/2015/2015-10-30-adaptor-ligation-oly-alfi-digested-gdna-for-rad-seq-3/index.html",
    "title": "Adaptor Ligation – Oly AlfI-Digested gDNA for RAD-seq",
    "section": "",
    "text": "Continued to follow the 2bRAD protocol (PDF) developed by Eli Meyer’s lab.\nDigested DNA from yesterday was heat inactivated for 10mins @ 65C and was not run out on a gel due to the fact that the input gDNA was degraded and a shift in the high molecular weight band (indicating the digestion was successful) would not exist because a high molecular weight band is absent in these samples.\n\nAnneal Adaptors\nAfter preparing the two adaptors below, they were incubated for 10mins @ RT:\n\nAdaptor 1 (2μM final concentration of each oligo): 1.5μL of 5ILL-NR (100μM) + 1.5μL of anti-ILL (100μM) + 72μL H2O = 75μL total\nAdaptor 2 (2μM final concentration of each oligo): 1.5μL of 3ILL-NR (100μM) + 1.5μL of anti-ILL (100μM) + 72μL H2O = 75μL total\n\nAfter annealing, the adaptors were stored on ice.\n\n\nAdaptor Ligation\nAll components were stored on ice. Ligation reactions were prepared on ice and performed in 0.5mL snap cap tubes.\n\n\n\n\n\nREAGENT\n\n\nSINGLE REACTION (μL)\n\n\nx11\n\n\n\n\nDigested DNA\n\n\n10\n\n\nNA\n\n\n\n\nATP (10mM)\n\n\n1\n\n\n11\n\n\n\n\n10x T4 Ligase Buffer\n\n\n4\n\n\n44\n\n\n\n\nAdaptor 1 (2μM)\n\n\n5\n\n\n55\n\n\n\n\nAdaptor 2 (2μM)\n\n\n5\n\n\n55\n\n\n\n\nT4 DNA Ligase\n\n\n1\n\n\n11\n\n\n\n\nNanoPure H2O\n\n\n24\n\n\n264\n\n\n\n\nTOTAL\n\n\n50\n\n\n440\n\n\n\n\n\nCombined 40μL of the master mix with 10μL of AlfI-digested DNA in a 0.5mL snap cap tube.\nIncubated ligation reaction @ 16C O/N in PTC-200 thermal cycler (MJ Research) – no heated lid.\nLigations will be stored @ -20C until I can continue working with them on Tuesday."
  },
  {
    "objectID": "posts/2015/2015-02-09-library-prep-quantification-of-c-gigas-larvae-oa-1000ppm-library/index.html",
    "href": "posts/2015/2015-02-09-library-prep-quantification-of-c-gigas-larvae-oa-1000ppm-library/index.html",
    "title": "Library Prep - Quantification of C.gigas larvae OA 1000ppm library",
    "section": "",
    "text": "The completed BS Illumina library made on Friday (1000ppm) was quantified via fluorescence using the Quant-iT DNA BR Kit (Life Technologies/Invitrogen).  Also quantified Jake’s libraries. Used 1μL of  each sample and the standards.  All standards were run in duplicate.  Due to limited sample, the libraries were only processed singularly, without replication.  Fluorescence was measured on a FLx800 plate reader (BioTek), using the Gen5 (BioTek) software for all calculations.\nResults:\n20150209_CgigasOA_BSlibrraryQuants_OluridaLibraryQuants\nThe good news is that the standard curve looked fine, with an R²=0.998.\nThe bad news is that there’s no detectable DNA in the sample, just like last time.\nPossibly something is totally shot with this sample?  Will quantify the sheared DNA and decide what to do.\nI quantified the sheared DNA and there’s nothing there! Where did it go? I just don’t get it. It was sheared, speed-vac’d and resuspended.  All the DNA should still be in the tubes…"
  },
  {
    "objectID": "posts/2015/2015-05-05-rna-isolation-geoduck-gonad-in-paraffin-histology-blocks-3/index.html",
    "href": "posts/2015/2015-05-05-rna-isolation-geoduck-gonad-in-paraffin-histology-blocks-3/index.html",
    "title": "RNA Isolation – Geoduck Gonad in Paraffin Histology Blocks",
    "section": "",
    "text": "UPDATE 20150528: The RNA isolated in this notebook entry may have been consolidated on 20150528.\nLast week’s RNA isolation (a second attempt at obtaining RNA from the samples) performed poorly. I will re-isolate RNA from the following samples:\n\n02\n03\n04\n07\n08\n09\n35\n38\n46\n65\n67\n68\n\nInstead of full sections from each histology cassette, I gouged/shaved off samples directly from the tissue in each of the blocks to maximize the amount of tissue input. However, due to the small size and susceptibility to flying around because of static electricity, none of these were able to be weighed prior to processing.\nIMPORTANT:\n\nUsed Buffer TR1 + β-mercaptoethanol (β-ME) prepared 20150427 as well as fresh Buffer TR1 + β-ME prepared today.\nI used aliquots of DNase prepared on 20150408.\n\nSamples were then processed with the PAXgene Tissue RNA Kit in a single group.\nIsolated RNA according to the PAXgene Tissue RNA Kit protocol with the following alterations:\n\n“Max speed” spins were performed at 19,000g.\nTissue disruption was performed with the Disruptor Genie @ 45C for 15mins.\nShaking incubation step was performed with Disruptor Genie\nSamples were eluted with 40μL of Buffer TR4, incubated @ 65C for 5mins, immediately placed on ice and quantified on the Roberts Lab NanoDrop1000.\n\nResults:\n(http://eagle.fish.washington.edu/Arabidopsis/20150505_Geoduck_histo_RNA_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150505_Geoduck_histo_RNA_plots.JPG)\nWell, despite the low numbers, all of the samples (excluding 46 - 68) are double the yield of what I saw previously. This is good, but the amount of RNA from these is probably borderline sufficient quantity for RNA-Seq.\nThe kit has enough columns for six sample preps. I think I’ll attempt this strategy again (gouging/shaving directly from tissue in histo cassette), but really take a fair amount of tissue this time and see if I can get more.\nAll samples were stored @ -80C in Shellfish RNA Box #5."
  },
  {
    "objectID": "posts/2015/2015-09-02-genomic-dna-isolation-olympia-oyster-adductor-musle-mantle/index.html",
    "href": "posts/2015/2015-09-02-genomic-dna-isolation-olympia-oyster-adductor-musle-mantle/index.html",
    "title": "Genomic DNA Isolation - Olympia oyster adductor musle & mantle",
    "section": "",
    "text": "Isolated gDNA from Ostrea lurida (Olympia oyster) adductor muscle & mantle samples collected by Brent & Steven on 20150812 using the E.Z.N.A Mollusc DNA Kit (Omega Bio-Tek) according to the manufacturer’s protocol, with the following adjustments:\n\n29.8mg of adductor muscle\n28.7mg of mantle\nTissues homogenized in 350μL of ML1 Buffer with disposable mortar/pestle tubes using only three pestles strokes\nHomogenized tissue incubated in ML1 Buffer + Proteinase K @ 60C for 2.5hrs\nAdded 310μL of MBL Buffer to adductor muscle sample and 265μL of MBL Buffer to mantle sample\nAdded 620μL of 100% EtOH and 530μL of 100% EtOH to the adductor muscle and mantle sample, respectively.\nEluted with 50μL Elution Buffer.\n\nSpec’d on Roberts Lab NanoDrop1000 (ThermoFisher) and stored temporarily at 4C to avoid freeze-thawing before sending off for sequencing.\nResults:\n(http://eagle.fish.washington.edu/Arabidopsis/20150901_gDNA_oly_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150901_gDNA_oly_plots.JPG)\nYields are good (~6μg for the adductor muscle and ~10μg for the mantle).\nThe adductor muscle sample looks pretty good (perfect 260/280 ratio and solid 260/230 ratio), while the mantle sample looks OK (good 260/280 ratio, tolerable 260/230 ratio). Will run samples on gel to assess gDNA integrity."
  },
  {
    "objectID": "posts/2015/2015-12-22-illumina-methylation-library-quantification-bs-seq-olyc-gigas-libraries/index.html",
    "href": "posts/2015/2015-12-22-illumina-methylation-library-quantification-bs-seq-olyc-gigas-libraries/index.html",
    "title": "Illumina Methylation Library Quantification - BS-seq Oly/C.gigas Libraries",
    "section": "",
    "text": "Re-quantified the libraries that were completed yesterday using the Qubit3.0 dsDNA HS (high sensitivity) assay because the library concentrations were too low for the normal broad range kit.\nResults:\nQubit Quants and Library Normalization Calcs: 20151222_qubit_illumina_methylation_libraries\n\n\n\n\n**SAMPLE**\n\n**CONCENTRATION (ng/μL)**\n\n\n\n1NF11\n\n\n2.42\n\n\n\n1NF15\n\n\n1.88\n\n\n\n1NF16\n\n\n2.74\n\n\n\n1NF17\n\n\n2.54\n\n\n\n2NF5\n\n\n2.72\n\n\n\n2NF6\n\n\n2.44\n\n\n\n2NF7\n\n\n2.38\n\n\n\n2NF8\n\n\n1.88\n\n\n\nM2\n\n\n2.18\n\n\n\nM3\n\n\n2.56\n\n\n\nNF2_6\n\n\n2.5\n\n\n\nNF_18\n\n\n2.66\n\n\n\n\n\nThings look pretty good. The [TruSeq DNA Methylation Library Kit (Illumina)(https://github.com/sr320/LabDocs/blob/master/protocols/Commercial_Protocols/Illumina_truseq-dna-methylation-library-prep-guide-15066014-a.pdf) suggests that the libraries produced should end up with concentrations >3ng/μL, but we have plenty of DNA here to make a pool for running on the HiSeq2500."
  },
  {
    "objectID": "posts/2015/2015-09-17-agarose-gel-olympia-oyster-whole-body-gdna-integrity-check/index.html",
    "href": "posts/2015/2015-09-17-agarose-gel-olympia-oyster-whole-body-gdna-integrity-check/index.html",
    "title": "Agarose Gel - Olympia oyster Whole Body gDNA Integrity Check",
    "section": "",
    "text": "Ran the gDNA isolated yesterday from Ostrea lurida whole body on a 0.8% modified TAE gel (w/EtBr) to assess gDNA integrity. Used 1μL of each sample.\nResults:\n(https://raw.githubusercontent.com/sr320/LabDocs/master/protocols/Commercial_Protocols/ThermoFisher_OgeneRuler_DNA_Ladder_Mix_F100439.jpg)\nThe results are not good. Every sample exhibits serious degradation (the smearing that’s present in each lane). There should be a distinct, high molecular weight band with no smearing if the gDNA was high quality and intact. These extractions also served as a comparison in slight differences in the extraction procedure (homogenization with & without mortar/pestle), as described in Steven’s post. However, those differences seem to have no impact on the quality of the resulting gDNA.\nI [isolated gDNA from Ostrea lurida tissue samples two weeks ago using the E.Z.N.A. Mollusc DNA Kit (Omega Bio-Tek)(2015/09/01/agarose-gel-geoduck-olympia-oyster-gdna-integrity-check.html) and didn’t see this level of degradation. Additionally, Katherine Silliman used the E.Z.N.A. Mollusc DNA Kit to isolate gDNA from Ostrea lurida larvae and obtained high quality gDNA in virtually all of her samples. Below is my gel and Katherine’s gel for quick comparison to the one above:\n[caption id=“” align=“alignleft” width=“301”](http://eagle.fish.washington.edu/Arabidopsis/20150901_gDNA_geoduck_oly.jpg) Ostrea lurida gDNA isolated from adductor muscle & mantle tissues (lanes 4 & 5). Despite low quantity loading, notice that smearing below high molecular weight bands is limited to a low molecular weight range.[/caption]\n[caption id=“” align=“alignleft” width=“213”](https://marinegenes.files.wordpress.com/2015/09/gel_9_11_15.jpg?w=584) Katherine’s gel of Ostrea lurida gDNA isolated from larvae.[/caption]\nI can’t be certain what is causing this issue. We previously had this same issue with a different group of Ostrea lurida whole body gDNA isolations (using a DNeasy Blood & Tissue Kit [Qiagen]). Two different kits using whole bodies and both sets of extractions have produced similarly bad results. It’s certainly possible that some nastiness (that’s a scientific term, btw) is being introduced by using whole body instead of specific tissues.\nAnother possible contributor to the DNA degradation we’ve seen is how the samples were collected and stored. I’m not up-to-date on exactly how the preservation was accomplished, but I do know that the Ostrea lurida whole body samples I previously worked with were just masses of black when I removed them from shells/tubes for isolation. So, in that case, it wasn’t terribly surprising that that the gDNA obtained from those was degraded. It should also be noted that Katherine’s extraction were from whole larvae that had been stored in RNAlater. Although a direct comparison cannot be made due to the difference in developmental stage between Katherine’s samples and these, it lends some evidence to the possibility that sample collection/storage is a contributor to the degraded gDNA we’re obtaining from whole body oyster extractions. However, with that being said, I’m not sure what the collection and storage background is on this particular set of samples."
  },
  {
    "objectID": "posts/2015/2015-07-02-pcr-sea-pen-luciferase/index.html",
    "href": "posts/2015/2015-07-02-pcr-sea-pen-luciferase/index.html",
    "title": "PCR - Sea Pen luciferase",
    "section": "",
    "text": "Ran a PCR to obtain luciferase DNA for sequencing.\nUsed sea pen gDNA extracted by Jonathan on 20150527.\nPrimers:\n\n\n\n\n\nSRID\n\nName\n\n\n\n\n1604\n\nRr_46_65F\n\n\n\n\n1603\n\nRr_887_868R\n\n\n\n\n\nMaster mix calcs are here: 20150702_seapen_PCR\nCycling params:\n\n95C - 10mins\n95C - 15s\n55C - 15s\n72C - 1min\nGo to Step 2 39 times\n\nRan samples on 0.8% agarose, low TAE gel stained with EtBr.\nResults:\n(https://github.com/sr320/LabDocs/blob/master/protocols/Commercial_Protocols/ThermoFisher_OGeneRuler100bpDNA_ladder.jpg?raw=true)\nLoading:\nLane 1 - ladder\nLane 2 - empty\nLane 3 - sea pen gDNA\nLane 4 - NTC\nPCR did not work. Was expecting a band of ~800bp.\nLooks like I may have overloaded the PCR reaction with gDNA. Used 10μL of gDNA.\nHowever, that is quite the smear, suggesting a significant amount of degradation present in the gDNA.\nWill re-run this PCR next week with less gDNA (or, cDNA instead) in order to generate a PCR product."
  },
  {
    "objectID": "posts/2015/2015-06-17-reverse-transcription-o-lurida-dnased-rna-controls-and-1hr-heat-shock/index.html",
    "href": "posts/2015/2015-06-17-reverse-transcription-o-lurida-dnased-rna-controls-and-1hr-heat-shock/index.html",
    "title": "Reverse Transcription - O.lurida DNased RNA Controls and 1hr Heat Shock",
    "section": "",
    "text": "Performed reverse transcription on the Olympia oyster DNased RNA from the control samples and the 1hr heat shock samples of Jake’s project. To accommodate the large numbers of anticipated genes to be targeted in subsequent qPCRs, I prepared 100μL reactions (normally, 25μL reactions are prepared) using 250ng of each DNased RNA. A 1:10 dilution of the oligo dT primers (Promega) was prepared to improve pipetting accuracy. All incubations were performed in a thermal cycler without using a heated lid.\nDNased RNA was combined with NanoPure H2O and oligo dT primers in 48 wells of a PCR plate, heated @ 70C for 10mins and immediately placed on ice. After 5mins, the plate was spun 2000g @ RT for 2mins and returned to ice.\n25.25μL of a master mix containing 5x M-MLV Buffer (Promega), dNTPs (10mM each; Promega), and M-MLV Reverse Transcriptase (50U/rxn; Promega) was distributed to each well and mixed via pipetting. The plate was heated @ 42C for 1hr, 95C for 3mins. The plate was spun 2000g @ RT for 2mins and then stored @ -20C.\nPlate layout and all calculations can be found here (Google Sheet): 20150616_Jake_Oly_cDNA_Calcs"
  },
  {
    "objectID": "posts/2015/2015-05-13-qpcr-jake-o-lurida-ctenidia-rna-control-samples-from-20150507/index.html",
    "href": "posts/2015/2015-05-13-qpcr-jake-o-lurida-ctenidia-rna-control-samples-from-20150507/index.html",
    "title": "qPCR - Jake O.lurida ctenidia RNA (Control Samples) From 20150507",
    "section": "",
    "text": "Ran qPCRs on the O.lurida total RNA I isolated on 20150507 to assess presence of gDNA carryover with Oly Actin primers (SR IDs: 1505, 1504).\nUsed 1μL from all templates.\nAll samples were run in duplicate.\nPositive control was HL1 O.lurida DNA isolated by Jake on 20150323.\nMaster mix calcs are here: 20150512_qPCR_Oly_RNA\nCycling params:\n\n95C - 3mins\n\n40 cycles of:\n\n95C - 5s\n60C - 20s\n\nMelt curve\nPlate layout: 20150512_qPCR_plate_Jake_Oly_Control_RNA\nResults:\nqPCR Data File (Opticon2): Sam_20150512_105811.tad\nqPCR Report (Google Spreadsheet): 20150512_qPCR_Report_Jake_Oly_Control_RNA\nExcluding the no template controls (NTC), all samples produced amplification. Will require DNasing before making cDNA.\nOn a side note, it should be noted that the efficiencies for all of the reactions were pretty bad; probably averaging 50%. Not entirely sure why or what that indicates.\nIn the amplification plots below, the positive control reps are the two red lines coming up at cycle ~22.\n\nAmplification Plots\n(http://eagle.fish.washington.edu/Arabidopsis/20150512_qPCR_Amp_Jake_Oly_Control_RNA.JPG)\n\n\nMelt Curves\n(http://eagle.fish.washington.edu/Arabidopsis/20150512_qPCR_Melt_Jake_Oly_Control_RNA.JPG)"
  },
  {
    "objectID": "posts/2015/2015-11-17-gel-extraction-oly-rad-seq-prep-scale-pcr/index.html",
    "href": "posts/2015/2015-11-17-gel-extraction-oly-rad-seq-prep-scale-pcr/index.html",
    "title": "Gel Extraction - Oly RAD-Seq Prep Scale PCR",
    "section": "",
    "text": "Extracted the PCR products from the gel slices from 20151113 using the QIAQuick Gel Extraction Kit (Qiagen) according to the manufacturer’s protocol. Substituted MiniElute columns so that I could elute with a smaller volume than what is used in the QIAQuick standard protocol.\nSamples were eluted with 20μL of Buffer EB.\nWill quantify these libraries via qPCR."
  },
  {
    "objectID": "posts/2015/2015-11-14-pcr-oly-rad-seq-prep-scale-pcr-2/index.html",
    "href": "posts/2015/2015-11-14-pcr-oly-rad-seq-prep-scale-pcr-2/index.html",
    "title": "PCR – Oly RAD-seq Prep Scale PCR",
    "section": "",
    "text": "Continuing with the RAD-seq library prep. Following the Meyer Lab 2bRAD protocol. After determining the minimum number of PCR cycles to run to generate a visible, 166bp band on a gel yesterday, ran a full library “prep scale” PCR.\n\n\n\n\n\nREAGENT\n\n\nSINGLE REACTION (μL)\n\n\nx11\n\n\n\n\nTemplate\n\n\n40\n\n\nNA\n\n\n\n\nILL-HT1 (1μM)\n\n\n5\n\n\n55\n\n\n\n\nILL-BC# (1μM)\n\n\n5\n\n\nNA\n\n\n\n\nNanoPure H2O\n\n\n5\n\n\n55\n\n\n\n\ndNTPs (1mM)\n\n\n20\n\n\n220\n\n\n\n\nILL-LIB1 (10μM)\n\n\n2\n\n\n22\n\n\n\n\nILL-LIB2 (10μM)\n\n\n2\n\n\n22\n\n\n\n\n5x Q5 Reaction Buffer\n\n\n20\n\n\n220\n\n\n\n\nQ5 DNA Polymerase\n\n\n1\n\n\n11\n\n\n\n\nTOTAL\n\n\n100\n\n\n550\n\n\n\n\n\nCombined the following for PCR reactions:\n\n55μL PCR master mix\n40μL ligation mix\n5μL of ILL-BC# (1μM) – The barcode number and the respective sample are listed below.\n\n\n\n\n\n\nSAMPLE\n\n\nBARCODE\n\n\nSEQUENCE\n\n\n\n\nOly RAD 02\n\n\n 1\n\n\n CGTGAT\n\n\n\n\nOly RAD 03\n\n\n 2\n\n\n ACATCG\n\n\n\n\nOly RAD 04\n\n\n 3\n\n\n GCCTAA\n\n\n\n\nOly RAD 06\n\n\n 4\n\n\n TGGTCA\n\n\n\n\nOly RAD 07\n\n\n 5\n\n\n CACTGT\n\n\n\n\nOly RAD 08\n\n\n 6\n\n\n ATTGGC\n\n\n\n\nOly RAD 14\n\n\n 7\n\n\n GATCTG\n\n\n\n\nOly RAD 17\n\n\n 8\n\n\n TCAAGT\n\n\n\n\nOly RAD 23\n\n\n 9\n\n\n CTGATC\n\n\n\n\nOly RAD 30\n\n\n10\n\n\nAAGCTA\n\n\n\n\n\nCycling was performed on a PTC-200 (MJ Research) with a heated lid:\n\n\n\n\n\nSTEP\n\n\nTEMP (C)\n\n\nTIME (s)\n\n\n\n\nInitial Denaturation\n\n\n\n98\n\n\n\n\n30\n\n\n\n\n\n17 cycles\n\n\n\n98\n60\n72\n\n\n\n\n5\n20\n10\n\n\n\n\n\n\nAfter cycling, added 16μL of 6x loading dye to each sample.\nLoaded 10μL of ladder on each of the two gels.\nResults:\n(https://raw.githubusercontent.com/sr320/LabDocs/master/protocols/Commercial_Protocols/ThermoFisher_OgeneRuler_DNA_Ladder_Mix_F100439.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/20151113_gel_oly_RAD_prep_PCR_01.png)\n(http://eagle.fish.washington.edu/Arabidopsis/20151113_gel_oly_RAD_prep_PCR_02.png)\n(http://eagle.fish.washington.edu/Arabidopsis/20151113_gel_oly_RAD_prep_PCR_03.png)\n(http://eagle.fish.washington.edu/Arabidopsis/20151113_gel_oly_RAD_prep_PCR_04.png)\nThings looked fine. Excised the bands from each sample indicated by the green arrow. Before and after gel images show regions excised. Will purify the bands and quantify library yields."
  },
  {
    "objectID": "posts/2015/2015-11-04-dna-isolations-oly-fidalgo-2sn-ctenidia/index.html",
    "href": "posts/2015/2015-11-04-dna-isolations-oly-fidalgo-2sn-ctenidia/index.html",
    "title": "DNA Isolations – Oly Fidalgo 2SN Ctenidia",
    "section": "",
    "text": "Isolated DNA from 24 2SN ctenidia samples from Friday’s sampling (#32 - 55). Samples were thawed at RT.\nDNA was isolated using the E.Z.N.A. Mollusc Kit (Omega BioTek) according to the manufacturer’s protocol with the following changes:\n\nSamples were incubated @ 60C for only 1hr, per Steven’s recommendation (an attempt to prevent degradation)\nNo optional steps were performed\nUsed 300μL of MBL Buffer for all samples (this was more than the recovered volume of aqueous phase from each sample)\nSingle elution of 50μL\n\nSamples were stored @ -20C in: Oly gDNA Oly Reciprocal Transplant Final Sampling Box #1.\nSome notes:\n\nTotal time (including 1hr incubation): 4.5hrs.\nShort incubation time did not completely digest samples\nPartial tissue digestions led to difficulties in recovering entire aqueous phase, post chloroform treatment"
  },
  {
    "objectID": "posts/2015/2015-02-27-dna-quantification-claires-sheared-c-gigas-mantle-heat-shock-samples/index.html",
    "href": "posts/2015/2015-02-27-dna-quantification-claires-sheared-c-gigas-mantle-heat-shock-samples/index.html",
    "title": "DNA Quantification - Claire’s Sheared C.gigas Mantle Heat Shock Samples",
    "section": "",
    "text": "I previously checked Claire’s sheared DNA on the Bioanalyzer to verify the fragment size and to quantify the samples. Looking at her notebook, her numbers differ greatly from the Bioanalyzer, possibly due to the fact that the DNA1000 assay chip used only measures DNA fragments up to 1000bp in size. If her shearing was incomplete, then there would be DNA fragments larger than 1000bp that wouldn’t have been measured by the Bioanalyzer. So, I decided to quantify the samples on the NanoDrop1000 (ThermoFisher) again.\nResults:\nSpreadsheet: 20150226_Claire_sheared_Emma_1000ppm_OD260s\n(http://eagle.fish.washington.edu/Arabidopsis/20150226_Claire_sheared_Emma_1000ppm_plots.JPG)\nComparison of NanoDrop1000 and Bioanalyzer measurements.\n\n\n\n\n\nSample\n\n\nNanoDrop (ng/μL)\n\n\nBioanalyzer (ng/μL)\n\n\n\n\n2M sheared\n\n\n48.03\n\n\n16.28\n\n\n\n\n4M sheared\n\n\n190.96\n\n\n58.52\n\n\n\n\n6M sheared\n\n\n141.56\n\n\n42.98\n\n\n\n\n2MHS sheared\n\n\n221.93\n\n\n32.45\n\n\n\n\n4MHS sheared\n\n\n257.48\n\n\n43.82\n\n\n\n\n6MHS sheared\n\n\n202.02\n\n\n51.12\n\n\n\n\n\nThe NanoDrop is known to overestimate sample quantities due to the indiscriminate nature of UV spectrophotometry and that could be the reason for the large discrepancy between the two measurements (i.e. RNA carryover may lead to overestimation). As such, I’ll quantify the samples using a fluorescence-based assay for double stranded DNA tomorrow in hopes of getting the most accurate measurement."
  },
  {
    "objectID": "posts/2015/2015-12-19-reagent-prep-rna-pico-6000-ladder/index.html",
    "href": "posts/2015/2015-12-19-reagent-prep-rna-pico-6000-ladder/index.html",
    "title": "Reagent Prep - RNA Pico 6000 Ladder",
    "section": "",
    "text": "Prepared the RNA Pico 6000 ladder (Agilent) according to the manufacturer’s protocol:\n\nDenatured @ 70C for 2mins\nImmediately put on ice\nAdded 90μL H2O\n\nMade 2μL aliquots of the ladder in 0.5mL snap cap tubes. Samples were boxed, labeled, and stored @ -80C (Rack #9)."
  },
  {
    "objectID": "posts/2015/2015-12-18-bisulfite-treatment-oly-reciprocal-transplant-dna-c-gigas-lotterhos-dna-for-bs-seq/index.html",
    "href": "posts/2015/2015-12-18-bisulfite-treatment-oly-reciprocal-transplant-dna-c-gigas-lotterhos-dna-for-bs-seq/index.html",
    "title": "Bisulfite Treatment - Oly Reciprocal Transplant DNA & C.gigas Lotterhos DNA for BS-seq",
    "section": "",
    "text": "After confirming that the DNA available for this project looked good, I performed bisulfite treatment on the following gDNA samples:\n\n1NF11\n1NF15\n1NF16\n1NF17\n2NF5\n2NF6\n2NF7\n2NF8\nNF2_6\nNF2_18\nM2\nM3\n\nSample names breakdown like this:\n1NF#\n1 = Fidalgo Bay outplants\nNF = Fidalgo Bay broodstock origination\n\n= Sample number\n2NF#\nSame as above, but:\n2 = Oyster Bay outplants\nNF2_# (Oysters grown in Oyster Bay; DNA provided by Katherine Silliman)\nNF2 = Fidalgo Bay broodstock origination, family #2\n\n\n= Sample number\nM2/M3 = C.gigas from Katie Lotterhos\nFollowed the guidelines of the [TruSeq DNA Methylation Library Prep Guide (Illumina)(https://github.com/sr320/LabDocs/blob/master/protocols/Commercial_Protocols/Illumina_truseq-dna-methylation-library-prep-guide-15066014-a.pdf).\nUsed the [EZ DNA Methylation-Gold Kit (ZymoResearch)(https://github.com/sr320/LabDocs/blob/master/protocols/Commercial_Protocols/ZymoResearch_EZ_DNA_Methylation-Gold_Kit_d5005i.pdf) according to the manufacturer’s protocol with the following changes/notes:\n\nUsed 100ng DNA (per Illumina recs; Zymo recommends at least 200ng for “optimal results”).\nThermal cycling was performed in 0.5mL thin-wall tubes in a PTC-200 (MJ Research) using a heated lid\nCentrifugations were performed at 13,000g\nDesulphonation incubation for 20mins.\n\nDNA quantity calculations are here (Google Sheet): 20151218_oly_bisulfite_calcs\nSamples were stored @ -20C. Will check samples via Bioanalyzer before proceeding to library construction."
  },
  {
    "objectID": "posts/2015/2015-10-30-dna-isolation-geoduck-olympia-oyster-2/index.html",
    "href": "posts/2015/2015-10-30-dna-isolation-geoduck-olympia-oyster-2/index.html",
    "title": "DNA Isolation – Geoduck & Olympia Oyster",
    "section": "",
    "text": "Amazingly, we need more gDNA for the two genome sequencing projects (geoduck and Olympia oyster). Used geoduck adductor muscle sample from Box 1 of the geoduck samples collected by Brent & Steven on 20150811. Used Olympia oyster ctenidia from Box 1 of adductor muscle sample collected by Brent & Steven on 20150812.\nTissues were split in approximately half, minced and transferred to tubes with 1mL of DNAzol + 50μg/mL of Proteinase K (Fermentas). Previously, I had just homogenized samples. I’m hoping that the overnight digestion with Proteinase K will help increase yields from these.\nTissue weights:\n\nGeoduck adductor muscle tube 1: 292mg (gone)\nGeoduck adductor muscle tube 2: 320mg (gone)\nOlympia oyster ctenidia tube 1: 135mg (gone)\nOlympia oyster ctenidia tube 2: 130mg (gone)\n\nSamples were isolated using DNAzol (Molecular Research Center) according to the manufacturer’s protocol, with the following adjustments:\n\nSamples were incubated O/N @ RT on a rotator.\nAfter Proteinase K digestion, added 40μL RNAse A (100mg/mL) and incubated @ RT for 15mins.\nPerformed optional centrifugation step (10,000g, 10mins @ RT)\nInitial pellet wash was performed using a 70%/30% DNAzol/EtOH\nPellets were resuspended Buffer EB (Qiagen)\n\nResuspension volume = 500μL total for each species\nSamples were incubated O/N at RT to facilitate pellet resuspension.\nNOTE: Geoduck “pellets” were not very DNA pellet-like. Very loose, white, and sort of disintegrate (but not dissolve in solution) when attempted to resuspend."
  },
  {
    "objectID": "posts/2015/2015-05-07-rna-isolation-jakes-o-lurida-ctenidia-1hr-heat-stress-from-20150422/index.html",
    "href": "posts/2015/2015-05-07-rna-isolation-jakes-o-lurida-ctenidia-1hr-heat-stress-from-20150422/index.html",
    "title": "RNA Isolation - Jake’s O. lurida Ctenidia 1hr Heat Stress from 20150422",
    "section": "",
    "text": "Isolated RNA from Jake’s Olympia oyster ctenidia, 1hr heat shock, collected on 20150422. Samples had been homogenized and stored @ -80C.\nThe following sample tubes (heat-shocked oyster ctenidia) were removed from -80C and thawed at RT:\n\n42215 HT1 1\n42215 HT1 2\n42215 HT1 3\n42215 HT1 4\n42215 HT1 5\n42215 HT1 6\n42215 HT1 7\n42215 HT1 8\n42215 NT1 1\n42215 NT1 1\n42215 NT1 2\n42215 NT1 3\n42215 NT1 4\n42215 NT1 5\n42215 NT1 6\n42215 NT1 7\n42215 NT1 8\n42215 ST1 1\n42215 ST1 2\n42215 ST1 3\n42215 ST1 4\n42215 ST1 5\n42215 ST1 6\n42215 ST1 7\n42215 ST1 8\n\nNOTE: Samples NT1 1 and NT1 2 only had 700μL of RNAzol RT in them. Added additional 300μL of RNAzol RT to each.\nNOTE: 0.1% DEPC-H2O used throughout this procedure was prepared on 7/15/2010 by me.\nAccording to Jake’s notebook entry, the samples should have been previously homogenized in RNAzol RT. However, none of the samples showed evidence of being homogenized:\n(http://eagle.fish.washington.edu/Arabidopsis/Pics/20150506_Oly_tissue_RNAzol.JPG)\nIn theory, if these samples were snap frozen on liquid nitrogen after being placed in the RNAzol RT, there should be almost no impact on the RNA.\nProcedure:\nSamples were homogenized with disposable pestle in their respective tubes and vortexed.\nAdded 400μL of 0.1% DEPC-H2O to each sample and vortexed 15s.\nIncubated samples 15mins at RT.\nCentrifuged tubes 15mins at RT @ 16,000g.\n750μL of the supe was transferred to a clean tube, added equal volume of isopropanol (750μL), mix by inversion (20 times), and incubated at RT for 15mins.\nCentrifuged 12,000g for 10mins.\nDiscarded supe.\nWashed pellets with 500μL of 75% EtOH (made with 0.1% DEPC-H2O) and centrifuged 4,000g for 3mins at RT. Repeated one time.\nRemoved EtOH and resuspended in  100μL of 0.1% DEPC-H2O. Most samples required vortexing to dissolve pellet.\nSample tubes were transferred to ice, quantified on the Roberts Lab NanoDrop1000, and stored @ -80C in their original box, pictured:\n(http://eagle.fish.washington.edu/Arabidopsis/Pics/20150506_Jake_Oly_RNA_box.JPG)\nResults:\n(http://eagle.fish.washington.edu/Arabidopsis/20150506_Jake_Oly_1h_HS_RNA_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150506_Jake_Oly_1h_HS_RNA_plots-01.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150506_Jake_Oly_1h_HS_RNA_plots-02.JPG)\nGoogle Spreadsheet with absorbance data: 20150506_Jake_Oly_1h_HS_RNA_ODs\nOverall, the samples have excellent yields. The exceptions being the two samples that had less than 1mL of RNAzol RT in them to start (their yields are actually fine, but relative to all the other samples, they aren’t great). Should I have left them that way instead of adding additional RNAzol RT? Was there something wrong with these samples in the first place and that’s why they didn’t have a full 1mL of RNAzol RT in the tube already?\nThe 260/280 ratios are pretty good for most of the samples (>1.8), however I’d prefer to see RNA with 260/280 ratios >1.9.\nThe 260/230 ratios are amazing! The best I’ve seen coming straight out of an RNA isolation in a long time.\nEventually (once I’ve isolated RNA from the control set that corresponds to these heat shock samples), I’ll check for gDNA carryover and then, probably, DNase the RNA."
  },
  {
    "objectID": "posts/2015/2015-01-13-speedvac-c-gigas-larvae-oa-dna/index.html",
    "href": "posts/2015/2015-01-13-speedvac-c-gigas-larvae-oa-dna/index.html",
    "title": "SpeedVac - C.gigas larvae OA DNA",
    "section": "",
    "text": "The DNA extracted and sheared on 20150109 was in a volume too great to proceed with bisulfite conversion.  Dried the samples to complete dryness in a SpeedVac (~4hrs).  Reconsitituted DNA in 24μL of NanoPure water.  Will bisulfite convert tomorrow.\nSample list:\n\n\n\n\n\nSAMPLE ID\n\n\nDATE\n\n\nTREATMENT (ppm)\n\n\n\nLARVAE\n\n\nTOTAL DNA (ng)\n\n\n\n\n6B5\n\n\n20110513\n\n\n400\n\n\n5,000\n\n\n105\n\n\n\n\n1B2\n\n\n20110513\n\n\n1000\n\n\n5,000\n\n\n109\n\n\n\n\n6B2\n\n\n20110513\n\n\n400\n\n\n10,000\n\n\n117\n\n\n\n\n1B1\n\n\n20110513\n\n\n1000\n\n\n10,000\n\n\n593\n\n\n\n\n1B1\n\n\n20110519\n\n\n1000\n\n\nNA\n\n\n500\n\n\n\n\n1B2\n\n\n20110519\n\n\n1000\n\n\nNA\n\n\n500\n\n\n\n\n6B2\n\n\n20110519\n\n\n400\n\n\nNA\n\n\n269\n\n\n\n\n6B1\n\n\n20110519\n\n\n400\n\n\nNA\n\n\n345\n\n\n\n\n\nUpdated the quantification spreadsheet with a column labeled “New” that calculates the new concentrations of the above samples in the 24μL volume.\nhttps://docs.google.com/spreadsheets/d/1e7EF05akWeBtO7Xz0UWXhIzRlkVU5HA_rjCE3c4SPEw/edit?usp=sharing\n``"
  },
  {
    "objectID": "posts/2015/2015-10-31-oyster-sampling-oly-fidalgo-2sn-2hl-2nf-reciprocal-transplants-final-samplings/index.html",
    "href": "posts/2015/2015-10-31-oyster-sampling-oly-fidalgo-2sn-2hl-2nf-reciprocal-transplants-final-samplings/index.html",
    "title": "Oyster Sampling - Oly Fidalgo 2SN, 2HL, 2NF Reciprocal Transplants Final Samplings",
    "section": "",
    "text": "The remaining Olympia oysters from Jake Heare’s reciprocal transplant experiment have been retrieved from field sites and are awaiting sampling. The oysters have been stored in the cold room (temp?) for 15 days so far.\nThe previous sampling scheme was described here: DNA Isolations – Fidalgo 2SN Reciprocal Transplants Final Samplings\nSampling scheme for today was as follows:\n\nAssign unique number to oysters (1-100 for each of the three populations)\nPhotograph with ruler for future shell measurements\nWeigh oysters\nDissect ctenidia for DNA isolation in 350μL MBL1 Buffer + 25μL Proteinase K (reagents part of the E.Z.N.A. Mollusc Kit [Omega BioTek)\nPreserve portion of remaining body tissue (not viscera; gonad/digestive gland) in 1mL RNAlater (Life Technologies)\n\nCtenidia samples were stored -80C in the buffer/pro k solution for DNA isolation at a later date.\nRNAlater samples will be stored over the weekend at 4C and then transferred to -20C for long term storage.\nAll oyster data is here (Google Sheet): Oly reciprocal final sampling\nAll photos from today’s sampling are here: Oyster Measurement Photos"
  },
  {
    "objectID": "posts/2015/2015-04-14-sequence-data-analysis-c-gigas-larvae-oa-bs-seq-data/index.html",
    "href": "posts/2015/2015-04-14-sequence-data-analysis-c-gigas-larvae-oa-bs-seq-data/index.html",
    "title": "Sequence Data Analysis - C.gigas Larvae OA BS-Seq Data",
    "section": "",
    "text": "Compared total amount of data generated from each index. The commands below send the output of the ‘ls -l’ command to awk. Awk sums the file sizes, found in the 5th field ($5) of the ‘ls -l’ command, then prints the sum, divided by 1024^3 to convert from bytes to gigabytes.\nIndex: CTTGTA\n$ ls -l 2212_lane2_[C]* | awk '{sum += $5} END {print sum/1024/1024/1024}' 5.33341\nIndex: GCCAAT $ ls -l 2212_lane2_[G]* | awk '{sum += $5} END {print sum/1024/1024/1024}' 7.00596\nThere’s ~1.4x data in the GCCAAT files.\nRan FASTQC on the following files downloaded earlier today:\n2212_lane2_CTTGTA_L002_R1_001.fastq.gz 2212_lane2_CTTGTA_L002_R1_002.fastq.gz 2212_lane2_CTTGTA_L002_R1_003.fastq.gz 2212_lane2_CTTGTA_L002_R1_004.fastq.gz 2212_lane2_GCCAAT_L002_R1_001.fastq.gz 2212_lane2_GCCAAT_L002_R1_002.fastq.gz 2212_lane2_GCCAAT_L002_R1_003.fastq.gz 2212_lane2_GCCAAT_L002_R1_004.fastq.gz 2212_lane2_GCCAAT_L002_R1_005.fastq.gz 2212_lane2_GCCAAT_L002_R1_006.fastq.gz\nThe FASTQC command is below. This command runs FASTQC in a for loop over any files that begin with “2212_lane2_C” or “2212_lane2_G” and outputs the analyses to the Arabidopsis folder on Eagle:\n$for file in /Volumes/nightingales/C_gigas/2212_lane2_[CG]*; do fastqc \"$file\" --outdir=/Volumes/Eagle/Arabidopsis/; done\nFrom within the Eagle/Arabidopsis folder, I renamed the FASTQC output files to prepend today’s date:\n$for file in 2212_lane2_[GC]*; do mv \"$file\" \"20150413_$file\"; done\nThen, I unzipped the .zip files generated by FASTQC in order to have access to the images, to eliminate the need for screen shots for display in this notebook entry:\n$for file in 20150413_2212_lane2_[CG]*.zip; do unzip \"$file\"; done\nThe unzip output retained the old naming scheme, so I renamed the unzipped folders:\n\\(for file in 2212_lane2_[GC]*; do mv \"\\)file” “20150413_$file”; done\nThe FASTQC results are linked below: 20150413_2212_lane2_CTTGTA_L002_R1_001_fastqc.html 20150413_2212_lane2_CTTGTA_L002_R1_002_fastqc.html 20150413_2212_lane2_CTTGTA_L002_R1_003_fastqc.html 20150413_2212_lane2_CTTGTA_L002_R1_004_fastqc.html 20150413_2212_lane2_GCCAAT_L002_R1_001_fastqc.html 20150413_2212_lane2_GCCAAT_L002_R1_002_fastqc.html 20150413_2212_lane2_GCCAAT_L002_R1_003_fastqc.html 20150413_2212_lane2_GCCAAT_L002_R1_004_fastqc.html 20150413_2212_lane2_GCCAAT_L002_R1_005_fastqc.html 20150413_2212_lane2_GCCAAT_L002_R1_006_fastqc.html"
  },
  {
    "objectID": "posts/2015/2015-09-30-restriction-digest-oly-gdna-for-rad-seq-walfi/index.html",
    "href": "posts/2015/2015-09-30-restriction-digest-oly-gdna-for-rad-seq-walfi/index.html",
    "title": "Restriction Digest - Oly gDNA for RAD-seq w/AlfI",
    "section": "",
    "text": "Used a subset (10 samples) from the Ostrea lurida gDNA isolated 20150916 to prepare RAD libraries. This will be done to assess whether or not these samples, which appear to be heavily degraded, are viable for RAD-seq.\nFollowed the 2bRAD protocol (PDF) developed by Eli Meyer’s lab.\nPrepared 1.2μg of each of the following samples in a volume of 10μL:\nGoogle Sheet: 20150930_RADseq_DNA_calcs\nPrepared a 150μM working stock of the SAM buffer needed for the restriction digestion by diluting 30μL of the supplied stock (500μM) in 70μL NanoPure H2O (total volume = 100μL). This working stock was stored @ -20C in FTR 209 in the “RAD-seq Reagents” box.\nPrepared master mix for restriction enzyme reaction:\n\n\n\n\n\nREAGENT\n\n\nSINGLE REACTION (μL)\n\n\nx11\n\n\n\n\nDNA\n\n\n8\n\n\nNA\n\n\n\n\n10x Buffer R\n\n\n1.2μL\n\n\n13.2μL\n\n\n\n\n150μM SAM\n\n\n0.8μL\n\n\n8.8μL\n\n\n\n\nAlfI\n\n\n0.5μL\n\n\n5.5μL\n\n\n\n\nH2O\n\n\n1.5μL\n\n\n16.5μL\n\n\n\n\n\nCombined 4μL of the master mix with 8μL of each sample in 0.5mL snap cap tubes. Incubated @ 37C O/N in thermal cycler (no heated lid)."
  },
  {
    "objectID": "posts/2015/2015-03-02-library-quality-assessment-c-gigas-oa-larvae-illumina-libraries/index.html",
    "href": "posts/2015/2015-03-02-library-quality-assessment-c-gigas-oa-larvae-illumina-libraries/index.html",
    "title": "Library Quality Assessment - C.gigas OA larvae Illumina libraries",
    "section": "",
    "text": "Ran the 400ppm library and the 1000ppm library preps on a DNA1000 Assay Chip (Agilent) on the Agilent 2100 Bioanalyzer.\nResults:\nData File (XAD): 2100_expert_DNA_1000_DE72902486_2015-03-02_09-18-02.xad\nElectropherogram overlay of both samples:\nRed = 400ppm\nBlue = 1000ppm\n(http://eagle.fish.washington.edu/Arabidopsis/Bioanalyzer%20Data/20150302_BioanalyzerGigasLarvaeOA400_1000ppm.jpg)\nMeasurement data and parameters are here: 20150302_Bioanalyzer_Cgigas_400_1000ppm_BS-Seq\nBoth libraries look good; no adaptor contamination (peak would be present at ~125bp), good library sizes.\nPooled equal quantities of each library, based off the concentration values above, to prepare the sample for sequencing.\n\n\n\n\n\nComponent\n\n\nVolume (μL)\n\n\nQuantity (ng)\n\n\n\n\n400ppm library\n\n\n10\n\n\n14.7\n\n\n\n\n1000ppm library\n\n\n1.09\n\n\n14.7\n\n\n\n\nBuffer EB\n\n\n7.81\n\n\nN/A\n\n\n\n\n1% Tween20\n\n\n2.1\n\n\nN/A\n\n\n\n\nTotal\n\n\n21\n\n\nN/A\n\n\n\n\n\nThe pooled libraries will be submitted tomorrow to the Genomics Core Facility at the Univ. of Oregon for high-throughput sequencing (100bp, SE) on the HiSeq2500 (Illumina). Sample order #2212."
  },
  {
    "objectID": "posts/2015/2015-12-01-sample-submission-additional-olympia-oyster-gdna-for-genome-sequencing-bgi-2/index.html",
    "href": "posts/2015/2015-12-01-sample-submission-additional-olympia-oyster-gdna-for-genome-sequencing-bgi-2/index.html",
    "title": "Sample Submission - Additional Olympia Oyster gDNA for Genome Sequencing @ BGI",
    "section": "",
    "text": "Yep, BGI still needs more gDNA for the Olympia oyster genome sequencing project. Samples have been quantified via dye-based fluorescence, as opposed to the NanoDrop, so our quantities should be more accurate and in-line with what BGI will also find.\nSubmitted three separate isolations, just in case the quality of one was unacceptable, I didn’t want to pool the samples and have that one bad apple ruin the entire batch.\nIn total, submitted ~31μg.\nSamples were shipped on dry ice with the appropriate paperwork required by BGI (sample declaration letter).\nAssigned BGI Lot: 1512021005"
  },
  {
    "objectID": "posts/2015/2015-11-25-phenol-chloroform-dna-cleanup-geoduck-gdna/index.html",
    "href": "posts/2015/2015-11-25-phenol-chloroform-dna-cleanup-geoduck-gdna/index.html",
    "title": "Phenol-Chloroform DNA Cleanup - Geoduck gDNA",
    "section": "",
    "text": "The gDNA I extracted on 20151104 didn’t look great on the NanoDrop so I decided to perform a phenol-chloroform cleanup to see if I could improve the NanoDrop1000 absorbance spectrum and, in turn, the quality of the gDNA.\n\nAdded an equal volume (500μL) of phenol:chloroform:isoamyl alcohol (25:24:1) to the DNA\nMixed by hand - moderate shaking\nCentrifuged 2mins, 10,000g, RT\nTransferred aqueous phase to clean tube and discarded interphase & organic phase\nAdded an equal volume (280μL) of chlforoform:isoamyl alcohol (24:1)\nMixed by hand - moderate shaking\nCentrifuged 2mins, 10,000g, RT\nTransferred aqueous phase (210μL) to clean tube\nAdded 0.1vols (21μL) of 3M sodium acetate (pH = 5.2)\nAdded 2vols (420μL) of 100% EtOH\nMixed by inversion\nIncubated @ -20C, 1hr (probably not necessary since gDNA clearly precipitated out as soon as I mixed the sample)\nPelleted DNA by centrifuging 15mins, 12,000g, RT\nDiscarded supe\nWashed pellet with 1000μL cold (-20C) 70% EtOH\nCentrifuged 5mins, 12,000g, RT\nDiscarded supe\nRepeated was steps three more times\nResuspended pellet in 100μL of Buffer EB (Qiagen)\n\nDNA was quantified using two methods: NanoDrop1000 & QuantIT dsDNA BR Kit\nFor the Quant-IT kit, the samples were quantified using the QuantIT dsDNA BR Kit (Invitrogen) according to the manufacturer’s protocol.\nStandards were run in triplicate, samples were run in duplicate.\n96-well black (opaque) plate was used.\nFluorescence was measured on the Seeb Lab’s Victor 1420 plate reader (Perkin Elmer).\nResults:\n\n\n\n\n\nMETHOD\n\n\nCONCENTRATION (ng/μL)\n\n\nVOLUME (μL)\n\n\nYIELD (ng)\n\n\n\n\nNanoDrop1000\n\n\n371.83\n\n\n100\n\n\n37,183\n\n\n\n\nQuant-IT\n\n\n100.83\n\n\n100\n\n\n10,082\n\n\n\n\n\nThe NanoDrop1000 overestimates the concentration of the sample by 3.7x!\nRegardless, the yield isn’t all that great (using yield from Quant-IT), which has generally been the case for all of the geoduck gDNA isolations I’ve performed. It would probably be prudent to try isolating gDNA from a different tissue to see if yields improve…\nWill evaluate gDNA quality on a gel.\nFluorescence (Google Sheet): 20151124_geoduck_oly_gDNA_quants\nNanoDrop1000 Measurements and Plots\nThe clean up procedure didn’t really seem to help with the geoduck sample, as we’re still seeing a significant amount of absorbance from 230 - 250nm.\n(http://eagle.fish.washington.edu/Arabidopsis/20151124_gDNA_geoduck_oly_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20151124_gDNA_geoduck_oly_plots.JPG)"
  },
  {
    "objectID": "posts/2015/2015-09-21-sample-submission-geoduck-gdna-for-genome-sequencing-bgi/index.html",
    "href": "posts/2015/2015-09-21-sample-submission-geoduck-gdna-for-genome-sequencing-bgi/index.html",
    "title": "Sample Submission - Geoduck gDNA for Genome Sequencing @ BGI",
    "section": "",
    "text": "Shipped the pooled gDNA we’ve been accumulating to BGI to initiate the geoduck genome sequencing project.\nSample was shipped on dry ice with the appropriate paperwork required by BGI (sample declaration letter).\nAssigned BGI Lot: 1509191002"
  },
  {
    "objectID": "posts/2015/2015-11-25-dna-isolation-geoduck-ctenidia-gdna/index.html",
    "href": "posts/2015/2015-11-25-dna-isolation-geoduck-ctenidia-gdna/index.html",
    "title": "DNA Isolation - Geoduck Ctenidia gDNA",
    "section": "",
    "text": "Isolated additional gDNA for the genome sequencing. In an attempt to obtain better yields, I used ctenidia (instead of adductor muscle). Additionally, to try to improve the quality (260/280 & 260/230 ratios) of the gDNA, I added a chloroform step after the initial tissue homogenization.\nUsed 190mg of Panopea generosa ctenidia collected by Brent & Steven on 20150811.\n\nHomogenized in 500μL of DNAzol.\nAdded additional 500μL of DNAzol.\nCentrifuged 12,000g, 10mins, @ RT.\nSplit supernatant equally into two tubes.\nAdded 500μL of chloroform and mixed moderately fast by hand.\nCentrifuged 12,000g, 10mins, RT.\nCombined aqueous phases from both tubes in a clean tube.\nAdded 500μL of 100% EtOH and mixed by inversion.\nSpooled precipitated gDNA and transferred to clean tube.\nPerformed 3 washes w/70% EtOH.\nDried pellet 3mins.\nResuspended in 200μL of Buffer EB (Qiagen).\nCentrifuged 10,000g, 5mins, RT to pellet insoluble material.\nTransferred supe to clean tube.\n\nDNA was quantified using two methods: NanoDrop1000 & Qubit 3.0 (ThermoFisher).\nFor the Qubit, the samples were quantified using the Qubit dsDNA BR reagents (Invitrogen) according to the manufacturer’s protocol and used 1μL of sample for measurement.\nResults:\nQubit Data (Google Sheet): 20151125_qubit_gDNA_geoduck_oly_quants\n\n\n\n\n\nMETHOD\n\n\nCONCENTRATION (ng/μL)\n\n\nTOTAL (μg)\n\n\n\n\nQubit\n\n\n105\n\n\n21.0\n\n\n\n\nNanoDrop1000\n\n\n173\n\n\n34.6\n\n\n\n\n\nYield is definitely much, much better than adductor muscle! Should’ve switched to a different tissue a long time ago! We should finally have sufficient quantities of gDNA to allow for BGI to proceed with the rest of the genome sequencing! Will run sample on gel to evaluate integrity and then send off to BGI.\nThe NanoDrop & Qubit numbers still aren’t close (as expected).\nThe addition of the chloroform step definitely helped improve the 260/280 OD ratio (see below). However, the addition of that step had no noticeable impact on the 260/230 OD ratios, which is a bit disappointing.\nNanoDrop Absorbance Values & Plots\n(http://eagle.fish.washington.edu/Arabidopsis/20151125_gDNA_geoduck_oly_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20151125_gDNA_geoduck_oly_plots.JPG)"
  },
  {
    "objectID": "posts/2015/2015-08-06-qpcr-jakes-o-lurida-ctenidia-1hr-post-mechanical-stress-dnased-rna/index.html",
    "href": "posts/2015/2015-08-06-qpcr-jakes-o-lurida-ctenidia-1hr-post-mechanical-stress-dnased-rna/index.html",
    "title": "qPCR - Jake’s O.lurida ctenidia 1hr post-mechanical stress DNased RNA",
    "section": "",
    "text": "Ran qPCR on DNased RNA from earlier today to assess whether there was any residual gDNA after the DNase treatment with Oly_Actin_F/R primers (SR IDs: 1505, 1504).\nUsed 1μL from all templates.\nAll samples were run in duplicate.\nPositive control was HL1 O.lurida DNA isolated by Jake on 20150323.\nCycling params:\n\n95C – 2.5mins\n40 cycles of:\n\n95C – 10s\n60C – 20s\n\nMelt curve\n\nMaster mix calcs are here: 201500806_qPCR_Oly_DNased_RNA\nqPCR Plate Layout: 20150806_qPCR_plate_Jake_Oly_DNased_RNA\n\nRESULTS:\nqPCR Data File (Opticon):\n\n20150806_165044.tad\n\nqPCR Report (Google Spreadsheet): - 20150806_qPCR_Report_Jake_Oly_DNased_RNA\nPositive control comes up around cycle ~21.\nNo amplification in the no template controls.\nTwo wells of the DNased RNA samples exhibit amplification (E3, F6), however the corresponding respective replicate does not. Will proceed with reverse transcription.\n\nAmplification Plots\nPositive Controls\n\n\n\n\nMelt Curves\n\nPositive Controls (HL1)\n\n\n\n\n\n\nDNased RNA Samples\nFollow the green and red lines with the vertical bars. The different colors reflect that those are two different samples. Additionally, their respective replicates do not exhibit amplification."
  },
  {
    "objectID": "posts/2015/2015-05-15-qpcr-jakes-o-lurida-ctenidia-dnased-rna-1hr-heat-shock-samples/index.html",
    "href": "posts/2015/2015-05-15-qpcr-jakes-o-lurida-ctenidia-dnased-rna-1hr-heat-shock-samples/index.html",
    "title": "qPCR – Jake’s O.lurida ctenidia DNased RNA (1hr Heat Shock Samples)",
    "section": "",
    "text": "Ran qPCR on DNased RNA from earlier today to assess whether there was any residual gDNA after the DNase treatment with Oly_Actin_F/R primers (SR IDs: 1505, 1504).\nUsed 1μL from all templates.\nAll samples were run in duplicate.\nPositive control was HL1 O.lurida DNA isolated by Jake on 20150323.\nCycling params:\n\n95C – 2.5mins\n40 cycles of:\n\n95C – 10s\n60C – 20s\n\nMelt curve\n\nMaster mix calcs are here (used same calcs from the other day): 20150512_qPCR_Oly_RNA\nPlate layout: 20150514_qPCR_plate_Jake_Oly_1hr_HS_DNased_RNA\nResults:\nqPCR Data File (Opticon): Sam_20150514_170332.tad\nqPCR Report (Google Spreadsheeet): 20150514_qPCR_Report_Jake_Oly_DNased_1hr_HS_RNA\nPositive control samples are the only samples that produced amplification (cycle ~20). Will proceed to making cDNA.\n\nAmplification Plots\n(http://eagle.fish.washington.edu/Arabidopsis/20150514_qPCR_Amp_DNased_RNA_Jake_Oly_1hr_HS.JPG)\n\n\nMelt Curves\n(http://eagle.fish.washington.edu/Arabidopsis/20150514_qPCR_Melt_DNased_RNA_Jake_Oly_1hr_HS.JPG)"
  },
  {
    "objectID": "posts/2015/2015-07-10-ssofast-evagreen-supermix-aliquots/index.html",
    "href": "posts/2015/2015-07-10-ssofast-evagreen-supermix-aliquots/index.html",
    "title": "SsoFast EvaGreen Supermix Aliquots",
    "section": "",
    "text": "Prepared sterile, 1.0mL aliquots of SsoFast EvaGreen Supermix (received today) in 2.0mL screw cap tubes. All aliquots were dated and stored @ -20C in the “PCR Supplies” box.\nBioRad Lot#: 730003517"
  },
  {
    "objectID": "posts/2015/2015-06-01-sample-submission-geoduck-gonad-for-rna-seq/index.html",
    "href": "posts/2015/2015-06-01-sample-submission-geoduck-gonad-for-rna-seq/index.html",
    "title": "Sample Submission - Geoduck Gonad for RNA-seq",
    "section": "",
    "text": "Prepared two pools of geoduck RNA for RNA-seq (Illumina HiSeq2500, 100bp, PE) with GENEWIZ, Inc.\nI pooled a set of female and a set of male RNAs that had been selected by Steven based on the Bioanalyzer results from Friday.\nThe female RNA pool used 210ng of each sample, with the exception being sample #08. This sample used 630ng. The reason for this was due to the fact that there weren’t any other female samples to use from this developmental time point. The two other developmental time points each had three samples contributing to the pool. So, three times the quantity of the other individual samples was used to help equalize the time point contribution to the pooled sample. Additionally, 630ng used the entirety of sample #08.\nThe male RNA pool used 315ng of each sample. This number differs from the 210ng used for the female RNAs so that the two pools would end up with the same total quantity of RNA. However, now that I’ve typed this, this doesn’t matter since the libraries will be equalized before being run on the Illumina HiSeq2500. Oh well. As long as each sample in each pool contributed to the total amount of RNA, then it’s all good.\nThe two pools were shipped O/N on dry ice.\n\nGeo_pool_M\nGeo_pool_F\n\nCalculations (Google Sheet): 20150601_Geoduck_GENEWIZ_calcs"
  },
  {
    "objectID": "posts/2015/2015-12-09-sample-submission-olympia-oyster-mbd-enriched-dna-to-zymoresearch/index.html",
    "href": "posts/2015/2015-12-09-sample-submission-olympia-oyster-mbd-enriched-dna-to-zymoresearch/index.html",
    "title": "Sample Submission - Olympia oyster MBD-enriched DNA to ZymoResearch",
    "section": "",
    "text": "We opted to go with ZymoResearch for this project because they could do the bisulfite treatment and finish the sequencing by the end of January.\nSubmitted the following 18 Ostrea lurida MBD-enriched gDNA samples to ZymoResearch for bisulfite treatment and subsequent Illumina sequencing (50bp, single read):\n\n\n\n\n\nhc1_2B\n\n\n\n\nhc1_4B\n\n\n\n\nhc2_15B\n\n\n\n\nhc2_17\n\n\n\n\nhc3_1\n\n\n\n\nhc3_10\n\n\n\n\nhc3_11\n\n\n\n\nhc3_5\n\n\n\n\nhc3_7\n\n\n\n\nhc3_9\n\n\n\n\nss2_14B\n\n\n\n\nss2_18B\n\n\n\n\nss2_9B\n\n\n\n\nss3_14B\n\n\n\n\nss3_15B\n\n\n\n\nss3_16B\n\n\n\n\nss3_20\n\n\n\n\nss3_3B\n\n\n\n\nss3_4B\n\n\n\n\nss5_18\n\n\n\n\n\nThe samples will be bisulfite treated, Illumina libraries constructed, multiplexed, and this multiplexed library will be sequenced three times."
  },
  {
    "objectID": "posts/2015/2015-05-07-bioinformatics-trimmomaticfastqc-on-c-gigas-larvae-oa-ngs-data/index.html",
    "href": "posts/2015/2015-05-07-bioinformatics-trimmomaticfastqc-on-c-gigas-larvae-oa-ngs-data/index.html",
    "title": "Bioinformatics - Trimmomatic/FASTQC on C.gigas Larvae OA NGS Data",
    "section": "",
    "text": "In another troubleshooting attempt for this problematic BS-seq Illumina data, I’m going to use Trimmomatic to remove the first 39 bases of each read. This is due to the fact that even after the previous quality trimming with Trimmomatic, the first 39 bases still showed inconsistent quality:\n(http://eagle.fish.washington.edu/Arabidopsis/20150414_trimmed_2212_lane2_CTTGTA_L002_R1_001_fastqc/Images/per_base_sequence_content.png)\nRan Trimmomatic on just a single data set to try things out: 2212_lane2_CTTGTA_L002_R1_001.fastq.gz\nNotebook Viewer: 20150506_Cgigas_larvae_OA_trimmomatic_FASTQC\nJupyter (IPython) notebook: 20150506_Cgigas_larvae_OA_trimmomatic_FASTQC.ipynb\n\n\nResults:\nTrimmed FASTQ: 20150506_trimmed_2212_lane2_CTTGTA_L002_R1_001.fastq.gz\nFASTQC Report: 20150506_trimmed_2212_lane2_CTTGTA_L002_R1_001_fastqc.html\n(http://eagle.fish.washington.edu/Arabidopsis/20150506_trimmed_2212_lane2_CTTGTA_L002_R1_001_fastqc/Images/per_base_sequence_content.png)\nYou can see how flat the newly trimmed data is (which is what one would expect).\nSteven will take this trimmed dataset and try additional mapping with it to see if removal of the first 39 bases will improve the mapping."
  },
  {
    "objectID": "posts/2015/2015-12-18-agarose-gel-oly-gdna-for-bs-seq-libraries-take-two/index.html",
    "href": "posts/2015/2015-12-18-agarose-gel-oly-gdna-for-bs-seq-libraries-take-two/index.html",
    "title": "Agarose Gel - Oly gDNA for BS-seq Libraries, Take Two",
    "section": "",
    "text": "The gel I ran earlier today looked real rough, due to the fact that I didn’t bother to equalize loading quantities of samples (I just loaded 1μL of all samples regardless of concentration). So, I’m repeating it using 100ng of DNA from all samples.\nAdditionally, this gel also includes C.gigas samples that Katie Lotterhos sent to us to see how they look.\nRan a 0.8% agarose, low-TAE gel, stained with ethidium bromide.\nResults: (https://raw.githubusercontent.com/sr320/LabDocs/master/protocols/Commercial_Protocols/ThermoFisher_OgeneRuler_DNA_Ladder_Mix_F100439.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/20151217_gel_Oly_gDNA_02.jpg)\nLook at that! The samples look MUCH nicer when they’re not overloaded and uniformly loaded!\nMost have a prominent high molecular weight band (the band that’s closes to the top of the ladder, not the DNA visible in the wells). All exhibit smearing, but 2NF1 shows a weird accumulation of low molecular weight DNA.\nKatie’s C.gigas samples (M1, M2, M3) look similar to the Olympia oyster gDNA, however her samples appear to have residual RNA in them (the fuzzy band ~500bp).\nWill discuss with Steven which samples he wants to use for bisulfite treament and library construction."
  },
  {
    "objectID": "posts/2015/2015-07-31-server-hdd-failure-owl/index.html",
    "href": "posts/2015/2015-07-31-server-hdd-failure-owl/index.html",
    "title": "Server HDD Failure - Owl",
    "section": "",
    "text": "We had our first true test of the Synology RAID redundancy with our Synology 1812+ server (Owl). One of the hard drives (HDD) failed. All of the other drives were fine, the data was intact and we had a new replacement HDD on hand. However, there was one shortcoming: no email notification of the drive failure. Luckily, the Synology server is next to Steven’s office and he could hear an audible beeping alerting him to the fact that something was wrong. In any case, the email notifications have been fixed and a replacement hard drive was added to the system. Here’s how these things were accomplished.\n\nFix email notifications\nThe system was previously set to use Steven’s Comcast SMTP server. Sending a test email from Owl failed, indicating authentication failure. I changed this to use the University of Washington’s email server for outgoing messages. Here’s how…\nIn the Synology Disk Station Manager (DSM):\nControl Panel > Notifications\n\nService provider: Custom SMTP Server\nSMTP server: smtp.washington.edu\nSMTP port: 587\nUsername: myUWnetID@uw.edu\nPassword: myUWpassword\n\nInteresting note, there’s a “Push Service” tab in the “Notifications” window. This allows you to have Synology send emails to email addresses when the server has an issue. This eliminates the need for the SMTP settings shown above which may not be easy to find and/or understand for a given email service provider. The “Push Service” appears to be much simpler and more user friendly to set up.\n\n\nHot Swap HDD\nWe’ve kept a backup HDD on hand for just this occasion, so the HDD failure wasn’t too concerning. Here’re the steps I followed to swap the HDD and have the Synology system initialize/build the new HDD:\nRemove the dead HDD and put the new HDD in.\n(http://eagle.fish.washington.edu/Arabidopsis/Synology_DiskStation_DS1812_Quick_Installation_Guide-_Syno_QIG_18bay_enu_pdf.jpg)\nInitialize/build/repair the new HDD.\nIn Synology DSM:\nStorage Manger > Volume\nNotice, there should be eight drives listed, but since one has died, only seven are shown:\n(http://eagle.fish.washington.edu/Arabidopsis/20150731_Owl01.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/20150731_Owl02.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/20150731_Owl03.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/20150731_Owl04.jpg)\nThat’s it! Easy breezy!\nI’ve checked with Seagate on the dead HDD and it is still under warranty. Will get that returned and also purchase a new backup drive to have on hand."
  },
  {
    "objectID": "posts/2015/2015-09-15-genomic-dna-isolation-geoduck-adductor-muscle-foot-3/index.html",
    "href": "posts/2015/2015-09-15-genomic-dna-isolation-geoduck-adductor-muscle-foot-3/index.html",
    "title": "Genomic DNA Isolation – Geoduck Adductor Muscle & Foot",
    "section": "",
    "text": "Isolated gDNA from Panopea generosa (geoduck) adductor muscle & foot samples collected by Brent & Steven on 20150811 using the DNAzol (Molecular Research Center) according to the manufacturer’s protocol, with the following adjustments:\n\n102.5mg of adductor muscle 1\n76.7mg of adductor muscle 2\n84.2mg of foot 1\n54.5mg of foot 2\nTissues homogenized in 750μL of DNAzol with disposable mortar/pestle tubes using 10 pestle strokes\nAfter homogenization, topped off tubes to 1000μL with DNAzol and incubated @ RT for 10mins.\nPerformed optional centrifugation step (10,000g, 10mins @ RT)\nInitial pellet wash was performed using a 70%/30% DNAzol/EtOH\nPellets were resuspended in 200μL of Buffer EB (Qiagen)\nInsoluble material was pelleted (12,000g, 10mins @ RT) and supe transferred to new tubes\n\nSpec’d on Roberts Lab NanoDrop1000 (ThermoFisher) and stored temporarily at 4C to avoid freeze-thawing before sending off for sequencing next week.\nResults:\n(http://eagle.fish.washington.edu/Arabidopsis/20150915_gDNA_geoduck_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150915_gDNA_geoduck_plots.JPG)\nThere was a great deal of insoluble material from the get-go that was carried through the entire isolation.\nOverall, the 260/280 ratios look pretty good, but the 260/230 ratios are just trash. As can be seen in the plots above, there is clearly significant absorbance in the 230 – 250nm, suggesting some contaminant carryover (phenol/salt).\nWill evaluate gDNA integrity on agarose gel.\nYields from this isolation:\nAdductor muscle 1: 11.03μg\nAdductor muscle 2: 1.95μg\nFoot 1: 4.6μg\nFoot 2: 1.64μg\nTotal geoduck gDNA from this isolation: 19.2μg\nTotal geoduck gDNA accumulated for this project: 69μg\nStill need an additional 4μg at a minimum! Will isolate more gDNA tomorrow…"
  },
  {
    "objectID": "posts/2015/2015-11-22-mbd-enrichment-sonicated-olympia-oyster-gdna/index.html",
    "href": "posts/2015/2015-11-22-mbd-enrichment-sonicated-olympia-oyster-gdna/index.html",
    "title": "MBD Enrichment - Sonicated Olympia Oyster gDNA",
    "section": "",
    "text": "Olympia oyster gDNA that had previously been sonicated and fragmented was enriched for the methylated fragments using the MethylMiner Methylated DNA Enrichment Kit (Invitrogen).\nPrepared the following components:\n\n20mL 1x Bind/Wash Buffer (4mL 5x Bind/Wash Buffer + 16mL H2O)\n640μL of beads (35μL of beads x 18 samples )\n200μL MBD-Biotin Protein (63μL MBD-Biotin Protein + 137μL 1x Bind/Wash Buffer)\n\nFollowed the manufacturer’s protocol for input DNA quantities 1μg - 10μg.\nUsed single fraction, high salt elution.\nNeglected to account for the control reaction during initial set up and did not have sufficient quantities of beads to run a control reaction.\nThe table below provides the individual sample volumes and the volumes of the buffer, beads, H2O for the MBD capture reactions.\nSamples listed with “NA” were not processed because they did not fragment during sonication.\n\n\n\n\n\nSample\n\n\nVolume (μL)\n\n\nBuffer/Beads (μL)\n\n\nH2O (μL)\n\n\nTotal (μL)\n\n\n\n\nhc1_2B\n\n\n75\n\n\n135\n\n\n290\n\n\n500\n\n\n\n\nhc1_4B\n\n\n90\n\n\n135\n\n\n275\n\n\n500\n\n\n\n\nhc2_15B\n\n\n75\n\n\n135\n\n\n290\n\n\n500\n\n\n\n\nhc2_17\n\n\n75\n\n\n135\n\n\n290\n\n\n500\n\n\n\n\nhc3_1\n\n\n75\n\n\n135\n\n\n290\n\n\n500\n\n\n\n\nhc3_5\n\n\n75\n\n\n135\n\n\n290\n\n\n500\n\n\n\n\nhc3_7\n\n\n70\n\n\n135\n\n\n295\n\n\n500\n\n\n\n\nhc3_9\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n\n\nhc3_10\n\n\n70\n\n\n135\n\n\n295\n\n\n500\n\n\n\n\nhc3_11\n\n\n70\n\n\n135\n\n\n295\n\n\n500\n\n\n\n\nss2_9B\n\n\n190\n\n\n135\n\n\n175\n\n\n500\n\n\n\n\nss2_14B\n\n\n195\n\n\n135\n\n\n170\n\n\n500\n\n\n\n\nss2_18B\n\n\n195\n\n\n135\n\n\n170\n\n\n500\n\n\n\n\nss3_3B\n\n\n190\n\n\n135\n\n\n175\n\n\n500\n\n\n\n\nss3_4B\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nNA\n\n\n\n\nss3_14B\n\n\n195\n\n\n135\n\n\n170\n\n\n500\n\n\n\n\nss3_15B\n\n\n195\n\n\n135\n\n\n170\n\n\n500\n\n\n\n\nss3_16B\n\n\n195\n\n\n135\n\n\n170\n\n\n500\n\n\n\n\nss3_20\n\n\n135\n\n\n135\n\n\n230\n\n\n500\n\n\n\n\nss5_18\n\n\n75\n\n\n135\n\n\n290\n\n\n500\n\n\n\n\n\nNon-captured & wash fractions were pooled into single samples and stored @ -20C.\nMBD fraction was EtOH precipitated according to the manufacturer’s protocol and incubate O/N @ -80C."
  },
  {
    "objectID": "posts/2015/2015-02-20-bioanalyzer-c-gigas-sheared-dna-from-20140108/index.html",
    "href": "posts/2015/2015-02-20-bioanalyzer-c-gigas-sheared-dna-from-20140108/index.html",
    "title": "Bioanalyzer - C.gigas Sheared DNA from 20140108",
    "section": "",
    "text": "To complement MBD ChiP-seq data and RNA-seq data that we have from this experiment, we want to generate, at a minimum, some BS-seq data from the same C.gigas individuals used for the other aspects of this experiment.  Claire had previously isolated DNA and sheared the DNA on 20140108. If possible, we’d like to perform MBD enrichment, but the current quantities of DNA may prevent us from this.\nTo quantify the DNA and evaluate the shearing profile, I ran 1μL of each of the following mantle pre-/post-heat shock samples on a DNA 1000 chip (Agilent) on the Agilent 2100 Bioanalyzer. in the Seeb Lab:\nM = mantle HS = heat shocked\n\n2M sheared\n4M sheared\n6M sheared\n2M HS sheared\n4M HS sheared\n6M HS sheared\n\nResults:\nBioanalyzer Data File (XAD): 2100_expert_DNA_1000_DE72902486_2015-02-19_11-32-35 (2).xad\nElectropherograms:\n\n\n\n2100 Bioanalyzer electropherograms of Claire’s sheared C.gigas DNA\n\n\nSpreadsheet: 2100 expert_DNA 1000_DE72902486_2015-02-19_11-32-35_Results_001\nClaire’s notebook entry doesn’t ever specify what her target shear size was, but the Bioanalyzer analysis suggests an average size of ~500bp.\nAlso interesting to note is that Claire’s sample concentrations (as measured on the NanoDrop1000) are significantly greater than what is calculated by the Bioanalyzer. Since the Bioanalyzer chip used (DNA1000) only goes to 1000bp, is it possible the differences in concentrations is due to incomplete shearing of the samples (e.g. a significant portion of the DNA is >1000bp in size and thus not factored in to the Bioanlyzer concentrations calculations)?\nWill check sample volumes and determine total amount of remaining DNA for each sample and then assess how to proceed next (i.e. MBD or just BS-seq).\nUPDATE 20150226:\nSample volumes were measured and total quantity (ng) of DNA in each sample were added to the spreadsheet above.\nBased on the quantities of DNA we have for each sample, will discuss sequencing options (e.g. MBD or not, self-prepare libraries or not, etc) with Steven."
  },
  {
    "objectID": "posts/2015/2015-01-15-dna-bisulfite-conversion-c-gigas-larvae-oa-sheared-dna/index.html",
    "href": "posts/2015/2015-01-15-dna-bisulfite-conversion-c-gigas-larvae-oa-sheared-dna/index.html",
    "title": "DNA Bisulfite Conversion - C.gigas larvae OA Sheared DNA",
    "section": "",
    "text": "After discussing with Steven, decided to use only samples from 20110513, due to high algae amounts present in the 20110519 samples.\nPooled the DNA of the 400ppm samples (6B2 & 6B5) and pooled the DNA of the 1000ppm samples(1B1 & 1B2) , for a total of two samples. 50ng of each sample was used to make the pools, for a toal of 100ng of DNA in each pool. Calculations are below: https://docs.google.com/spreadsheets/d/1e7EF05akWeBtO7Xz0UWXhIzRlkVU5HA_rjCE3c4SPEw/edit?usp=sharing\n``\nEach pooled sample was brought up to a final volume of 24μL for use in bisulfite conversion kit.\nPerformed bisulfite conversion of sheared DNA from 20150113 using the Methylamp DNA Modification Kit (Epigentek) according the manufacturer’s protocol.\nSamples were eluted with 10μL of Buffer R6 and stored @ -20C."
  },
  {
    "objectID": "posts/2015/2015-08-06-rna-quantification-o-lurida-1hr-post-mechanical-heat-stress-dnased-rna/index.html",
    "href": "posts/2015/2015-08-06-rna-quantification-o-lurida-1hr-post-mechanical-heat-stress-dnased-rna/index.html",
    "title": "RNA Quantification - O.lurida 1hr post-mechanical heat stress DNased RNA",
    "section": "",
    "text": "DNased RNA from 07272015 was quantified using the Roberts Lab NanoDrop1000.\nResults:\nThe 260/280 ratios don’t look great, but that is most likely due to the DNase treatment. The DNase that’s added to each sample isn’t actually removed, so that additional protein will skew the 260/280 ratios. Will proceed with qPCR to check for any residual gDNA in these samples.\n(http://eagle.fish.washington.edu/Arabidopsis/20150806_Jake_oly_mech_stress_DNasedRNA_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150806_Jake_oly_mech_stress_DNasedRNA_plots_01.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150806_Jake_oly_mech_stress_DNasedRNA_plots_02.JPG)"
  },
  {
    "objectID": "posts/2015/2015-09-01-server-email-notifications-fix-eagle/index.html",
    "href": "posts/2015/2015-09-01-server-email-notifications-fix-eagle/index.html",
    "title": "Server Email Notifications Fix - Eagle",
    "section": "",
    "text": "The system was previously set to use Steven’s Comcast SMTP server. Sending a test email from Eagle failed, indicating authentication failure. I changed this to use the University of Washington’s email server for outgoing messages. Here’s how…\nIn the Synology Disk Station Manager (DSM):\nControl Panel > Notifications\n\nService provider: Custom SMTP Server\nSMTP server: smtp.washington.edu\nSMTP port: 587\nUsername: myUWnetID@uw.edu\nPassword: myUWpassword"
  },
  {
    "objectID": "posts/2015/2015-02-28-bs-seq-library-prep-c-gigas-larvae-oa-1000ppm/index.html",
    "href": "posts/2015/2015-02-28-bs-seq-library-prep-c-gigas-larvae-oa-1000ppm/index.html",
    "title": "BS-seq Library Prep - C.gigas Larvae OA 1000ppm",
    "section": "",
    "text": "Bisulfite Conversion\nPooled 200ng each of the sheared 1B1 (4μL) & 1B2 (used the entire sample, 20μL) 5.13.11 1000ppm C.gigas larvae DNA samples for a total of 400ng. Total volume = 24μL.\nQuantified the pooled DNA using the NanoDrop1000 (ThermoFisher) prior to initiating bisulfite conversion.\n(http://eagle.fish.washington.edu/Arabidopsis/20150227_Emma_1000ppm_pool_preBS_plot.JPG)\nClearly, the NanoDrop measurements differ from the expected concentration. NanoDrop suggests the total amount of input DNA is ~1400ng (58ng/μL x 24μL = 1392ng). This is most likely due to RNA carryover, as DNA quantification using a fluorescence-based, double-stranded DNA assay performed previously shows a drastically lower concentration.\nProceeded with bisulfite conversion using the Methylamp DNA Modification Kit (Epigentek) in 1.5mL tube, according to the manufacturer’s protocol:\n\nAdded 1μL to sample, incubated 10mins @ 37C in water bath\nMade fresh R1/R2/R3 solution (1.1mL R3 buffer added to vial of R2, vortexed 2mins, 40μL R1 added to mixture - Remainder stored @ -20C in “-20C Kit Components Box”)\nAdded 125μL of R1/R2/R3 solution to sample, incubated 90mins @ 65C in heating block with water\nAddd 300μL R4 to sample, mixed, transferred to column, spun 12,000RPM 30s\nAdded 200μL R5 to column, spun 12,000RPM 30s\nAdded 50μL R1/ethanol solution to column, incubated 8mins @ RT, spun 12,000RPM 30s\nWashed column with 200μL of 90% EtOH, spun 12,000RPM 30s; repeated one time.\nEluted DNA with 12μL R6, spun 12,000RPM 30s\n\nQuantified post-bisulfite-treated sample on NanoDrop1000:\n(http://eagle.fish.washington.edu/Arabidopsis/20150227_Emma_1000ppm_pool_postBS_plot.JPG)\nDefinitely a low yield (~108ng) relative to the input (~400ng). Will proceed with Illumina library prep.\n\n\nLibrary Prep\nIllumina library prep was performed with [EpiNext Post-Bisulfite DNA Library Preparation Kit (Illumina) (Epigentek)(https://github.com/sr320/LabDocs/blob/master/protocols/Commercial_Protocols/Epigentek_PostBisulfiteIlluminaLibraryPrep_P-1055.pdf).  Changes to the manufacturer’s protocol:\n\nSamples were transferred to 1.5mL snap cap tubes for all magnetic bead steps in order to fit in our tube magnets.\nPCR cycles: 15\n\nNo other changes were made to the manufacturer’s protocol.\nEpigentek Barcode Indices assigned, per their recommendations for using two libraries for multiplexing (this will be combined with the 400ppm library):\nBarcode #12 – CTTGTA\nThe library was stored @ -20C and will be checked via Bioanalyzer on Monday."
  },
  {
    "objectID": "posts/2015/2015-09-16-agarose-gel-geoduck-olympia-oyster-gdna-integrity-check-3/index.html",
    "href": "posts/2015/2015-09-16-agarose-gel-geoduck-olympia-oyster-gdna-integrity-check-3/index.html",
    "title": "Agarose Gel - Geoduck & Olympia Oyster gDNA Integrity Check",
    "section": "",
    "text": "Ran 0.8% agarose 1x modified TAE gel stained with EtBr to assess the integrity of geoduck gDNA and Olympia oyster gDNA isolated earlier today.\nRan ~500ng of each sample:\nGeoduck adductor muscle 1: 6.8μL\nGeoduck adductor muscle 2: 20μL (260ng)\nGeoduck foot 1: 16.6μL\nGeoduck foot 2: 20μL (200ng)\nOly adductor muscle: 4μL\nOly mantle: 4.7μL\nResults:\n(https://raw.githubusercontent.com/sr320/LabDocs/master/protocols/Commercial_Protocols/ThermoFisher_OgeneRuler_DNA_Ladder_Mix_F100439.jpg)\nThe gel is loaded in the order listed above (going left to right on the gel).\nAll samples look really good with prominent high molecular weight bands and little smearing."
  },
  {
    "objectID": "posts/2015/2015-05-22-qpcr-re-run-jakes-o-lurida-dnased-rna-samples-nc1-sc1-sc2-sc4-from-20150514/index.html",
    "href": "posts/2015/2015-05-22-qpcr-re-run-jakes-o-lurida-dnased-rna-samples-nc1-sc1-sc2-sc4-from-20150514/index.html",
    "title": "qPCR - Re-run Jake’s O.lurida DNased RNA Samples NC1, SC1, SC2, SC4 from 20150514",
    "section": "",
    "text": "The following DNased RNA samples showed inconsistencies between qPCR reps (one rep showed amplification, the other rep did not) on 20150514:\n\nNC1\nSC1\nSC2\nSC4\n\nReran these four samples to obtain a definitive answer as to whether or not they have residual gDNA in them prior to using them to make cDNA.\nUsed Oly_Actin primers (SR IDs: 1504, 1505)\nUsed 1μL from all templates.\nAll samples were run in duplicate.\nPositive control was HL1 O.lurida DNA isolated by Jake on 20150323.\nCycling params:\n\n95C – 2.5mins\n40 cycles of:\n\n95C – 10s\n60C – 20s\n\nMelt curve\n\nMaster mix calcs: 20150521_qPCR_Oly_DNased_RNA\nPlate layout: 20150521_qPCR_plate_Jake_Oly_DNased_RNA\nResults:\nqPCR Data File (Opticon): Sam_20150521_145749.tad qPCR Report (Google Sheet): 20150521_qPCR_Report_Jake_Oly_DNased_RNA\nNo amplification in any of the RNA samples, nor the NTCs. Will make cDNA.\n\nAmplification Plots\n(http://eagle.fish.washington.edu/Arabidopsis/20150521_qPCR_Amp_Jake_Oly_DNased%20RNA_.JPG)\n\n\nMelt Curves\n(http://eagle.fish.washington.edu/Arabidopsis/20150521_qPCR_Melt_Jake_Oly_DNased%20RNA_.JPG)"
  },
  {
    "objectID": "posts/2015/2015-02-09-sequencing-data-lsu-c-virginica-mbd-bs-seq/index.html",
    "href": "posts/2015/2015-02-09-sequencing-data-lsu-c-virginica-mbd-bs-seq/index.html",
    "title": "Sequencing Data - LSU C.virginica MBD BS-Seq",
    "section": "",
    "text": "Our sequencing data (Illumina HiSeq2500, 100SE) for this project has completed by Univ. of Oregon Genomics Core Facility (order number 2112).\nSamples sequenced/pooled for this run:\n\n\n\n\n\nSample\n\n\nTreatment\n\n\nBarcode\n\n\n\n\nHB2\n\n\n25,000ppm oil\n\n\nATCACG\n\n\n\n\nHB16\n\n\n25,000ppm oil\n\n\nTTAGGC\n\n\n\n\nHB30\n\n\n25,000ppm oil\n\n\nTGACCA\n\n\n\n\nNB3\n\n\nNo oil\n\n\nACAGTG\n\n\n\n\nNB6\n\n\nNo oil\n\n\nGCCAAT\n\n\n\n\nNB11\n\n\nNo oil\n\n\nCAGATC\n\n\n\n\n\nAll code listed below was run on OS X 10.9.5\nDownloaded all 15 fastq.gz files to Owl/web/nightingales/C_virginica:\n$curl -O https://gcf.uoregon.edu:8080/job/download/2112?fileName=lane1_NoIndex_L001_R1_001.fastq.gz $curl -O https://gcf.uoregon.edu:8080/job/download/2112?fileName=lane1_NoIndex_L001_R1_002.fastq.gz $curl -O https://gcf.uoregon.edu:8080/job/download/2112?fileName=lane1_NoIndex_L001_R1_003.fastq.gz $curl -O https://gcf.uoregon.edu:8080/job/download/2112?fileName=lane1_NoIndex_L001_R1_004.fastq.gz $curl -O https://gcf.uoregon.edu:8080/job/download/2112?fileName=lane1_NoIndex_L001_R1_005.fastq.gz $curl -O https://gcf.uoregon.edu:8080/job/download/2112?fileName=lane1_NoIndex_L001_R1_006.fastq.gz $curl -O https://gcf.uoregon.edu:8080/job/download/2112?fileName=lane1_NoIndex_L001_R1_007.fastq.gz $curl -O https://gcf.uoregon.edu:8080/job/download/2112?fileName=lane1_NoIndex_L001_R1_008.fastq.gz $curl -O https://gcf.uoregon.edu:8080/job/download/2112?fileName=lane1_NoIndex_L001_R1_009.fastq.gz $curl -O https://gcf.uoregon.edu:8080/job/download/2112?fileName=lane1_NoIndex_L001_R1_010.fastq.gz $curl -O https://gcf.uoregon.edu:8080/job/download/2112?fileName=lane1_NoIndex_L001_R1_011.fastq.gz $curl -O https://gcf.uoregon.edu:8080/job/download/2112?fileName=lane1_NoIndex_L001_R1_012.fastq.gz $curl -O https://gcf.uoregon.edu:8080/job/download/2112?fileName=lane1_NoIndex_L001_R1_013.fastq.gz $curl -O https://gcf.uoregon.edu:8080/job/download/2112?fileName=lane1_NoIndex_L001_R1_014.fastq.gz $curl -O https://gcf.uoregon.edu:8080/job/download/2112?fileName=lane1_NoIndex_L001_R1_015.fastq.gz\nRenamed all files by removing the beginning of each file name (2112?fileName=) and replacing that with 2112_:\n$for file in 2112*lane1_NoIndex_L001_R1_0*; do mv \"$file\" \"${file/#2112?fileName=/2112_}\"; done\nCreated a directory readme.md (markdown) file to list & describe directory contents: readme.md\n$ls *.gz >> readme.md\nNote: In order for the readme file to appear in the web directory listing, the file cannot be all upper-case.\nCreated MD5 checksums for each fastq.gz file: checksums.md5\n$md5 *.gz >> checksums.md5"
  },
  {
    "objectID": "posts/2015/2015-09-15-genomic-dna-isolation-olympia-oyster-adductor-musle-mantle-2/index.html",
    "href": "posts/2015/2015-09-15-genomic-dna-isolation-olympia-oyster-adductor-musle-mantle-2/index.html",
    "title": "Genomic DNA Isolation - Olympia oyster adductor musle & mantle",
    "section": "",
    "text": "Previously isolated gDNA from these tissues on 20150901. However, found out after the isolations that BGI needs >73μg of gDNA for the genome sequencing project, which is significantly more than I obtained previously.\nIsolated gDNA from Ostrea lurida (Olympia oyster) adductor muscle & mantle samples collected by Brent & Steven on 20150812 using DNAzol (Molecular Research Center) according to the manufacturer’s protocol, with the following adjustments:\n\n89.8mg of adductor muscle\n92.2mg of mantle\nTissues homogenized in 750μL of DNAzol with disposable mortar/pestle tubes using 10 pestle strokes\nAfter homogenization, topped off tubes to 1000μL with DNAzol and incubated @ RT for 10mins.\nPerformed optional centrifugation step (10,000g, 10mins @ RT)\nInitial pellet wash was performed using a 70%/30% DNAzol/EtOH\nPellets were resuspended in 200μL of Buffer EB (Qiagen)\nInsoluble material was pelleted (12,000g, 10mins @ RT) and supe transferred to new tubes\n\nSpec’d on Roberts Lab NanoDrop1000 (ThermoFisher) and stored temporarily at 4C to avoid freeze-thawing before sending off for sequencing.\nResults:\n(http://eagle.fish.washington.edu/Arabidopsis/20150914_gDNA_Oly_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150914_gDNA_Oly_plots.JPG)\nThere was a great deal of insoluble material from the get-go that was carried through the entire isolation.\nOverall, the 260/280 ratios look pretty good, but the 260/230 ratios are just trash. As can be seen in the plots above, there is clearly significant absorbance in the 230 - 250nm, suggesting some contaminant carryover (phenol/salt).\nWill evaluate gDNA integrity on agarose gel.\nTotal yield from this isolation is still below the minimum quantity of gDNA needed for the sequencing project. Will need to perform another round of gDNA isolation."
  },
  {
    "objectID": "posts/2015/2015-06-16-sample-submission-olympia-oyster-sea-pen-pcrs-sanger-sequencing/index.html",
    "href": "posts/2015/2015-06-16-sample-submission-olympia-oyster-sea-pen-pcrs-sanger-sequencing/index.html",
    "title": "Sample Submission – Olympia oyster & Sea Pen PCRs Sanger Sequencing",
    "section": "",
    "text": "Prepared two DNA plates and corresponding primer plates for sequencing at the UW HTGC from the purified gel-purified PCRs from yesterday. Primer plates were prepared by adding 7μL of NanoPure H2O to each well and then adding 3μL of 10μM primer to the appropriate wells. For the DNA plates, added 10μL of DNA to the appropriate wells.\nNOTE: The H2A_ST1 samples had insufficient volume of DNA for all four sequencing reactions. Added 30μL of NanoPure water to purified DNA, mixed and distributed to the appropriate wells.\nSequencing plates layouts can be seen here (Google Sheet): sequence_log.\nSubmitted the plates to the UW HTGC for Sanger sequencing."
  },
  {
    "objectID": "posts/2015/2015-08-03-goals-august-2015/index.html",
    "href": "posts/2015/2015-08-03-goals-august-2015/index.html",
    "title": "Goals - August 2015",
    "section": "",
    "text": "Review of last month’s goals:\n\nO.lurida RNA Isolation & Reverse Transcription -\nRNA has been isolated and DNased from Jake’s mechanically stressed samples.\n\n\nMiscellany -\nImproved organization of -80C, added frequently used protocols to the Roberts Lab GitHub Wiki, connected BGI rep with purchasing to get the PO situation figured out for Olympia oyster and geoduck genome sequencing, sent samples to BGI for Olympia oyster genome-by-sequencing (GBS).\n\n\n\n\n O.lurida Reverse Transcription\nNeed to quantify the DNased RNA from Jake’s mechanically stressed oysters and then verify that the DNase treatment worked. Will then proceed with reverse transcription.\n\n\nMiscellany\nContinue work on -80C organization, continue creating “readme” files for folders on our server(s), continue migration from Wikispaces to GitHub, attempt to combine our PrimerDatabase and our Primer Stocks spreadsheets into a single document (and create a SQL database from that), fix the shortfalls from our EH&S lab inspection."
  },
  {
    "objectID": "posts/2015/2015-04-24-rna-isolation-geoduck-gonad-in-paraffin-histology-blocks/index.html",
    "href": "posts/2015/2015-04-24-rna-isolation-geoduck-gonad-in-paraffin-histology-blocks/index.html",
    "title": "RNA Isolation – Geoduck Gonad in Paraffin Histology Blocks",
    "section": "",
    "text": "UPDATE 20150528: The RNA isolated in this notebook entry may have been consolidated on 20150528.\nIsolated RNA from geoduck gonad previously preserved with the PAXgene Tissue Fixative and Stabilizer and then embedded in paraffin blocks. See Grace’s notebook for full details on samples and preservation.\nRNA was isolated from the following samples using the PAXgene Tissue RNA Kit (Qiagen) from the following geoduck sample blocks:\n\n02\n03\n04\n07\n08\n09\n35\n38\n41\n46\n51\n65\n67\n68\n69\n70\n\nIMPORTANT:\n\nI used Buffer TR1 + β-mercaptoethanol (β-ME) prepared on 20150408 for samples 02, 03, 04, 07. The rest of the samples were processed with buffer prepared today.\nI used aliquots of DNase prepared on 20150408.\n\nFive 5μm sections were taken from each block. A new blade was used for each block.\nSamples were then processed with the PAXgene Tissue RNA Kit in two groups of eight.\nIsolated RNA according to the PAXgene Tissue RNA Kit protocol with the following alterations:\n\n“Max speed” spins were performed at 19,000g.\nTissue disruption was performed with the Disruptor Genie @ 45C for 15mins.\nShaking incubation step was performed with Disruptor Genie\nSamples were eluted with 40μL of Buffer TR4, incubated @ 65C for 5mins, immediately placed on ice and quantified on the Roberts Lab NanoDrop1000.\n\nResults:\n(http://eagle.fish.washington.edu/Arabidopsis/20150424_Geoduck_block_RNA_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150424_Geoduck_block_RNA_ODs_plots.JPG)\nWell, these results are certainly not good.\nThe first set of eight samples I processed yielded no RNA (except #38, which is only marginally better than nothing). All the samples (excluding #38) have been discarded.\nThe second set of eight samples I processed range from amazing to poor (#68 was barely worth keeping).\nI’ll review the protocol, but at the moment I’m at a loss to explain why the first set of eight samples came up empty. Will perform another on these blocks on Monday. Grrrrr.\nSamples were stored at -80C in Shellfish RNA Box #5."
  },
  {
    "objectID": "posts/2015/2015-10-09-restriction-digest-oly-gdna-for-rad-seq-walfi-2/index.html",
    "href": "posts/2015/2015-10-09-restriction-digest-oly-gdna-for-rad-seq-walfi-2/index.html",
    "title": "Restriction Digest – Oly gDNA for RAD-seq w/AlfI",
    "section": "",
    "text": "Used a subset (10 samples) from the Ostrea lurida gDNA isolated 20150916 to prepare RAD libraries.\nFollowed the 2bRAD protocol (PDF) developed by Eli Meyer’s lab.\nPrepared 9.0μg of each of the following samples in a volume of 10μL:\nGoogle Sheet: 20151009_RADseq_DNA_calcs\nPrepared a 150μM working stock of the SAM buffer needed for the restriction digestion by diluting 30μL of the supplied stock (500μM) in 70μL NanoPure H2O (total volume = 100μL). This working stock was stored @ -20C in FTR 209 in the “RAD-seq Reagents” box.\nPrepared master mix for restriction enzyme reaction:\n\n\n\n\n\nREAGENT\n\n\nSINGLE REACTION (μL)\n\n\nx11\n\n\n\n\nDNA\n\n\n8\n\n\nNA\n\n\n\n\n10x Buffer R\n\n\n1.2μL\n\n\n13.2μL\n\n\n\n\n150μM SAM\n\n\n0.8μL\n\n\n8.8μL\n\n\n\n\nAlfI\n\n\n0.5μL\n\n\n5.5μL\n\n\n\n\nH2O\n\n\n1.5μL\n\n\n16.5μL\n\n\n\n\n\nCombined 4μL of the master mix with 8μL of each sample in 0.5mL snap cap tubes. Incubated @ 37C 2hrs. in thermal cycler (PTC-200; no heated lid). Heat inactivated the digest @ 65C for 10mins."
  },
  {
    "objectID": "posts/2015/2015-02-07-bisulfite-ngs-library-prep-bisulfite-conversion-illumina-library-construction-of-c-gigas-larvae-dna/index.html",
    "href": "posts/2015/2015-02-07-bisulfite-ngs-library-prep-bisulfite-conversion-illumina-library-construction-of-c-gigas-larvae-dna/index.html",
    "title": "Bisulfite NGS Library Prep - Bisulfite Conversion & Illumina Library Construction of C.gigas larvae DNA",
    "section": "",
    "text": "Bisulfite Conversion\nThe previous attempt at constructing a library for the 1000ppm larvae samples failed. I had previously sheared, quantified, and concentrated the DNA from this sample. As I had done previously, I combined 50ng from each of the two 1000ppm samples for a total of 100ng, and brought the sample volume up to 24μL with NanoPure H2O.\nBisulfite conversion was performed with the Methylamp DNA Modification Kit (Epigentek) according to the manufacturer’s protocol.\nSample was eluted with 10μL of Buffer R6 for immediate use.\n\n\nLibrary Prep\nBisulfite Illumina library was made with [EpiNext Post-Bisulfite DNA Library Preparation Kit (Illumina) (Epigentek)(https://github.com/sr320/LabDocs/blob/master/protocols/Commercial_Protocols/Epigentek_PostBisulfiteIlluminaLibraryPrep_P-1055.pdf).  Changes to the manufacturer’s protocol:\n\nSamples were transferred to 1.5mL snap cap tubes for all magnetic bead steps in order to fit in our tube magnets.\nSkipped Step 7.1 (per manufacturer’s recommendation for samples starting with <200ng)\nRan 13 cycles during the library amplification step (per manufacturer’s recommendation for samples starting with 100ng)\n\nSample was transferred to 1.5mL snap cap tube and stored @ -20C.  Will quantify library on Monday when Jake is also finished with his 12 libraries."
  },
  {
    "objectID": "posts/2015/2015-04-30-blastn-c-gigas-oa-larvae-to-ensembl-1-24-blast-db/index.html",
    "href": "posts/2015/2015-04-30-blastn-c-gigas-oa-larvae-to-ensembl-1-24-blast-db/index.html",
    "title": "BLASTN - C.gigas OA Larvae to C.gigas Ensembl 1.24 BLAST DB",
    "section": "",
    "text": "In an attempt to figure out what’s going on with the Illumina data we recently received for these samples, I BLASTed the 400ppm data set that had previously been de-novo assembled by Steven: EmmaBS400.fa.\nI also created a nucleotide BLAST database (DB) from the Crassostrea_gigas.GCA_000297895.1.24.fa\nJupyter (IPython) Notebook: 20150429_Gigas_larvae_OA_BLASTn.ipynb\nNotebook Viewer: 20150429_Gigas_larvae_OA_BLASTn\n\n\nResults:\nThe results are not great.\nAll query contigs successfully BLAST to sequences in the C.gigas Ensembl BLAST DB. However, only 33 of the sequences (out of ~37,000) have an e-value of 0.0. The next best e-value for any matches is 0.001. For the uninitiated, that value is not very good, especially when you’re BLASTing against the same exact species DB.\nWill BLASTn the C.gigas contigs against the entire GenBank nt (all nucleotides) to see what the taxonomy breakdown looks like of these sequences."
  },
  {
    "objectID": "posts/2015/2015-10-01-adaptor-ligation-oly-alfi-digested-gdna-for-rad-seq/index.html",
    "href": "posts/2015/2015-10-01-adaptor-ligation-oly-alfi-digested-gdna-for-rad-seq/index.html",
    "title": "Adaptor Ligation - Oly AlfI-Digested gDNA for RAD-seq",
    "section": "",
    "text": "Yesterday’s AlfI over night restriction digest was heat inactivated by heating @ 65C for 10mins. Samples were stored on ice.\nContinued to follow  the 2bRAD protocol (PDF) developed by Eli Meyer’s lab.\nDigested DNA was not run out on a gel due to the fact that the input gDNA was degraded and a shift in the high molecular weight band (indicating the digestion was successful) would not exist because a high molecular weight band is absent in these samples.\nThe following oligos were reconstituted in TE buffer (pH = 8.0) to 100μM:\n\n3ILL-NR\n5ILL-NR\nanti-ILL\nILL-BC1 (Barcode sequence: CGTGAT)\nILL-HT1 (Barcode sequence: ATGCAT)\nILL-HT2 (Barcode sequence: CGTACG)\nILL-LIB1\nILL-LIB2\n\n\nAnneal Adaptors\nAfter preparing the two adaptors below, they were incubated for 10mins @ RT:\n\nAdaptor 1 (2μM final concentration of each oligo): 1.5μL of 5ILL-NR (100μM) + 1.5μL of anti-ILL (100μM) + 72μL H2O = 75μL total\nAdaptor 2 (2μM final concentration of each oligo): 1.5μL of 3ILL-NR (100μM) + 1.5μL of anti-ILL (100μM) + 72μL H2O = 75μL total\n\nAfter annealing, the adaptors were stored on ice.\n\n\nAdaptor Ligation\nAll components were stored on ice. Ligation reactions were prepared on ice and performed in 0.5mL snap cap tubes.\n\n\n\n\n\nREAGENT\n\n\nSINGLE REACTION (μL)\n\n\nx11\n\n\n\n\nDigested DNA\n\n\n10\n\n\nNA\n\n\n\n\nATP (10mM)\n\n\n1\n\n\n11\n\n\n\n\n10x T4 Ligase Buffer\n\n\n4\n\n\n44\n\n\n\n\nAdaptor 1 (2μM)\n\n\n5\n\n\n55\n\n\n\n\nAdaptor 2 (2μM)\n\n\n5\n\n\n55\n\n\n\n\nT4 DNA Ligase\n\n\n1\n\n\n11\n\n\n\n\nNanoPure H2O\n\n\n24\n\n\n264\n\n\n\n\nTOTAL\n\n\n50\n\n\n440\n\n\n\n\n\nAdded 40μL of the master mix to each tube of AlfI-digested DNA (12μL). NOTE: I made a mistake here. I should have only combined 10μL of DNA with the 40μL of master mix for each. My mistake was due, in part, to the way the Meyer Lab 2bRAD protocol is written. In the Digestion section of the protocol, Step 5 (run 2μL of the digests on a gel) is listed as optional. However, in Step 2a of the Ligation section, it says to add the “remaining 10μL of digested DNA”. The use of the word “remaining” in this instance is misleading because it implies to use all that’s left in the tube.\nIncubated ligation reaction @ 16C for 3hrs in PTC-200 thermal cycler (MJ Research) - no heated lid.\nTransferred tubes to ice while preparing subsequent"
  },
  {
    "objectID": "posts/2015/2015-04-09-rna-isolation-geoduck-foot-in-paraffin-histology-blocks/index.html",
    "href": "posts/2015/2015-04-09-rna-isolation-geoduck-foot-in-paraffin-histology-blocks/index.html",
    "title": "RNA Isolation - Geoduck Gonad in Paraffin Histology Blocks",
    "section": "",
    "text": "Isolated RNA from geoduck gonad previously preserved with the PAXgene Tissue Fixative and Stabilizer and then embedded in paraffin blocks. See Grace’s notebook for full details on samples and preservation.\nRNA was isolated from only two samples using the PAXgene Tissue RNA Kit (Qiagen) from the following geoduck sample blocks to test out the kit:\n\n34\n42\n\nIMPORTANT:\n\nPrior to beginning, I prepared Buffer TR1 by adding 10μL of β-mercaptoethanol (β-ME) to 1000μL of Buffer TR1). This will be good for up to six weeks at RT.\nReconstituted DNase I with 550μL of RNase-free H2O. Aliquoted in 100μL volumes and stored @ -20C in the “-20C Kit Components” box.\n\nFive 5μm sections were taken from each block.\nIsolated RNA according to the PAXgene Tissue RNA Kit protocol with the following alterations:\n\n“Max speed” spins were performed at 19,000g.\nTissue disruption was performed with the Disruptor Genie @ 45C for 15mins.\nShaking incubation step was performed with Disruptor Genie\nSamples were eluted with 34μL of Buffer TR4, incubated @ 65C for 5mins, immediately placed on ice and quantified on the Roberts Lab NanoDrop1000.\n\nSamples were stored at -80C in Shellfish RNA Box #5.\nNOTE: The spreadsheet linked indicates other samples exist in the slots that I placed these two samples. Will need to update the spreadsheet to be accurate.\nResults:\n(http://eagle.fish.washington.edu/Arabidopsis/20150408%20-%20Geoduck%20block%20RNA%20ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150408%20-%20Geoduck%20block%20RNA%20ODs%20plots.JPG)\nLooks like the kit worked! Yields are pretty good (~800ng) from each. The 260/280 ratios are great for both samples. Oddly, the 260/230 ratios for the two samples are pretty much polar opposites of each other; not sure why.\nWill proceed with the remainder of the samples that were selected by Steven and Brent. Or, maybe I should try to make some cDNA from these RNA samples to verify the integrity of the RNA…"
  },
  {
    "objectID": "posts/2015/2015-11-18-qpcr-oly-rad-seq-library-quantification-2/index.html",
    "href": "posts/2015/2015-11-18-qpcr-oly-rad-seq-library-quantification-2/index.html",
    "title": "qPCR – Oly RAD-Seq Library Quantification",
    "section": "",
    "text": "After yesterday’s attempt at quantification revealed insufficient dilution of the libraries, I repeated the qPCRs using 1:100000 dilutions of each of the libraries. Used the KAPA Illumina Quantification Kit (KAPA Biosystems) according to the manufacturer’s protocol.\nMade 1:100000 dilutions of each library were made with NanoPure H2O.\nRan all samples, including standards, in triplicate on the Roberts Lab Opticon2 (BioRad).\nPlate set up and master mix can be found here: 20151117_qPCR_plate_layout_Oly_RAD.JPG\nResults:\nqPCR Data File (Opticon2): Sam_20151117_100745.tad\nqPCR Data (Google Sheet): 20151117_RAD_qPCR_data\nOverall, the new dilutions worked well, with all the library samples coming up between Ct 9 - 15, which is well within the range of the standard curve.\nManually adjusted the baseline threshold to be above any background fluorescence (see images below).\nAll samples, except Oly RAD 30, exhibit two peaks in the melt curve indicating contaminating primer dimers. Additionally, the peak heights appear to be roughly equivalent. Can we use this fact to effectively “halve” the concentration of our sample to make a rough estimate of library-only PCR products?\nHere are the calculated library concentrations, based on the KAPA Biosystems formulas\n\n\n\n\n\nLibrary\n\n\nLibrary Stock Conc. (nM)\n\n\nStock Halved (nM)\n\n\n\n\nOly RAD 02\n\n\n46.70\n\n\n23.35\n\n\n\n\nOly RAD 03\n\n\n79.35\n\n\n39.67\n\n\n\n\nOly RAD 04\n\n\n61.35\n\n\n30.67\n\n\n\n\nOly RAD 06\n\n\n30.61\n\n\n15.30\n\n\n\n\nOly RAD 07\n\n\n477.05\n\n\n238.53\n\n\n\n\nOly RAD 08\n\n\n46.32\n\n\n23.16\n\n\n\n\nOly RAD 14\n\n\n224.91\n\n\n112.46\n\n\n\n\nOly RAD 17\n\n\n24.56\n\n\n12.28\n\n\n\n\nOly RAD 23\n\n\n49.56\n\n\n24.78\n\n\n\n\nOly RAD 30\n\n\n11.19\n\n\n NA\n\n\n\n\n\nAmplification plots of standard curve samples:\n(http://eagle.fish.washington.edu/Arabidopsis/20151117_RAD_qPCR_stds_amp.png)\nMelt curve plots of standard curve samples. Shows expected “shoulder” to the left of the primary peak:\n(http://eagle.fish.washington.edu/Arabidopsis/20151117_RAD_qPCR_stds_melt.png)\nAmplification plots of RAD library samples:\n(http://eagle.fish.washington.edu/Arabidopsis/20151117_RAD_qPCR_samples_amp.png)\nMelt curve plots of RAD library samples. Peak on the right corresponds to primer dimer. Peak heights between primer dimer and desired PCR product are nearly equivalent for each respective sample, suggesting that each product is contributing equally to the fluorescence generated in the reactions:\n(http://eagle.fish.washington.edu/Arabidopsis/20151117_RAD_qPCR_samples_melt_01.png)\nMelt curve plot of Oly RAD library 30. Notice there’s only a single peak due to the lack of primer dimers in this sample:\n(http://eagle.fish.washington.edu/Arabidopsis/20151117_RAD_qPCR_samples_melt_02.png)"
  },
  {
    "objectID": "posts/2015/2015-07-03-automatic-notebook-backups-wget-script-synology-task-scheduler/index.html",
    "href": "posts/2015/2015-07-03-automatic-notebook-backups-wget-script-synology-task-scheduler/index.html",
    "title": "Automatic Notebook Backups - wget Script & Synology Task Scheduler",
    "section": "",
    "text": "I’ve been tweaking a [shell script (notebook_backups.sh)(https://github.com/sr320/LabDocs/blob/master/code/script-box/notebook_backups.sh) to use the shell program wget to retrieve fully functional HTML versions of our online notebooks for offline viewing. I had been planning on setting up a cron job to automatically run this script on our Synology server (Eagle) at a set day/time. However, I came across the Task Scheduler that’s built right into the Synology GUI! So, I set up the Task Scheduler to run the notebook_backups.sh script every Sunday. See screenshots below.\n(http://eagle.fish.washington.edu/Arabidopsis/Screenshot%202015-07-02%2016.04.10.png)\n(http://eagle.fish.washington.edu/Arabidopsis/Screenshot%202015-07-02%2016.05.52.png)\n(http://eagle.fish.washington.edu/Arabidopsis/Screenshot%202015-07-02%2016.06.51.png)\n\n\nThe Task Scheduler was not running the script. Additionally, the Task Scheduler would not run the script even when I manually instructed the Task Scheduler to run. Some internet searching revealed that the Task Scheduler requires you to indicate what type of task is being run (e.g. bash, shell, ash, php, etc.), even if your script contains the proper “shebang” or header that normally instructs the computer which program to use to run the script. See the image below for how the Task Scheduler is currently set up. The arrow indicates that addition of “sh” to the beginning of the Task Scheduler’s path to the script. This tells the Task Scheduler to use the Shell to run the script.\n(http://eagle.fish.washington.edu/Arabidopsis/20150714_Syno_Task_Scheduler.jpg)"
  },
  {
    "objectID": "posts/2015/2015-12-10-samples-received-c-gigas-tissue-dna-from-katie-lotterhos/index.html",
    "href": "posts/2015/2015-12-10-samples-received-c-gigas-tissue-dna-from-katie-lotterhos/index.html",
    "title": "Samples Received - C.gigas Tissue & DNA from Katie Lotterhos",
    "section": "",
    "text": "Received 6 samples from Katie today. The box was labeled and stored @ -20C.\nHere description of the samples, via email:\n\nLotterhos samples (gigas) arriving tomorrow\n\nMantle tissue samples of C. gigas were collected on 20140705 (source: Pipestem Inlet) by KEL\nExtraction on 20141028 by VG using Qiagen DNAeasy Blood and Tissue Kit\nBeadwash on 20150720 by VG using homemade sera-mag speed beads\nQubit 3.0 quantification on 20151206 by KEL and the following amounts were sent:\n\nM1: 13 uL of 386 ug/mL M2: 13.8 uL of 326 ug/mL M3: 13.15 uL of 380 ug/mL (solution looked cloudy)\n\n(http://eagle.fish.washington.edu/Arabidopsis/20151210_katie_lotterhos_samples.jpeg)"
  },
  {
    "objectID": "posts/2015/2015-05-13-qpcr-jake-o-lurida-ctenidia-rna-heat-shock-samples-from-20150506/index.html",
    "href": "posts/2015/2015-05-13-qpcr-jake-o-lurida-ctenidia-rna-heat-shock-samples-from-20150506/index.html",
    "title": "qPCR - Jake O.lurida ctenidia RNA (Heat Shock Samples) from 20150506",
    "section": "",
    "text": "Ran qPCRs on the O.lurida total RNA I isolated on 20150506 to assess presence of gDNA carryover with Oly Actin primers (SR IDs: 1505, 1504).\nUsed 1μL from all templates.\nAll samples were run in duplicate.\nPositive control was HL1 O.lurida DNA isolated by Jake on 20150323.\nMaster mix calcs are here: 20150512_qPCR_Oly_RNA\nCycling params:\n\n95C - 3mins\n40 cycles of:\n\n95C - 5s\n60C - 20s\n\nMelt curve\n\nPlate layout: 20150512_qPCR_plate_Jake_Oly_HS_RNA\nResults:\nqPCR Data File (Opticon2): Sam_20150512_123246.tad\nqPCR Report (Google Spreadsheet):20150512_qPCR_Report_Jake_Oly_HS_RNA\nExcluding the no template controls (NTC), all samples produced amplification. Will require DNasing before making cDNA.\nRelated to the qPCR I ran earlier today with these same primers, the efficiencies of the reactions on this plate are significantly better (i.e. normal; >80% efficiencies) than the earlier qPCR. The improved efficiency would also explain why the positive control comes up two cycles earlier on this run.\nIn the amplification plots below, the positive control reps are the two lines coming up at cycle ~20.\n\nAmplification Plots\n(http://eagle.fish.washington.edu/Arabidopsis/20150512_qPCR_Amp_Jake_Oly_HS_RNA_.JPG)\n\n\nMelt Curves\n(http://eagle.fish.washington.edu/Arabidopsis/20150512_qPCR_Melt_Jake_Oly_HS_RNA_.JPG)"
  },
  {
    "objectID": "posts/2015/2015-03-14-truseq-adaptor-identification-method-comparison-lsu-c-virginica-oil-spill-sequences/index.html",
    "href": "posts/2015/2015-03-14-truseq-adaptor-identification-method-comparison-lsu-c-virginica-oil-spill-sequences/index.html",
    "title": "TruSeq Adaptor Identification Method Comparison - LSU C.virginica Oil Spill Sequences",
    "section": "",
    "text": "We recently received Illumina HiSeq2500 data back from this project. Initially looking at the data, something seems off.  Using FASTQC, the quality drops of drastically towards the last 20 bases of the reads. We also see a high degree of Illumina TruSeq adaptor/index sequences present in our data.\nSince this sequencing run was multiplexed (i.e. multiple libraries were pooled and run together on the HiSeq), we need to demultiplex our sequences before performing any trimming. Otherwise, the trimming could remove the index (barcodes) sequences from the data and prevent us from separating out the different libraries from each other.\nHowever, it turns out, demultiplexing is not a simple, straightforward task. There are a variety of programs available and they all have different options. I decided to compare TruSeq index identification using two programs:\n-grep (grep is a built-in command line (bash) program that searches through files to find matches to user-provided information.) -fastx_barcode_splitter.pl (fastx_barcode_splitter.pl is a component of the fastx_tookit that searches through FASTQ files to identify matches to user-provided index/barcode sequences.)\nThe advantage(s) of using grep is that it’s extremely fast, easy to use, and already exists on most Unix-based computers (Linux, OS X), thus not requiring any software installation. The disadvantage(s) of using grep for a situation like this is that it is not amenable to allowing for mismatches and/or partial matches to the user-provided information.\nThe advantage(s) of using fastx_barcode_splitter.pl is that it can accept a user-defined number of mismatches and/or partial matches to the user-defined index/barcode sequences. The disadvantage(s) of using fastx_barcode_splitter.pl is that it requires the user to specify the expected location of the index/barcode sequence in the target sequence: either the beginning of the line or the end of the line. It will not search beyond the length(s) of the provided index/barcode sequences. That means if you index/barcode exists in the middle of your sequences, this program will not find it. Additionally, since this program doesn’t exist natively on Unix-based machines, it must be downloaded and installed by the user.\nSo, I tested both of these programs to see how they compared at matching both long (the TruSeq adaptor/index sequences identified with FASTQC) and “short” (the actual 6bp index sequence) barcodes.\nTo simplify testing, only a single sequence file was used from the data set.\nAll analysis was done in a Jupyter (IPython) notebook.\nFASTQC HTML file for easier viewing of FASTQC output.\nNBViewer version of embedded notebook below.\n\n\nResult:\n\ngrep\nlong barcodes: Found in ~12% of all reads\nshort barcodes: Found in ~25% of all reads\n\n\nfastx_barcode_splitter\nlong barcodes, beginning of line: Found in ~15% of all reads\nlong barcodes, end of line: Found in < 0.008% of all reads (yes, that is actually percentage)\nshort barcodes, beginning of line: Found in ~1.3% of all reads\nshort barcodes, end of line: Found in ~2.7% of all reads\nOverall, the comparison is interesting, however, the important take home from this is that in the best-case scenario (grep, short barcodes), we’re only able to identify 25% of the reads in our sequences!\nIt should also be noted that my analysis only used sequences in one orientation. It would be a good idea to also do this analysis by searching with the reverse and reverse complements of these sequences."
  },
  {
    "objectID": "posts/2015/2015-11-25-dna-isolation-olympia-oyster-outer-mantle-gdna/index.html",
    "href": "posts/2015/2015-11-25-dna-isolation-olympia-oyster-outer-mantle-gdna/index.html",
    "title": "DNA Isolation - Olympia Oyster Outer Mantle gDNA",
    "section": "",
    "text": "Since we still don’t have sufficient gDNA for the full scope of the Olympia oyster genome sequencing, I isolated more gDNA.\nIsolated gDNA from 118mg outer mantle tissue collected by Steven & Brent on 20150812.\nTissue was thoroughly minced with a clean razor blade and then processed with the E.Z.N.A. Mollusc Kit (Omega BioTek) with the following changes:\n\nDoubled solution volumes for steps before sample was loaded on columns\nSample was split equally in two tubes prior to addition of 100% EtOH\nAll mixing was done by shaking - no vortexing! Done this way to, hopefully, maintain gDNA integrity\nElution volume = 50μL\nElution was repeated using the initial elution to maximize recovery while maintaining low sample volume.\nThe two preps were pooled - final volume = 79μL\n\nDNA was quantified using two methods: NanoDrop1000 & QuantIT dsDNA BR Kit\nFor the Quant-IT kit, the samples were quantified using the QuantIT dsDNA BR Kit (Invitrogen) according to the manufacturer’s protocol.\nStandards were run in triplicate, samples were run in duplicate.\n96-well black (opaque) plate was used.\nFluorescence was measured on the Seeb Lab’s Victor 1420 plate reader (Perkin Elmer).\nResults:\n\n\n\n\n\nMETHOD\n\n\nCONCENTRATION (ng/μL)\n\n\nVOLUME (μL)\n\n\nYIELD (ng)\n\n\n\n\nNanoDrop1000\n\n\n552.53\n\n\n79\n\n\n43,650\n\n\n\n\nQuant-IT\n\n\n219.07\n\n\n79\n\n\n17,307\n\n\n\n\n\nThe NanoDrop1000 overestimates the concentration of the sample by 2.5x!\nRegardless, this is a solid yield and, when combined with the other Ostrea lurida gDNA that I cleaned up today, should push the total amount of gDNA submitted to BGI over the required threshold.\nWill evaluate gDNA quality on a gel.\nFluorescence (Google Sheet): 20151124_geoduck_oly_gDNA_quants\nNanoDrop1000 Measurements and Plots\n(http://eagle.fish.washington.edu/Arabidopsis/20151124_gDNA_geoduck_oly_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20151124_gDNA_geoduck_oly_plots.JPG)"
  },
  {
    "objectID": "posts/2015/2015-11-20-dna-sonication-oly-gdna-for-mbd/index.html",
    "href": "posts/2015/2015-11-20-dna-sonication-oly-gdna-for-mbd/index.html",
    "title": "DNA Sonication - Oly gDNA for MBD",
    "section": "",
    "text": "In preparation for MBD enrichment, fragmented Olympia oyster gDNA with a target size of ~350bp.\nGenomic DNA samples were isolated and provided to us by Katherine Silliman at UIC. Selected samples will compare Hood Canal (HC) and Oyster Bay (SS, South Sound) populations.\nUsed the Seeb Lab’s Bioruptor 300 (Diagenode) sonicator.\n(http://eagle.fish.washington.edu/Arabidopsis/20151119_bioruptor_settings.JPG)\nAfter sonication, samples were run on a the Seeb Lab’s 2100 Bioanalyzer (Agilent) on DNA 12000 chips.\nResults:\nHOOD CANAL SAMPLES\n(http://eagle.fish.washington.edu/Arabidopsis/Bioanalyzer%20Data/20151119_bioanalyzer_oly_hood_canal_all_electropherograms.jpg)\nOYSTER BAY SAMPLES\n(http://eagle.fish.washington.edu/Arabidopsis/Bioanalyzer%20Data/20151119_bioanalyzer_oly_oyster_bay_all_electropherograms.jpg)\nMore detailed analysis (including average fragment size for each samples) will be coming soon…"
  },
  {
    "objectID": "posts/2015/2015-05-22-reverse-transcription-subset-of-jakes-o-lurida-dnased-rna/index.html",
    "href": "posts/2015/2015-05-22-reverse-transcription-subset-of-jakes-o-lurida-dnased-rna/index.html",
    "title": "Reverse Transcription - Subset of Jake’s O.lurida DNased RNA",
    "section": "",
    "text": "Currently don’t have sufficient reagents to perform reverse transcription on the entire set of DNased RNA (control and 1hr.heat-shocked O.lurida ctenidia samples). To enable Jake to start testing out some of his primers while we wait for reagents to come in, Steven suggested I generate some cDNA for him to use.\nUsed the following DNased RNA:\n\nHC1\nNC1\nSC1\nHT1 1\nNT1 1\nST1 1\n\nReverse Transcription Calcs: 20150522_Jake_Oly_cDNA_Calcs\nBriefly:\n\nReactions run in 0.5mL snap cap tubes\n250ng of DNased RNA used in each reaction\nCombined DNased RNA with oligo dT primers and water; incubated 70C 5mins; immediately placed on ice\nAdded 6.75μL of buffer/dNTP/enzyme master mix to each sample; incubated 42C for 1hr; 95C for 3mins\n\nSamples will be given to Jake and stored @ -20C."
  },
  {
    "objectID": "posts/2015/2015-10-06-sample-submission-additional-olympia-oyster-gdna-for-genome-sequencing-bgi/index.html",
    "href": "posts/2015/2015-10-06-sample-submission-additional-olympia-oyster-gdna-for-genome-sequencing-bgi/index.html",
    "title": "Sample Submission - Additional Olympia Oyster gDNA for Genome Sequencing @ BGI",
    "section": "",
    "text": "Previous shipment of gDNA proved to be of insufficient quantity when assessed by BGI, so needed to isolate more.\nShipped the pooled gDNA we’ve been accumulating to BGI to contine the geoduck genome sequencing project.\nSample was shipped on dry ice with the appropriate paperwork required by BGI (sample declaration letter).\nAssigned BGI Lot: 1510071002"
  },
  {
    "objectID": "posts/2015/2015-09-18-agarose-gel-geoduck-olympia-oyster-gdna-integrity-check-4/index.html",
    "href": "posts/2015/2015-09-18-agarose-gel-geoduck-olympia-oyster-gdna-integrity-check-4/index.html",
    "title": "Agarose Gel - Geoduck & Olympia oyster gDNA Integrity Check",
    "section": "",
    "text": "Ran a 0.8% agarose, 1x modified TAE gel (w/EtBr) with geoduck and Olympia oyster gDNA that was precipitated earlier today. Used 5μL of each sample (~500ng).\nResults:\n[caption id=“” align=“alignleft” width=“255”](http://eagle.fish.washington.edu/Arabidopsis/20150917_gel_gDNA_geoduck_oly.jpg) Geoduck gDNA on left. Oly gDNA on right.[/caption]\n(https://raw.githubusercontent.com/sr320/LabDocs/master/protocols/Commercial_Protocols/ThermoFisher_OgeneRuler_DNA_Ladder_Mix_F100439.jpg)\nOverall, the DNA still looks very good. Slight smearing (indicating slight degradation), but the high molecular weight band is very prominent. Will fill out the necessary BGI forms and ship samples out on Monday."
  },
  {
    "objectID": "posts/2015/2015-09-02-agarose-gel-geoduck-olympia-oyster-gdna-integrity-check/index.html",
    "href": "posts/2015/2015-09-02-agarose-gel-geoduck-olympia-oyster-gdna-integrity-check/index.html",
    "title": "Agarose Gel - Geoduck & Olympia Oyster gDNA Integrity Check",
    "section": "",
    "text": "Ran 0.8% agarose 1x modified TAE gel stained with EtBr to assess the integrity of [geoduck gDNA (from 20150828)(2015/08/28/genomic-dna-isolation-geoduck-adductor-muscle-foot.html) and Olympia oyster gDNA (from 20150901).\nRan 500ng of each sample:\nGeoduck adductor muscle: 4.87μL\nGeoduck foot: 4.50μL\nOly adductor muscle: 4.22μL\nOly mantle: 2.51μL\nResults:\n(https://raw.githubusercontent.com/sr320/LabDocs/master/protocols/Commercial_Protocols/ThermoFisher_OgeneRuler_DNA_Ladder_Mix_F100439.jpg)\nThe gel was loaded in the same order as the sample volumes listed above.\nThe gel is a bit disappointing.\n\nGeoduck adductor\nHigh molecular weight band present, but extremely faint. Not too much smearing, but accumulation of low molecular weight smudge suggests residual RNA. This is despite the fact that the kit used for isolation (E.Z.N.A. Mollusc DNA Kit) has a RNase treatment. This residual RNA could explain why the amount loaded on the gel appears to be so little compared to other samples (the RNA is contributing to the absorbance at 260nm, thus inflating the calculated concentration of gDNA).\n\n\nGeoduck foot\nHigh molecular weight band present and bright. Some smearing (i.e. degradation) present, along with degarded DNA visible at ~500bp. This sample may require a Bioanalyzer run to accurately quantify the high molecular weight DNA, as the lower molecular weight DNA (i.e. degarded DNA) is “artificially” inflating the concentration of the DNA in the sample.\n\n\nOly adductor\nHigh molecular weight band present and bright. Some smearing (i.e. degradation) present, along with degarded DNA visible at ~500bp. This sample may require a Bioanalyzer run to accurately quantify the high molecular weight DNA, as the lower molecular weight DNA (i.e. degarded DNA) is “artificially” inflating the concentration of the DNA in the sample.\n\n\nOly mantle\nHigh molecular weight band present, but extremely faint. Some smearing and a smudge around 500bp, indicating degraded DNA. The low visibility of this sample on the gel suggests that the concentration determined by the NanoDrop1000 is inaccurate. However, unlike the geoduck adductor sample, it doesn’t appear that RNA carryover is responsible, as there is no noticeable low molecular weight (~100bp) smudge.\nOverall, the geoduck foot and the Oly adductor samples are likely usable. Currently awaiting clarification from BGI for DNA quantity requirements for the genome sequencing of these two species."
  },
  {
    "objectID": "posts/2015/2015-09-17-ethanol-precipitation-geoduck-olympia-oyster-gdna/index.html",
    "href": "posts/2015/2015-09-17-ethanol-precipitation-geoduck-olympia-oyster-gdna/index.html",
    "title": "Ethanol Precipitation - Geoduck & Olympia oyster gDNA",
    "section": "",
    "text": "Pooled all of the geoduck gDNA from all the previous geoduck isolations for the Geoduck Genome Sequencing Project and pooled all of the Ostrea lurida gDNA from previous Ostrea lurida isolations for the Olympia Oyster Genome Sequencing Project.\nBoth sets of gDNA were ethanol (EtOH) precipitated. This was done for two reasons - to concentrate the samples to the minimum necessary concentration required by BGI (>119ng/μL) and to try to improve the poor 260/230 ratios (which are likely due to high salt carryover).\nPrecipitation was performed by consolidating each species of DNA in 15mL conicals, adding 0.1 volumes of 3M sodium acetate (pH= 5.2) and then adding 2.5 volumes of ice cold (-20C) 100% EtOH. Volumes used are below.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample\n\n\nDNA Vol (μL)\n\n\n3M Sodium Acetate Vol. (μL)\n\n\n100% EtOH Vol (μL)\n\n\nTotal Vol (μL)\n\n\n\n\nGeoduck\n\n\n1860\n\n\n186\n\n\n5115\n\n\n7161\n\n\n\n\nOly\n\n\n780\n\n\n78\n\n\n2145\n\n\n3003\n\n\n\n\n\nSamples were mixed by inversion and incubated @ -80C for 3hrs.\nDNA was pelleted by spinning tubes at 12,000g for 30mins @ 4C in a SL-50T (Sorval) rotor in a T21 (Sorval) table top centrifuge.\nSupernatant was decanted and pellets were transferred to 1.5mL snap cap tubes.\nPellets were washed three times with 70% EtOH.\nAfter the last wash, the supe was removed and pellets were air dried for 5mins @ RT.\nIn order to exceed the target concentration (>110ng/μL) needed by BGI, the pellets were resuspended in 500μL (150ng/μL) of EB Buffer (Qiagen). This is assuming each sample has at least 75μg of DNA.\nSamples were spec’d on the Roberts Lab NanoDrop1000.\nResults:\n(http://eagle.fish.washington.edu/Arabidopsis/20150917_gDNA_geoduck_oly_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150917_gDNA_geoduck_oly_plots.JPG)\nConcentrations are on point, the 260/280 ratios are still good and the 260/230 ratios are greatly improved. Samples are ready to send off to BGI for sequencing!\nTotal yields:\nGeoduck: 84μg\nOly: 86μg\nWill run these samples out on a gel to verify that the gDNA is still intact and didn’t get degraded during the precipitation."
  },
  {
    "objectID": "posts/2015/2015-03-17-epinext-adaptor-1-counts-lsu-c-virginica-oil-spill-samples/index.html",
    "href": "posts/2015/2015-03-17-epinext-adaptor-1-counts-lsu-c-virginica-oil-spill-samples/index.html",
    "title": "Epinext Adaptor 1 Counts - LSU C.virginica Oil Spill Samples",
    "section": "",
    "text": "Before contacting the Univ. of Oregon facility for help with this sequence demultiplexing dilemma, I contacted Epigentek to find out what the other adaptor sequence that is used in the EpiNext Post-Bisulfite DNA Library Preparation Kit (Illumina). I used grep and fastx_barcode_splitter to determine how many reads (if any) contained this adaptor sequence. All analysis was performed in the embedded Jupyter (IPython) notebook embedded below.\nNBviewer: 20150317_LSU_OilSpill_EpinextAdaptor1_ID.ipynb\n\n\nResults:\nThis adaptor sequence is not present in any of the reads in the FASTQ file analyzed."
  },
  {
    "objectID": "posts/2015/2015-07-01-opticon2-calibration/index.html",
    "href": "posts/2015/2015-07-01-opticon2-calibration/index.html",
    "title": "Opticon2 Calibration",
    "section": "",
    "text": "Jake and Steven recently noticed localized “hot spots” on most of Jake’s recent qPCRs, where higher levels of fluorescence were consistently showing up in interior portions of the plates than the outer portion of the plates.\nOrdered 5nmol of 6-FAM T10 Calibration Standard from Biosearch Technologies and resuspended it in 50μL of 1x dilution buffer (10mM Tris-HCl pH8.0, 50mM NaCl, 5mM MgCl2) to make a 100μM solution. Buffer and dye were stored @ -20C after use.\nBuffer calculations: Total Volume = 15mL\n\n1.5mL of 100mM Tris-HCl\n150μL of 5M NaCl\n750μL of 100mM MgCl2\n\nMade a working dilution of the 6-FAM dye of 300nM in 5mL of 1x dilution buffer (15uL of 100uM dye in 5mL of buffer).\nRan the calibration protocol on the Opticon2 (BioRad) using 50μL of dye in all wells when required by the calibration protocol.\nResults:\n\nEMPTY PLATE MEASUREMENTS\n[caption id=“” align=“alignnone” width=“438”](http://eagle.fish.washington.edu/Arabidopsis/20150630_qPCR_cal_empty_ch1.JPG) Empty Plate - Channel 1 voltage measurements[/caption]\n[caption id=“” align=“alignnone” width=“438”](http://eagle.fish.washington.edu/Arabidopsis/20150630_qPCR_cal_empty_ch2.JPG) Empty Plate - Channel 2 voltage measurements[/caption]\n[caption id=“” align=“alignnone” width=“438”](http://eagle.fish.washington.edu/Arabidopsis/20150630_qPCR_cal_empty_ch1_2.JPG) Empty Plate - Ratio of Channel 1 to Channel 2 voltage measurements.[/caption]\nThe empty plate measurements above show the expected low voltage measurements, but also show a  ~5-fold difference in min/max voltages in each channel. Additionally, the voltage ratios (the third image above) show a wavy pattern, but a smooth, even level from well-to-well is what would be expected if the Opticon was in measuring things properly.\nDYE PLATE MEASUREMENTS\n[caption id=“” align=“alignnone” width=“437”](http://eagle.fish.washington.edu/Arabidopsis/20150630_qPCR_cal_dye_ch1.JPG) Dye Measurements - Channel 1 voltage measurements[/caption]\n[caption id=“” align=“alignnone” width=“435”](http://eagle.fish.washington.edu/Arabidopsis/20150630_qPCR_cal_dye_ch2.JPG) Dye Measurements - Channel 2 voltage measurements[/caption]\n[caption id=“” align=“alignnone” width=“438”](http://eagle.fish.washington.edu/Arabidopsis/20150630_qPCR_cal_dye_ch1_2.JPG) Dye Measurements - Channel 1 to Channel 2 voltage measurement ratios.[/caption]\nThe voltages measured in each channel show the expected increase in voltages relative to the empty plate (> 10x voltage than empty plate). However, the spread between the min/max voltages in both channels is ~4-fold. Additionally, the ratio between the two channels still shows the wavy pattern across all the wells instead of the expected even ratio from well-to-well that should result from the calibration.\nIt appears the calibration has not resolved the issue.\nTo verify that calibration has failed, I ran two sets of qPCR “protocols” that simply read the dye plate to measure fluorescence across the plate in two plate orientations.\nOriginal Orientation Data File (TAD): 20150630_162622_calibration_test.tad 180 degree rotation Data File (TAD): 20150630_162622_calibration_test_180.tad\n[caption id=“” align=“alignnone” width=“647”](http://eagle.fish.washington.edu/Arabidopsis/20150630_qPCR_dye_reads.JPG) Dye Fluorescence - Original Orientation[/caption]\n[caption id=“” align=“alignnone” width=“648”](http://eagle.fish.washington.edu/Arabidopsis/20150630_qPCR_dye_reads2.JPG) Dye Fluorescence - Original Orientation with Fluorescence Graph[/caption]\n[caption id=“” align=“alignnone” width=“653”](http://eagle.fish.washington.edu/Arabidopsis/20150630_qPCR_dye_reads_180.JPG) Dye Fluorescence - 180 Degree Rotation[/caption]\n[caption id=“” align=“alignnone” width=“664”](http://eagle.fish.washington.edu/Arabidopsis/20150630_qPCR_dye_reads2_180.JPG) Dye Fluorescence - 180 Degree Rotation with Fluorescence Graph[/caption]\nFirst thing to notice is that there’s clearly uneven fluorescence detection across the plate. Viewing the images that also contain the fluorescence graphs reveals a spread of ~8-fold between the highest and lowest fluorescence detection.\nThe second thing to notice is that, despite rotating the plate 180 degrees, the rotation has no effect on the fluorescence detected in each block location.\nBoth of these taken together provide strong evidence that there’s an issue with the machine."
  },
  {
    "objectID": "posts/2015/2015-10-12-pcr-oly-rad-seq-test-scale-pcr-3/index.html",
    "href": "posts/2015/2015-10-12-pcr-oly-rad-seq-test-scale-pcr-3/index.html",
    "title": "PCR - Oly RAD-seq Test-scale PCR",
    "section": "",
    "text": "Continuing with the RAD-seq library prep. Following the Meyer Lab 2bRAD protocol.\nPrior to generating full-blown libraries, we needed to run a “test-scale” PCR to identify the minimum number of cycles needed to produce the intended product size (166bp).\nI ran PCR reactions on a subset (Sample #: 2, 3, & 4) of the 10 samples that I performed adaptor ligations on Friday.\nPCR reactions were set up on ice in 0.5mL PCR tubes.\n\n\n\n\n\nREAGENT\n\n\nSINGLE REACTION (μL)\n\n\nx4.4\n\n\n\n\nTemplate\n\n\n8\n\n\nNA\n\n\n\n\nNanoPure H2O\n\n\n1\n\n\n4.4\n\n\n\n\ndNTPs (1mM)\n\n\n4\n\n\n17.6\n\n\n\n\nILL-LIB1 (10μM)\n\n\n0.4\n\n\n1.76\n\n\n\n\nILL-LIB2 (10μM)\n\n\n0.4\n\n\n1.76\n\n\n\n\nILL-HT1 (1μM)\n\n\n1\n\n\n4.4\n\n\n\n\nILL-BC1 (1μM)\n\n\n1\n\n\n4.4\n\n\n\n\n5x Q5 Reaction Buffer\n\n\n4\n\n\n17.6\n\n\n\n\nQ5 DNA Polymerase\n\n\n0.2\n\n\n0.88\n\n\n\n\nTOTAL\n\n\n20\n\n\n52.8\n\n\n\n\n\nCombined 12μL of master mix with 8μL of the ligation reaction from earlier today.\nCycling was performed on a PTC-200 (MJ Research) with a heated lid:\n\n\n\n\n\nSTEP\n\n\nTEMP (C)\n\n\nTIME (s)\n\n\n\n\nInitial Denaturation\n\n\n\n98\n\n\n\n\n30\n\n\n\n\n\n27 cycles\n\n\n\n98\n60\n72\n\n\n\n\n5\n20\n10\n\n\n\n\n\n\nWe’re following the “1/4 reduced representation” aspect of the protocol. As such, 5μL of each reaction was pulled immediately after the extension (72C – machine was paused) of cycles 12, 17, 22, & 27 in order to determine the ideal number of cycles to use. Also ran the ligation reactions (labeled “Ligations” on the gel below) of the samples as a pre-PCR comparison. Treated them the same as the PCR reactions: mixed 8μL of the ligation with 12μL of H2O, used 5μL of that mix to load on gel.\nThese samples were run on a 1x modified TAE 2% agarose gel (w/EtBr).\nResults:\n(https://raw.githubusercontent.com/sr320/LabDocs/master/protocols/Commercial_Protocols/ThermoFisher_OgeneRuler_DNA_Ladder_Mix_F100439.jpg)\n[caption id=“” align=“alignnone” width=“698”](http://eagle.fish.washington.edu/Arabidopsis/20151012_RAD_test_scale_PCR.jpg) Test-scale PCR gel. Green arrow indicates desired band. The numbers below the headings indicate the sample number.[/caption]\nThis looks pretty good. The green arrow on the gel indicates the desired band size (~166bp). Although difficult to see on this gel image, there is a gradient in band intensities across the cycles (band intensity increases as cycle number increases). Looks like we can use 12 cycles for our PCRs.\nOne other aspect of this gel that is very interesting is the ligations. The three ligation samples all show an intact high molecular weight band! This is very surprising, since the input gDNA from these three samples does not look this."
  },
  {
    "objectID": "posts/2015/2015-04-24-bioanalyzer-data-geoduck-rna-from-histology-blocks/index.html",
    "href": "posts/2015/2015-04-24-bioanalyzer-data-geoduck-rna-from-histology-blocks/index.html",
    "title": "Bioanalyzer Data - Geoduck RNA from Histology Blocks",
    "section": "",
    "text": "I received the Bioanalyzer data back for the geoduck foot RNA samples I submitted 20150422. The two samples were run on the RNA Pico chip assay.\nResults:\nBioanalzyer 2100 Data File (XAD): SamWhite_Eukaryote Total RNA Pico_2015-04-23_13-04-16.xad\nData file requires 2100_Expert_B0208_SI648_SR2 version of the software (Windows).\n\nGel Representation\n(http://eagle.fish.washington.edu/Arabidopsis/Bioanalyzer%20Data/20150423_pico_bioanlayzer_geoduck_gel.jpg)\n\n\nElectropherogram\n(http://eagle.fish.washington.edu/Arabidopsis/Bioanalyzer%20Data/20150423_pico_bioanlayzer_geoduck_electropherogram.jpg)\nThe samples look really good! As we’ve seen previously in shellfish RNA, there is a single, prominent rRNA band/peak with very little degradation (smearing and/or no prominent peak/band).\nWill proceed with RNA isolation from the remaining histology blocks."
  },
  {
    "objectID": "posts/2015/2015-11-22-ethanol-precipitation-olympia-oyster-mbd/index.html",
    "href": "posts/2015/2015-11-22-ethanol-precipitation-olympia-oyster-mbd/index.html",
    "title": "Ethanol Precipitation - Olympia oyster MBD",
    "section": "",
    "text": "Precipitated the MBD enriched DNA from yesterday according to the MethylMiner Methylated DNA Enrichment Kit (Invitrogen) protocol.\nHowever, since the protocol has two elution steps that are each saved separately from each other for each sample, I did the following to combine the two elution fractions into a single sample:\n\nPelleted one elution fraction from each sample\nDiscarded supernatant from pelleted sample\nTransferred second elution fraction to the pellet from the first elution fraction\nPelleted second elution fraction\n\nThe rest of the ethanol precipitation procedure was followed per the manufacturer’s protocol.\nFinal pellets were resuspended in 25μL of Buffer EB (Qiagen) and stored @ 4C.\nMBD enriched DNA will be quantified tomorrow."
  },
  {
    "objectID": "posts/2015/2015-07-11-rna-isolation-o-lurida-ctenidia-1hr-post-mechanical-stress/index.html",
    "href": "posts/2015/2015-07-11-rna-isolation-o-lurida-ctenidia-1hr-post-mechanical-stress/index.html",
    "title": "RNA Isolation - O.lurida Ctenidia 1hr Post-Mechanical Stress",
    "section": "",
    "text": "Isolated RNA from [Jake’s Ostrea lurida ctenidia samples that had been subjected to mechanical stress (from 20150422)(https://heareresearch.blogspot.com/2015/04/4-22-2015-heatmechanical-shock.html).\nDespite the indication in this notebook, the samples had not been previously homogenized in RNAzol RT. I thawed the samples, homogenized them and followed the RNAzol RT protocol for total RNA isolation. Here’s the list of samples:\n\n42215 NM1 1\n42215 NM1 2\n42215 NM1 3\n42215 NM1 4\n42215 NM1 5\n42215 NM1 6\n42215 NM1 7\n42215 NM1 8\n\nRNA was resuspended in 50μL of 0.1%DEPC-H2O and stored @ -80C in the original box they came from."
  },
  {
    "objectID": "posts/2015/2015-10-03-dna-isolation-geoduck-olympia-oyster/index.html",
    "href": "posts/2015/2015-10-03-dna-isolation-geoduck-olympia-oyster/index.html",
    "title": "DNA Isolation - Geoduck & Olympia Oyster",
    "section": "",
    "text": "Amazingly, we need more gDNA for the two genome sequencing projects (geoduck and Olympia oyster). Used geoduck “foot 1” sample from Box 1 of the foot samples collected by Brent & Steven on 20150811. Used Olympia oyster adductor muscle from Box 1 of adductor muscle sample collected by Brent & Steven on 20150812.\nAlso need to evaluate DNA quality of initial broodstock samples from Jake’s Olympia oyster reciprocal transplant experiment. Used mantle samples stored in EtOH collected by Hannah (see her notebook entries on July 25 & Sept 5, 2013)\nTissue weights:\n\nGeoduck foot: 108.5mg (gone)\nOlympia oyster adductor: 258.7mg (gone)\nOly NF1A: 7.1mg (gone)\nOly SN49A: 20.8mg\n\nSamples were isolated using DNAzol (Molecular Research Center) according to the manufacturer’s protocol, with the following adjustments:\n\nTissues homogenized in 750μL of DNAzol with disposable mortar/pestle tubes using 10 pestle strokes\nAfter homogenization, topped off tubes to 960μL with DNAzol, added 40μL RNAse A (100mg/mL) and incubated @ RT for 15mins.\nPerformed optional centrifugation step (10,000g, 10mins @ RT)\nInitial pellet wash was performed using a 70%/30% DNAzol/EtOH\nPellets were resuspended Buffer EB (Qiagen)\nInsoluble material was pelleted (12,000g, 10mins @ RT) and supe transferred to new tubes\n\nGenome sequencing resuspension volumes: 50μL\nOly reciprocoal resuspension volumes: 25μL\nSpec’d on Roberts Lab NanoDrop1000.\nResults:\n(http://eagle.fish.washington.edu/Arabidopsis/20151002_gDNA_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20151002_gDNA_plots.JPG)\n\nGenome Sequencing Samples\nThe 260/280 ratios look fine. The 260/230 ratios look poor, as is usually the case after DNAzol isolations.\nYields:\nGeoduck: 7.6μg\nOly: 16.5μg\nThe geoduck yield is insufficient to make up the quantity of gDNA still needed by BGI for sequencing. Will have to isolate more gDNA on Monday.\n\n\nReciprocal Transplant Samples\nThe 260/280 ratios look fine. The 260/230 ratios look poor, as is usually the case after DNAzol isolations.\nYields:\nNF1A: 7,1μg\nSN49A: 1.375μg\nThe yields are surprisingly good! Next up is to evaluate the gDNA quality on a gel to see if the samples from this experiment will be usable."
  },
  {
    "objectID": "posts/2015/2015-04-13-sequence-data-c-gigas-oa-larvae-bs-seq-demultiplexed/index.html",
    "href": "posts/2015/2015-04-13-sequence-data-c-gigas-oa-larvae-bs-seq-demultiplexed/index.html",
    "title": "Sequence Data - C.gigas OA Larvae BS-Seq Demultiplexed",
    "section": "",
    "text": "I had previously contacted Doug Turnbull at the Univ. of Oregon Genomics Core Facility for help demultiplexing this data, as it was initially returned to us as a single data set with “no index” (i.e. barcode) set for any of the libraries that were sequenced. As it turns out, when multiplexed libraries are sequenced using the Illumina platform, an index read step needs to be “enabled” on the machine for sequencing. Otherwise, the machine does not perform the index read step (since it wouldn’t be necessary for a single library). Surprisingly, the sample submission form for the Univ. of Oregon Genomics Core Facility  doesn’t request any information regarding whether or not a submitted sample has been multiplexed. However, by default, they enable the index read step on all sequencing runs. I provided them with the barcodes and they demultiplexed them after the fact.\nI downloaded the new, demultiplexed files to Owl/nightingales/C_gigas:\nlane2_CTTGTA_L002_R1_001.fastq.gz lane2_CTTGTA_L002_R1_002.fastq.gz lane2_CTTGTA_L002_R1_003.fastq.gz lane2_CTTGTA_L002_R1_004.fastq.gz lane2_GCCAAT_L002_R1_001.fastq.gz lane2_GCCAAT_L002_R1_002.fastq.gz lane2_GCCAAT_L002_R1_003.fastq.gz lane2_GCCAAT_L002_R1_004.fastq.gz lane2_GCCAAT_L002_R1_005.fastq.gz lane2_GCCAAT_L002_R1_006.fastq.gz\nNotice that the file names now contain the corresponding index!\nRenamed the files, to append the order number to the beginning of the file names:\n$for file in lane2*; do mv \"$file\" \"2212_$file\"; done\nNew file names:\n2212_lane2_CTTGTA_L002_R1_001.fastq.gz 2212_lane2_CTTGTA_L002_R1_002.fastq.gz 2212_lane2_CTTGTA_L002_R1_003.fastq.gz 2212_lane2_CTTGTA_L002_R1_004.fastq.gz 2212_lane2_GCCAAT_L002_R1_001.fastq.gz 2212_lane2_GCCAAT_L002_R1_002.fastq.gz 2212_lane2_GCCAAT_L002_R1_003.fastq.gz 2212_lane2_GCCAAT_L002_R1_004.fastq.gz 2212_lane2_GCCAAT_L002_R1_005.fastq.gz 2212_lane2_GCCAAT_L002_R1_006.fastq.gz\nUpdated the checksums.md5 file to include the new files (the command is written to exclude the previously downloaded files that are named “2212_lane2_NoIndex_”; the [^N] regex excludes any files that have a capital ‘N’ at that position in the file name):\n$for file in 2212_lane2_[^N]*; do md5 \"$file\" >> checksums.md5; done\nUpdated the readme.md file to reflect the addition of these new files."
  },
  {
    "objectID": "posts/2015/2015-06-12-sample-submission-olympia-oyster-pcrs-sanger-sequencing/index.html",
    "href": "posts/2015/2015-06-12-sample-submission-olympia-oyster-pcrs-sanger-sequencing/index.html",
    "title": "Sample Submission - Olympia oyster PCRs Sanger Sequencing",
    "section": "",
    "text": "Submitted a plate of purified PCR products (PCR products prepared by Jake on 20150609 and 20150610) that Jake set up yesterday, to the UW High-Throughput Genomics Center for Sanger sequencing.\nPlate layout is here (Google Sheet): sequence_log\nOrder #:112381"
  },
  {
    "objectID": "posts/2015/2015-09-15-agarose-gel-geoduck-olympia-oyster-gdna-integrity-check-2/index.html",
    "href": "posts/2015/2015-09-15-agarose-gel-geoduck-olympia-oyster-gdna-integrity-check-2/index.html",
    "title": "Agarose Gel - Geoduck & Olympia Oyster gDNA Integrity Check",
    "section": "",
    "text": "Ran 0.8% agarose 1x modified TAE gel stained with EtBr to assess the integrity of geoduck gDNA and Olympia oyster gDNA isolated yesterday.\nRan ~500ng of each sample:\nGeoduck adductor muscle 1: 4.4μL\nGeoduck adductor muscle 2: 20μL (355ng)\nGeoduck foot 1: 20μL\nGeoduckk foot 2: 6.9μL\nOly adductor muscle: 5.5μL\nOly mantle: 3.05μL\nResults:\n(https://raw.githubusercontent.com/sr320/LabDocs/master/protocols/Commercial_Protocols/ThermoFisher_OgeneRuler_DNA_Ladder_Mix_F100439.jpg)\nThe gel is loaded in the order listed above (going left to right on the gel).\nAll samples look really good with prominent high molecular weight bands and little smearing.\nCurrent total approximate yields from all extractions from both species are as follows:\nGeoduck: 49.8μg\nOlympia oyster: 54.1μg\nStill need ~25μg of each species to have sufficient quantities for sequencing."
  },
  {
    "objectID": "posts/2015/2015-05-14-dnase-treatment-jakes-o-lurida-ctenidia-rna-controls-from-20150507/index.html",
    "href": "posts/2015/2015-05-14-dnase-treatment-jakes-o-lurida-ctenidia-rna-controls-from-20150507/index.html",
    "title": "DNase Treatment - Jake’s O.lurida Ctenidia RNA (Controls) from 20150507",
    "section": "",
    "text": "Since the O.lurida RNA I isolated on 20150507 showed residual gDNA via qPCR, I treated 5μg of RNA from each sample using the Turbo DNA-free Kit (Ambion/Life Technologies), following the “rigorous” protocol.\nBriefly:\n\n50μL reactions were carried out in 0.5mL tubes\nadded 1μL of DNase to each tube\nincubated 30mins @ 37C\nadded additional 1μL of DNased\nincubated 30mins @ 37C\nadded 0.2 vols (10.2μL) of DNase Inactivation Reagent\nincubated and mixed for 2mins @ RT\ntransferred 50μL of supe to sterile 1.5mL snap cap tubes\nspec’d on Roberts Lab NanoDrop1000\n\nSamples were stored @ -80C in Shellfish RNA Box #5 and Box #6.\nDNase reaction calcs: 20150514_Jake_Oly_control_DNase_calcs\nResults:\nGoogle Spreadsheet: 20150514_DNased_RNA_Jake_Oly_controls_ODs\n(http://eagle.fish.washington.edu/Arabidopsis/20150514_DNased_RNA_Jake_oly_controls_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150514_DNased_RNA_Jake_oly_controls_plots_01.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150514_DNased_RNA_Jake_oly_controls_plots_02.JPG)\nOverall, samples look fine. Will check for residual gDNA via qPCR."
  },
  {
    "objectID": "posts/2015/2015-11-25-dna-quality-assessment-geoduck-olympia-oyster-gdna/index.html",
    "href": "posts/2015/2015-11-25-dna-quality-assessment-geoduck-olympia-oyster-gdna/index.html",
    "title": "DNA Quality Assessment - Geoduck & Olympia Oyster gDNA",
    "section": "",
    "text": "Have three separate sets of geoduck & olympia oyster gDNA that need to be run on gels before sending to BGI for genome sequencing:\nGEODUCK\n\nPhenol-chloroform cleanup from 20151124\nMollusc kit extraction from 20151124\nDNAzol isolation from earlier today\n\nOLYMPIA OYSTER\n\nPhenol-chloroform cleanup from 20151124\nMollusc kit extraction from 20151124\nDNAzol isolation from earlier today\n\nRan 100ng of each sample on a 0.8% agarose 1x modified TAE gel w/EtBr.\nResults:\n(https://raw.githubusercontent.com/sr320/LabDocs/master/protocols/Commercial_Protocols/ThermoFisher_OgeneRuler_DNA_Ladder_Mix_F100439.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/20151125_gel_gDNA_geoduck_oly.jpg)\nAll the samples from both sets appear to be overloaded. Overloading is generally seen as the streaking seen immediately above each band.\nGEODUCK\nOverall, the samples look pretty good. Sadly, the worst of the three (due to the most smearing - i.e. degradation) appears to be the DNA extracted using the E.Z.N.A. Mollusc Kit (Omega BioTek).\nAlso of note are the two bands present in the DNAzol sample. These bands are likely ribosomal RNA because I neglected to perform a RNase treatment during the extraction. Doh!\nOLYMPIA OYSTER\nNone of them are particularly great. Just like the geoduck set, the worst of the three came from the E.Z.N.A Mollusc Kit (Omega BioTek).\nAlso, just like the geoduck set, there are two bands present in the DNAzol sample. These bands are likely ribosomal RNA because I neglected to perform a RNase treatment during the extraction. Doh!\nThe phenol-chloroform clean up sample is either jacked up or severely overloaded, based on the crazy streaking that’s present. However, this sample looked similar after the initial extraction on 20151113.\nI will send these samples separately (i.e. will not pool them into single samples) to BGI to run QC and, hopefully, add them to the DNA they already have to complete the genome sequencing for these two projects."
  },
  {
    "objectID": "posts/2015/2015-12-19-bioanalyzer-bisulfite-treated-olyc-gigas-dna/index.html",
    "href": "posts/2015/2015-12-19-bioanalyzer-bisulfite-treated-olyc-gigas-dna/index.html",
    "title": "Bioanalyzer - Bisulfite-treated Oly/C.gigas DNA",
    "section": "",
    "text": "Following the guidelines of the [TruSeq DNA Methylation Library Prep Guide (Illumina)(https://github.com/sr320/LabDocs/blob/master/protocols/Commercial_Protocols/Illumina_truseq-dna-methylation-library-prep-guide-15066014-a.pdf), I ran 1μL of each sample on an RNA Pico 6000 chip on the Seeb Lab’s Bioanalyzer 2100 (Agilent) to confirm that bisulfite conversion from earlier today worked.\nResults:\nData File 1(Bioanlyzer 2100): 2100 expert_Eukaryote Total RNA Pico_DE72902486_2015-12-18_21-05-04.xad\nData File 1(Bioanlyzer 2100): 2100 expert_Eukaryote Total RNA Pico_DE72902486_2015-12-18_21-42-55.xad\n(http://eagle.fish.washington.edu/Arabidopsis/20151218_bioanalyzer_RNApico_oly_bisulfite_01.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/20151218_bioanalyzer_RNApico_oly_bisulfite_02.jpg)\nFirstly, the ladder failed to produce any peaks. Not sure why this happened. Possibly not denatured? Seems unlikely, but next time I run the Pico assay, I’ll denature the ladder aliquot I use prior to running.\nOverall, the samples look as they should (see image from TruSeq DNA Methylation Kit manual below), albeit some are a bit lumpy.\n(http://eagle.fish.washington.edu/Arabidopsis/20151218_bioanalyzer_illumina_bisulfite.jpg)"
  },
  {
    "objectID": "posts/2015/2015-10-01-pcr-oly-rad-seq-test-scale-pcr/index.html",
    "href": "posts/2015/2015-10-01-pcr-oly-rad-seq-test-scale-pcr/index.html",
    "title": "PCR - Oly RAD-seq Test-scale PCR",
    "section": "",
    "text": "Continuing with the RAD-seq library prep. Following the Meyer Lab 2bRAD protocol.\nPrior to generating full-blown libraries, we need to run a “test-scale” PCR to identify the minimum number of cycles needed to produce the intended product size (166bp).\nI ran PCR reactions on a subset (Sample #: 4, 7, 14, & 30) of the 10 samples that I performed adaptor ligations on earlier today.\nAll components were stored on ice.\ndNTPs - 1mM working stock was made\n\n10μL dNTPs (10mM)\n90μL NanoPure H2O\n\nILL-LIB1 & 2 - 10μM working stocks were made\n\n10μL ILL-LIB1 or -LIB2 (100μM)\n90μL NanoPure H2O\n\nILL-HT1 & 2 - 1μM working stocks were made\n\n1μL ILL-HT1 or -HT2 (100μM)\n99μL NanoPure H2O\n\nILL-BC1 - 1μM working stock was made\n\n1μL ILL-BC1 (100μM)\n99μL NanoPure H2O\n\nPCR reactions were set up on ice in 0.5mL PCR tubes.\n\n\n\n\n\nREAGENT\n\n\nSINGLE REACTION (μL)\n\n\nx4.4\n\n\n\n\nTemplate\n\n\n8\n\n\nNA\n\n\n\n\nNanoPure H2O\n\n\n1\n\n\n4.4\n\n\n\n\ndNTPs (1mM)\n\n\n4\n\n\n17.6\n\n\n\n\nILL-LIB1 (10μM)\n\n\n0.4\n\n\n1.76\n\n\n\n\nILL-LIB2 (10μM)\n\n\n0.4\n\n\n1.76\n\n\n\n\nILL-HT1 (1μM)\n\n\n1\n\n\n4.4\n\n\n\n\nILL-BC1 (1μM)\n\n\n1\n\n\n4.4\n\n\n\n\n5x Q5 Reaction Buffer\n\n\n4\n\n\n17.6\n\n\n\n\nQ5 DNA Polymerase\n\n\n0.2\n\n\n0.88\n\n\n\n\nTOTAL\n\n\n20\n\n\n52.8\n\n\n\n\n\nCombined 12μL of master mix with 8μL of the ligation reaction from earlier today.\nCycling was performed on a PTC-200 (MJ Research) with a heated lid:\n\n\n\n\n\nSTEP\n\n\nTEMP (C)\n\n\nTIME (s)\n\n\n\n\nInitial Denaturation\n\n\n\n98\n\n\n\n\n30\n\n\n\n\n\n27 cycles\n\n\n\n98\n60\n72\n\n\n\n\n5\n20\n10\n\n\n\n\n\n\nWe’re following the “1/4 reduced representation” aspect of the protocol. As such, 5μL of each reaction was pulled immediately after the extension (72C - machine was paused) of cycles 12, 17, 22, & 27 in order to determine the ideal number of cycles to use. Also ran the ligation reactions (labelled “Digests” on the gel below) of two samples (samples #: 4 & 7) as a pre-PCR comparison.\nThese samples were run on a 1x modified TAE 2% agarose gel (w/EtBr).\nResults:\n(https://raw.githubusercontent.com/sr320/LabDocs/master/protocols/Commercial_Protocols/ThermoFisher_OgeneRuler_DNA_Ladder_Mix_F100439.jpg)\nThe results aren’t great. No band(s) visible in any samples at even the highest cycle number (27 cycles). Although, if you squint pretty hard, an extremely faint band might be visible in between the 100/200bp markers in the 27 cycles group.\nRegardless, the PCRs will need to be repeated with an increased number of cycles. This is not terribly surprising, as the Meyer Lab protocol indicates that degraded samples will likely need a greater number of cycles than what they recommend and that cycle number will have to be determined empirically."
  },
  {
    "objectID": "posts/2015/2015-05-08-rna-isolation-geoduck-gonad-in-paraffin-histology-blocks-4/index.html",
    "href": "posts/2015/2015-05-08-rna-isolation-geoduck-gonad-in-paraffin-histology-blocks-4/index.html",
    "title": "RNA Isolation – Geoduck Gonad in Paraffin Histology Blocks",
    "section": "",
    "text": "UPDATE 20150528: The RNA isolated in this notebook entry may have been consolidated on 20150528.\nThe RNA isolation I performed earlier this week proved to be better for some of the samples (scraping tissue directly from the blocks), but still exhibited low yields from some samples. I will perform a final RNA isolation attempt (the kit only has six columns left) from the following samples:\n\n02\n03\n04\n07\n08\n09\n\nInstead of full sections from each histology cassette, I gouged samples directly from the tissue in each of the blocks to maximize the amount of tissue input.\nIMPORTANT:\n\nUsed Buffer TR1 + β-mercaptoethanol (β-ME) prepared 201500505 as well as fresh Buffer TR1 + β-ME prepared today.\nI used aliquots of DNase prepared on 20150408.\n\nSamples were then processed with the PAXgene Tissue RNA Kit in a single group.\nIsolated RNA according to the PAXgene Tissue RNA Kit protocol with the following alterations:\n\n“Max speed” spins were performed at 19,000g.\nTissue disruption was performed with the Disruptor Genie @ 45C for 15mins.\nShaking incubation step was performed with Disruptor Genie\nSamples were eluted with 40μL of Buffer TR4, incubated @ 65C for 5mins, immediately placed on ice and quantified on the Roberts Lab NanoDrop1000.\n\nAll samples were stored @ -80C in Shellfish RNA Box #5.\nResults:\n(http://eagle.fish.washington.edu/Arabidopsis/20150508_geoduck_histo_RNA_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150508_geoduck_histo_RNA_plots.JPG)\nTwo samples (02 and 07) produced great yields and perfect RNA (260/280 and 260/230 of ~2.0). The remainder of the samples showed little improvement compared to what I’ve been obtaining from the previous three attempts. Will discuss with Steven and Brent about how to proceed with this project."
  },
  {
    "objectID": "posts/2015/2015-03-20-sequencing-data-c-gigas-larvae-oa/index.html",
    "href": "posts/2015/2015-03-20-sequencing-data-c-gigas-larvae-oa/index.html",
    "title": "Sequencing Data - C.gigas Larvae OA",
    "section": "",
    "text": "Our sequencing data (Illumina HiSeq2500, 100SE) for this project has completed by Univ. of Oregon Genomics Core Facility (order number 2212).\nSamples sequenced/pooled for this run:\n\n\n\n\n\nSample\n\n\nTreatment\n\n\nBarcode\n\n\n\n\n400ppm\n\n\n400ppm\n\n\nGCCAAT\n\n\n\n\n1000ppm\n\n\n1000ppm\n\n\nCTTGTA\n\n\n\n\n\nAll code listed below was run on OS X 10.9.5\nRan a bash script called “download.sh” to download all the files. The script contents were:\n#!/bin/bash curl -O https://gcf.uoregon.edu:8080/job/download/2212?fileName=lane2_NoIndex_L002_R1_001.fastq.gz curl -O https://gcf.uoregon.edu:8080/job/download/2212?fileName=lane2_NoIndex_L002_R1_002.fastq.gz curl -O https://gcf.uoregon.edu:8080/job/download/2212?fileName=lane2_NoIndex_L002_R1_003.fastq.gz curl -O https://gcf.uoregon.edu:8080/job/download/2212?fileName=lane2_NoIndex_L002_R1_004.fastq.gz curl -O https://gcf.uoregon.edu:8080/job/download/2212?fileName=lane2_NoIndex_L002_R1_005.fastq.gz curl -O https://gcf.uoregon.edu:8080/job/download/2212?fileName=lane2_NoIndex_L002_R1_006.fastq.gz curl -O https://gcf.uoregon.edu:8080/job/download/2212?fileName=lane2_NoIndex_L002_R1_007.fastq.gz curl -O https://gcf.uoregon.edu:8080/job/download/2212?fileName=lane2_NoIndex_L002_R1_008.fastq.gz curl -O https://gcf.uoregon.edu:8080/job/download/2212?fileName=lane2_NoIndex_L002_R1_009.fastq.gz curl -O https://gcf.uoregon.edu:8080/job/download/2212?fileName=lane2_NoIndex_L002_R1_010.fastq.gz curl -O https://gcf.uoregon.edu:8080/job/download/2212?fileName=lane2_NoIndex_L002_R1_011.fastq.gz curl -O https://gcf.uoregon.edu:8080/job/download/2212?fileName=lane2_NoIndex_L002_R1_012.fastq.gz\nDownloaded all 12 fastq.gz files to Owl/web/nightingales/C_gigas\nRenamed all files by removing the beginning of each file name (2112?fileName=) and replacing that with 2212_:\n$for file in 2212*lane2_NoIndex_L002_R1_0*; do mv \"$file\" \"${file/#2212?fileName=/2212_}\"; done\nCreated a directory readme.md (markdown) file to list & describe directory contents: readme.md\n$ls *.gz >> readme.md\nNote: In order for the readme file to appear in the web directory listing, the file cannot be all upper-case.\nCreate MD5 checksums for each the files: checkums.md5\n$md5 2212* >> checksums.md5"
  },
  {
    "objectID": "posts/2015/2015-01-28-bisuflite-ngs-library-prep-c-gigas-larvae-oa-bisulfite-dna-continued-from-yesterday/index.html",
    "href": "posts/2015/2015-01-28-bisuflite-ngs-library-prep-c-gigas-larvae-oa-bisulfite-dna-continued-from-yesterday/index.html",
    "title": "Bisuflite NGS Library Prep - C.gigas larvae OA bisulfite DNA (continued from yesterday)",
    "section": "",
    "text": "Continued Illumina library prep of bisulfite-treated DNA samples (400ppm and 1000ppm; from [20150114)(2015/01/14/dna-bisulfite-conversion-c-gigas-larvae-oa-sheared-dna.html)  with Methylamp DNA Modification Kit (Epigentek). Performed bead clean up immediately after End Repair.\nPCR cycles: 14\nNo other changes were made to the manufacturer’s protocol.\nEpigentek Barcode Indices assigned, per their recommendations for using two libraries for multiplexing:\n400ppm - barcode #6 - GCCAAT\n1000ppm - barcode #12 - CTTGTA\nThe two libraries were stored @ -20C and will be quantified tomorrow."
  },
  {
    "objectID": "posts/2015/2015-08-29-genomic-dna-isolation-geoduck-adductor-muscle-foot/index.html",
    "href": "posts/2015/2015-08-29-genomic-dna-isolation-geoduck-adductor-muscle-foot/index.html",
    "title": "Genomic DNA Isolation - Geoduck Adductor Muscle & Foot",
    "section": "",
    "text": "Isolated gDNA from Panopea generosa (geoduck) adductor muscle & foot samples collected by Brent & Steven on 20150811 using the E.Z.N.A Mollusc DNA Kit (Omega Bio-Tek) according to the manufacturer’s protocol, with the following adjustments:\n\n41.8mg of adductor muscle\n30.0mg of foot used\nTissues homogenized in 350μL of ML1 Buffer with disposable mortar/pestle tubes using only three pestles strokes\nHomogenized tissue incubated in ML1 Buffer + Proteinase K @ 60C for 2.5hrs\nAdded 265μL of MBL Buffer\nAdded 514μL of 100% EtOH.\nEluted with 75μL Elution Buffer.\n\nSpec’d on Roberts Lab NanoDrop1000 (ThermoFisher) and stored temporarily at 4C to avoid freeze-thawing before sending off for sequencing next week.\nResults:\n(http://eagle.fish.washington.edu/Arabidopsis/20150828_geoduck_gDNA_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150828_geoduck_gDNA_plots.JPG)\nYields are good (~7ug).\nQuality (260/280 ratios) looks great for both samples.\n260/230 ratio not very good for adductor muscle, but perfect for foot tissue.\nWill run samples on gel to assess gDNA integrity."
  },
  {
    "objectID": "posts/2015/2015-08-06-reverse-transcription-o-lurida-dnased-rna-1hr-post-mechanical-stress/index.html",
    "href": "posts/2015/2015-08-06-reverse-transcription-o-lurida-dnased-rna-1hr-post-mechanical-stress/index.html",
    "title": "Reverse Transcription – O.lurida DNased RNA 1hr post-mechanical stress",
    "section": "",
    "text": "Performed reverse transcription on the Olympia oyster DNased RNA from the 1hr post-mechanical stress samples from Jake’s project. To accommodate the large numbers of anticipated genes to be targeted in subsequent qPCRs, I prepared 100μL reactions (normally, 25μL reactions are prepared) using 250ng of each DNased RNA. A 1:10 dilution of the oligo dT primers (Promega) was prepared to improve pipetting accuracy. All incubations were performed in a thermal cycler without using a heated lid.\nDNased RNA was combined with NanoPure H2O and oligo dT primers in 24 wells of a PCR plate, heated @ 70C for 10mins and immediately placed on ice. After 5mins, the plate was spun 2000g @ RT for 2mins and returned to ice.\n25.25μL of a master mix containing 5x M-MLV Buffer (Promega), dNTPs (10mM each; Promega), and M-MLV Reverse Transcriptase (50U/rxn; Promega) was distributed to each well and mixed via pipetting. The plate was heated @ 42C for 1hr, 95C for 3mins. The plate was spun 2000g @ RT for 2mins and then stored @ -20C.\nPlate layout and all calculations can be found here (Google Sheet): 20150806_Jake_oly_mech_stress_cDNA_calcs"
  },
  {
    "objectID": "posts/2015/2015-04-16-quality-trimming-lsu-c-virginica-oil-spill-mbd-bs-seq-data/index.html",
    "href": "posts/2015/2015-04-16-quality-trimming-lsu-c-virginica-oil-spill-mbd-bs-seq-data/index.html",
    "title": "Quality Trimming - LSU C.virginica Oil Spill MBD BS-Seq Data",
    "section": "",
    "text": "Jupyter (IPython) Notebook: 20150414_C_virginica_LSU_Oil_Spill_Trimmomatic_FASTQC.ipynb\nNBviewer: 20150414_C_virginica_LSU_Oil_Spill_Trimmomatic_FASTQC.ipynb\n\n\n\nTrimmed FASTQC\n\nNB3 No oil Index - ACAGTG\n20150414_trimmed_2112_lane1_ACAGTG_L001_R1_001_fastqc.html 20150414_trimmed_2112_lane1_ACAGTG_L001_R1_002_fastqc.html\n\n\n\n\n\nNB6 No oil Index - GCCAAT\n20150414_trimmed_2112_lane1_GCCAAT_L001_R1_001_fastqc.html 20150414_trimmed_2112_lane1_GCCAAT_L001_R1_002_fastqc.html\n\n\n\n\n\nNB11 No oil Index - CAGATC\n20150414_trimmed_2112_lane1_CAGATC_L001_R1_001_fastqc.html 20150414_trimmed_2112_lane1_CAGATC_L001_R1_002_fastqc.html 20150414_trimmed_2112_lane1_CAGATC_L001_R1_003_fastqc.html\n\n\n\n\n\nHB2 25,000ppm oil Index - ATCACG\n20150414_trimmed_2112_lane1_ATCACG_L001_R1_001_fastqc.html 20150414_trimmed_2112_lane1_ATCACG_L001_R1_002_fastqc.html 20150414_trimmed_2112_lane1_ATCACG_L001_R1_003_fastqc.html\n\n\n\n\n\nHB16 25,000ppm oil Index - TTAGGC\n20150414_trimmed_2112_lane1_TTAGGC_L001_R1_001_fastqc.html 20150414_trimmed_2112_lane1_TTAGGC_L001_R1_002_fastqc.html\n\n\n\n\n\nHB30 25,000ppm oil Index - TGACCA\n20150414_trimmed_2112_lane1_TGACCA_L001_R1_001_fastqc.html"
  },
  {
    "objectID": "posts/2015/2015-10-09-adaptor-ligation-oly-alfi-digested-gdna-for-rad-seq-2/index.html",
    "href": "posts/2015/2015-10-09-adaptor-ligation-oly-alfi-digested-gdna-for-rad-seq-2/index.html",
    "title": "Adaptor Ligation – Oly AlfI-Digested gDNA for RAD-seq",
    "section": "",
    "text": "Continued to follow the 2bRAD protocol (PDF) developed by Eli Meyer’s lab.\nDigested DNA from earlier today was not run out on a gel due to the fact that the input gDNA was degraded and a shift in the high molecular weight band (indicating the digestion was successful) would not exist because a high molecular weight band is absent in these samples.\n\nAnneal Adaptors\nAfter preparing the two adaptors below, they were incubated for 10mins @ RT:\n\nAdaptor 1 (2μM final concentration of each oligo): 1.5μL of 5ILL-NR (100μM) + 1.5μL of anti-ILL (100μM) + 72μL H2O = 75μL total\nAdaptor 2 (2μM final concentration of each oligo): 1.5μL of 3ILL-NR (100μM) + 1.5μL of anti-ILL (100μM) + 72μL H2O = 75μL total\n\nAfter annealing, the adaptors were stored on ice.\n\n\nAdaptor Ligation\nAll components were stored on ice. Ligation reactions were prepared on ice and performed in 0.5mL snap cap tubes.\n\n\n\n\n\nREAGENT\n\n\nSINGLE REACTION (μL)\n\n\nx11\n\n\n\n\nDigested DNA\n\n\n10\n\n\nNA\n\n\n\n\nATP (10mM)\n\n\n1\n\n\n11\n\n\n\n\n10x T4 Ligase Buffer\n\n\n4\n\n\n44\n\n\n\n\nAdaptor 1 (2μM)\n\n\n5\n\n\n55\n\n\n\n\nAdaptor 2 (2μM)\n\n\n5\n\n\n55\n\n\n\n\nT4 DNA Ligase\n\n\n1\n\n\n11\n\n\n\n\nNanoPure H2O\n\n\n24\n\n\n264\n\n\n\n\nTOTAL\n\n\n50\n\n\n440\n\n\n\n\n\nCombined 40μL of the master mix with 10μL of AlfI-digested DNA in a 0.5mL snap cap tube.\nIncubated ligation reaction @ 16C for 3hrs in PTC-200 thermal cycler (MJ Research) – no heated lid.\nLigations were stored @ -20C until I can continue working with them on Monday."
  },
  {
    "objectID": "posts/2015/2015-05-14-iso-creation-opticonmonitor3-disc-cloning/index.html",
    "href": "posts/2015/2015-05-14-iso-creation-opticonmonitor3-disc-cloning/index.html",
    "title": "ISO Creation - OpticonMonitor3 Disc Cloning",
    "section": "",
    "text": "Since many newer computers are coming without optical disc drives (including my laptop, which I want to install this software on), I created an .iso disc image of the OpticonMonitor3 (BioRad) installation disc.\nUsing OS X Disk Utility:\n\nFile > New Disk Image\nDropdown > CD/DVD Master\n\nThis creates a Mac-specific .cdr image of the installation CD. Converted to a universal .iso disc image with the following command line:\n$hdiutil makehybrid -iso -joliet -o [filename].iso [filename].cdr\nReplaced [filename] with OpticonMonitor3.\nMoved the newly created OpticonMonitor3.iso file to our server (Eagle/Backup/Software/Windows).\nNow the .iso file should be able to be mounted and installed on any Windows computer without the need for a physical installation CD."
  },
  {
    "objectID": "posts/2015/2015-02-27-dna-quantification-c-gigas-larvae-1000ppm/index.html",
    "href": "posts/2015/2015-02-27-dna-quantification-c-gigas-larvae-1000ppm/index.html",
    "title": "DNA Quantification - C.gigas Larvae 1000ppm",
    "section": "",
    "text": "After the discovery that there wasn’t any DNA in the BS-seq Illumina library prep and no DNA in the bisulfite-treated DNA pool, I decided to try to recover any residual DNA left in the 1B2 sample. Sample 1B2 (sheared on 20150109) was dry, so I added 20μL of Buffer EB (Qiagen) to the tube. I vortexed both the 1B1 and 1B2 samples and quantified on the NanoDrop1000 (ThermoFisher). I also re-quantified the pooled BS-treated sample that had been used as input DNA for the libraries.\nResults:\nSpreadsheet: 20150226_Claire_sheared_Emma_1000ppm_OD260s\nSample 1B1 has ample DNA in it. Since these samples are pools of larvae, we may be able to just proceed with this sample and not worry about pooling with the biological replicate 1B2.\nSample 1B2 has a low amount of DNA, but it’s a usable quantity (total 400ng).\nPooled samples has nothing.\nWill make a new pool of DNA from both 1B1 and 1B2 and attempt to make a new bisulfite-treated library."
  },
  {
    "objectID": "posts/2015/2015-09-15-genomic-dna-isolation-olympia-oyster-adductor-musle-mantle-3/index.html",
    "href": "posts/2015/2015-09-15-genomic-dna-isolation-olympia-oyster-adductor-musle-mantle-3/index.html",
    "title": "Genomic DNA Isolation – Olympia oyster adductor musle & mantle",
    "section": "",
    "text": "Isolated gDNA from Ostrea lurida (Olympia oyster) adductor muscle & mantle samples collected by Brent & Steven on 20150812 using DNAzol (Molecular Research Center) according to the manufacturer’s protocol, with the following adjustments:\n\n73.5mg of adductor muscle\n146mg of mantle\nTissues homogenized in 750μL of DNAzol with disposable mortar/pestle tubes using 10 pestle strokes\nAfter homogenization, topped off tubes to 1000μL with DNAzol and incubated @ RT for 10mins.\nPerformed optional centrifugation step (10,000g, 10mins @ RT)\nInitial pellet wash was performed using a 70%/30% DNAzol/EtOH\nPellets were resuspended in 200μL of Buffer EB (Qiagen)\nInsoluble material was pelleted (12,000g, 10mins @ RT) and supe transferred to new tubes\n\nSpec’d on Roberts Lab NanoDrop1000 (ThermoFisher) and stored temporarily at 4C to avoid freeze-thawing before sending off for sequencing.\nResults:\n(http://eagle.fish.washington.edu/Arabidopsis/20150915_gDNA_oly_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150915_gDNA_oly_plots.JPG)\nThere was a great deal of insoluble material from the get-go that was carried through the entire isolation.\nOverall, the 260/280 ratios look pretty good, but the 260/230 ratios are just trash. As can be seen in the plots above, there is clearly significant absorbance in the 230 – 250nm, suggesting some contaminant carryover (phenol/salt).\nWill evaluate gDNA integrity on agarose gel.\nYields from this isolation:\nAdductor muscle: 18.75μg\nMantle: 15.9μg\nTotal Olympia oyster gDNA from this isolation: 34.65μg\nTotal Olympia oyster gDNA accumulated for this project: 88.75μg\nGreat! Have sufficient gDNA to send to BGI (minimum of 73μg needed). Assuming gDNA integrity looks good on a gel, I will pool samples tomorrow, quantify the pooled gDNA and prepare for submission."
  },
  {
    "objectID": "posts/2015/2015-11-13-pcr-oly-rad-seq-test-scale-pcr-4/index.html",
    "href": "posts/2015/2015-11-13-pcr-oly-rad-seq-test-scale-pcr-4/index.html",
    "title": "PCR – Oly RAD-seq Test-scale PCR",
    "section": "",
    "text": "Continuing with the RAD-seq library prep. Following the Meyer Lab 2bRAD protocol.\nPrior to generating full-blown libraries, we needed to run a “test-scale” PCR to identify the minimum number of cycles needed to produce the intended product size (166bp).\nI ran PCR reactions on a subset (Sample #: 2, 3, 17, & 30) of the 10 samples that I performed adaptor ligations on 20151029.\nPCR reactions were set up on ice in 0.5mL PCR tubes.\n\n\n\n\n\nREAGENT\n\n\nSINGLE REACTION (μL)\n\n\nx4.4\n\n\n\n\nTemplate\n\n\n8\n\n\nNA\n\n\n\n\nNanoPure H2O\n\n\n1\n\n\n4.4\n\n\n\n\ndNTPs (1mM)\n\n\n4\n\n\n17.6\n\n\n\n\nILL-LIB1 (10μM)\n\n\n0.4\n\n\n1.76\n\n\n\n\nILL-LIB2 (10μM)\n\n\n0.4\n\n\n1.76\n\n\n\n\nILL-HT1 (1μM)\n\n\n1\n\n\n4.4\n\n\n\n\nILL-BC1 (1μM)\n\n\n1\n\n\n4.4\n\n\n\n\n5x Q5 Reaction Buffer\n\n\n4\n\n\n17.6\n\n\n\n\nQ5 DNA Polymerase\n\n\n0.2\n\n\n0.88\n\n\n\n\nTOTAL\n\n\n20\n\n\n52.8\n\n\n\n\n\nCombined 12μL of master mix with 8μL of the ligation reaction from earlier today.\nCycling was performed on a PTC-200 (MJ Research) with a heated lid:\n\n\n\n\n\nSTEP\n\n\nTEMP (C)\n\n\nTIME (s)\n\n\n\n\nInitial Denaturation\n\n\n\n98\n\n\n\n\n30\n\n\n\n\n\n27 cycles\n\n\n\n98\n60\n72\n\n\n\n\n5\n20\n10\n\n\n\n\n\n\nWe’re following the “1/4 reduced representation” aspect of the protocol. As such, 5μL of each reaction was pulled immediately after the extension (72C – machine was paused) of cycles 12, 17, 22, & 27 in order to determine the ideal number of cycles to use. Also ran the ligation reactions (labeled “Ligations” on the gel below) of the samples as a pre-PCR comparison. Treated them the same as the PCR reactions: mixed 8μL of the ligation with 12μL of H2O, used 5μL of that mix to load on gel.\nThese samples were run on a 1x modified TAE 1.2% agarose gel (w/EtBr).\nResults:\n(https://raw.githubusercontent.com/sr320/LabDocs/master/protocols/Commercial_Protocols/ThermoFisher_OgeneRuler_DNA_Ladder_Mix_F100439.jpg)\n[caption id=“” align=“alignnone” width=“701”](http://eagle.fish.washington.edu/Arabidopsis/20151112_gel_oly_RAD_test_scale_PCR.png) Gel image denoting sample numbers within each cycle number. Green arrow indicates the expected migration of our target band size of 166bp.[/caption]\nLooks like cycle 17 is the minimum cycle number with which we begin to see a consistent ~166bp band. Will continue on with the “prep-scale” PCR using 17 cycles."
  },
  {
    "objectID": "posts/2015/2015-12-31-data-received-oly-2brad-illumina-sequencing-from-genewiz/index.html",
    "href": "posts/2015/2015-12-31-data-received-oly-2brad-illumina-sequencing-from-genewiz/index.html",
    "title": "Data Received - Oly 2bRAD Illumina Sequencing from Genewiz",
    "section": "",
    "text": "The data was made available to use on 20151224 and took two days to download.\nThe full list of samples (and the individual samples/libraries/indexes) submitted to Genewiz for this project by Katherine Silliman & me can be seen here (Google Sheet): White_BS1511196_R2_barcodes\nThe data supplied were all of the Illumina output files (currently not entirely sure where/how we want to store all of this, but we’ll probably want to use them for attempting our own demultiplexing since there were a significant amount of reads that Genewiz was unable to demultiplex), in addition to demultiplexed FASTQ files. The FASTQ files were buried in inconvenient locations, and there are over 300 of them, so I used the power of the command line to find them and copy them to a single location: https://owl.fish.washington.edu/nightingales/O_lurida/2bRAD_Dec2015/\nFind and copy all FASTQ files:\n<code>find /run/user/1000/gvfs/smb-share\\:server\\=owl.fish.washington.edu\\,share\\=home/ -name '*.fastq.*' -exec cp -n '{}' /run/user/1000/gvfs/smb-share\\:server\\=owl.fish.washington.edu\\,share\\=web/nightingales/O_lurida/ \\;</code>\nCode explanation:\n<code>find</code>\n\nCommand line program used for searching for files\n/run/user/1000/gvfs/smb-share:server=owl.fish.washington.edu,share=home/ \nLocation of the files I wanted to search through. The path looks a little crazy because I was working remotely and had the server share mounted.\n-name ‘.fastq.’\nThe name argument tells the find command to look for filenames that have “.fastq” in them.\n-exec cp -n ‘{}’\nThe exec option tells the find command to execute a subsequent action upon finding a match. In this case, I’m using the copy command (cp) and telling the program not to overwrite (clobber, -n) any duplicate files.\n/run/user/1000/gvfs/smb-share:server=owl.fish.washington.edu,share=web/nightingales/O_lurida/2bRAD_Dec2015 ;\nThe location where I want the matched files copied.\n\nI created a readme file in the directory directory with these files: readme.md\nI wanted to add some information about the project to the readme file, like total number of sequencing reads generated and the number of reads in each FASTQ file.\nHere’s how to count the total of all reads generated in this project\n<code>totalreads=0; for i in *.gz; do linecount=`gunzip -c \"$i\" | wc -l`; readcount=$((linecount/4)); totalreads=$((readcount+totalreads)); done; echo $totalreads</code>\nTotal Reads: 588,396,334\nCode explanation:\n<code>totalreads=0;</code>\n\nCreates variable called “totalreads” and initializes value to 0.\nfor i in *.gz;\nInitiates a for loop to process any filenames that end with “.gz”. The FASTQ files have been compressed with gzip and end with the .gz extension.\ndo linecount=\nCreates variable called “linecount” that stores the results of the following command:\ngunzip -c \"$i\" | wc -l;\nUnzips the files ($i) to stdout (-c) instead of actually uncompressing them. This is piped to the word count command, with the line flag (wc -l) to count the number of lines in the files.\nreadcount=$((linecount/4));\nDivides the value stored in linecount by 4. This is because an entry for a single Illumina read comprises four lines. This value is stored in the “readcount” variable.\ntotalreads=$((readcount+totalreads));\nAdds the readcount for the current file and adds the value to totalreads.\ndone;\nEnd the for loop.\necho $totalreads\nPrints the value of totalreads to the screen.\n\nNext, I wanted to generate list of the FASTQ files and corresponding read counts, and append this information to the readme file.\n<code>for i in *.gz; do linecount=`gunzip -c \"$i\" | wc -l`; readcount=$(($linecount/4)); printf \"%s\\t%s\\n%s\\t\\t\\n\" \"$i\" \"$readcount\" >> readme.md; done</code>\nCode explanation:\n<code>for i in *.gz; do linecount=`gunzip -c \"$i\" | wc -l`; readcount=$(($linecount/4));</code>\n\nSame for loop as above that calculates the number of reads in each FASTQ file.\nprintf “%s%s” “\\(i\" \"\\)readcount” >> readme.md;\nThis formats the the printed output. The “%scode>>> readme.md; done\nThis appends the result from each loop to the readme.md file and ends the for loop (done)."
  },
  {
    "objectID": "posts/2015/2015-04-16-quality-trimming-c-gigas-larvae-oa-bs-seq-data/index.html",
    "href": "posts/2015/2015-04-16-quality-trimming-c-gigas-larvae-oa-bs-seq-data/index.html",
    "title": "Quality Trimming - C.gigas Larvae OA BS-Seq Data",
    "section": "",
    "text": "Jupyter (IPython) Notebook: 20150414_C_gigas_Larvae_OA_Trimmomatic_FASTQC.ipynb\nNBviewer: 20150414_C_gigas_Larvae_OA_Trimmomatic_FASTQC.ipynb\n\n\n\nTrimmed FASTQC\n\n400ppm Index - GCCAAT\n20150414_trimmed_2212_lane2_GCCAAT_L002_R1_001_fastqc.html 20150414_trimmed_2212_lane2_GCCAAT_L002_R1_002_fastqc.html 20150414_trimmed_2212_lane2_GCCAAT_L002_R1_003_fastqc.html 20150414_trimmed_2212_lane2_GCCAAT_L002_R1_004_fastqc.html 20150414_trimmed_2212_lane2_GCCAAT_L002_R1_005_fastqc.html 20150414_trimmed_2212_lane2_GCCAAT_L002_R1_006_fastqc.html\n\n\n\n\n\n\n\n\n1000ppm Index - CTTGTA\n20150414_trimmed_2212_lane2_CTTGTA_L002_R1_001_fastqc.html 20150414_trimmed_2212_lane2_CTTGTA_L002_R1_002_fastqc.html 20150414_trimmed_2212_lane2_CTTGTA_L002_R1_003_fastqc.html 20150414_trimmed_2212_lane2_CTTGTA_L002_R1_004_fastqc.html"
  },
  {
    "objectID": "posts/2015/2015-12-01-sample-submission-additional-geoduck-gdna-for-genome-sequencing-bgi-2/index.html",
    "href": "posts/2015/2015-12-01-sample-submission-additional-geoduck-gdna-for-genome-sequencing-bgi-2/index.html",
    "title": "Sample Submission - Additional Geoduck gDNA for Genome Sequencing @ BGI",
    "section": "",
    "text": "Yep, BGI still needs more gDNA for the geoduck genome sequencing project. Samples have been quantified via dye-based fluorescence, as opposed to the NanoDrop, so our quantities should be more accurate and in-line with what BGI will also find.\nSubmitted three separate isolations, just in case the quality of one was unacceptable, I didn’t want to pool the samples and have that one bad apple ruin the entire batch.\nIn total, submitted ~33μg.\nSamples were shipped on dry ice with the appropriate paperwork required by BGI (sample declaration letter).\nAssigned BGI Lot: 1512021004"
  },
  {
    "objectID": "posts/2015/2015-11-05-dna-quantification-quality-assessment-geoduck-oly-gdna/index.html",
    "href": "posts/2015/2015-11-05-dna-quantification-quality-assessment-geoduck-oly-gdna/index.html",
    "title": "DNA Quantification & Quality Assessment - Geoduck & Oly gDNA",
    "section": "",
    "text": "Quantified the following samples with the Roberts Lab NanoDrop1000 (ThermoFisher) and assessed DNA integrity on the Seeb Lab Bioanalyzer 2100 (Agilent) using the DNA 12000 chip assay:\n\ngeoduck gDNA for genome sequencing\nOlympia oyster gDNA for genome sequencing\n\nResults:\nBioanalyzer Data File (XAD file): 2100 expert_DNA 12000_DE72902486_2015-11-04_15-06-32.xad\n(http://eagle.fish.washington.edu/Arabidopsis/20151104_gDNA_geo_oly_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20151104_gDNA_geo_oly_plots.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/Bioanalyzer%20Data/20151104_bioanalyzer_geoduck_electropherogram.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/Bioanalyzer%20Data/20151104_bioanalyzer_oly_electropherogram.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/Bioanalyzer%20Data/20151104_bioanalyzer_geoduck_oly_gels.jpg)\nOK, there’s a LOT going on here. Will update this notebook with my thoughts sometime tomorrow…"
  },
  {
    "objectID": "posts/2015/2015-09-16-genomic-dna-isolation-geoduck-adductor-muscle-foot-4/index.html",
    "href": "posts/2015/2015-09-16-genomic-dna-isolation-geoduck-adductor-muscle-foot-4/index.html",
    "title": "Genomic DNA Isolation – Geoduck Adductor Muscle & Foot",
    "section": "",
    "text": "Just need a tad bit more gDNA for the geoduck genome sequencing project with BGI. Currently have ~69 and need a minimum of 73μg.\nIsolated gDNA from Panopea generosa (geoduck) adductor muscle & foot samples collected by Brent & Steven on 20150811 using the DNAzol (Molecular Research Center) according to the manufacturer’s protocol, with the following adjustments:\n\n124.4mg of adductor muscle 1\nTissue homogenized in 750μL of DNAzol with disposable mortar/pestle tubes using 10 pestle strokes\nAfter homogenization, topped off tube to 1000μL with DNAzol and incubated @ RT for 10mins.\nPerformed optional centrifugation step (10,000g, 10mins @ RT)\nInitial pellet wash was performed using a 70%/30% DNAzol/EtOH\nPellet was resuspended in 400μL of Buffer EB (Qiagen)\nInsoluble material was pelleted (12,000g, 10mins @ RT) and supe transferred to new tube\n\nSpec’d on Roberts Lab NanoDrop1000 (ThermoFisher) and stored temporarily at 4C to avoid freeze-thawing before sending off for sequencing next week.\nResults:\n(http://eagle.fish.washington.edu/Arabidopsis/20150916_gDNA_geoduck_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150916_gDNA_geoduck_plots.JPG)\nThere was a great deal of insoluble material from the get-go that was carried through the entire isolation.\nOverall, the 260/280 ratio looks pretty good, but the 260/230 ratio is just trash. As can be seen in the plots above, there is clearly significant absorbance in the 230 – 250nm, suggesting some contaminant carryover (phenol/salt).\nWill assess gDNA integrity on a gel.\nYield of geoduck gDNA from this isolation: ~48μg\nTotal accumulated geoduck gDNA for this project: ~117μg\nGreat! Have sufficient gDNA to send to BGI (minimum of 73μg needed). Assuming gDNA integrity looks good on a gel, I will pool samples tomorrow, quantify the pooled gDNA and prepare for submission."
  },
  {
    "objectID": "posts/2016/2016-01-09-data-received-bisulfite-treated-illumina-sequencing-from-genewiz/index.html",
    "href": "posts/2016/2016-01-09-data-received-bisulfite-treated-illumina-sequencing-from-genewiz/index.html",
    "title": "Data Received - Bisulfite-treated Illumina Sequencing from Genewiz",
    "section": "",
    "text": "Received notice the sequencing data was ready from Genewiz for the samples submitted 20151222.\nDownload the FASTQ files from Genewiz project directory:\n<code>wget -r -np -nc -A \"*.gz\" ftp://username:password@ftp2.genewiz.com/Project_BS1512183</code>\nSince two species were sequenced (C.gigas & O.lurida), the corresponding files are in the following locations:\nhttps://owl.fish.washington.edu/nightingales/O_lurida/\nhttps://owl.fish.washington.edu/nightingales/C_gigas/\nIn order to process the files, I needed to identify just the FASTQ files from this project and save the list of files to a bash variable called ‘bsseq’:\n<code>bsseq=$(ls | grep '^[0-9]\\{1\\}_*' | grep -v \"2bRAD\")</code>\nExplanation:\n<code>bsseq=</code>\n\nThis initializes a variable called “bsseq” to the values contained in the command following the equals sign.\n$(ls | grep ’1{1}_*’ | grep -v “2bRAD”)\nThis lists (ls) all files, pipes them to the grep command (|), grep finds those files that begin with (^) one or two digits followed by an underscore ([0-9{1}_*), pipes those results (|) to another grep command which excludes (-v) any results containing the text “2bRAD”.\n\n\n\n\n\nFILENAME\n\nSAMPLE NAME\n\nSPECIES\n\n\n\n1_ATCACG_L001_R1_001.fastq.gz\n\n1NF11\n\nO.lurida\n\n\n\n2_CGATGT_L001_R1_001.fastq.gz\n\n1NF15\n\nO.lurida\n\n\n\n3_TTAGGC_L001_R1_001.fastq.gz\n\n1NF16\n\nO.lurida\n\n\n\n4_TGACCA_L001_R1_001.fastq.gz\n\n1NF17\n\nO.lurida\n\n\n\n5_ACAGTG_L001_R1_001.fastq.gz\n\n2NF5\n\nO.lurida\n\n\n\n6_GCCAAT_L001_R1_001.fastq.gz\n\n2NF6\n\nO.lurida\n\n\n\n7_CAGATC_L001_R1_001.fastq.gz\n\n2NF7\n\nO.lurida\n\n\n\n8_ACTTGA_L001_R1_001.fastq.gz\n\n2NF8\n\nO.lurida\n\n\n\n9_GATCAG_L001_R1_001.fastq.gz\n\nM2\n\nC.gigas\n\n\n\n10_TAGCTT_L001_R1_001.fastq.gz\n\nM3\n\nC.gigas\n\n\n\n11_GGCTAC_L001_R1_001.fastq.gz\n\nNF2_6\n\nO.lurida\n\n\n\n12_CTTGTA_L001_R1_001.fastq.gz\n\nNF_18\n\nO.lurida\n\n\n\n\n\nI wanted to add some information about the project to the readme file, like total number of sequencing reads generated and the number of reads in each FASTQ file.\nHere’s how to count the total of all reads generated in this project\n<code>totalreads=0; for i in $bsseq; do linecount=`gunzip -c \"$i\" | wc -l`; readcount=$((linecount/4)); totalreads=$((readcount+totalreads)); done; echo $totalreads</code>\nTotal reads = 138,530,448\nC.gigas reads: 22,249,631\nO.lurida reads: 116,280,817\nCode explanation:\n<code>totalreads=0;</code>\n\nCreates variable called “totalreads” and initializes value to 0.\nfor i in $bsseq;\nInitiates a for loop to process the list of files stored in $bsseq variable. The FASTQ files have been compressed with gzip and end with the .gz extension.\ndo linecount=\nCreates variable called “linecount” that stores the results of the following command:\ngunzip -c \"$i\" | wc -l;\nUnzips the files ($i) to stdout (-c) instead of actually uncompressing them. This is piped to the word count command, with the line flag (wc -l) to count the number of lines in the files.\nreadcount=$((linecount/4));\nDivides the value stored in linecount by 4. This is because an entry for a single Illumina read comprises four lines. This value is stored in the “readcount” variable.\ntotalreads=$((readcount+totalreads));\nAdds the readcount for the current file and adds the value to totalreads.\ndone;\nEnd the for loop.\necho $totalreads\nPrints the value of totalreads to the screen.\n\nNext, I wanted to generate list of the FASTQ files and corresponding read counts, and append this information to the readme file.\n<code>for i in $bsseq; do linecount=`gunzip -c \"$i\" | wc -l`; readcount=$(($linecount/4)); printf \"%s\\t%s\\n%s\\t\\t\\n\" \"$i\" \"$readcount\" >> readme.md; done</code>\nCode explanation:\n<code>for i in $bsseq; do linecount=`gunzip -c \"$i\" | wc -l`; readcount=$(($linecount/4));</code>\n\nSame for loop as above that calculates the number of reads in each FASTQ file.\nprintf “%s%s” “\\(i\" \"\\)readcount” >> readme.md;\nThis formats the the printed output. The “%scode>>> readme.md; done\nThis appends the result from each loop to the readme.md file and ends the for loop (done).\n\n\n\n\n\nFootnotes\n\n\n0-9↩︎"
  },
  {
    "objectID": "posts/2016/2016-12-20-sample-submission-geoduck-reduced-representation-bisulfite-pooled-libraries/index.html",
    "href": "posts/2016/2016-12-20-sample-submission-geoduck-reduced-representation-bisulfite-pooled-libraries/index.html",
    "title": "Sample Submission - Geoduck Reduced Representation Bisulfite Pooled Libraries",
    "section": "",
    "text": "Hollie Putnam asked me to help her get samples ready for submission for Illumina sequencing at Genewiz.\nShe had previously prepared reduced representation bisulfite libraries on 20161215.\nShe also prepped a whole genome library on 20161201 - specifically sample EPI_135 WG.\nShe needed these samples combined in to four separate pools. However, Pool 5 was to be pooled with a total of five samples, including EPI_135 WG. She asked that the EPI_135 WG sample make up 50% of the DNA in the pool.\nUsing her previously determined sample concentrations, I pooled the libraries in equal quantities.\nCalculations (Google Sheet): 20161219_hollie_library_pool_calcs\nThe pool volumes are high and, the calculated pool concentrations are low. Due to time limitations on our end, it was not feasible for me to SpeedVac these down to achieve the target concentration of 10nM. I’ve notified Hollie and asked her to see if Genewiz will perform that service.\nSamples were shipped on dry ice to Genewiz via FedEx Standard Overnight."
  },
  {
    "objectID": "posts/2016/2016-01-28-data-received-panopea-generosa-genome-sequencing-files-from-bgi/index.html",
    "href": "posts/2016/2016-01-28-data-received-panopea-generosa-genome-sequencing-files-from-bgi/index.html",
    "title": "Data Received - Panopea generosa genome sequencing files from BGI",
    "section": "",
    "text": "Downloaded data from the BGI project portal to our server, Owl, using the Synology Download Station. Although the BGI portal is aesthetically nice, it’s set up poorly for bulk downloads and took a few tries to download all of the files.\nData integrity was assessed and read counts for each file were generated. The files were moved to their permanent storage location on Owl: https://owl.fish.washington.edu/nightingales/P_generosa/\nThe readme.md file was updated to include project/file information.\nThe file manipulations were performed in a Jupyter notebook (see below).\nTotal reads generated for this project: 1,208,635,950\nBGI provided us with the raw data files for us to play around with, but they are also currently in the process of performing the genome assembly.\nJupyter Notebook file: 20160126_Olurida_BGI_data_handling.ipynb\nNotebook Viewer: 20160126_Olurida_BGI_data_handling.ipynb"
  },
  {
    "objectID": "posts/2016/2016-01-28-data-received-ostrea-lurida-genome-sequencing-files-from-bgi/index.html",
    "href": "posts/2016/2016-01-28-data-received-ostrea-lurida-genome-sequencing-files-from-bgi/index.html",
    "title": "Data Received - Ostrea lurida genome sequencing files from BGI",
    "section": "",
    "text": "Downloaded data from the BGI project portal to our server, Owl, using the Synology Download Station. Although the BGI portal is aesthetically nice, it’s set up poorly for bulk downloads and took a few tries to download all of the files.\nData integrity was assessed and read counts for each file were generated. The files were moved to their permanent storage location on Owl: https://owl.fish.washington.edu/nightingales/O_lurida\nThe readme.md file was updated to include project/file information.\nThe file manipulations were performed in a Jupyter notebook (see below).\nTotal reads generated for this project: 1,225,964,680\nBGI provided us with the raw data files for us to play around with, but they are also currently in the process of performing the genome assembly.\nJupyter Notebook file: 20160126_Olurida_BGI_data_handling.ipynb\nNotebook Viewer: 20160126_Olurida_BGI_data_handling.ipynb"
  },
  {
    "objectID": "posts/2016/2016-06-30-dna-quantification-coral-dna-from-jose-m-eirin-lopez-florida-international-university/index.html",
    "href": "posts/2016/2016-06-30-dna-quantification-coral-dna-from-jose-m-eirin-lopez-florida-international-university/index.html",
    "title": "DNA Quantification - Coral DNA from Jose M. Eirin-Lopez (Florida International University)",
    "section": "",
    "text": "Quantified the DNA we received from Jose on 20160615 using the Qubit 3.0 Flouorometer (ThermoFisher) with the dsDNA Broad Range (BR) Kit according to the manufacturer’s protocol. Used 1μL of each sample.\nResults are here (Google Sheet): Coral_DNA_QubitData_2016-06-30_08-45-56.xls\nHere is a table of sample concentrations:\n\n\n\n\n\nSample\n\n\nConcentration(ng/μL)\n\n\n\n\nH1 1\n\n\n52.4\n\n\n\n\nH1 5\n\n\n34\n\n\n\n\nH1 6\n\n\n13\n\n\n\n\nH1 8\n\n\n22\n\n\n\n\nH1 10\n\n\n39\n\n\n\n\nH1 12\n\n\n52.4\n\n\n\n\nH5 1\n\n\n14.7\n\n\n\n\nH5 5\n\n\n20.8\n\n\n\n\nH5 6\n\n\n54\n\n\n\n\nH5 8\n\n\n18.4\n\n\n\n\nH5 10\n\n\n46.6\n\n\n\n\nH5 12\n\n\n29.8\n\n\n\n\nH24 1\n\n\n16.2\n\n\n\n\nH24 5\n\n\n25\n\n\n\n\nH24 6\n\n\n20.2\n\n\n\n\nH24 8\n\n\n22\n\n\n\n\nH24 10\n\n\n22\n\n\n\n\nH24 12\n\n\n30.6\n\n\n\n\n\nWill proceed with DNA methylation assessment."
  },
  {
    "objectID": "posts/2016/2016-04-06-data-analysis-oly-gbs-data-from-bgi/index.html",
    "href": "posts/2016/2016-04-06-data-analysis-oly-gbs-data-from-bgi/index.html",
    "title": "Data Analysis - Oly GBS Data from BGI Using Stacks",
    "section": "",
    "text": "UPDATE (20160418) : I’m posting this more for posterity, as Stacks continually locked up at both the “ustacks” and “cstacks” stages. These processes would take days to run (on the full 96 samples) and then the processes would become “stuck” (viewed via the top command in OS X).\nHave moved on to trying PyRAD in the meantime.\nNeed to get the GBS from BGI data analyzed.\n[Installed Stacks (and its dependencies on Hummingbird earlier today)(2016/04/06/software-install-samtools-0-1-19-and-stacks-1-37.html).\nBelow is the Jupyter (iPython) notebook I ran to perform this analysis.\nJupyter (iPython) Notebook: 20160406_Oly_GBS_STACKS.ipynb\nJupyter Notebook Viewer: 20160406_Oly_GBS_STACKS"
  },
  {
    "objectID": "posts/2016/2016-12-14-data-management-download-final-bgi-genome-assembly-files/index.html",
    "href": "posts/2016/2016-12-14-data-management-download-final-bgi-genome-assembly-files/index.html",
    "title": "Data Management - Download Final BGI Genome & Assembly Files",
    "section": "",
    "text": "We received info to download the final data and genome assembly files for geoduck and Olympia oyster from BGI.\nIn total, the downloads took a little over three days to complete!\nThe notebook detailing how the files were downloaded is below, but it should be noted that I had to strip the output cells because the output from the download command made the file too large to upload to GitHub, and the size of the notebook file would constantly crash the browser/computer that it was opened in. So, the notebook below is here for posterity.\nJupyter Notebook: 20161206_docker_BGI_genome_downloads.ipynb"
  },
  {
    "objectID": "posts/2016/2016-03-14-data-received-initial-geoduck-genome-assembly-from-bgi/index.html",
    "href": "posts/2016/2016-03-14-data-received-initial-geoduck-genome-assembly-from-bgi/index.html",
    "title": "Data Received - Initial Geoduck Genome Assembly from BGI",
    "section": "",
    "text": "The initial assembly of the Ostrea lurida genome is available from BGI. Currently, we’ve stashed it here:\nhttps://owl.fish.washington.edu/P_generosa_genome_assemblies_BGI/20160314/\nThe data provided consisted of the following three files:\n\nmd5.txt\nN50.txt\nscaffold.fa.fill\n\nmd5.txt - Checksum file to verify integrity of files after downloading.\nN50.txt - Contains some very limited stats on scaffolds provided.\nscaffold.fa.fill - A FASTA file of scaffolds. Since these are scaffolds (and NOT contigs!), there are many regions containing NNNNNN’s that have been put in place for scaffold assembly based on paired-end spatial information. As such, the N50 information is not as useful as it would be if these were contigs.\nAdditional assemblies will be provided at some point. I’ve emailed BGI about what we should expect from this initial assembly and what subsequent assemblies should look like."
  },
  {
    "objectID": "posts/2016/2016-05-16-data-management-olympia-oyster-small-insert-library-genome-assembly-from-bgi/index.html",
    "href": "posts/2016/2016-05-16-data-management-olympia-oyster-small-insert-library-genome-assembly-from-bgi/index.html",
    "title": "Data Management - Olympia Oyster Small Insert Library Genome Assembly from BGI",
    "section": "",
    "text": "Received another set of Ostrea lurida genome assembly data from BGI. In this case, it’s data assembled from the small insert libraries they created for this project.\nAll data is stored here: https://owl.fish.washington.edu/O_lurida_genome_assemblies_BGI/20160512/\nThey’ve provided a [Genome Survey (PDF)(https://owl.fish.washington.edu/O_lurida_genome_assemblies_BGI/20160512/20160512_F15FTSUSAT0327_genome_survey.pdf) that has some info about the data they’ve assembled. In it, is the estimated genome size:\nOlympia oyster genome size: 1898.92 Mb\nAdditionally, there’s a table breaking down the N50 distributions of scaffold and contig sizes.\nData management stuff was performed in a Jupyter (iPython) notebook; see below.\nJupyter Notebook: 20160516_Oly_Small_Insert_Library_Genome_Read_Counts.ipynb"
  },
  {
    "objectID": "posts/2016/2016-09-12-oyster-sampling-olympia-oyster-oa-populations-at-manchester/index.html",
    "href": "posts/2016/2016-09-12-oyster-sampling-olympia-oyster-oa-populations-at-manchester/index.html",
    "title": "Oyster Sampling - Olympia Oyster OA Populations at Manchester",
    "section": "",
    "text": "I helped Katherine Silliman with her oyster sampling today from her ocean acidification experiment with Olympia oysters (Ostrea lurida) at the Kenneth K. Chew Center for Shellfish Research & Restoration, which is housed at the NOAA Northwest Fisheries Science Center at Manchester in a partnership with the [Puget Sound Restoration Fund (PSRF)(http://www.restorationfund.org/). We sampled the following tissues and stored in 1mL RNAlater:\n\nadductor muscle (A)\nctenidia (C)\nmantle (M)\n\nWhen there was sufficient ctenidia tissue, an additional sample was stored in 75% ethanol for potential microbial analysis.\nTissue was collected from two oysters from each of the following oyster populations:\n\nBritish Columbia (BC)\nCalifornia (CA)\nOregon (OR)\n\nOysters were sampled from each of the following tanks:\n\n1A\n2A\n3A\n4A\n1B\n2B\n3B\n4B\n\nTubes were labeled in the following fashion:\n\nPopulation & Tank (e.g. OR3B)\nTag#\nTissue\n\nIf no tag was present on the oyster, the oyster was assigned a number (beginning at 150 and increased sequentially) and photographed with a ruler for future measurement. White colored tags were written with the number followed by the letter ‘W’ (e.g. 78W) - no tag color info was recorded for other tag colors.\nAdditionally, gonad developmental stage was roughly assessed: ripe, kinda ripe, or not ripe.\nAll info was recorded by Katherine in her notepad. All samples were retained by Katherine (not sure where she stored them).\nUtensils were flame sterilized between oysters and gloves/work surfaces were washed with a 10% bleach solution between oysters.\nHere are a few pics from the day:\n(http://eagle.fish.washington.edu/Arabidopsis/20160912_manchester_01.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/20160912_manchester_02.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/20160912_manchester_03.jpg)"
  },
  {
    "objectID": "posts/2016/2016-05-31-computer-setup-cluster-node003-conversion/index.html",
    "href": "posts/2016/2016-05-31-computer-setup-cluster-node003-conversion/index.html",
    "title": "Computer Setup - Cluster Node003 Conversion",
    "section": "",
    "text": "Here’s an overview of some of the struggles getting node003 converted/upgraded to function as an independent computer (as opposed to a slave node in the Apple computer cluster).\n\n6TB HDD\nOnly 2.2TB recognized when connected to Hummingbird via Firewire - internet suggests that is max for Xserve; USB might recognize full drive) - Hummingbird is a converted Xserve running Mavericks\nReformatted on different Mac and full drive size recognized\nConnected to Hummingbird (via USB) and full 6TB recognized\nConnected to Mac Mini to install OS X\nTried installing OS X 10.8.5 (Mountain Lion) via CMD+r at boot, but failed partway through installation\nTried and couldn’t reformat drive through CMD+r at boot with Disk Utility\nBroken partition tables identified on Linux, used GParted to establish partition table, back to Mac Mini and OS X (Mountain Lion) install worked\nUpgraded to OS X 10.11.5 (El Capitan)\nInserted drive to Mac cluster node003 - wouldn’t boot all the way - Apple icon, progress bar > Do Not Enter symbol\nRemoved drive, put original back in, connected 6TB HDD via USB, but booting from USB not an option (when booting and holding Option key)\nProbably due to node003 being part of cluster - reformatted original node003 drive with clean install of OS X Server.\nBooting from USB now an option and worked with 6TB HDD!\nPut 6TB HDD w/El Capitan in internal sled and won’t boot! Apple icon, progress bar > Do Not Enter symbol\nInstalled OS X 10.11.5 (El Capitan) on old 1TB drive and inserted into node003 - worked perfectly!\nWill just use 1TB boot drive and figure out another use for 6TB HDD\nRenamed node003 to roadrunner\nCurrent plan is to upgrade from 12GB to 48GB of RAM and then automate moving data off this drive to long-term storage on Owl (Synology server)."
  },
  {
    "objectID": "posts/2016/2016-04-28-sra-release-transcriptomic-profiles-of-adult-female-male-gonads-in-panopea-generosa-pacific-geoduck/index.html",
    "href": "posts/2016/2016-04-28-sra-release-transcriptomic-profiles-of-adult-female-male-gonads-in-panopea-generosa-pacific-geoduck/index.html",
    "title": "SRA Release - Transcriptomic Profiles of Adult Female & Male Gonads in Panopea generosa (Pacific geoduck)",
    "section": "",
    "text": "The RNAseq data that [I previously submitted to NCBI short read archive (SRA)(2016/03/24/sra-submission-transcriptomic-profiles-of-adult-female-male-gonads-in-panopea-generosa-pacific-geoduck.html) has been released to the public today. Here are the various links for the project:\nStudy: SRP072283 - http://trace.ncbi.nlm.nih.gov/Traces/study/?acc=SRP072283\nBioProject: PRJNA316216 - http://www.ncbi.nlm.nih.gov/bioproject/PRJNA316216\nStudy: SRP072283 - http://trace.ncbi.nlm.nih.gov/Traces/sra/?study=SRP072283\nFemale Pool Experiment: SRX1659865 - http://www.ncbi.nlm.nih.gov/sra/SRX1659865 Male Pool Experiment: SRX1659865 - http://www.ncbi.nlm.nih.gov/sra/SRX1659866"
  },
  {
    "objectID": "posts/2016/2016-02-03-data-received-ostrea-lurida-mbd-enriched-bs-seq/index.html",
    "href": "posts/2016/2016-02-03-data-received-ostrea-lurida-mbd-enriched-bs-seq/index.html",
    "title": "Data Received - Ostrea lurida MBD-enriched BS-seq",
    "section": "",
    "text": "Received the Olympia oyster, MBD-enriched BS-seq sequencing files (50bp, single read) from ZymoResearch (submitted 20151208). Here’s the sample list:\n\nE1_hc1_2B\nE1_hc1_4B\nE1_hc2_15B\nE1_hc2_17\nE1_hc3_1\nE1_hc3_5\nE1_hc3_7\nE1_hc3_10\nE1_hc3_11\nE1_ss2_9B\nE1_ss2_14B\nE1_ss2_18B\nE1_ss3_3B\nE1_ss3_14B\nE1_ss3_15B\nE1_ss3_16B\nE1_ss3_20\nE1_ss5_18\n\nThe 18 samples listed above had previously been MBD-enriched and then sent to ZymoResearch for bisulfite conversion, multiplex library construction, and subsequent sequencing. The library (multiplex of all samples) was sequenced in a single lane, three times. Thus, we would expect 54 FASTQ files. However, ZymoResearch was dissatisfied with the QC of the initial sequencing run (completed on 20160129), so they re-ran the samples (completed on 20160202). This created two sets of data, resulting in a total of 108 FASTQ files.\nZymoResearch data portal does not allow bulk download of files. However, I ended up using Chrono Download Manager extension for Google Chrome to allow for automated downloading of each file (per ZymoResearch recommendation).\nAfter download, the files were moved to their permanent storage location on Owl: https://owl.fish.washington.edu/nightingales/O_lurida/20160203_mbdseq\nThe readme.md file was updated to include project/file information.\nThe file manipulations were performed in a Jupyter notebook (see below).\nTotal reads generated for this project: 1,481,836,875\nJupyter Notebook file: 20160203_Olurida_Zymo_Data_Handling.ipynb\nNotebook Viewer: 20160203_Olurida_Zymo_Data_Handling.ipynb"
  },
  {
    "objectID": "posts/2016/2016-11-17-data-management-tracking-o-lurida-fastq-file-corruption/index.html",
    "href": "posts/2016/2016-11-17-data-management-tracking-o-lurida-fastq-file-corruption/index.html",
    "title": "Data Management - Tracking O.lurida FASTQ File Corruption",
    "section": "",
    "text": "UPDATE 20170104 - These two corrupt files have been replaced with non-corrupt files.\n\nSean identified an issue with one of the original FASTQ files provided to use by BGI. Additionally, Steven had (unknowingly) identified the same corrupt file, as well as a second corrupt file in the set of FASTQ files. The issue is discussed here: https://github.com/sr320/LabDocs/issues/334\nSteven noticed the two files when he ran the program FASTQC and two files generated no output (but no error message!).\nThe two files in question are:\n\n151118_I137_FCH3KNJBBXX_L5_wHAXPI023905-96_1.fq.gz\n151114_I191_FCH3Y35BCXX_L2_wHAMPI023991-66_2.fq.gz\n\nThis post is an attempt to document where things went wrong, but having glanced through this data a bit already, it won’t provide any answers.\nI originally downloaded the data on 20160127 to my home folder on Owl (this is detailed in the Jupyter notebook in that post) and generated/compared MD5 checksum values. The values matched at that time.\nSo, let’s investigate a bit further…\nLaunch Docker container\n<code>docker run - p 8888:8888 -v /Users/sam/data/:/data -v /Users/sam/owl_home/:/owl_home -v /Users/sam/owl_web/:owl_web -v /Users/sam/gitrepos/LabDocs/jupyter_nbs/sam/:/jupyter_nbs -it 0ba43904567e</code>\nThe command allows access to Jupyter Notebook over port 8888 and makes my Jupyter Notebook GitHub repo and my data files accessible to the Docker container.\nOnce the container was started, started Jupyter Notebook with the following command inside the Docker container:\njupyter notebook\nThis command is configured in the Docker container to launch a Jupyter Notebook without a browser on port 8888.\nJupyter notebook file: 20161117_docker_oly_genome_fastq_corruption.ipynb\nI’ve embedded the notebook below, but it’s much easier to view (there are many lengthy commands/filenames that wrap lines in the embedded version below) the actual file linked above."
  },
  {
    "objectID": "posts/2016/2016-05-23-data-analysis-oly-gbs-data-using-stacks-1-37/index.html",
    "href": "posts/2016/2016-05-23-data-analysis-oly-gbs-data-using-stacks-1-37/index.html",
    "title": "Data Analysis - Oly GBS Data Using Stacks 1.37",
    "section": "",
    "text": "This analysis ran (or, more properly, was attempted) for a couple of weeks and failed a few times. The failures seemed to be linked to the external hard drive I was reading/writing data to. It continually locked up, leading to “Segmentation fault” errors.\nWe’ve replaced the external with a different one in hopes that it’ll be able to handle the workload. Will be attempting to re-run Stacks with the new external hard drive.\nI’m posting the Jupyter notebook here for posterity.\nJupyter notebook: 20160428_Oly_GBS_STACKS.ipynb"
  },
  {
    "objectID": "posts/2016/2016-11-18-data-analysis-initial-o-lurida-fst-determination-from-gbs-data/index.html",
    "href": "posts/2016/2016-11-18-data-analysis-initial-o-lurida-fst-determination-from-gbs-data/index.html",
    "title": "Data Analysis - Initial O.lurida Fst Determination from GBS Data",
    "section": "",
    "text": "Finally running some analysis on the output from my PyRad analysison 20160727.\nI’m following Katherine Silliman’s Jupyter notebook (2bRAD Subset Population Structure Analysis.ipynb) as a guide.\nThe initial analysis (which isn’t much) is in the Jupyter notebook below. The analysis will be continued on a later date.\nJupyter notebook: 20161117_docker_oly_vcf_analysis.ipynb\nI’ve embedded the notebook below, but it’s much easier to view (there are many lengthy commands/filenames that wrap lines in the embedded version below) the actual file linked above."
  },
  {
    "objectID": "posts/2016/2016-06-09-docker-one-liner-to-create-docker-container/index.html",
    "href": "posts/2016/2016-06-09-docker-one-liner-to-create-docker-container/index.html",
    "title": "Docker - One liner to create Docker container",
    "section": "",
    "text": "One liner to create Docker container for Jupyter notebook usage and data analysis on roadrunner (Xserve):\nThis does the following:\n\nMaps roadrunner port 8888 to Docker container port 8888 (for Jupyter notebook access outside of the Docker container)\nMounts my local Jupyter notebooks directory to the\n/notebooks\n\ndirectory in the Docker container\n\nMounts my local data directory to the\n/data\n\ndirectory in the Docker container\n\nMounts my local analysis directory to the\n/analysis\n\ndirectory in the Docker container\nThese commands allow me to interact with data outside of the Docker container."
  },
  {
    "objectID": "posts/2016/2016-03-15-data-management-o-lurida-genotype-by-sequencing-gbs-data-from-bgi/index.html",
    "href": "posts/2016/2016-03-15-data-management-o-lurida-genotype-by-sequencing-gbs-data-from-bgi/index.html",
    "title": "Data Management - O. lurida genotype-by-sequencing (GBS) data from BGI",
    "section": "",
    "text": "We received a hard drive from BGI on 20160223 (while I was out on paternity leave) containing the Ostrea lurida GBS data.\nBriefly, three sets (i.e. populations) of Olympia oyster tissue was collected from oysters raised in Oyster Bay and were sent to BGI for DNA extraction and GBS. A total of 23 individuals from each of the following three populations were sequenced (a grand total of 96 samples):\n\n1HL - (Hood Canal, Long Spit)\n1NF - (North Sound, Fidalgo Bay)\n1SN - (South Sound, Oyster Bay)\n\nAn overview of this project can be viewed on our GitHub Olympia oyster wiki.\nData was copied from the HDD to the following location on Owl (our server): https://owl.fish.washington.edu/nightingales/O_lurida/20160223_gbs/\nThe data was generated from paired-end Illumina sequencing, so there are two FASTQ files for each individual.\nThe files were analyzed to create a MD5 checksum, perform read counts, and create a readme (markdown format) file. This was performed in a Jupyter/iPython notebook (see below).\nIMPORTANT NOTE: The directory where this data is housed was renamed AFTER the Jupyter notebook was run. As such, the directory listed above will not be seen in the Jupyter notebook.\nJupyter notebook file: 20160314_Olurida_GBS_data_management.ipynb\nNotebook Viewer: 20160314_Olurida_GBS_data_management.ipynb"
  },
  {
    "objectID": "posts/2016/2016-12-21-sample-submission-geoduck-tissue-gdna-for-illumina-pilot-sequencing-project/index.html",
    "href": "posts/2016/2016-12-21-sample-submission-geoduck-tissue-gdna-for-illumina-pilot-sequencing-project/index.html",
    "title": "Sample Submission - Geoduck Tissue & gDNA for Illumina Pilot Sequencing Project",
    "section": "",
    "text": "Sent the following samples to Illumina for possible selection in a new pilot sequencing platform they’re working on.\nThe 12 samples will be used for RNAseq for genome annotation - numbers indicate desired sequencing priority.\nJuvenile and larval samples were from Hollie Putnam (see links below for more info).\nOther tissue was from a single, adult geoduck, collected by Brent & Steven on 20150811.\n\nGonad\nHeart\nCtenidia\nJuvenile OA exposure (super low)  (EPI_115, EPI_116)\nJuvenile ambient exposure (ambient treatment) (EPI_123, EPI_124)\nLarvae day 0 (EPI_74, EPI_75)\nLarvae day 5 (EPI_99)\nCrystalline style\nByssus gland\nMantle\nLabial palps\nJuvenile OA exposure - low treatment (EPI_107, EPI_108)\n\nIn addition to the above 12 samples, ~1.5μg of geoduck gDNA (isolated this morning) was sent."
  },
  {
    "objectID": "posts/2016/2016-10-03-goals-october-2016/index.html",
    "href": "posts/2016/2016-10-03-goals-october-2016/index.html",
    "title": "Goals - October 2016",
    "section": "",
    "text": "Last month’s goals, as it turns out, were way too ambitious. This month’s goal will be to get the Oly GBS data analysis fully completed (currently have individuals data, but need summary of the three populations data). I’ll also get the data sets and data analysis prepared/placed in satisfactory repositories in preparation for publication in Scientific Data."
  },
  {
    "objectID": "posts/2016/2016-08-29-data-management-synology-cloud-sync-to-uw-google-drive/index.html",
    "href": "posts/2016/2016-08-29-data-management-synology-cloud-sync-to-uw-google-drive/index.html",
    "title": "Data Management - Synology Cloud Sync to UW Google Drive",
    "section": "",
    "text": "After a bit of a scare this weekend (Synology DX513 expansion unit no longer detected two drives after a system update - resolved by powering down the system and rebooting it), we revisited our approach for backing up data.\nOur decision was to utilize UW Google Drive, as it provides unlimited storage space!\nSynology has an available app for syncing data to/from Google Drive, so I set up both Owl (Synology DS1812+) and Eagle (Synology DS413) to sync all of their data to a shared UW Google Drive account. This should provide a functional backup solution for the massive amounts of data we’re storing and it will simplify tracking where/what is backed up where. Now, instead of wondering if certain directories are backed up via CrashPlan or Backblaze or Time Backup to another Synology server, we know that everything is backed up to Google Drive.\n(http://eagle.fish.washington.edu/Arabidopsis/20160829_eagle_cloud_sync.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/20160829_owl_cloud_sync.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/20160829_google_drive.jpg)"
  },
  {
    "objectID": "posts/2016/2016-02-05-data-management-high-throughput-sequencing-data/index.html",
    "href": "posts/2016/2016-02-05-data-management-high-throughput-sequencing-data/index.html",
    "title": "Data Management - High-throughput Sequencing Data",
    "section": "",
    "text": "We’ve had a recent influx of sequencing data, which is great, but it created a bit of a backlog documenting what we’ve received.\nI updated our Google Sheet (Nightingales) with the data from geoduck genome sequencing data from BGI, Olympia oyster genome sequencing data from BGI, and MBD bisulfite sequencing data from ZymoResearch.\nI also fixed the :FileLocation” column by replacing the “HYPERLINK” function with “CONCATENATE”.\nGoogle Sheet: Nightingales\nAfter updating the Nightingales Google Sheet, I updated the corresponding Google Fusion Table (also called Nightingales).\nTo update the Fusion Table, you have to do the following:\n\ndelete all rows in the Nightingales Google Fusion Table (Edit > Delete all rows)\nImport data from the Nightingales Google Spreadsheet (File > Import more rows…)\n\nFusion Table: Nightingales\nAt initial glance, the Fusion Table appears the same as the Google Sheet. However, if you follow the link to the full Fusion Table, it offers some unique ways to visually explore the data contained in the Fusion Table.\nAfter that I decided to deal with the fact that many of the directories on Owl (https://owl.fish.washington.edu/nightingales/) lack readme files and subsequent information about the sequencing files in those folders.\nSo, I took an inordinate amount of time to write a script that would automate as much of the process as I could think of.\nThe goal of the script is to perform the following:\n\nIdentify folders that do not have readme files.\nIdentify folders that do not have checksum files.\nCreate readme files in those directories lacking readme files\nAppend the directory path to each new readme file\nAppend sequencing file names and corresponding read counts to the new readme files\n\nWill run the script. Hope it works…"
  },
  {
    "objectID": "posts/2016/2016-09-08-data-received-jays-coral-epiradseq/index.html",
    "href": "posts/2016/2016-09-08-data-received-jays-coral-epiradseq/index.html",
    "title": "Data Received - Jay’s Coral epiRADseq",
    "section": "",
    "text": "We received notice that Jay’s coral (Porites spp) epiRADseq data was available from the Genomic Sequencing Laboratory at UC-Berkeley.\nDownloaded the FASTQ files from the project directory to Owl/nightingales/Porites_spp:\n<code>time wget -r -np -nc -A \"*.gz\" --ask-password ftp://gslftp@gslserver.qb3.berkeley.edu/160830_100PE_HS4KB/Roberts</code>\nGenerated MD5 checksums for each file:\n<code>for i in *.gz; do md5 $i >> checksums.md5; done</code>\nCalculate total number of reads for this sequencing run:\n<code>totalreads=0; for i in *.gz; do linecount=`gunzip -c \"$i\" | wc -l`; readcount=$((linecount/4)); totalreads=$((readcount+totalreads)); done; echo $totalreads</code>\nTotal reads: 573,378,864\nCalculate read counts for each file and write the data to the readme.md file in the Owl/web/nightingales/Porites_spp directory:\n<code>for i in *.gz; do linecount=`gunzip -c \"$i\" | wc -l`; readcount=$(($linecount/4)); printf \"%s\\t%s\\n\" \"$i\" \"$readcount\" >> readme.md; done</code>\nSee this Jupyter notebook for code explanations.\nAdded sequencing info to [Next_Gen_Seq_Library_Database (Google Sheet)(https://docs.google.com/spreadsheets/d/1r4twxfBHpWfQoznbn2dAQhgMvmlZvQqW9I2_uVZX_aU/edit?usp=sharing) and the Nightingales Spreadsheet (Google Sheet) and Nightingales Fusion Table (Google Fusion Table)."
  },
  {
    "objectID": "posts/2016/2016-12-01-computing-an-excercuse-in-futility/index.html",
    "href": "posts/2016/2016-12-01-computing-an-excercuse-in-futility/index.html",
    "title": "Computing - An Excercise in Futility",
    "section": "",
    "text": "Trying to continue my Oly GBS analsyis from the other day and follow along with Katherine Silliman’s notebook\nHowever, I hit a major snag: I can’t seem to run R in my Jupyter notebook! This is a major pain, since the notebook needs to be able to switch between languages; that’s the beauty of using these notebooks.\nBelow, is a documentation of my torments today.\nCurrently, I’m creating a new Docker image that uses the Debian Apt repository to install R version 3.1.1. Going through Apt instead of installing from source (as I had been previously done in the Dockerfile) should install all the necessary dependencies for R and get resolve some of the error messages I’m seeing.\nOtherwise, the last resort will be to use R outside of the notebook and document that process separately.\nAnyway, this is the kind of stuff that is immensely time consuming and frustrating that most people don’t realize goes on with all of this computing stuff…\nNotebook: 20161129_docker_R_magics_failure.ipynb"
  },
  {
    "objectID": "posts/2016/2016-03-24-sra-submission-transcriptomic-profiles-of-adult-female-male-gonads-in-panopea-generosa-pacific-geoduck/index.html",
    "href": "posts/2016/2016-03-24-sra-submission-transcriptomic-profiles-of-adult-female-male-gonads-in-panopea-generosa-pacific-geoduck/index.html",
    "title": "SRA Submission - Transcriptomic Profiles of Adult Female & Male Gonads in Panopea generosa (Pacific geoduck).",
    "section": "",
    "text": "RNAseq experiment, which is part of a larger project that involves characterizing geoduck gonad development across multiple stages: histologically, proteomically, and transcriptomically. Initial sample collection performed by Grace Crandall.\nThe current status can be seen in the screen cap below. Current release date is set for a year from now, but will likely bump it up. Need Steven to review the details of the submission (BioProject, Experiment descriptions, etc.) before I initiate the public release. Will update this post with the SRA number once we receive it.\nHere’s the list of files uploaded to the SRA:\nGeo_Pool_F_GGCTAC_L006_R1_001.fastq.gz Geo_Pool_F_GGCTAC_L006_R2_001.fastq.gz Geo_Pool_M_CTTGTA_L006_R1_001.fastq.gz Geo_Pool_M_CTTGTA_L006_R2_001.fastq.gz\nMate pair sequencing files were uploaded together within a single “Run”.\n(http://eagle.fish.washington.edu/Arabidopsis/20160324_Submission_SRA394896.jpg)"
  },
  {
    "objectID": "posts/2016/2016-12-02-goals-december-2016/index.html",
    "href": "posts/2016/2016-12-02-goals-december-2016/index.html",
    "title": "Goals - December 2016",
    "section": "",
    "text": "Well, I’ve finally progressed with the Olly GBS analysis!\nI’m nearly finished with the analysis of the de novo PyRad data. Next, I’ll run PyRad using our Oly partial genome that we have from BGI. This will allow a more descriptive evaluation of SNP loci, since we’ll actually be able to associate the SNPs with various gene annotations, thus providing more meaningful insight.\nOn the Oly genome front, I also need to submit samples for PacBio sequencing. This will be an attempt to fill in the gaps of the Oly genome scaffold we currently have.\nFinally, if all goes well, I’ll get something written up and submitted to Scientific Data."
  },
  {
    "objectID": "posts/2016/2016-08-18-manuscript-submission-oly-stress-response-to-peerj-for-review/index.html",
    "href": "posts/2016/2016-08-18-manuscript-submission-oly-stress-response-to-peerj-for-review/index.html",
    "title": "Manuscript Submission - Oly Stress Response to PeerJ for Review",
    "section": "",
    "text": "Submitted the following manuscript to PeerJ for peer review:\n\n“Differential response to stress in Ostrea lurida (Carpenter 1864) as measured by gene expression”\nThe pre-print version can be viewed here: https://peerj.com/preprints/1595/"
  },
  {
    "objectID": "posts/2016/2016-06-06-goals-june-2016/index.html",
    "href": "posts/2016/2016-06-06-goals-june-2016/index.html",
    "title": "Goals - June 2016",
    "section": "",
    "text": "Current goals are as follows:\n\nComplete Oly GBS data analysis. This is getting closer to actually being done. Had some issues with an external hard drive crashing. I’ve since replaced that and the analysis is running (it takes multiple days per stage of the analysis on Hummingbird).\nConfigure computing instances on Amazon AWS to improve our ability to handle these large data sets in a more timely fashion.\nBegin using the UW’s Hyak computing cluster to improve our ability to handles these large data sets in a more timely fashion."
  },
  {
    "objectID": "posts/2016/2016-03-14-data-received-initial-olympia-oyster-genome-assembly-from-bgi/index.html",
    "href": "posts/2016/2016-03-14-data-received-initial-olympia-oyster-genome-assembly-from-bgi/index.html",
    "title": "Data Received - Initial Olympia oyster Genome Assembly from BGI",
    "section": "",
    "text": "The initial assembly of the Ostrea lurida genome is available from BGI. Currently, we’ve stashed it here:\nhttps://owl.fish.washington.edu/O_lurida_genome_assemblies_BGI/20160314/\nThe data provided consisted of the following three files:\n\nmd5.txt\nN50.txt\nscaffold.fa.fill\n\nmd5.txt - Checksum file to verify integrity of files after downloading.\nN50.txt - Contains some very limited stats on scaffolds provided.\nscaffold.fa.fill - A FASTA file of scaffolds. Since these are scaffolds (and NOT contigs!), there are many regions containing NNNNNN’s that have been put in place for scaffold assembly based on paired-end spatial information. As such, the N50 information is not as useful as it would be if these were contigs.\nAdditional assemblies will be provided at some point. I’ve emailed BGI about what we should expect from this initial assembly and what subsequent assemblies should look like."
  },
  {
    "objectID": "posts/2016/2016-06-15-samples-received-coral-dna-from-jose-m-eirin-lopez-florida-international-university/index.html",
    "href": "posts/2016/2016-06-15-samples-received-coral-dna-from-jose-m-eirin-lopez-florida-international-university/index.html",
    "title": "Samples Received - Coral DNA from Jose M. Eirin-Lopez (Florida International University)",
    "section": "",
    "text": "Steven received these coral DNA samples today. Here’s his post on Google Plus (stored @ 4C in FTR 213):\n(https://lh5.googleusercontent.com/-89eeYS4d_qs/V2HnaJnHCFI/AAAAAAABjmE/l3mqY5UR1AYTVyHTd5tZSq3Wny3VMihFgCL0B/w671-h894-no/ef7e3a62-b96a-43e5-875e-cc08e766927b)\nHere’s the email from Jose describing the samples:\n“Dear Steven, the coral DNA samples were sent today by my student Javier (cc’ed here) to your lab. Here’s an excel attached with info for the samples including concentration and treatment of the coral from which they were extracted (N, nitrogen; NP, nitrogen+phosphorous; C, control).\nPlease let us know when you get these in the lab so we know all is fine!\nthanks!\nChema”\nHere’s the spreadsheet he sent (renamed for easier identification later on - original file sent was title DNA Qbit readings), uploaded to Google Drive:\n20160615_coral_DNA_Qbit_readings.xls"
  },
  {
    "objectID": "posts/2016/2016-03-28-sra-submission-genome-sequencing-of-the-olympia-oyster-ostrea-lurida/index.html",
    "href": "posts/2016/2016-03-28-sra-submission-genome-sequencing-of-the-olympia-oyster-ostrea-lurida/index.html",
    "title": "SRA Submission – Genome sequencing of the Olympia oyster (Ostrea lurida)",
    "section": "",
    "text": "Adding our Olympia oyster genome sequencing (sequencing done by BGI) to the NCBI Sequence Read Archive (SRS). The current status can be seen in the screen cap below. Release date is set for a year from now, but will likely bump it up. Need Steven to review the details of the submission (BioProject, Experiment descriptions, etc.) before I initiate the public release. Will update this post with the SRA number once we receive it.\nHere’s the list of files uploaded to the SRA:\n151114_I191_FCH3Y35BCXX_L1_wHAIPI023992-37_1.fq.gz 151114_I191_FCH3Y35BCXX_L1_wHAIPI023992-37_2.fq.gz 151114_I191_FCH3Y35BCXX_L2_wHAMPI023991-66_1.fq.gz 151114_I191_FCH3Y35BCXX_L2_wHAMPI023991-66_2.fq.gz 151118_I137_FCH3KNJBBXX_L5_wHAXPI023905-96_1.fq.gz 151118_I137_FCH3KNJBBXX_L5_wHAXPI023905-96_2.fq.gz 160103_I137_FCH3V5YBBXX_L3_WHOSTibkDCABDLAAPEI-62_1.fq.gz 160103_I137_FCH3V5YBBXX_L3_WHOSTibkDCABDLAAPEI-62_2.fq.gz 160103_I137_FCH3V5YBBXX_L3_WHOSTibkDCACDTAAPEI-75_1.fq.gz 160103_I137_FCH3V5YBBXX_L3_WHOSTibkDCACDTAAPEI-75_2.fq.gz 160103_I137_FCH3V5YBBXX_L4_WHOSTibkDCABDLAAPEI-62_1.fq.gz 160103_I137_FCH3V5YBBXX_L4_WHOSTibkDCABDLAAPEI-62_2.fq.gz 160103_I137_FCH3V5YBBXX_L4_WHOSTibkDCACDTAAPEI-75_1.fq.gz 160103_I137_FCH3V5YBBXX_L4_WHOSTibkDCACDTAAPEI-75_2.fq.gz 160103_I137_FCH3V5YBBXX_L5_WHOSTibkDCAADWAAPEI-74_1.fq.gz 160103_I137_FCH3V5YBBXX_L5_WHOSTibkDCAADWAAPEI-74_2.fq.gz 160103_I137_FCH3V5YBBXX_L6_WHOSTibkDCAADWAAPEI-74_1.fq.gz 160103_I137_FCH3V5YBBXX_L6_WHOSTibkDCAADWAAPEI-74_2.fq.gz\nPaired-end sequencing files were uploaded together within a single “Run”. (http://eagle.fish.washington.edu/Arabidopsis/20160328_SRA_submission_oly_genome_seq.jpg)\nSRA Info: SRA: SRS1365663 Study: SRP072461 BioProject: PRJNA316624 BioSample: SAMN04588827"
  },
  {
    "objectID": "posts/2016/2016-07-27-data-analysis-pyrad-analysis-of-olympia-oyster-gbs-data/index.html",
    "href": "posts/2016/2016-07-27-data-analysis-pyrad-analysis-of-olympia-oyster-gbs-data/index.html",
    "title": "Data Analysis - PyRad Analysis of Olympia Oyster GBS Data",
    "section": "",
    "text": "Previously, I ran a PyRad analysis on just a subset of these samples in an attempt to have some data for a grant pre-proposal.\nI’ve now completed a PyRad analysis on the full set. Now, I just need to figure out what to do with the output from this…\nJupyter Notebook: 20160715_ec2_oly_gbs_pyrad.ipynb"
  },
  {
    "objectID": "posts/2016/2016-12-30-data-management-geoduck-rrbs-data-integrity-verification/index.html",
    "href": "posts/2016/2016-12-30-data-management-geoduck-rrbs-data-integrity-verification/index.html",
    "title": "Data Management - Geoduck RRBS Data Integrity Verification",
    "section": "",
    "text": "Yesterday, I downloaded the Illumina FASTQ files provided by Genewiz for Hollie Putnam’s reduced representation bisulfite geoduck libraries. However, Genewiz had not provided a checksum file at the time.\nI received the checksum file from Genewiz and have verified that the data is intact. Verification is described in the Jupyter notebook below.\nData files are located here: owl/web/nightingales/P_generosa\nJupyter notebook (GitHub): 20161230_docker_geoduck_RRBS_md5_checks.ipynb"
  },
  {
    "objectID": "posts/2016/2016-11-04-computing-retrieve-data-from-amazon-ec2-instance/index.html",
    "href": "posts/2016/2016-11-04-computing-retrieve-data-from-amazon-ec2-instance/index.html",
    "title": "Computing - Retrieve data from Amazon EC2 Instance",
    "section": "",
    "text": "I had an existing instance that still had data on it from my PyRad analysis on 20160727 that I needed to retrieve.\nLogged into Amazon AWS via the web interface and started my existing instance (via the Actions > Instance State > Start menu). After the instance started and generated a new public IP address, I SSH’d into the instance:\n<code>ssh -i \"/full/path/to/bioinformatics.pem\" ubuntu@instance.public.ip.address</code>\nNOTE: I needed the full path to the PEM file! Tried multiple times using a relative path (e.g. ~/Documents/bionformatics.pem) and received error messages that the file did not exist and “Permission denied (public key)”.\nChanged to the directory with the PyRAD analysis and created a tarball to speed up eventual download from the EC2 instance to my local computer:\n<code>tar -cvzf 20160715_pyrad_analysis.tar.gz /home/ubuntu/data/analysis/</code>\nAfter compression, I used secure copy to copy the file from the EC2 instance to my local computer:\n<code>scp -i \"/full/path/to/bioinformatics.pem\" ubuntu@instance.public.ip.address:/home/ubuntu/data/20160715_pyrad_analysis.tar.gz /Volumes/toaster/sam/</code>\nThis didn’t work initially because I attempted to transfer the file using Hummingbird (instead of my computer). The SSH connection kept timing out. The reason for this was that I hadn’t previously used Hummingbird to connect to the EC2 instance and Hummingbird’s IP address wasn’t listed in the Security Groups table as being allowed to connect. I made that change using the Amazon AWS web interface:\n(http://eagle.fish.washington.edu/Arabidopsis/20161104_ec2_security_groups.png)\nOnce transfer was complete, I terminated the EC2 instance and the corresponding data volume."
  },
  {
    "objectID": "posts/2016/2016-03-28-sra-submission-genome-sequencing-of-the-pacific-geoduck-panopea-generosa/index.html",
    "href": "posts/2016/2016-03-28-sra-submission-genome-sequencing-of-the-pacific-geoduck-panopea-generosa/index.html",
    "title": "SRA Submission – Genome sequencing of the Pacific geoduck (Panopea generosa)",
    "section": "",
    "text": "Adding our geoduck genome sequencing (sequencing done by BGI) to the NCBI Sequence Read Archive (SRS). The current status can be seen in the screen cap below. Release date is set for a year from now, but will likely bump it up. Need Steven to review the details of the submission (BioProject, Experiment descriptions, etc.) before I initiate the public release. Will update this post with the SRA number once we receive it.\nHere’s the list of files uploaded to the SRA:\n151114_I191_FCH3Y35BCXX_L1_wHAIPI023989-79_1.fq.gz 151114_I191_FCH3Y35BCXX_L1_wHAIPI023989-79_2.fq.gz 151122_I136_FCH3L2FBBXX_L7_wHAXPI023990-97_1.fq.gz 151122_I136_FCH3L2FBBXX_L7_wHAXPI023990-97_2.fq.gz 160103_I137_FCH3V5YBBXX_L3_WHPANwalDDAADWAAPEI-101_1.fq.gz 160103_I137_FCH3V5YBBXX_L3_WHPANwalDDAADWAAPEI-101_2.fq.gz 160103_I137_FCH3V5YBBXX_L4_WHPANwalDDAADWAAPEI-101_1.fq.gz 160103_I137_FCH3V5YBBXX_L4_WHPANwalDDAADWAAPEI-101_2.fq.gz 160103_I137_FCH3V5YBBXX_L5_WHPANwalDDABDLAAPEI-100_1.fq.gz 160103_I137_FCH3V5YBBXX_L5_WHPANwalDDABDLAAPEI-100_2.fq.gz 160103_I137_FCH3V5YBBXX_L5_WHPANwalDDACDTAAPEI-102_1.fq.gz 160103_I137_FCH3V5YBBXX_L5_WHPANwalDDACDTAAPEI-102_2.fq.gz 160103_I137_FCH3V5YBBXX_L6_WHPANwalDDABDLAAPEI-100_1.fq.gz 160103_I137_FCH3V5YBBXX_L6_WHPANwalDDABDLAAPEI-100_2.fq.gz 151114_I191_FCH3Y35BCXX_L2_wHAMPI023988-81_1.fq.gz 151114_I191_FCH3Y35BCXX_L2_wHAMPI023988-81_2.fq.gz 160103_I137_FCH3V5YBBXX_L6_WHPANwalDDACDTAAPEI-102_1.fq.gz 160103_I137_FCH3V5YBBXX_L6_WHPANwalDDACDTAAPEI-102_2.fq.gz\nMate pair sequencing files were uploaded together within a single “Run”.\n\nSRA info:\n\nBioProject PRJNA316601\nBioSample SAMN04588719\nwHAIPI023989-79: SRR3306093\nwHAMPI023988-81: SRR3306094\nwHAXPI023990-97: SRR3306300\nWHPANwalDDAADWAAPEI-101: SRR3306306\nWHPANwalDDABDLAAPEI-100: SRR3306307\nWHPANwalDDACDTAAPEI-102: SRR3306336"
  },
  {
    "objectID": "posts/2016/2016-08-01-goals-august-2016/index.html",
    "href": "posts/2016/2016-08-01-goals-august-2016/index.html",
    "title": "Goals - August 2016",
    "section": "",
    "text": "Complete Olympia oyster GBS data analysis - Progress has actually been made! After many struggles, I managed to get a PyRad analysis of the entire data set to complete. Now, I just have to figure out what to do with the output files…\nTroubleshoot Stacks analysis of Olympia oyster GBS data analysis - After switching computing to Amazon AWS, I thought this would be a breeze. However, the analysis keeps failing (without errors) on the “ustacks” portion of the pipeline; no output files are created even though the analysis runs (after 20hrs!!). Although it would be nice to get Stacks to complete successfully (just once!), now that I have a completed set of analysis from PyRad, troubleshooting this will be a little lower on the priority list.\nStart using Hyak - We need computing power and Hyak is a free resource. Although Amazon AWS is pretty sweet , it ends up being a bit costly…"
  },
  {
    "objectID": "posts/2016/2016-03-08-data-management-o-lurida-2brad-dec2015-undetermined-fastq-files/index.html",
    "href": "posts/2016/2016-03-08-data-management-o-lurida-2brad-dec2015-undetermined-fastq-files/index.html",
    "title": "Data Management - O.lurida 2bRAD Dec2015 Undetermined FASTQ files",
    "section": "",
    "text": "An astute observation by Katherine Sillimanrevealed that the FASTQ files I had moved to our high-throughput sequencing archive on our server Owl, only had two FASTQ files labeled as “undetermined”. Based on the number of lanes we had sequenced, we should have had many more. Turns out that the undetermined FASTQ files that were present in different sub-folders of the Genewiz project data were not uniquely named. Thus, when I moved them over (via a bash script), the undetermined files were continually overwritten, until we were left with only two FASTQ files labeled as undetermined.\nSo, I re-downloaded the entire project folder from Genewiz servers and renamed the FASTQ files labeled as undetermined and then copied them over to the archive on Owl:\nhttps://owl.fish.washington.edu/nightingales/O_lurida/2bRAD_Dec2015/\nI also zipped up the raw data project from Genewiz and moved it to the same archive location and updated the checksum.md5 and readme.md files.\nDetails can be found in the Jupyter (iPython) notebook below.\nJupyter Notebook file: 20160308_find_rename_2bRAD_undetermined_fastqs.ipynb\nNotebook Viewer: 20160308_find_rename_2bRAD_undetermined_fastqs.ipynb"
  },
  {
    "objectID": "posts/2016/2016-12-15-dna-isolation-ostrea-lurida-dna-for-pacbio-sequencing/index.html",
    "href": "posts/2016/2016-12-15-dna-isolation-ostrea-lurida-dna-for-pacbio-sequencing/index.html",
    "title": "DNA Isolation - Ostrea lurida DNA for PacBio Sequencing",
    "section": "",
    "text": "In an attempt to improve upon the partial genome assembly we received from BGI, we will be sending DNA to the UW PacBio core facility for additional sequencing.\nIsolated DNA from mantle tissue from the same Ostrea lurida individual used for the BGI sequencing efforts. Tissue was collected by Brent & Steven on 20150812.\nUsed the E.Z.N.A. Mollusc Kit (Omega) to isolate DNA from two separate 50mg pieces of mantle tissue according to the manufacturer’s protocol, with the following changes:\n\nSamples were homogenized with plastic, disposable pestle in 350μL of ML1 Buffer\nIncubated homogenate at 60C for 1.5hrs\nNo optional steps were used\nPerformed three rounds of 24:1 chloroform:IAA treatment\nEluted each in 50μL of Elution Buffer and pooled into a single sample\n\nQuantified the DNA using the Qubit dsDNA BR Kit (Invitrogen). Used 1μL of DNA sample.\nConcentration = 326ng/μL (Quant data is here [Google Sheet]: 20161214_gDNA_Olurida_qubit_quant\nYield is good and we have more than enough (~5μg is required for sequencing) to proceed with sequencing.\nEvaluated gDNA quality (i.e. integrity) by running ~500ng (1.5μL) of sample on 0.8% agarose, low-TAE gel stained with ethidium bromide.\nUsed 5μL of O’GeneRuler DNA Ladder Mix (ThermoFisher).\nResults:\n(https://github.com/sr320/LabDocs/blob/9073dc7caf2dcf40e7739fc7ce9d922b28468dc3/protocols/Commercial_Protocols/ThermoFisher_OgeneRuler_DNA_Ladder_Mix_F100439.jpg?raw=true)\n(http://eagle.fish.washington.edu/Arabidopsis/20161214_gel_Oly_gDNA.jpg)\nOverall, the gel looks OK. A fair amount of smearing, but a strong, high molecular weight band is present. The intensity of the smearing is likely due to the fact that the gel is overloaded for this particular well size. If I had used a broader comb and/or loaded less DNA, the band would be more defined and the smearing would be less prominent.\nWill submit sample to the UW PacBio facility tomorrow!"
  },
  {
    "objectID": "posts/2016/2016-11-07-data-management-modify-eagleowl-cloud-sync-account/index.html",
    "href": "posts/2016/2016-11-07-data-management-modify-eagleowl-cloud-sync-account/index.html",
    "title": "Data Management - Modify Eagle/Owl Cloud Sync Account",
    "section": "",
    "text": "Re-examining our backup options for our two Synology servers (Eagle & Owl), I realized that they were both backing up to the just my account on UW’s unlimited Google Drive storage.\nThe desired backup was to go to our shared UW account, so that others in the lab would have access to the backups.\nStrangely, I could not add the shared UW account (srlab) to my list of Google accounts. In order to verify the shared UW account with Google, I had to connect to the servers’ web interfaces in a private browsing session and then I was able to provide the correct user account info/permissions.\nAnyway, it’s all going to our shared UW account now."
  },
  {
    "objectID": "posts/2016/2016-11-07-data-management-modify-eagleowl-cloud-sync-account/index.html#select-google-drive-as-the-sync-provider",
    "href": "posts/2016/2016-11-07-data-management-modify-eagleowl-cloud-sync-account/index.html#select-google-drive-as-the-sync-provider",
    "title": "Data Management - Modify Eagle/Owl Cloud Sync Account",
    "section": "SELECT GOOGLE DRIVE AS THE SYNC PROVIDER:",
    "text": "SELECT GOOGLE DRIVE AS THE SYNC PROVIDER:\n(http://eagle.fish.washington.edu/Arabidopsis/Screenshot%202016-11-07%2009.52.08.png)"
  },
  {
    "objectID": "posts/2016/2016-11-07-data-management-modify-eagleowl-cloud-sync-account/index.html#shared-uw-account-is-not-a-choice",
    "href": "posts/2016/2016-11-07-data-management-modify-eagleowl-cloud-sync-account/index.html#shared-uw-account-is-not-a-choice",
    "title": "Data Management - Modify Eagle/Owl Cloud Sync Account",
    "section": "SHARED UW ACCOUNT IS NOT A CHOICE:",
    "text": "SHARED UW ACCOUNT IS NOT A CHOICE:\n(http://eagle.fish.washington.edu/Arabidopsis/Screenshot%202016-11-07%2009.52.33.png)"
  },
  {
    "objectID": "posts/2016/2016-11-07-data-management-modify-eagleowl-cloud-sync-account/index.html#try-add-account",
    "href": "posts/2016/2016-11-07-data-management-modify-eagleowl-cloud-sync-account/index.html#try-add-account",
    "title": "Data Management - Modify Eagle/Owl Cloud Sync Account",
    "section": "TRY “ADD ACCOUNT”:",
    "text": "TRY “ADD ACCOUNT”:\n(http://eagle.fish.washington.edu/Arabidopsis/Screenshot%202016-11-07%2009.52.46.png)"
  },
  {
    "objectID": "posts/2016/2016-11-07-data-management-modify-eagleowl-cloud-sync-account/index.html#but-add-account-doesnt-work-drop-down-menu-doesnt-offer-srlab-as-a-choice",
    "href": "posts/2016/2016-11-07-data-management-modify-eagleowl-cloud-sync-account/index.html#but-add-account-doesnt-work-drop-down-menu-doesnt-offer-srlab-as-a-choice",
    "title": "Data Management - Modify Eagle/Owl Cloud Sync Account",
    "section": "BUT ADD ACCOUNT DOESN’T WORK (DROP-DOWN MENU DOESN’T OFFER SRLAB AS A CHOICE)”",
    "text": "BUT ADD ACCOUNT DOESN’T WORK (DROP-DOWN MENU DOESN’T OFFER SRLAB AS A CHOICE)”\n(http://eagle.fish.washington.edu/Arabidopsis/Screenshot%202016-11-07%2009.53.11.png)"
  },
  {
    "objectID": "posts/2016/2016-11-07-data-management-modify-eagleowl-cloud-sync-account/index.html#repeat-steps-but-connect-to-synology-via-private-browsing-session-and-its-good-to-go",
    "href": "posts/2016/2016-11-07-data-management-modify-eagleowl-cloud-sync-account/index.html#repeat-steps-but-connect-to-synology-via-private-browsing-session-and-its-good-to-go",
    "title": "Data Management - Modify Eagle/Owl Cloud Sync Account",
    "section": "REPEAT STEPS, BUT CONNECT TO SYNOLOGY VIA PRIVATE BROWSING SESSION AND IT’S GOOD TO GO:",
    "text": "REPEAT STEPS, BUT CONNECT TO SYNOLOGY VIA PRIVATE BROWSING SESSION AND IT’S GOOD TO GO:\n(http://eagle.fish.washington.edu/Arabidopsis/Screenshot_2016-11-07_10_05_25.png)"
  },
  {
    "objectID": "posts/2016/2016-11-07-data-management-modify-eagleowl-cloud-sync-account/index.html#set-local-and-remote-folders",
    "href": "posts/2016/2016-11-07-data-management-modify-eagleowl-cloud-sync-account/index.html#set-local-and-remote-folders",
    "title": "Data Management - Modify Eagle/Owl Cloud Sync Account",
    "section": "SET LOCAL AND REMOTE FOLDERS:",
    "text": "SET LOCAL AND REMOTE FOLDERS:\n(http://eagle.fish.washington.edu/Arabidopsis/Screenshot%202016-11-07%2010.13.44.png)"
  },
  {
    "objectID": "posts/2016/2016-11-07-data-management-modify-eagleowl-cloud-sync-account/index.html#confirmation-that-its-set-up",
    "href": "posts/2016/2016-11-07-data-management-modify-eagleowl-cloud-sync-account/index.html#confirmation-that-its-set-up",
    "title": "Data Management - Modify Eagle/Owl Cloud Sync Account",
    "section": "CONFIRMATION THAT IT’S SET UP:",
    "text": "CONFIRMATION THAT IT’S SET UP:\n(http://eagle.fish.washington.edu/Arabidopsis/Screenshot%202016-11-07%2010.07.15.png)"
  },
  {
    "objectID": "posts/2016/2016-11-07-data-management-modify-eagleowl-cloud-sync-account/index.html#and-its-running",
    "href": "posts/2016/2016-11-07-data-management-modify-eagleowl-cloud-sync-account/index.html#and-its-running",
    "title": "Data Management - Modify Eagle/Owl Cloud Sync Account",
    "section": "AND, IT’S RUNNING:",
    "text": "AND, IT’S RUNNING:\n(http://eagle.fish.washington.edu/Arabidopsis/Screenshot%202016-11-07%2010.07.40.png)\n(http://eagle.fish.washington.edu/Arabidopsis/Screenshot%202016-11-07%2014.05.10.png)"
  },
  {
    "objectID": "posts/2016/2016-07-13-computing-the-very-quick-guide-to-amazon-web-services-cloud-computing-instances-ec2/index.html",
    "href": "posts/2016/2016-07-13-computing-the-very-quick-guide-to-amazon-web-services-cloud-computing-instances-ec2/index.html",
    "title": "Computing - The Very Quick “Guide” to Amazon Web Services Cloud Computing Instances (EC2)",
    "section": "",
    "text": "This all takes a surprisingly long time to set up.\nSetup AWS Identity and Access Management (IAM): https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction.html?icmpid=docs_iam_console\nInstall AWS command line interface: https://aws.amazon.com/cli/\nCopy files to S3 bucket:\n<code>aws s3 cp /Volumes/web/nightingales/O_lurida/20160223_gbs/160123_I132_FCH3YHMBBXX_L4_OYSzenG1AAD96FAAPEI-109_1.fq.gz s3://Samb</code>\n\n\n\n\n\n<code>aws s3 cp /Volumes/web/nightingales/O_lurida/20160223_gbs/160123_I132_FCH3YHMBBXX_L4_OYSzenG1AAD96FAAPEI-109_2.fq.gz s3://Samb</code>\nLaunch EC2 instance c4.2xlarge (Ubuntu 14.04 LTS, 8 vCPUs, 16 GiB RAM). Configured to have SSH open (TCP, port 22) and also to be able to access Jupyter Notebook via tunnel (TCP, port 8888). Set with “My IP” to limit access to these ports.\nCreate new key pair. Have to change permissions:\n<code>chmod 400 bioinformatics.pem</code>\nConnect to instance\nFor Amazon AMI:\n<code>ssh -i \"bioinformatics.pem\" ec2-user@ip.address.of.instance</code>\nFor Amazon Ubuntu Server:\n<code>ssh -i \"bioinformatics.pem\" ubuntu@ip.address.of.instance\n\n\n</code>\nUpdate/Upgrade default Ubuntu packages at after initial launch:\n<code>sudo apt-get update</code>\n\n\n\n\n\n<code>sudo apt-get upgrade</code>\nSet up Docker\nInstall Docker for Ubuntu 14.04 and copy our bioinformatics Dockerfile to the /home directory of the EC2 instance:\n<code>ssh -i \"bioinformatics.pem\" /Users/Sam/GitRepos/LabDocs/code/dockerfiles/Dockerfile.bio ubuntu@ip.address.of.instance:</code>\nAccess data stored in Amazon S3 bucket(s)\nMounting S3 storage as volume in EC2 instance requires https://github.com/s3fs-fuse/s3fs-fuse\nMount bucket:\n<code>sudo s3fs Samb /mnt/s3bucket/ -o passwd_file=/home/ubuntu/s3fs_creds</code>\nError:\n<code>s3fs: BUCKET Samb, name not compatible with virtual-hosted style.</code>\nTurns out, the error is due to the bucket name having an uppercase letter.\nMade new bucket in S3 (via web interface) and copied data files to the new bucket. Will try mounting again once the files are copied over (this will take awhile; the two files total 36GB).."
  },
  {
    "objectID": "posts/2016/2016-10-25-data-management-geoduck-small-insert-library-genome-assembly-from-bgi/index.html",
    "href": "posts/2016/2016-10-25-data-management-geoduck-small-insert-library-genome-assembly-from-bgi/index.html",
    "title": "Data Management – Geoduck Small Insert Library Genome Assembly from BGI",
    "section": "",
    "text": "Received another set of Panopea generosa genome assembly data from BGI back in May! I neglected to create MD5 checksums, as well as a readme file for this data set! Of course, I needed some of the info that the readme file should’ve had and it wasn’t there. So, here’s the skinny…\nIt’s data assembled from the small insert libraries they created for this project.\nAll data is stored here: https://owl.fish.washington.edu/P_generosa_genome_assemblies_BGI/20160512/\nThey’ve provided a [Genome Survey (PDF)(https://owl.fish.washington.edu/P_generosa_genome_assemblies_BGI/20160512/20160512_F15FTSUSAT0328_genome_survey.pdf) that has some info about the data they’ve assembled. In it, is the estimated genome size:\nGeoduck genome size: 2972.9 Mb\nAdditionally, there’s a table breaking down the N50 distributions of scaffold and contig sizes.\nData management stuff was performed in a Jupyter (iPython) notebook; see below.\nJupyter Notebook: 20161025_Pgenerosa_Small_Library_Genome_Read_Counts.ipynb"
  },
  {
    "objectID": "posts/2016/2016-07-14-dissection-frozen-geoduck-pacific-oyster/index.html",
    "href": "posts/2016/2016-07-14-dissection-frozen-geoduck-pacific-oyster/index.html",
    "title": "Dissection - Frozen Geoduck & Pacific Oyster",
    "section": "",
    "text": "We’re working on a project with Washington Department of Natural Resources’ (DNR) Micah Horwith to identify potential proteomic biomarkers in geoduck (Panopea generosa) and  Pacific oyster (Crassostrea gigas). One aspect of the project is how to best conduct sampling of juvenile geoduck (Panopea generosa) and Pacific oyster (Crassostrea gigas) to minimize changes in the proteome of ctenidia tissue during sampling. Generally, live animals are shucked, tissue dissected, and then the tissue is “snap” frozen. However, Micah’s crew will be collecting animals from wild sites around Puget Sound and, because of the remote locations and the means of collection, will have limited tools and time to perform this type of sampling. Time is a significant component that will have great impact on proteomic status in each individual.\nAs such, Micah and crew wanted to try out a different means of sampling that would help preserve the state of the proteome at the time of collection. Micah and crew have collected some juveniles of both species and “snap” frozen them in the field in a dry ice/ethanol bath in hopes of being able to best preserve the ctenidia proteome status. I’m attempting to dissect out the frozen ctenidia tissue from both types of animals and am reporting on the success/failure of this method of preservation-sampling protocol.\nTo test this, I transferred animals (contained in baggies) from the -80C to dry ice. Utensils and weigh boats were cooled on dry ice.\nResults:\nQuick summary: This method won’t and I think sampling will have to take place in the field.\nThe details of why this won’t work (along with images of the process) are below.\nFirst issue with this sampling method (and should be noted because I believe dry ice/ethanol baths will be used, even with a different sampling methodology) is that the ethanol in the dry ice bath at the time of animal collection is a potential problem for labeling baggies. Notice in the screenshot below that the label for the geoduck baggie (the baggie on the left) has, for all intents and purposes, completely washed off:\n(http://eagle.fish.washington.edu/Arabidopsis/DSC_1234.jpg)\nStarting with C.gigas, opening the animal was relatively easy. Granted, the animal has become brittle, but access to, and identification of, tissues ended up being pretty easy:\n(http://eagle.fish.washington.edu/Arabidopsis/DSC_1235.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/DSC_1236.jpg)\nHowever, dissecting out just ctenidia is a lost cause. The mantle and the ctendia are, essentially, fused together in a frozen block through the oyster. Although the image below might look like part of the shell, it is not. It is strictly a chunk of frozen ctenidia/mantle tissue:\n(http://eagle.fish.washington.edu/Arabidopsis/DSC_1237.jpg)\nThe geoduck were even more difficult. In fact, I couldn’t even manage to remove the soft tissue from the shell (for the uninitiated, there are two geoduck in the image below). I only managed to crush most of the tissue contained within the shell, making it even more impossible (if that’s possible) to identify and dissect out the ctenidia:\n(http://eagle.fish.washington.edu/Arabidopsis/DSC_1238.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/DSC_1239.jpg)"
  },
  {
    "objectID": "posts/2016/2016-05-03-gbs-frustrations/index.html",
    "href": "posts/2016/2016-05-03-gbs-frustrations/index.html",
    "title": "GBS Frustrations",
    "section": "",
    "text": "This isn’t really a notebook entry - it’s more of a traditional blog post.\nIt’s a quick summary of the frustrations and struggles I’ve encountered while trying to analyze the Olympia oyster GBS data. Hopefully it will serve as a place holder for others to find (and avoid) some of the pitfalls I’ve encountered so far. But, mostly, this is just for me to vent…\n\nUsing the Stacks program (on Hummingbird over the network to our server Owl) takes forever and, more importantly, consistently fails to complete the ustacks and cstacks programs.\nUsing the Stacks program (on Hummingbird via external HDD connected through Firewire) takes forever (combined, process_radtags and ustacks has been running since 20160428; that’s eight days)!!! Granted, this is running on all 96 samples, but, regardless, this type of time frame is not very conducive to productivity.\nThe “raw” non-demultiplexed fastq files supplied by BGI have a ‘N’ in the barcode in the FASTQ header lines. This prevents Stacks (and possibly Tassel - I’ll get to this in a second) from being able to perform the demultiplexing. Here’s a screen shot of what I’m talking about:\n\n(http://owl.fish.washington.edu/Athaliana/20160503_BGI_GBS_fastq_header_barcode.png)\n\nCyverse has a program called Tassel that should be able to handle GBS data just like ours. However, it doesn’t produce the expected output to proceed to the second step. Although I haven’t tested it, it’s possible that the problem is related to the ‘N’ in the FASTQ header barcode sequence I mentioned above. I suspect it’s related because the first step in using Tassel is demultiplexing utilizing a supplied barcode keyfile.\nCyverse has Stacks installed, but in order to use it, someone has to build a Cyverse “app.” I’ve tried and the process is brutal. It’s not conducive for a program (that is really a suite of programs) like Stacks that has so many command line options and, depending on your input file types (e.g. “non-standard” Illumina filenames for paired-end sequencing), requires looping over filenames to specify corresponding file pairs.\nPyrad actually worked relatively well, but the VCF output file (for visualizing in the Integrative Genomics Viewer) has an ill-formed header that IGV won’t accept. Attempts at tweaking the header don’t seem to resolve the issue. Additionally, it’s not apparent in the output files if individuals get grouped, even though there is an option to specify which individuals should be grouped together.\nAnd, the most frustrating thing of all???!!!  I just realized how to handle the problematic barcodes in the FASTQ headers!! Instead of trying to alter the FASTQ files (which I’ve been messing around with over the past few days), all I’ve needed to do this entire time is CHANGE THE BARCODE KEY FILE THAT STACKS AND/OR TASSEL USES TO HAVE A ‘N’ AT THE BEGINNING OF EACH BARCODE!\n\nI’m going to go cry now…\nRegardless of that last one, it doesn’t change the fact that Stacks is painfully slow and, at times, unreliable."
  },
  {
    "objectID": "posts/2016/2016-12-19-sample-submission-ostrea-lurida-gdna-for-pacbio-sequencing/index.html",
    "href": "posts/2016/2016-12-19-sample-submission-ostrea-lurida-gdna-for-pacbio-sequencing/index.html",
    "title": "Sample Submission - Ostrea lurida gDNA for PacBio Sequencing",
    "section": "",
    "text": "Submitted 10μg (30.7μL) of the O.lurida gDNA I isolated on 20161214 to the UW PacBio facility - Order #450.\nSequencing will be 10 SMRT cells. Turnaround time is ~7-8 weeks for UW customers (UW customers get queue priority)."
  },
  {
    "objectID": "posts/2016/2016-12-21-dna-isolation-geoduck-gdna-for-potential-illumina-initiated-sequencing-project/index.html",
    "href": "posts/2016/2016-12-21-dna-isolation-geoduck-gdna-for-potential-illumina-initiated-sequencing-project/index.html",
    "title": "DNA Isolation - Geoduck gDNA for Potential Illumina-initiated Sequencing Project",
    "section": "",
    "text": "We were approached by Cindy Lawley (Illumina Market Development) yesterday to see if we’d be able to participate in some product development. We agreed and need some geoduck DNA to send them, in case she’s able to get our species greenlighted for use.\nIsolated DNA from ctenidia tissue from the same Panopea generosa individual used for the BGI sequencing efforts. Tissue was collected by Brent & Steven on 20150811.\nUsed the E.Z.N.A. Mollusc Kit (Omega) to isolate DNA from two separate 50mg pieces of ctenidia tissue according to the manufacturer’s protocol, with the following changes:\n\nSamples were homogenized with plastic, disposable pestle in 350μL of ML1 Buffer\nIncubated homogenate at 60C for 1hr\nNo optional steps were used\nPerformed three rounds of 24:1 chloroform:IAA treatment\nEluted each in 50μL of Elution Buffer and pooled into a single sample\n\nQuantified the DNA using the Qubit dsDNA BR Kit (Invitrogen). Used 1μL of DNA sample.\nConcentration = 19.4ng/μL (Quant data is here [Google Sheet]: 20161221_gDNA_qubit_quant\nYield is low (~1.8μg), but have enough to satisfy the minimum of 1μg requested by Cindy Lawley.\nEvaluated gDNA quality (i.e. integrity) by running ~250ng (12.5μL) of sample on 0.8% agarose, low-TAE gel stained with ethidium bromide.\nUsed 5μL of O’GeneRuler DNA Ladder Mix (ThermoFisher).\nResults:\n\n\nOverall, the sample looks good. Strong, high molecular weight band is present with minimal smearing. However, there is a smear in the ~500bp range. This is most likely residual RNA. This is surprsing since the E.Z.N.A Mollusc Kit includes n RNase step. Regardless, having intact, high molecular weight DNA is the important part for this project. Will prepare to send remainder (~1.5μg) of geoduck to Illumina with other requested samples."
  },
  {
    "objectID": "posts/2016/2016-04-28-data-management-o-lurida-raw-bgi-gbs-fastq-data/index.html",
    "href": "posts/2016/2016-04-28-data-management-o-lurida-raw-bgi-gbs-fastq-data/index.html",
    "title": "Data Management - O.lurida Raw BGI GBS FASTQ Data",
    "section": "",
    "text": "BGI had previously supplied us with demultiplexed GBS FASTQ files. However, they had not provided us with the information/data on how those files were created. I contacted them and they’ve given us the two original FASTQ files, as well as the library index file and corresponding script they used for demultiplexing all of the files. The Jupyter (iPython) notebook below updates our checksum and readme files in our server directory that’s hosting the files: http://owl.fish.washington.edu/nightingales/O_lurida/20160223_gbs/\nSee Jupyter Notebook below for processing details.\nJupyter Notebook: 20160427_Oly_GBS_data_management.ipynb"
  },
  {
    "objectID": "posts/2016/2016-07-08-dna-methylation-quantification-coral-dna-from-jose-m-eirin-lopez-florida-international-university/index.html",
    "href": "posts/2016/2016-07-08-dna-methylation-quantification-coral-dna-from-jose-m-eirin-lopez-florida-international-university/index.html",
    "title": "DNA Methylation Quantification - Coral DNA from Jose M. Eirin-Lopez (Florida International University)",
    "section": "",
    "text": "Ran the coral DNA I quantified on 20160630 through the MethylFlash Methylated DNA Quantification Kit [Colorimetric] (Epigentek) kit to quantify global methylation.\nUsed 100ng of DNA per 8uL per replicate (x2 replicates = total 200ng in 16uL). Calcs are here (Google Sheet): 20160705_coral_DNA_methylation_calcs\nManufacturer’s protocol was followed.\nDilutions of kit reagents:\nME5 (1:1000) 2.6uL ME5 + 2597.4uL diluted ME1\nME6 (1:2000) 1.3uL ME6 + 2598.7uL diluted ME1\nME7 (1:5000) 0.52uL ME7 + 2599.48uL diluted ME1\nSamples were quantified on the Seeb’s plate reader @ 450nm  (Wallac 1420 Victor 2  [Perkin Elmer])\nResults:\nGoogle Sheet: 20160707_coral_DNA_methylflash\n\n\n\n\nsample\n\ntreatment\n\n5-mC(ng)\n\n\n\nH1_1\n\nnitrogen\n\n0.8712248853\n\n\n\nH1_10\n\nnitrogen\n\n0.6917168368\n\n\n\nH1_12\n\ncontrol\n\n0.2738478893\n\n\n\nH1_5\n\nnitrogen & phosphorous\n\n0.9663585942\n\n\n\nH1_6\n\ncontrol\n\n0.6494783825\n\n\n\nH1_8\n\nnitrogen & phosphorous\n\n0.4244913398\n\n\n\nH24_1\n\nnitrogen\n\n0.372603297\n\n\n\nH24_10\n\nnitrogen\n\n0.4237237786\n\n\n\nH24_12\n\ncontrol\n\n0.5350511937\n\n\n\nH24_5\n\nnitrogen & phosphorous\n\n0.1495527697\n\n\n\nH24_6\n\ncontrol\n\n0.2291900804\n\n\n\nH24_8\n\nnitrogen & phosphorous\n\n0.2213437801\n\n\n\nH5_1\n\nnitrogen\n\n-0.1233169902\n\n\n\nH5_10\n\nnitrogen\n\n0.6997668774\n\n\n\nH5_12\n\ncontrol\n\n0.2307000493\n\n\n\nH5_5\n\nnitrogen & phosphorous\n\n-0.07790933048\n\n\n\nH5_6\n\ncontrol\n\n0.4562401662\n\n\n\nH5_8\n\nnitrogen & phosphorous\n\n0.5949647121\n\n\n\n\n\nOverall, it’s difficult to really interpret these results. I believe the data is a time course (e.g. H5 = hour 5, H24 = hour 24). Additionally, looking at treatments, there appear to be replicates, but it’s not clear what type of replicates they are (i.e. technical or biological). Generally, it seems like the control samples have lower quantities of methylated DNA than the treated samples. However, this doesn’t hold true for all three of the groups.\nAnd, not that it really matters, but I don’t even know what species this is…\nIn any case, this was an attempt to gather some preliminary data for a grant that Steven is attempting to put together, so the original experiment and the subsequent data aren’t as robust as one would expect for a full-blown research project."
  },
  {
    "objectID": "posts/2016/2016-11-16-computer-management-additional-configurations-for-reformatted-xserves/index.html",
    "href": "posts/2016/2016-11-16-computer-management-additional-configurations-for-reformatted-xserves/index.html",
    "title": "Computer Management - Additional Configurations for Reformatted Xserves",
    "section": "",
    "text": "Sean got the remaining Xserves configured to run independently from the master node of the cluster they belonged to and installed OS X 10.11 (El Capitan).\nThe new computer names are Ostrich (formerly node004) and Emu (formerly node002).\nHe enabled remote screen sharing and remote access for them.\nSean also installed a working hard drive on Roadrunner and got that back up and running.\nI went through this morning and configured the computers with some other changes (some for my user account, others for the entire computer):\n\nRenamed computers to reflect just the corresponding bird name (hostnames had been labeled as “bird name’s Xserve”)\nCreated srlab user accounts\nChanged srlab user accounts to Standard instead of Administrative\nCreated steven user account\nTurned on Firewalls\nGranted remote login access to all users (instead of just Administrators)\nInstalled Docker Toolbox\nChanged power settings to start automatically after power failure\nAdded computer name to login screen via Terminal:\nsudo defaults write /Library/Preferences/com.ap.loginwindow LoginwindowText “TEXT GOES HERE”\nChanged computer HostName via Terminal so that Terminal displays computer name:\nsudo scutil –set HostName “TEXT GOES HERE”\nInstalled Mac Homebrew (I don’t know if installation of Homebrew is “global” - i.e. installs for all users)\nUsed Mac Homebrew to install wget\nUsed Mac Homebrew to install tmux"
  },
  {
    "objectID": "posts/2016/2016-04-11-data-management-concatenate-fastq-files-from-oly-mbdseq-project/index.html",
    "href": "posts/2016/2016-04-11-data-management-concatenate-fastq-files-from-oly-mbdseq-project/index.html",
    "title": "Data Management - Concatenate FASTQ files from Oly MBDseq Project",
    "section": "",
    "text": "Steven requested I concatenate the MBDseq files we received for this project:\n\nconcatenate the s4, s5, s6 file sets for each individual\nconcatenate the full file sets for each individual\n\nRan the concatenations in the Jupyter (iPython) notebook below. All files were saved to Owl/nightingales/O_lurida/2016\nJupyter Notebook: 20160411_Concatenate_Oly_MBDseq.ipynb\nNBviewer: 20160411_Concatenate_Oly_MBDseq"
  },
  {
    "objectID": "posts/2016/2016-04-27-computing-speed-benchmark-comparisons-between-local-external-server-files/index.html",
    "href": "posts/2016/2016-04-27-computing-speed-benchmark-comparisons-between-local-external-server-files/index.html",
    "title": "Computing - Speed Benchmark Comparisons Between Local, External, & Server Files",
    "section": "",
    "text": "I decided to run a quick test to see what difference in speed (i.e. time) we might see between handling files that are stored locally, on an external hard drive (HDD), or on our server (Owl).\nThis isn’t tightly controlled because it’s possible that other people were using resources on the server, thus slowing things down. However, this situation would be a true real world experience, so it is probably an accurate representation of what we’d experience on a daily basis.\nhttps://github.com/sr320/LabDocs/blob/master/jupyter_nbs/sam/20160427_speed_comparison.ipynb"
  },
  {
    "objectID": "posts/2016/2016-09-19-data-received-jays-coral-epiradseq-not-demultiplexed/index.html",
    "href": "posts/2016/2016-09-19-data-received-jays-coral-epiradseq-not-demultiplexed/index.html",
    "title": "Data Received – Jay’s Coral epiRADseq - Not Demultiplexed",
    "section": "",
    "text": "Previously downloaded Jay’s epiRADseq data that was provided by the Genomic Sequencing Laboratory at UC-Berkeley. It was provided already demultiplexed (which is very nice of them!). To be completionists on our end, we requested the non-demultiplexed data set.\nDownloaded the FASTQ files from the project directory to Owl/nightingales/Porites_spp:\n<code>time wget -r -np -nc --ask-password ftp://gslftp@gslserver.qb3.berkeley.edu/160830_100PE_HS4KB_L4</code>\nIt took awhile:\n<code>FINISHED --2016-09-19 11:39:21--\nTotal wall clock time: 4h 26m 21s\nDownloaded: 11 files, 36G in 4h 17m 18s (2.39 MB/s)</code>\nHere are the files:\n\nJD001_A_S1_L004_R2_001.fastq.gz\nJD001_A_S1_L004_R1_001.fastq.gz\nJD001_A_S1_L004_I1_001.fastq.gz\n160830_100PE_HS4KB_L4_Stats/\n\nAdapterTrimming.txt\nConversionStats.xml\nDemultiplexingStats.xml\nDemuxSummaryF1L4.txt\nFastqSummaryF1L4.txt\n\n\nGenerated MD5 checksums for each file:\n<code>for i in *.gz; do md5 $i >> checksums.md5; done</code>\nCalculate total number of reads for this sequencing run:\n<code>totalreads=0; for i in *S1*R*.gz; do linecount=`gunzip -c \"$i\" | wc -l`; readcount=$((linecount/4)); totalreads=$((readcount+totalreads)); done; echo $totalreads\n</code>\nTotal reads: 662,868,166 (this isn’t entirely accurate, as it is counting all three files; probably should’ve just counted the R1 and R2 files…)\nCalculate read counts for each file and write the data to the readme.md file in the Owl/web/nightingales/Porites_spp directory:\n<code>for i in *S1*R*.gz; do linecount=`gunzip -c \"$i\" | wc -l`; readcount=$(($linecount/4)); printf \"%s\\t%s\\n\" \"$i\" \"$readcount\" >> readme.md; done</code>\nSee this Jupyter notebook for code explanations.\nAdded sequencing info to [Next_Gen_Seq_Library_Database (Google Sheet)(https://docs.google.com/spreadsheets/d/1r4twxfBHpWfQoznbn2dAQhgMvmlZvQqW9I2_uVZX_aU/edit?usp=sharing) and the Nightingales Spreadsheet (Google Sheet) and Nightingales Fusion Table (Google Fusion Table)."
  },
  {
    "objectID": "posts/2016/2016-03-23-data-management-sra-submission-overview/index.html",
    "href": "posts/2016/2016-03-23-data-management-sra-submission-overview/index.html",
    "title": "Data Management - SRA Submission Overview",
    "section": "",
    "text": "We have an enormous backlog of high-throughput sequencing files (641 FASTQ files, to be exact) that we need/want to get added to the NCBI Sequence Read Archive (SRA).\nThis post provides a brief summary of what’s involved in the process (mostly via screen shots) and attempts to identify the various pitfalls/pains that I’ve already stumbled through trying to get a set of six FASTQ files submitted properly.\nOVERALL - It’s horrible and tedious.\nImportant things to note:\n\nOnce any of the three required components for SRA submission have been created (SRA, BioProject, and BioSamples), they can no longer be edited/deleted by the user! Understandable if they’ve already been publicly released, but if they’re still in pre-public release status, I think the user should be able to make changes as they see fit. As it currently stands, the user has to email the help desk at SRA and/or BioProjects to make any changes.\nExtremely difficult to figure out which information will show up (and where it will show up) in the final, formatted SRA record - no guide to this that I could find. Thus, if you screw it up, it’s a major, major hassle to try to change anything.\nWhen creating a “Run” (within an “Experiment”, within your SRA submission), only include sequencing files that provide the same data (e.g. if you have multiple sequence files, each generated from different individuals/samples, then you need to create a separate “Experiment” and “Run” for each of those files - otherwise, all files uploaded to a “Run” are combined into a single SRA file that loses any distinguishing info from the separate sequencing files).\nWhen creating a batch submission for BioSamples, there’s no way to set a Title attribute. This means all of your submissions (in my case) will have all have a title of “Invertebrate sample”. Considering that I will likely end up with dozens of BioSamples, that means there’s no easy way to distinguish them from each other without some extra clicking and poking around.\n\nHere’s the best way to proceed:\n\nCreate a BioProject. This will sit at the top of the hierarchy in the SRA submission and will be displayed as the STUDY associated with the SRA.\nCreate BioSample(s). This will be the next level of the hierarchy in the SRA submission and will be displayed as SAMPLE. This only shows up in the SRA when you create a new “Experiment”\nCreate SRA. This will end up encompassing any BioProject(s) and BioSample(s) that you need to include to describe the sequencing files you’re submitting to the SRA.\nCreate an Experiment.\nCreate a Run. This option is available once you’ve saved your experiment. This is where you provide your sequencing filename and associated MD5 checksum. This will also provide you with the login info to upload your sequencing files via FTP to NCBI servers. You can associate multiple sequencing files within a single run. This should be done if your sequencing files all provide data for the BioSample you selected. However, if you have sequencing files that are associated with different BioSamples, then you need to create an individual Experiment (and Run) for each BioSample!\n\nHere are some links that might come in handy (although, none are that great)…\nSRA Getting Started (helpful):\n\nhttps://trace.ncbi.nlm.nih.gov/Traces/sra/?cmd=show&f=sra_sub_expl&view=get_started\n\nSRA Metadata Overview (this is helpful):\n\nhttps://www.ncbi.nlm.nih.gov/sra/docs/submitmeta/\n\nSRA Submission Quick Start Guide (this is useful!):\n\nhttps://www.ncbi.nlm.nih.gov/sra/docs/submit/\n\nFTP Upload Instructions:\n\nhttps://www.ncbi.nlm.nih.gov/sra/docs/submitfiles/\n\nUser UN-friendly SRA Guide:\n\nhttps://www.ncbi.nlm.nih.gov/books/NBK47528/?report=reader\n\nAnd, here are the screen caps, roughly in chronological order of how the process presents itself. It’s too time consuming to caption any of these, so I’m putting them up for a reference. Also, all of the information seen in these screen caps has been deleted (because the entire submission was totally jacked up in multiple facets), so don’t look for any of the various submission IDs - they no longer exist. This is really just to visually show how many steps there are in order to get stuff submitted - it’s brutal."
  },
  {
    "objectID": "posts/2016/2016-04-06-software-install-samtools-0-1-19-and-stacks-1-37/index.html",
    "href": "posts/2016/2016-04-06-software-install-samtools-0-1-19-and-stacks-1-37/index.html",
    "title": "Software Install - samtools-0.1.19 and stacks-1.37",
    "section": "",
    "text": "Getting ready to analyze our Ostrea lurida genotype-by-sequencing data and wanted to use the Stacks software.\nWe have an existing version of Stacks on Hummingbird (the Apple server blade I will be running this analysis on), but I figured I might as well install the latest version (stacks-1.37).\nAdditionally, Stacks requires samtools-0.1.19 to run, which we did NOT have installed.\nI tracked all of this in the Jupyter (iPython) notebook below.\nDue to permissions issues during installation, I frequently had to leave the Jupyter notebook to run “sudo” in bash. As such, the notebook is messy, but does outline the necessary steps to get these two programs installed.\nJupyter notebook: 20160406_STACKS_install.ipynb\nNBviewer: 20160406_STACKS_install.ipynb"
  },
  {
    "objectID": "posts/2016/2016-08-22-server-hdd-failure-owl-2/index.html",
    "href": "posts/2016/2016-08-22-server-hdd-failure-owl-2/index.html",
    "title": "Server HDD Failure – Owl",
    "section": "",
    "text": "Noticed that Owl (Synology DS1812+ server) was beeping.\nI also noticed, just like the last time we had to replace a HDD in Owl, that I didn’t receive a notification email… As it turns out, this time the reason no notification email was received was due to the fact that I had changed my UW password and we use my UW account for authorizing usage of the UW email server through Owl. So, the emails Owl’s been trying to send have failed because the authorization password was no longer valid… Yikes!\nAnyway, I’ve updated the password on Owl for using the UW email servers and swapped out the bad drive with a backup drive we keep on hand for just such an occasion. See the first post about this subject for a bit more detail on the process of swapping hard drives.\nUnfortunately, the dead HDD is out of warranty, however we already have another backup drive on-hand.\nBelow are some screen caps of today’s incident:\n(http://eagle.fish.washington.edu/Arabidopsis/20160822_owl_hdd_replacement_04.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/20160822_owl_hdd_replacement_01.jpg)\n\nNotice the empty slot in the graphical representation of the disk layout, as well as the “Available Slots” showing 1.\n(http://eagle.fish.washington.edu/Arabidopsis/20160822_owl_hdd_replacement_02.jpg)\n\n\n\n\n\nAfter replacing the HDD (but before the system has rebuilt the new HDD), the empty slot is now represented as a green block and the “Available Slots” is now zero and “Unused Disks” is now 1.\n(http://eagle.fish.washington.edu/Arabidopsis/20160822_owl_hdd_replacement_03.jpg)"
  },
  {
    "objectID": "posts/2016/2016-08-01-computing-amazon-ec2-cost-analysis/index.html",
    "href": "posts/2016/2016-08-01-computing-amazon-ec2-cost-analysis/index.html",
    "title": "Computing - Amazon EC2 Cost “Analysis”",
    "section": "",
    "text": "I recently moved some computing jobs over to Amazon’s Elastic Cloud Computing (EC2) in attempt to avoid some odd computing issues/errors I kept encountering on our lab computers (Apple Xserve 3,1).\nThe big trade off here is that the lab computers are paid for and using EC2 means we’ll be sinking more money into computing resources. With that expense should come faster processing (i.e. less time) to perform various analyses. As they say, time is money…\nLet’s look at how things’ve worked out so far.\nFirst, how much did we spend and how did we spend it (click on the image to enlarge)?\n(http://eagle.fish.washington.edu/Arabidopsis/20160801_AmazonEC2_costs.jpg)\nOf course, it’s easy to see that for the instance I was running, it cost us $0.419/hr. That’s great and all, but you sort of lose sense of what that ends up costing over the long-term. Let’s look at how things break out over a larger time scale.\nAccording to Amazon’s (very useful!) billing breakdown, we spent $187 in the month of July 2016. This doesn’t seem too bad. In fact, this would only cost us ~$2200/yr if we continue to run this instance in this fashion. However, let’s look at it a bit further.\nWe see that the instance ran for a total of 374 hrs during July 2016. Divide that by 24hrs/day and we see that the instance was running for 15.6 days; just over half the month. That means we would’ve spent ~$374 for the full month, which would equate to $4488/yr. For our lab, that kind of money starts to add up and one starts to wonder if it wouldn’t be better to invest in higher end hardware to use in the lab with a single “sunk” cost that will last us many, many years.\nRegardless, with the lab’s current computing hardware, we should compare another factor that’s involved with the expense of using Amazon EC2 instead of our lab computers: time.\nI performed a very rough “guestimation” of the time savings that EC2 has provided us.\nI compared the length of “real” time for the first step in the PyRad program using the same data set on one of our lab computers (roadrunner) and the Amazon EC2 instance:\n\nroadrunner: 1118 minutes\nEC2: 771 minutes\n\nRoadrunner is nearly 1.5x slower than the EC2 instance! To really appreciate what type of impact that has, we should look at the run time for the full PyRad analysis:\n\nroadrunner: 5546 minutes (NOTE: Due to incomplete analysis, roadrunner time is “guestimated” as 1.45 x EC2; see below)\nEC2: 3825 minutes\n\nLet’s convert those numbers into something more easily understood - hours and days:\n\nroadrunner: 95hrs\nroadrunner: ~4 days\nEC2: 63hrs\nEC2: ~2.6 days\n\nOf course, these times don’t take into account any technical issues that we might encounter (and I have encountered many technical issues using roadrunner) on either platform, but I can tell you that I’ve not had any headaches using EC2 (other than unintentional, self-imposed ones).\nAnother potential option is trying out InsideDNA. They offer cloud computing services that are specifically geared towards high-throughput bioinformatics analysis. They have many, many bioinformatics tools already installed and available to use on their platform. Additionally, they have nice tutorials on how to use some of these tools, which goes a long ways in getting started on any analyses using new software. Here are the various pricing tiers that they offer:\n(http://eagle.fish.washington.edu/Arabidopsis/20160801_insideDNA_pricing.jpg)\nThe “Advanced” tier ($100/month) certainly seems like it could potentially be better than using Amazon. However, this tier only offers 500GB of storage. If you look up above at the Amazon pricing breakdown, you’ll notice that I’ve already used 466GB of storage for just that one experiment! Additionally, the 1000 CPU hours seems great, but remember, this is likely divided by the number of CPUs that you end up using. The Amazon EC2 instance was running eight cores. If I were to run a similar set up on InsideDNA, that would amount to 125 CPU hours per core. Again, looking up above, we see that I ran the EC2 instance for 374 hours! That means the “Advanced” tier on InsideDNA wouldn’t be enough to get our jobs done.\nAnyway, in the grand scheme of things, using an Amazon EC2 instance periodically as we need it throughout the year isn’t terrible. However, if we start using the University of Washington Hyak computing cluster we may be able to avoid spending on EC2 and be able to have similar time savings (compared to using the lab computers). Need to get cracking on that…"
  },
  {
    "objectID": "posts/2016/2016-01-14-data-analysis-identification-of-duplicate-files-on-eagle/index.html",
    "href": "posts/2016/2016-01-14-data-analysis-identification-of-duplicate-files-on-eagle/index.html",
    "title": "Data Analysis - Identification of duplicate files on Eagle",
    "section": "",
    "text": "Recently, we’ve been bumping into our storage limit on Eagle (our Synology DS413):\n(http://eagle.fish.washington.edu/Arabidopsis/20160114_eagle_storage.jpg)\nBeing fairly certain that there’s a significant amount of large datasets that is duplicated throughout Eagle, I ran a program on Linux called “fslint”. It searches for duplicates files based on a few parameters and is smart enough to be able to compare files with different filenames that share the same file contents!\nI decided to check for duplicate files in the Eagle/archive folder and the Eagle/web folder. Initially, I tried searching for duplicates across all of Eagle, but after a week of running I got tired of waiting for results and ran the analysis on those two directories independently. As such, there is a possibility that there are more duplicates (consuming even more space) across the remainder of Eagle that have not been identified. However, this is a good starting point.\nHere are the two output files from the fslint analysis:\n\n20160104_duplicate_files_eagle_web.txt\n20151229_duplicate_files_eagle_archive.txt\n\nTo get a summary of the fslint output, I tallied the total amount of duplicates files that were >100MB in size. This was performed in a Jupyter notebook (see below): Notebook Viewer: 20160114_wasted_space_synologies.ipynb Jupyter (IPython) Notebook File: 20160114_wasted_space_synologies.ipynb \nHere are the cleaned output files from the fslint analysis:\n\n20151229_duplicate_files_eagle_archive_cleaned.txt\n20151229_duplicate_files_eagle_web_cleaned.txt\n\nSummary\nThere are duplicates of files (>100MB in size) that are consuming at least 730GB!\nSince the majority of these files exist in the Eagle/web folder, careful consideration will have to be taken in determining which duplicates (if any) can be deleted since it’s highly possible that there are notebooks that link to some of the files. Regardless, this analysis shows just how space is being consumed by the presence of large, duplicate files; something to consider for future data handling/storage/analysis with Eagle."
  },
  {
    "objectID": "posts/2016/2016-06-01-docker-improving-roberts-lab-reproducibility/index.html",
    "href": "posts/2016/2016-06-01-docker-improving-roberts-lab-reproducibility/index.html",
    "title": "Docker - Improving Roberts Lab Reproducibility",
    "section": "",
    "text": "In an attempt at furthering our lab’s abilities to maximize our reproducibility, I’ve been  working on developing an all-encompassing Docker image. Docker is a type of virtual machine (i.e. a self-contained computer that runs within your computer). For the Roberts Lab, the advantage of using Docker is that the Docker images can be customized to run a specific suite of software and these images can then be used by any other person in the lab (assuming they can run Docker on their particular operating system), regardless of operating system. In turn, if everyone is using the same Docker image (i.e. the same virtual machine with all the same software), then we should be able to reproduce data analyses more reliably, due to the fact that there won’t be differences between software versions that people are using. Additionally, using Docker greatly simplifies the setup of new computers with the requisite software.\nI’ve put together a Dockerfile (a Dockerfile is a text file/script that Docker uses to retrieve software and build a computer image with those specific instructions) which will automatically build a Docker image (i.e. virtual computer) that contains all of the normal bioinformatics software our lab uses. This has been a side project while I wait for Stacks analysis to complete (or, fail, depending on the day) and it’s finally usable! The image that is built from this Dockerfile will even let the user run R Studio and/or Jupyter Notebooks in their browser (I’m excited about this part)!\nHere’s the current list of software that will be installed:\n\n\n\n\n\nbedtools 2.25.0\n\n\n\n\n\n\n\n\n\nbismark 0.15.0\n\n\n\n\nblast 2.3.0+\n\n\n\n\nbowtie2 2.2.8\n\n\n\n\nbsmap 2.90\n\n\n\n\ncufflinks 2.1.1\n\n\n\n\nfastqc 0.11.5\n\n\n\n\nfastx_toolkit 0.0.13\n\n\n\n\nR 3.2.5\n\n\n\n\nRStudio Server0.99\n\n\n\n\npyrad 3.0.66\n\n\n\n\nsamtools 0.1.19\n\n\n\n\nstacks 1.40\n\n\n\n\ntophat 2.1.1\n\n\n\n\n\n\n\n\n\ntrimmomatic 0.36\n\n\n\n\n\nIn order to set this up, you need to install Docker and download the Dockerfile (Dockerfile.bio) I’ve created.\nI’ve written a bit of a user guide (specific to this Dockerfile) here to get people started: docker.md\nThe user guide explains a bit how all of this works and tries to progress from a “basic” this-is-how-to-get-started-with-Docker to an “advanced” description of how to map ports, mount local volumes in your containers, and how to start/attach previously used containers.\nThe next major goal I have with this Docker project is to get the R kernel installed for Jupyter Notebooks. Currently, the Jupyter Notebook installation is restricted to the default Python 2 kernel.\nAdditionally, I’d like to improve the usability of the Docker image by setting up aliases in the image. Meaning, a user who wants to use the bowtie program can just type “bowtie”. Currently, the user has to type “bowtie2_2.2.8” (although, with this being in the system PATH and tab-completion, it’s not that big of a deal), which is a bit ugly.\nFor some next level stuff, I’d also like to setup all Roberts Lab computers to automatically launch the Docker image when the user opens a terminal. This would greatly simplify things for new lab members. They wouldn’t have to deal with going through the various Docker commands to start a Docker container. Instead, their terminal would just put them directly into the container and the user would be none-the-wiser. They’d be reproducibly conducting data analysis without even having to think about it."
  },
  {
    "objectID": "posts/2016/2016-04-18-data-analysis-subset-olympia-oyster-gbs-data-from-bgi-as-single-population-using-pyrad/index.html",
    "href": "posts/2016/2016-04-18-data-analysis-subset-olympia-oyster-gbs-data-from-bgi-as-single-population-using-pyrad/index.html",
    "title": "Data Analysis - Subset Olympia Oyster GBS Data from BGI as Single Population Using PyRAD",
    "section": "",
    "text": "Attempting to get some sort of analysis of the Ostrea lurida GBS data from BGI, particularly since the last run at it using Stacks crashed (literally) and burned (not literally).\nKatherine Silliman at UIC recommended using PyRAD.\nI’ve taken the example Jupyter notebook from the PyRAD website and passed a subset of the 96 individuals through it.\nIn this instance, the subset of individuals were all analyzed as a single population. I have another Jupyter notebook running on a different computer that will separate the three populations that are present in this subset.\nOverall, I don’t fully understand the results. However, this seems to be the quickest assessment of the data (from the *.snps file generated):\n28 individuals, 36424 loci, 72251 snps\nAdditionally, I did run into an issue when I tried to visualize the data (using the *.vcf file generated) in IGV (see screen cap below). I’ve posted the issue to the pyrad GitHub repo in hopes of getting it resolved.\n(http://eagle.fish.washington.edu/Arabidopsis/20160419_IGV_pyrad_vcf_index_error.jpg)\nOne last thing. This might be obvious to most, but I discovered that trying to do all this computation over the network (via a mounted server share) is significantly slower than performing these operations on th efiles when they’re stored locally. Somewhere in the notebook you’ll notice that I copy all of the working directory from the server (Owl) to the local machine (Hummingbird). Things proceeded very quickly after doing that. Didn’t realize this would have so much impact on speed!!\nJupyter Notebook: 20160418_pyrad_oly_PE-GBS.ipynb\nNBviewer: 20160418_pyrad_oly_PE-GBS"
  },
  {
    "objectID": "posts/2016/2016-06-09-ram-upgrade-roadrunner-apple-xserve-to-48gb-ram/index.html",
    "href": "posts/2016/2016-06-09-ram-upgrade-roadrunner-apple-xserve-to-48gb-ram/index.html",
    "title": "RAM Upgrade - Roadrunner (Apple Xserve) to 48GB RAM",
    "section": "",
    "text": "We received the new 48GB RAM set we ordered from Other World Computing for the Apple Xserve (roadrunner) that I installed El Capitan (OS X 10.11.5) on two weeks ago.\nI installed it and this computer (which was plenty quick before) is extremely responsive now!\nBelow are some pics from the installation:\n(http://eagle.fish.washington.edu/Arabidopsis/Pics/20160609_RAM_48GB.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/Pics/20160609_xserve_cluster.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/Pics/20160609_xserve_clip.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/Pics/20160609_xserve_inside_old_RAM_01.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/Pics/20160609_xserve_inside_new_RAM_01.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/Pics/20160609_xserve_inside_new_RAM_02.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/Pics/20160609_roadrunner_screen.jpg)"
  },
  {
    "objectID": "posts/2016/2016-03-23-sra-submission-individual-transcriptomic-profiles-of-c-gigas-before-after-heat-shock/index.html",
    "href": "posts/2016/2016-03-23-sra-submission-individual-transcriptomic-profiles-of-c-gigas-before-after-heat-shock/index.html",
    "title": "SRA Submission - Individual Transcriptomic Profiles of C.gigas Before & After Heat Shock",
    "section": "",
    "text": "RNA-seq experiment conducted by Claire in 2013.\nShe sampled mantle tissue from three adult oysters, allowed them to recover from the sampling (one week?) and then subjected those same oysters to a 1hr heat shock at 40C and collected mantle tissue from them again.\nAs this is our first Small Read Archive (SRA) submission in many years, I decided to submit these to the SRA due to the small number of samples (6) from the Illumina sequencing we had done to make sure it was manageable.\nAn overview of the basic SRA submission process is here.\nThe current status can be seen in the screen cap below. Current release date is set for a year from now, but will likely bump it up. Need Steven to review the details of the submission (BioProject, Experiment descriptions, etc.) before I initiate the public release. Will update this post with the SRA number once we receive it.\nHere’s the list of files uploaded to the SRA:\n2M-HS_CCGTCC_L001_R1_001.fastq.gz 2M_AGTCAA_L001_R1_001.fastq.gz 4M-HS_GTCCGC_L001_R1_001.fastq.gz 4M_AGTTCC_L001_R1_001.fastq.gz 6M-HS_GTGAAA_L001_R1_001.fastq.gz 6M_ATGTCA_L001_R1_001.fastq.gz\nSRA Accession: SRP072251\n(http://eagle.fish.washington.edu/Arabidopsis/20160323_SRA_submission.jpg)"
  },
  {
    "objectID": "posts/2016/2016-07-14-computing-a-very-quick-guide-to-amazon-ec2-continued/index.html",
    "href": "posts/2016/2016-07-14-computing-a-very-quick-guide-to-amazon-ec2-continued/index.html",
    "title": "Computing - A Very Quick “Guide” to Amazon EC2 Continued",
    "section": "",
    "text": "Yesterday’s post ended with me trying to mount a S3 bucket to my EC2 instance using s3fs-fuse.\nWaited for the 36GB of data to copy over to new bucket with proper naming (i.e. no capital letters in name). Copying took hours; left lab before copying completed.\n(http://eagle.fish.washington.edu/Arabidopsis/20160714_s3f2_mount_error.jpg)\nSo, that didn’t work. The reason that it doesn’t work is that I uploaded the files to the S3 bucket via the Amazon AWS command line (awscli). Apparently, s3fs-fuse can’t mount S3 buckets that contain data uploaded via awscli [see this GitHub Issue for s3fs-fuse! However, I had to upload them via awscli because the web interface kept failing!\nThat means I need to upload the data directly to my EC2 instance, but my EC2 instance is set with the default storage capacity of 8GB so I need to increase the capacity to accommodate my two large files, as well as the anticipated intermediate files that will be generated by the types of analysis I plan on running. I’m guessing I’ll need at least 100GB to be safe. To do this, I have to expand the Elastic Block Storage (EBS) volume of my instance. The rest of stuff below is fully explained and covered very well in the EBS expansion link I have in the previous sentence.\nDon’t be fooled into thinking I figured any of this out on my own!\nExpanding the EC2 Instance\nThe initial part of the process is creating a Snapshot of my instance. This took a long time (2.5hrs). However, I did finally decide to refresh the page when I noticed that the “Status” progress bar hadn’t moved beyond 46% for well over an hour. After refreshing, the “Status” showed “Complete.” Maybe this actually was ready to go much faster, but the page didn’t automatically refresh? Regardless, in retrospect, since this EC2 instance is pretty much brand new and doesn’t have too many changes from when it was initialized, I probably should’ve just created a brand new EC2 instance with the desired amount of EBS…\nCreated volume from that Snapshot with 150GB of magnetic storage.\nAttached volume to the EC2 instance at /dev/sda1 (the default setting /dev/sdf resulted in an error message about the instance not having a root volume) and SSH’d into the instance. Odd, it seems to show that I still only have 8GB of storage (see the “Usage of…” in the screenshot below):\n(http://eagle.fish.washington.edu/Arabidopsis/20160714_ec2_expanded_volume_01.png)\nCheck to see if I actually have the expanded storage volume or not. It turns out, I do! (notice that the only drive listed is “xvda” and its partition, “xvda/xvda1” AND they are equal in size; 150G):\n(http://eagle.fish.washington.edu/Arabidopsis/20160714_ec2_expanded_volume_03.jpg)\nTime to upload (via the secure copy command) the files to my EC2 instance! The following commands upload the files to a folder called “data” in my /home directory. I also ran the “time” command at the beginning to get an idea of how long it takes to upload each of these files.\n<code>time scp -i ~/Dropbox/Lab/Sam/bioinformatics.pem /Volumes/web/nightingales/O_lurida/20160223_gbs/160123_I132_FCH3YHMBBXX_L4_OYSzenG1AAD96FAAPEI-109_1.fq.gz ubuntu@ec2.ip.address:~/data</code>\n\n\n\n\n\n<code>time scp -i ~/Dropbox/Lab/Sam/bioinformatics.pem /Volumes/web/nightingales/O_lurida/20160223_gbs/160123_I132_FCH3YHMBBXX_L4_OYSzenG1AAD96FAAPEI-109_2.fq.gz ubuntu@ec2.ip.address:~/data</code>\nDetails on upload times and file sizes:\n(http://eagle.fish.washington.edu/Arabidopsis/20160714_ec2_upload_times.png)\nConfim the files now reside in my EC2 instance:\n(http://eagle.fish.washington.edu/Arabidopsis/20160714_ec2_confirm_transfer.jpg)\nAlas, I should’ve captured all of this in a Jupyter Notebook. However, I didn’t because I thought I would need to enter passwords (which you can’t do with a Jupyter Notebook). It turns out, I didn’t need a password for anything; even when using “sudo” on the EC2 instance. Oh well, it’s set up and running with my data finally accessible. That’s all that really matters here.\nAlrighty, time to get rolling on some data analysis with a fancy new Amazon EC2 instance!!!"
  },
  {
    "objectID": "posts/2016/2016-12-15-data-management-integrity-check-of-final-bgi-olympia-oyster-geoduck-data/index.html",
    "href": "posts/2016/2016-12-15-data-management-integrity-check-of-final-bgi-olympia-oyster-geoduck-data/index.html",
    "title": "Data Management - Integrity Check of Final BGI Olympia Oyster & Geoduck Data",
    "section": "",
    "text": "After completing the downloads of these files from BGI, I needed to verify that the downloaded copies matched the originals. Below is a Jupyter Notebook detailing how I verified file integrity via MD5 checksums. It also highlights the importance of doing this check when working with large sequencing files (or, just large files in general), as a few of them had mis-matching MD5 checksums!\nAlthough the notebook is embedded below, it might be easier viewing via the notebook link (hosted on GitHub).\nAt the end of the day, I had to re-download some files, but all the MD5 checksums match and these data are ready for analysis:\nFinal Ostrea lurida genome files\nFinal Panopea generosa genome files\nJupyter Notebook: 20161214_docker_BGI_data_integrity_check.ipynb"
  },
  {
    "objectID": "posts/2016/2016-08-17-data-analysis-faststructure-population-analysis-of-oly-gbs-pyrad-output/index.html",
    "href": "posts/2016/2016-08-17-data-analysis-faststructure-population-analysis-of-oly-gbs-pyrad-output/index.html",
    "title": "Data Analysis - fastStructure Population Analysis of Oly GBS PyRAD Output",
    "section": "",
    "text": "After some basal readings about what Fst is (see notebook below for a definition and reference), I decided to try to use fastStructure to analyze the PyRAD output from 20160727.\nThe quick, TL;DR: after spending a bunch of time installing the program, it doesn’t handle the default Structure file (.str); requires some companion file types that PyRAD doesn’t output.\nI’ve put this here for posterity and background reference on Fst…\nWill proceed with using the full blown Structure program to try to glean some info from these three populations.\nJupyter Notebook: 20160816_oly_gbs_fst_calcs.ipynb"
  },
  {
    "objectID": "posts/2016/2016-12-02-data-analysis-continued-o-lurida-fst-analysis-from-gbs-data/index.html",
    "href": "posts/2016/2016-12-02-data-analysis-continued-o-lurida-fst-analysis-from-gbs-data/index.html",
    "title": "Data Analysis - Continued O.lurida Fst Analysis from GBS Data",
    "section": "",
    "text": "Continued the analysis I started the other day. Still following Katherine Silliman’s notebook for guidance.\nQuick summary of this analysis:\n\nMean Fst comparing all populations = 0.139539326187024\nMean Fst HL vs NF = 0.143075552548742\nMean Fst HL vs SN = 0.155234939276722\nMean Fst NF vs SN = 0.117889300124951\n\nNOTE: Mean Fst values were calculated after replacing negative Fst values with 0. Thus, the means are higher than they would be had the raw data been used. I followed Katherine’s notebook and she doesn’t explicitly explain why she does this, nor what the potential implications are for interpreting the data. Will have to discus her rationale behind this with her.\nJupyter notebook: 20161201_docker_oly_vcf_analysis_R.ipynb"
  },
  {
    "objectID": "posts/2016/2016-09-06-goals-september-2016/index.html",
    "href": "posts/2016/2016-09-06-goals-september-2016/index.html",
    "title": "Goals - September 2016",
    "section": "",
    "text": "Whoops! It’s already September 6th! The 1st of the month came and went without me noticing.\nOne goal for this month: Write up and submit Olympia oyster genotype-by-sequencing (GBS) data to Scientific Data for publication."
  },
  {
    "objectID": "posts/2016/2016-07-18-computing-not-enough-power/index.html",
    "href": "posts/2016/2016-07-18-computing-not-enough-power/index.html",
    "title": "Computing - Not Enough Power!",
    "section": "",
    "text": "Well, I tackled the storage space issue by expanding the EC2 Instance to have a 1000GB of storage space. Now that that’s no longer a concern, it turns out I’m running up against processing/memory limits!\nI’m running the EC2 c4.2xlarge (Ubuntu 14.04 LTS, 8 vCPUs, 16 GiB RAM) instance.\nI’m trying to run two programs simultaneously: PyRad and Stacks (specifically, the ustacks “sub” program).\nPyRad keeps crashing with some memory error stuff (see embedded Jupyter Notebook at the end of this post).\nUsed the following Bash program to visualize what’s happening with the EC2 Instance resources (i.e. processors and RAM utilization):\n<code>htop</code>\nDownloaded/installed to EC2 Instance using:\n<code>sudo apt-get install htop</code>\nI see why PyRad is dying. Here are two screen captures that show what resources are being used (click to see detail):\n(http://eagle.fish.washington.edu/Arabidopsis/20160718_ec2_ustacks_cpus.png)\n(http://eagle.fish.washington.edu/Arabidopsis/20160718_ec2_ustacks_mem.png)\nThe top image shows that ustacks is using 100% of all eight CPUs!\nThe second image shows when ustacks is finishing with one of the files it’s processing, it uses all of the memory (16GBs)!\nSo, I will have to wait until ustacks is finished running before being able to continue with PyRad.\nIf I want to be able to run these simultaneously, I can (using either of these options still requires me to wait until ustacks completes in order to manipulate the current EC2 instance to accommodate either of the two following options):\n\nIncrease the computing resources of this EC2 Instance\nCreate an additional EC2 Instance and run PyRad on one and Stacks programs on the other.\n\nHere’s the Jupyter Notebook with the PyRad errors (see “Step 3: Clustering” section):\n<code><iframe src=\"https://render.githubusercontent.com/view/ipynb?commit=f9a4627317620dc69e7c7502aec1894f10ac3254&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f73723332302f4c6162446f63732f663961343632373331373632306463363965376337353032616563313839346631306163333235342f6a7570797465725f6e62732f73616d2f32303136303731355f6563325f6f6c795f6762735f70797261642e6970796e62&nwo=sr320%2FLabDocs&path=jupyter_nbs%2Fsam%2F20160715_ec2_oly_gbs_pyrad.ipynb&repository_id=13746500#a22d1ce9-8f2d-419d-a0a5-446aba32da60\" width=\"100%\" height=\"2000\" scrolling=\"yes\"></iframe>\n</code>"
  },
  {
    "objectID": "posts/2016/2016-07-14-filter-replacement-xserve-server-rack-enclosure/index.html",
    "href": "posts/2016/2016-07-14-filter-replacement-xserve-server-rack-enclosure/index.html",
    "title": "Filter Replacement - Xserve Server Rack Enclosure",
    "section": "",
    "text": "Replaced the filters on the rack enclosure that houses the Apple Xserver server blades we have in the lab."
  },
  {
    "objectID": "posts/2016/2016-05-02-goals-may-2016/index.html",
    "href": "posts/2016/2016-05-02-goals-may-2016/index.html",
    "title": "Goals - May 2016",
    "section": "",
    "text": "Well, I guess the first goal is to remember to be more consistent about writing monthly goals…\nAnyway, here they are - short and sweet. Most of them are really part of a to-do list, as opposed to goals, but I’ll still put them down.\n\nAnalyze Olympia oyster GBS data\nContinue NGS archiving via SRA submissions\nContinue to work on building functional Docker image to improve laboratory reproducibility\nBuild Stacks app in Cyverse Discovery Environment\nStart using the UW Hyak computing cluster."
  },
  {
    "objectID": "posts/2016/2016-12-14-data-managment-trim-output-cells-from-jupyter-notebook/index.html",
    "href": "posts/2016/2016-12-14-data-managment-trim-output-cells-from-jupyter-notebook/index.html",
    "title": "Data Managment - Trim Output Cells from Jupyter Notebook",
    "section": "",
    "text": "Last week I downloaded the final BGI data files and assemblies for Olympia oyster and geoduck genome sequencing projects. However, the output from the download command made the Jupyter Notebook files too large to view and/or upload to GitHub. So, I had to trim the output cells from that notebook in order to render it usable/viewable.\nThe notebook below details how I did that and also examines the original version of that jumbo notebook to give some idea of what the command outputs were, for posterity.\nJupyter Notebook: 20161214_docker_notebook_trimming.ipynb"
  },
  {
    "objectID": "posts/2016/2016-06-14-docker-virtualbox-defaults-on-os-x/index.html",
    "href": "posts/2016/2016-06-14-docker-virtualbox-defaults-on-os-x/index.html",
    "title": "Docker - VirtualBox Defaults on OS X",
    "section": "",
    "text": "I noticed a discrepancy between what system info is detected natively on Roadrunner (Apple Xserve) and what was being shown when I started a Docker container.\nHere’s what Roadrunner’s system info looks like outside of a Docker container:\n(http://eagle.fish.washington.edu/Arabidopsis/20160613_roadrunner_system.png)\nHowever, here’s what is seen when running a Docker container:\n(http://eagle.fish.washington.edu/Arabidopsis/20160613_roadrunner_docker_default_system.png)\nIt’s important to notice the that the Docker container is only seeing 2 CPUs. Ideally, the Docker container would see that this system has 8 cores available. By default, however, it does not. In order to remedy this, the user has to adjust settings in VirtualBox. VirtualBox is a virtual machine thingy that gets installed with the Docker Toolbox for OS X. Apparently, Docker runs within VirtualBox, but this is not really transparent to a beginner Docker user on OS X.\nTo change the way VirtualBox (and, in turn, Docker) can access the full system hardware, you must launch the VirtualBox application (if you installed Docker using Docker Toolbox, you should be able to find this in your Applications folder). Once you’ve launched VirtualBox, you’ll have to turn off the virtual machine that’s currently running. Once that’s been accomplished, you can make changes and then restart the virtual machine."
  },
  {
    "objectID": "posts/2016/2016-06-14-docker-virtualbox-defaults-on-os-x/index.html#shutdown-virtualbox-machine-before-you-can-make-changes",
    "href": "posts/2016/2016-06-14-docker-virtualbox-defaults-on-os-x/index.html#shutdown-virtualbox-machine-before-you-can-make-changes",
    "title": "Docker - VirtualBox Defaults on OS X",
    "section": "Shutdown VirtualBox machine before you can make changes:",
    "text": "Shutdown VirtualBox machine before you can make changes:\n(http://eagle.fish.washington.edu/Arabidopsis/20160613_virtualbox_shutdown.png)"
  },
  {
    "objectID": "posts/2016/2016-06-14-docker-virtualbox-defaults-on-os-x/index.html#here-are-the-default-cpu-settings-that-virtualbox-is-using",
    "href": "posts/2016/2016-06-14-docker-virtualbox-defaults-on-os-x/index.html#here-are-the-default-cpu-settings-that-virtualbox-is-using",
    "title": "Docker - VirtualBox Defaults on OS X",
    "section": "Here are the default CPU settings that VirtualBox is using:",
    "text": "Here are the default CPU settings that VirtualBox is using:\n(http://eagle.fish.washington.edu/Arabidopsis/20160613_virtualbox_default_cpus.png)"
  },
  {
    "objectID": "posts/2016/2016-06-14-docker-virtualbox-defaults-on-os-x/index.html#maxed-out-the-cpu-slider",
    "href": "posts/2016/2016-06-14-docker-virtualbox-defaults-on-os-x/index.html#maxed-out-the-cpu-slider",
    "title": "Docker - VirtualBox Defaults on OS X",
    "section": "Maxed out the CPU slider:",
    "text": "Maxed out the CPU slider:\n(http://eagle.fish.washington.edu/Arabidopsis/20160613_virtualbox_eight_cpus.png)"
  },
  {
    "objectID": "posts/2016/2016-06-14-docker-virtualbox-defaults-on-os-x/index.html#here-are-the-default-ram-settings-that-virtualbox-is-using",
    "href": "posts/2016/2016-06-14-docker-virtualbox-defaults-on-os-x/index.html#here-are-the-default-ram-settings-that-virtualbox-is-using",
    "title": "Docker - VirtualBox Defaults on OS X",
    "section": "Here are the default RAM settings that VirtualBox is using:",
    "text": "Here are the default RAM settings that VirtualBox is using:\n(http://eagle.fish.washington.edu/Arabidopsis/20160613_virtualbox_default_RAM.png)"
  },
  {
    "objectID": "posts/2016/2016-06-14-docker-virtualbox-defaults-on-os-x/index.html#changed-ram-slider-to-24gb",
    "href": "posts/2016/2016-06-14-docker-virtualbox-defaults-on-os-x/index.html#changed-ram-slider-to-24gb",
    "title": "Docker - VirtualBox Defaults on OS X",
    "section": "Changed RAM slider to 24GB:",
    "text": "Changed RAM slider to 24GB:\n(http://eagle.fish.washington.edu/Arabidopsis/20160613_virtualbox_24GB_RAM.png)"
  },
  {
    "objectID": "posts/2016/2016-06-14-docker-virtualbox-defaults-on-os-x/index.html#now-lets-see-what-the-docker-container-reports-for-system-info-after-making-these-changes",
    "href": "posts/2016/2016-06-14-docker-virtualbox-defaults-on-os-x/index.html#now-lets-see-what-the-docker-container-reports-for-system-info-after-making-these-changes",
    "title": "Docker - VirtualBox Defaults on OS X",
    "section": "Now, let’s see what the Docker container reports for system info after making these changes:",
    "text": "Now, let’s see what the Docker container reports for system info after making these changes:\n(http://eagle.fish.washington.edu/Arabidopsis/20160613_roadrunner_docker_new_system.png)\nLooking at the CPUs now, we see it has 8 listed (as opposed to only 2 initially). I think this means that Docker now has full access to the hardware on this machine.\nThis situation is a weird shortcoming of Docker (and/or VirtualBox). Additionally, I think this issue might only exist on the OS X and Windows versions of Docker, since they require the installation of the Docker Toolbox (which installs VirtualBox). I don’t think Linux installations suffer from this issue."
  },
  {
    "objectID": "posts/2016/2016-07-01-goals-july-2016/index.html",
    "href": "posts/2016/2016-07-01-goals-july-2016/index.html",
    "title": "Goals - July 2016",
    "section": "",
    "text": "Unfortunately, most of this month’s goals are the same as last months!\n\nProcess Olympia oyster GBS data. I’ve been running two different analyses (Stacks and PyRad) on two different machines (Hummingbird and Roadrunner, respectively) and I keep encountering different problems! For example, just yesterday, the following popped up in Terminal on my SSH connection to a Docker container on Roadrunner running PyRad in a Jupyter Notebook (click on the image to enlarge):\n\n(http://eagle.fish.washington.edu/Arabidopsis/2016-06-30_screenshot.png)\nThe computer became completely unresponsive (for the second time in less than 24hrs). Maybe the problem is Docker. Maybe it’s creating a remote tunnel to a Docker container. Maybe it’s running Jupyter Notebook through a remote tunnel into a Docker container? I don’t know. At this point, I’ll just install PyRad directly on Roadrunner and try to get the analysis done that way. It certainly isn’t convenient because it means I have to be physically present at Roadrunner to execute commands and check on things…\n\nGet stuff running on Amazon AWS and Hyak as soon as possible. I think the increased computing power will improve my chances to actually complete the Oly GBS analysis due to the greater stability those computing environments provide.\nQuantify coral DNA methylation. This should be straightforward and completed on Tuesday, 20160705."
  },
  {
    "objectID": "posts/2016/2016-12-30-data-received-geoduck-rrbs-sequencing-data/index.html",
    "href": "posts/2016/2016-12-30-data-received-geoduck-rrbs-sequencing-data/index.html",
    "title": "Data Received - Geoduck RRBS Sequencing Data",
    "section": "",
    "text": "Hollie Putnam prepared some reduced representation bisulfite Illumina libraries and had them sequenced by Genewiz.\nThe data was downloaded and MD5 checksums were generated.\nIMPORTANT: MD5 checksums have not yet been provided by Genewiz! We cannot verify the integrity of these data files at this time! Checksums have been requested. Will create new notebook entry (and add link to said entry) once the checksums have been received and we can compare them.\nUPDATE 20161230 - Have received and verified checksums.\nJupyter notebook: 20161229_docker_genewiz_geoduck_RRBS_data.ipynb"
  },
  {
    "objectID": "posts/2016/2016-11-02-goals-november-2016/index.html",
    "href": "posts/2016/2016-11-02-goals-november-2016/index.html",
    "title": "Goals - November 2016",
    "section": "",
    "text": "Well, I’m serious this time. My goal for this month is to complete the Oly GBS data analysis and, get the data sets and data analysis prepared/placed in satisfactory repositories in preparation for publication in Scientific Data.\nAdditionally, I feel like I need to better document what I spend (waste?) my time on. For example, last month, I certainly got sidetracked trying to help/troubleshoot working with Docker. Here are just some of the issues that were encountered:\n\nInstall Multiqc and Trinity new version?\ncan’t view jupyter notebook in docker\nDocker Use on Roadrunner\nssh connection issues\nRoadrunner Connection?\nDocker and Jupyter Crash\n\nDespite having that list, I really should have notebook entries for each day I’m in lab, even if my day is spent struggling to get software installed and I don’t have any “product” for the day. Having the documentation of what I tried, what worked/didn’t work, will be helpful for future troubleshooting, and will provide some evidence that I actually did stuff.\nSo, I guess that’s a second goal for the month: Improve notebook documentation for days when I don’t generate a “product.”"
  },
  {
    "objectID": "posts/2016/2016-07-17-computing-amazon-ec2-instance-out-of-space/index.html",
    "href": "posts/2016/2016-07-17-computing-amazon-ec2-instance-out-of-space/index.html",
    "title": "Computing - Amazon EC2 Instance Out of Space?",
    "section": "",
    "text": "Running PyRad analysis on the Olympia oyster GBS data. PyRad exited with warnings about running out of space. However, looking at free disk space on the EC2 Instance suggests that there’s still space left on the disk. Possibly PyRad monitors the expected disk space usage during analysis to verify there will be sufficient disk space to write to? Regardless, will expand EC2 volume instance to a larger size…\n(http://eagle.fish.washington.edu/Arabidopsis/20160717_ec2_out_of_space.png)"
  },
  {
    "objectID": "posts/2017/2017-01-03-goals-january-2017/index.html",
    "href": "posts/2017/2017-01-03-goals-january-2017/index.html",
    "title": "Goals - January 2017",
    "section": "",
    "text": "One of the long-running goals I’ve had is to get this Oly GBS data taken care of and out the door to publication. I think I will finally succeed with this, with the help of Pub-A-Thon. Don’t get too excited, it’s not what you think. It is not the drinking extravaganza that the name implies. Instead, it’s a “friendly” lab competition to get some scientific publications assembled and submitted.\nAnother goal for this month is to get the -80C organized. We’ve made some major progress on lab organization, with major kudos going to Grace Crandall and her work on cleaning out fridges/freezers and putting together our lab inventory spreadsheet. The -80C organization is the final frontier of getting the lab fully under control and more well-regulated.\nContinuing on the organization front, it’d be great if we could get the Data Management Plan finished. Sean Bennett has helped get us much closer to completion. Hopefully this month we can get it finalized and have it be fully functional so that any lab member can easily figure out what to do when they receive new sequencing data.\nI’d also like to put together a more automated means of handling our high-throughput sequencing data when we receive it. Ideally, it’d be a Jupyter Notebook and all the user would have to do is enter the desired location (heck, maybe I could even simplify it further by requiring just a species name…) for the files to be stored and then press “play” on the notebook. The files would go through a post-download integrity check, moved to final location, re-check integrity, update checksum files, and update readme files. I have most of the bits here and there in various Jupyter Notebooks already, but haven’t taken the time to put them all together into a single, reusable notebook."
  },
  {
    "objectID": "posts/2017/2017-07-20-sample-submission-olympia-oyster-gonad-rna-to-katherine-silliman-univ-of-chicago/index.html",
    "href": "posts/2017/2017-07-20-sample-submission-olympia-oyster-gonad-rna-to-katherine-silliman-univ-of-chicago/index.html",
    "title": "Sample Submission - Olympia oyster gonad RNA to Katherine Silliman @ Univ. of Chicago",
    "section": "",
    "text": "Sent the following RNA to Katherine Silliman at the Univ. of Chicago for RNAseq. All RNA was isolated on 20170719, except SN-10-16, which was isolated on 20170710.\nNF-10-22 NF-10-23 NF-10-24 NF-10-26 NF-10-28 NF-10-30 SN-10-16 SN-10-17 SN-10-20 SN-10-25 SN-10-26 SN-10-31\nAll samples were sent on dry ice via FedEx Standard Overnight: 779698651635"
  },
  {
    "objectID": "posts/2017/2017-11-30-troubleshooting-pb-jelly-install-on-emu-continued/index.html",
    "href": "posts/2017/2017-11-30-troubleshooting-pb-jelly-install-on-emu-continued/index.html",
    "title": "Troubleshooting – PB Jelly Install on Emu Continued",
    "section": "",
    "text": "The last “fix” didn’t fix everything.\nThis time, I received an error message that was related to blasr. Some internet searching revealed that I needed to have various library files saved to a variable named: $LD_LIBRARY_PATH\nTo fix this, I added the following line to the /etc/bash.bashrc file:\n`\nexport \"LD_LIBRARY_PATH=${LD_LIBRARY_PATH:+${LD_LIBRARY_PATH}:}/home/shared/lib:\"</code>\nThe line uses a fancy bash test to determine if the $LD_LIBRARY_PATH variable already exists. This is to prevent the $LD_LIBRARY_PATH from having a leading “:”.\nAs usual, the solution to that problem was found courtesy of [StackExchange (#162891)(https://unix.stackexchange.com/questions/162891/append-to-path-like-variable-without-creating-leading-colon-if-unset).\nAlso, by putting this line in the /etc/bash.bashrc file, it makes the variable available for all users.\nBelow are some screen caps to document the process:\n\nRealization that PB Jelly still wasn’t going to work:\n(http://owl.fish.washington.edu/Athaliana/20171130_blasr_no_library.png)\n\n\nIdentify location of file listed in error message:\n(http://owl.fish.washington.edu/Athaliana/20171130_blasr_lib_ls.png)\n\n\nAdd command to /etc/bash.bashrc to set $LD_LIBRARY_PATH:\n(http://owl.fish.washington.edu/Athaliana/20171130_blasr_bashrc_lib_path.png)\n\n\nVerify $LD_LIBRARY_PATH:\n(http://owl.fish.washington.edu/Athaliana/20171130_LD_PATH_set.png)\n\n\nVerify blasr can run:\n(http://owl.fish.washington.edu/Athaliana/20171130_blasr_sucess.png)"
  },
  {
    "objectID": "posts/2017/2017-10-09-data-management-convert-oly-pacbio-h5-to-fastq/index.html",
    "href": "posts/2017/2017-10-09-data-management-convert-oly-pacbio-h5-to-fastq/index.html",
    "title": "Data Management - Convert Oly PacBio H5 to FASTQ",
    "section": "",
    "text": "After working with all of this Olympia oyster genome sequencing data, I remembered that we had an old, singular PacBio SMRT cell file (from June 2013). This file didn’t seem to be included in any recent assemblies of Sean’s or mine. This is most likely because we have it in the PacBio H5 format and not in FASTQ.\nI installed PacBio’s pbh5tools on my computer (swoose), converted the file and moved it to owl/nightingales/O_lurida\n<code>python bash5tools.py /mnt/owl/nightingales/O_lurida/m130619_081336_42134_c100525122550000001823081109281326_s1_p0.bas.h5 --outType fastq </code>\nI generated an MD5 checksum and appended to the checksums.md5 file in /owl/nightingales/O_lurida using the following command:\n<code>md5sum m130619_081336_42134_c100525122550000001823081109281326_s1_p0.fastq | awk '{print $2 \" = \" $1}' >> checksums.md5</code>\nThe command above pipes the output to awk to format the output to match the existing format of the checksums.md5 file (i.e. filename = hash).\nI’ve also updated our [Nightingales spreadsheet (Google Sheet)(https://docs.google.com/spreadsheets/d/1_XqIOPVHSBVGscnjzDSWUeRL7HUHXfaHxVzec-I-8Xk/edit?usp=sharing) to reflect this.\nWill generate updated PacBio assemblies with Canu and/or Racon."
  },
  {
    "objectID": "posts/2017/2017-03-21-computing-owl-partially-restored/index.html",
    "href": "posts/2017/2017-03-21-computing-owl-partially-restored/index.html",
    "title": "Computing - Owl Partially Restored",
    "section": "",
    "text": "Heard back from Synology and they indicated I should click the “Repair” option to fix the System Partition Failed error message seen previously.\nI did that and our data is now accessible again. However, all the user account info, scheduled tasks (e.g. Glacier backups, notebook backup script), IP configurations, mail configurations, etc. have all been reset.\nI downloaded/installed the various packages needed to have the server accessible via the web and configured the IP address settings.\nHave a note out to Synology to see if the configurations can be restored somehow. Once I hear back, we’ll get user accounts re-established.\nBelow is a chronological set of screen caps of the repair process:\n[caption id=“” align=“alignnone” width=“701”](http://eagle.fish.washington.edu/Arabidopsis/20170321_owl_folders_have_returned.png) Our data is still here! This is before performing the “Repair” operation, btw. It seems it just required some time to re-populate directory structure.[/caption]\n(http://eagle.fish.washington.edu/Arabidopsis/20170321_owl_click_repair.png)\n(http://eagle.fish.washington.edu/Arabidopsis/20170321_owl_click_repair_warning.png)\n[caption id=“” align=“alignnone” width=“700”](http://eagle.fish.washington.edu/Arabidopsis/20170321_owl_click_still_degraded.png) Still getting a “degraded” error message, but all drives appear normal. However, Disk 3 in the DX513 is not showing; possible cause for “degraded” status?[/caption]\n(http://eagle.fish.washington.edu/Arabidopsis/20170321_owl_manage_repair_disk3_01.png)\n(http://eagle.fish.washington.edu/Arabidopsis/20170321_owl_manage_repair_disk3.png)\n(http://eagle.fish.washington.edu/Arabidopsis/20170321_owl_manage_repair_disk3_02.png)\n[caption id=“” align=“alignnone” width=“701”](http://eagle.fish.washington.edu/Arabidopsis/20170321_owl_manual_ip.png) Set up manual IP settings by expanding the “LAN 1” connection.[/caption]"
  },
  {
    "objectID": "posts/2017/2017-05-11-dna-quantification-acropora-cervicornis-staghorn-coral-dna-from-javier-casariego-fiu-2/index.html",
    "href": "posts/2017/2017-05-11-dna-quantification-acropora-cervicornis-staghorn-coral-dna-from-javier-casariego-fiu-2/index.html",
    "title": "DNA Quantification - Acropora cervicornis (Staghorn coral) DNA from Javier Casariego (FIU)",
    "section": "",
    "text": "I quantified the three samples (listed below) that I SpeedVac’d yesterday using the the Roberts Lab Qubit 3.0.\n\n2h Block 1\n2h Block 8\nD35 Block 8\n\nQuantification was performed using the dsDNA Broad Range Kit.\nUsed 1uL of each sample.\nResults:\nOne sample (2h Block 1) is still slightly too dilute in order to use the recommended total amount of DNA for the methylation assay (100ng), but still falls well within the recommended range for the assay. Will proceed with the methylation assay for all samples.\nValues were added to the spreadsheet provided by Javier (Google Sheet): A.cervicornis_DNA_Extractions(May_2017).xlsx\nQubit output file (Google Sheet): 20170511_qubit_A_cervicornis_DNA"
  },
  {
    "objectID": "posts/2017/2017-10-23-assembly-comparison-oly-pacbio-canu-sam-vs-sean-with-quast/index.html",
    "href": "posts/2017/2017-10-23-assembly-comparison-oly-pacbio-canu-sam-vs-sean-with-quast/index.html",
    "title": "Assembly Comparison - Oly PacBio Canu: Sam vs. Sean with Quast",
    "section": "",
    "text": "I recently finished an assembly of our Olympia oyster PacBio data using Canu and thought it would be interesting to compare to Sean’s Canu assembly.\nGranted, this isn’t a totally true comparison because I think Sean’s assembly is further “polished” using Pilon or something like that, but the Quast analysis is so quick (like < 60 seconds), that it can’t hurt.\nSee the Jupyter Notebook below for the full deets on running Quast.\nResults:\nQuast output folder: https://owl.fish.washington.edu/Athaliana/quast_results/results_2017_10_23_18_01_25/\nInteractive report: https://owl.fish.washington.edu/Athaliana/quast_results/results_2017_10_23_18_01_25/report.html\n(http://owl.fish.washington.edu/Athaliana/20171023_quast_sbcanu_sjwcanu.png)\nJupyter Notebook (GitHub): 20171023_docker_oly_pacbio_canu_comparisons.ipynb"
  },
  {
    "objectID": "posts/2017/2017-09-18-genome-assembly-olympia-oyster-pacbio-minimapminiasmracon-2/index.html",
    "href": "posts/2017/2017-09-18-genome-assembly-olympia-oyster-pacbio-minimapminiasmracon-2/index.html",
    "title": "Genome Assembly - Olympia oyster PacBio minimap/miniasm/racon",
    "section": "",
    "text": "In this GitHub Issue, Steven had suggested I try out the minimap/miniasm/racon pipeline for assembling our Olympia oyster PacBio data.\nI followed the pipeline described by this paper: https://matzlab.weebly.com/uploads/7/6/2/2/76229469/racon.pdf.\nPreviously, ran the first part of the pipeline: minimap\nThis notebook entry just contains the miniasm execution. Will follow with racon.\nJupyter Notebook (GitHub): 20170918_docker_pacbio_oly_miniasm0.2.ipynb"
  },
  {
    "objectID": "posts/2017/2017-12-11-dna-isolation-quantification-crassotrea-virginica-mantle-gdna/index.html",
    "href": "posts/2017/2017-12-11-dna-isolation-quantification-crassotrea-virginica-mantle-gdna/index.html",
    "title": "DNA Isolation & Quantification - Crassostrea virginica Mantle gDNA",
    "section": "",
    "text": "DNA was isolated from a single adult Eastern oyster (Crassostrea virginica) for a pilot project with Qiagen to test their new DNA bisulfite conversion kit. The oyster was obtained yesterday afternoon (20171210) from the Taylo rShellfish Pioneer Square location. The oyster was stored @ 4C O/N.\nThe oyster was shucked and four pieces of upper mantle tissue (~35mg each) were snap frozen in liquid nitrogen (LN2). Tissues were pulverized under LN2 and then DNA was isolated separately from each sample using the E.Z.N.A. Mollusc DNA Kit (Omega) according to the manufcaturer’s protocol.\nSamples were eluted with 100uL of Elution Buffer and were pooled into a single tube.\nThe gDNA was quantified using the Qubit 3.0 (Invitrogen) and Qubit dsDNA Broad Range Kit (Invitrogen), using 5uL of sample.\nResults:\nQubit (Google Sheet): 20171211_qubit_virginica_DNA\nConcentration is 58.4ng/uL.\nThat makes the total yield ~23.36ug (23360ng). This is more than enough to perform two separate MeDIP preps and two separate reduced representation digestions with MspI.\nWill proceed with shearing of DNA for MeDIP."
  },
  {
    "objectID": "posts/2017/2017-03-23-data-management-olympia-oyster-pacbio-data-received/index.html",
    "href": "posts/2017/2017-03-23-data-management-olympia-oyster-pacbio-data-received/index.html",
    "title": "Data Received - Olympia oyster PacBio Data",
    "section": "",
    "text": "Back in December 2016, we sent off Ostrea lurida DNA to the UW PacBio sequencing facility. This is an attempt to fill in the gaps left from the BGI genome sequencing project.\nSee the GitHub Wiki dedicated to this for an overview of this UW PacBio sequencing.\nI downloaded the data to https://owl.fish.washington.edu/nightingales/O_lurida/20170323_pacbio/ using the required browser plugin, Aspera Connect. Technically, saving the data to a subfolder within a given species’ data folder goes against our data management plan (DMP) for high-throughput sequencing data, but the sequencing data output is far different than what we normally receive from an Illumina sequencing run. Instead of a just FASTQ files, we received the following from each PacBio SMRT cell we had run (we had 10 SMRT cells run):\n├── Analysis_Results\n│   ├── m170211_224036_42134_c101073082550000001823236402101737_s1_X0.1.bax.h5\n│   ├── m170211_224036_42134_c101073082550000001823236402101737_s1_X0.2.bax.h5\n│   ├── m170211_224036_42134_c101073082550000001823236402101737_s1_X0.3.bax.h5\n│   └── m170211_224036_42134_c101073082550000001823236402101737_s1_X0.bas.h5\n├── filter\n│   ├── data\n│   │   ├── control_reads.cmp.h5\n│   │   ├── control_results_by_movie.csv\n│   │   ├── data.items.json\n│   │   ├── data.items.pickle\n│   │   ├── filtered_regions\n│   │   │   ├── m170211_224036_42134_c101073082550000001823236402101737_s1_X0.1.rgn.h5\n│   │   │   ├── m170211_224036_42134_c101073082550000001823236402101737_s1_X0.2.rgn.h5\n│   │   │   └── m170211_224036_42134_c101073082550000001823236402101737_s1_X0.3.rgn.h5\n│   │   ├── filtered_regions.fofn\n│   │   ├── filtered_subread_summary.csv\n│   │   ├── filtered_subreads.fasta\n│   │   ├── filtered_subreads.fastq\n│   │   ├── filtered_summary.csv\n│   │   ├── nocontrol_filtered_subreads.fasta\n│   │   ├── post_control_regions.chunk001of003\n│   │   │   └── m170211_224036_42134_c101073082550000001823236402101737_s1_X0.1.rgn.h5\n│   │   ├── post_control_regions.chunk002of003\n│   │   │   └── m170211_224036_42134_c101073082550000001823236402101737_s1_X0.3.rgn.h5\n│   │   ├── post_control_regions.chunk003of003\n│   │   │   └── m170211_224036_42134_c101073082550000001823236402101737_s1_X0.2.rgn.h5\n│   │   ├── post_control_regions.fofn\n│   │   └── slots.pickle\n│   ├── index.html\n│   ├── input.fofn\n│   ├── input.xml\n│   ├── log\n│   │   ├── P_Control\n│   │   │   ├── align.cmpH5.Gather.log\n│   │   │   ├── align.plsFofn.Scatter.log\n│   │   │   ├── align_001of003.log\n│   │   │   ├── align_002of003.log\n│   │   │   ├── align_003of003.log\n│   │   │   ├── noControlSubreads.log\n│   │   │   ├── summaryCSV.log\n│   │   │   ├── updateRgn.noCtrlFofn.Gather.log\n│   │   │   ├── updateRgn_001of003.log\n│   │   │   ├── updateRgn_002of003.log\n│   │   │   └── updateRgn_003of003.log\n│   │   ├── P_ControlReports\n│   │   │   └── statsJsonReport.log\n│   │   ├── P_Fetch\n│   │   │   ├── adapterRpt.log\n│   │   │   ├── overviewRpt.log\n│   │   │   └── toFofn.log\n│   │   ├── P_Filter\n│   │   │   ├── filter.rgnFofn.Gather.log\n│   │   │   ├── filter.summary.Gather.log\n│   │   │   ├── filter_001of003.log\n│   │   │   ├── filter_002of003.log\n│   │   │   ├── filter_003of003.log\n│   │   │   ├── subreadSummary.log\n│   │   │   ├── subreads.subreadFastq.Gather.log\n│   │   │   ├── subreads.subreads.Gather.log\n│   │   │   ├── subreads_001of003.log\n│   │   │   ├── subreads_002of003.log\n│   │   │   └── subreads_003of003.log\n│   │   ├── P_FilterReports\n│   │   │   ├── loadingRpt.log\n│   │   │   ├── statsRpt.log\n│   │   │   └── subreadRpt.log\n│   │   ├── master.log\n│   │   └── smrtpipe.log\n│   ├── metadata.rdf\n│   ├── results\n│   │   ├── adapter_observed_insert_length_distribution.png\n│   │   ├── adapter_observed_insert_length_distribution_thumb.png\n│   │   ├── control_non-control_readlength.png\n│   │   ├── control_non-control_readlength_thumb.png\n│   │   ├── control_non-control_readquality.png\n│   │   ├── control_non-control_readquality_thumb.png\n│   │   ├── control_report.html\n│   │   ├── control_report.json\n│   │   ├── filter_reports_adapters.html\n│   │   ├── filter_reports_adapters.json\n│   │   ├── filter_reports_filter_stats.html\n│   │   ├── filter_reports_filter_stats.json\n│   │   ├── filter_reports_filter_subread_stats.html\n│   │   ├── filter_reports_filter_subread_stats.json\n│   │   ├── filter_reports_loading.html\n│   │   ├── filter_reports_loading.json\n│   │   ├── filtered_subread_report.png\n│   │   ├── filtered_subread_report_thmb.png\n│   │   ├── overview.html\n│   │   ├── overview.json\n│   │   ├── post_filter_readlength_histogram.png\n│   │   ├── post_filter_readlength_histogram_thumb.png\n│   │   ├── post_filterread_score_histogram.png\n│   │   ├── post_filterread_score_histogram_thumb.png\n│   │   ├── pre_filter_readlength_histogram.png\n│   │   ├── pre_filter_readlength_histogram_thumb.png\n│   │   ├── pre_filterread_score_histogram.png\n│   │   └── pre_filterread_score_histogram_thumb.png\n│   ├── toc.xml\n│   └── workflow\n│       ├── P_Control\n│       │   ├── align.cmpH5.Gather.sh\n│       │   ├── align.plsFofn.Scatter.sh\n│       │   ├── align_001of003.sh\n│       │   ├── align_002of003.sh\n│       │   ├── align_003of003.sh\n│       │   ├── noControlSubreads.sh\n│       │   ├── summaryCSV.sh\n│       │   ├── updateRgn.noCtrlFofn.Gather.sh\n│       │   ├── updateRgn_001of003.sh\n│       │   ├── updateRgn_002of003.sh\n│       │   └── updateRgn_003of003.sh\n│       ├── P_ControlReports\n│       │   └── statsJsonReport.sh\n│       ├── P_Fetch\n│       │   ├── adapterRpt.sh\n│       │   ├── overviewRpt.sh\n│       │   └── toFofn.sh\n│       ├── P_Filter\n│       │   ├── filter.rgnFofn.Gather.sh\n│       │   ├── filter.summary.Gather.sh\n│       │   ├── filter_001of003.sh\n│       │   ├── filter_002of003.sh\n│       │   ├── filter_003of003.sh\n│       │   ├── subreadSummary.sh\n│       │   ├── subreads.subreadFastq.Gather.sh\n│       │   ├── subreads.subreads.Gather.sh\n│       │   ├── subreads_001of003.sh\n│       │   ├── subreads_002of003.sh\n│       │   └── subreads_003of003.sh\n│       ├── P_FilterReports\n│       │   ├── loadingRpt.sh\n│       │   ├── statsRpt.sh\n│       │   └── subreadRpt.sh\n│       ├── Workflow.details.dot\n│       ├── Workflow.details.html\n│       ├── Workflow.details.svg\n│       ├── Workflow.profile.html\n│       ├── Workflow.rdf\n│       ├── Workflow.summary.dot\n│       ├── Workflow.summary.html\n│       └── Workflow.summary.svg\n├── filtered_subreads.fasta.gz\n├── filtered_subreads.fastq.gz\n├── m170211_224036_42134_c101073082550000001823236402101737_s1_X0.metadata.xml\n└── nocontrol_filtered_subreads.fasta.gz\nThat’s 20 directories and 127 files - for a single SMRT cell!\nGranted, there is the familiar FASTQ file (filtered_subreads.fastq), which is what will likely be used for downstream analysis, but it’s hard to make a decision on how we manage this data under the guidelines of our current DMP. It’s possible we might separate data files from the numerous other files (the other files are, essentially, metadata), but we need to decide which file type(s) (e.g. .h5 files, .fastq files) will server as the data files people will rely on for analysis. So, for the time being, this will be how the data is stored.\nI’ll update the readme file to reflect the addition of the top level folders (e.g. ../20170323_pacbio/170210_PCB-CC_MS_EEE_20kb_P6v2_D01_1/).\nI’ll also update the GitHub Wiki"
  },
  {
    "objectID": "posts/2017/2017-02-28-data-received-jays-coral-radseq-and-hollies-geoduck-epi-radseq/index.html",
    "href": "posts/2017/2017-02-28-data-received-jays-coral-radseq-and-hollies-geoduck-epi-radseq/index.html",
    "title": "Data Received - Jay’s Coral RADseq and Hollie’s Geoduck Epi-RADseq",
    "section": "",
    "text": "Jay received notice from UC Berkeley that the sequencing data from his coral RADseq was ready. In addition, the sequencing contains some epiRADseq data from samples provided by Hollie Putnam. See his notebook for multiple links that describe library preparation (indexing and barcodes), sample pooling, and species breakdown.\nFor quickest reference, here’s Jay’s spreadsheet with virtually all the sample/index/barcode/pooling info (Google Sheet): ddRAD/EpiRAD_Jan_16\nI’ve downloaded both the demultiplexed and non-demultiplexed data, verified data integrity by generating and comparing MD5 checksums, copied the files to each of the three species folders on owl/nightingales that were sequenced (Panopea generosa, Anthopleura elegantissima, Porites astreoides), generated and compared MD5 checksums for the files in their directories on owl/nightingales, and created/updated the readme files in each respective folder.\nData management is detailed in the Jupyter notebook below. The notebook is embedded in this post, but it may be easier to view on GitHub (linked below).\nReadme files were updated outside of the notebook.\nJupyter notebook (GitHub): 20170227_docker_jay_ngs_data_retrieval.ipynb"
  },
  {
    "objectID": "posts/2017/2017-03-07-fastqc-oly-bgi-gbs-raw-illumina-data-demultiplexed/index.html",
    "href": "posts/2017/2017-03-07-fastqc-oly-bgi-gbs-raw-illumina-data-demultiplexed/index.html",
    "title": "FASTQC - Oly BGI GBS Raw Illumina Data Demultiplexed",
    "section": "",
    "text": "Last week, I ran the two raw FASTQ files through FastQC. As expected, FastQC detected “errors”. These errors are due to the presence of adapter sequences, barcodes, and the use of a restriction enzyme (ApeKI) in library preparation. In summary, it’s not surprising that FastQC was not please with the data because it’s expecting a “standard” library prep that’s already been trimmed and demultiplexed.\nHowever, just for comparison, I ran the demultiplexed files through FastQC. The Jupyter notebook is linked (GitHub) and embedded below. I recommend viewing the Jupyter notebook on GitHub for easier viewing.\nResults:\nPretty much the same, but with slight improvements due to removal of adapter and barcode sequences. The restriction site still leads to FastQC to report errors, which is expected.\nLinks to all of the FastQC output files are linked at the bottom of the notebook.\nJupyter notebook (GitHub): 20170306_docker_fastqc_demultiplexed_bgi_oly_gbs.ipynb"
  },
  {
    "objectID": "posts/2017/2017-10-04-genome-assembly-minimapminiasmracon-overview/index.html",
    "href": "posts/2017/2017-10-04-genome-assembly-minimapminiasmracon-overview/index.html",
    "title": "Genome Assembly - minimap/miniasm/racon Overview",
    "section": "",
    "text": "Previously, I used the following three tools to do quick assembly of our Olympia oyster PacBio data:\n\nminimap\nminiasm\nracon\n\nI’m just posting this quick overview to make it easier to follow what was actually done without having to read through three different notebook entries and corresponding Jupyter notebooks.\nWhen I say “quick assembly”, I mean it. The entire assembly process probably takes about an hour on the computer I used - that seems fast.\nHere’s the quick and dirty of what was done:\n\n1 Run minimap:\nThis uses a pre-built set of defaults (the ava-pb in the code below) for analyzing PacBio data. Minimap only accepts two FASTQ files and you need to map your FASTQ file against itself. So, if you have multiple FASTQ sequencing files, you have to concatenate them into a single file prior to running minimap.\n<code>minimap2 -x ava-pb -t 23 \\\n20170911_oly_pacbio_cat.fastq \\\n20170911_oly_pacbio_cat.fastq \\\n> 20170911_minimap2_pacbio_oly.paf</code>\n\n\n2 Run miniasm:\nThis uses your concatenated FASTQ file and the PAF file output from the miniasm step. The code below is taken from the example provided in the miniasm documentation; there are other options available.\n<code>miniasm \\\n-f \\\n/home/data/20170911_oly_pacbio_cat.fastq /home/data/20170911_minimap2_pacbio_oly.paf > /home/data/20170918_oly_pacbio_miniasm_reads.gfa</code>\n\n\n3 Convert miniasm output GFA to FASTA\nThe FASTA file is needed to re-run minimap in Step 4 below.\n<code>awk '$1 ~/S/ {print \">\"$2\"\\n\"$3}' 20170918_oly_pacbio_miniasm_reads.gfa > 20170918_oly_pacbio_miniasm_reads.fasta</code>\n\n\n4 Run minimap with default settings\nUsing the default settings maps the FASTQ reads back to the contigs (the PAF file) created in the fist step. These mappings are required for Racon assembly (Step 5).\n<code>minimap2 \\\n-t 23 \\\n20170918_oly_pacbio_miniasm_reads.fasta 20170905_minimap2_pacibio_oly.paf > 20170918_minimap2_mapping_fasta_oly_pacbio.paf</code>\n\n\n5 Run racon\nThe output file is the FASTA file listed below.\n<code>racon -t 24 \\\n20170911_oly_pacbio_cat.fastq \\\n20170918_oly_pacbio_minimap_mappings.paf \\\n20170918_oly_pacbio_miniasm_assembly.gfa \\\n20170918_oly_pacbio_racon1_consensus.fasta</code>"
  },
  {
    "objectID": "posts/2017/2017-02-02-goals-february-2017/index.html",
    "href": "posts/2017/2017-02-02-goals-february-2017/index.html",
    "title": "Goals - February 2017",
    "section": "",
    "text": "First goal is to be the first person in lab to post their goals each month. Props to one of our new grad students, Yaamini Venkataraman on beating me this month!\nStuff that got tackled from last month’s goals:\nFreezer organization - This has happened, albeit without much effort on my part. Many thanks to the Big Cheese and [Grace for tackling this project[(https://genefish.wordpress.com/2017/01/28/80-organization)!\nData Management Plan - Some progress has been made on this. I improved the instructions on the DMP a bit, but the master spreadsheet on which the DMP revolves around (Nightingales) is still in a massive state of flux that needs a lot of attention.\nSequencing data handling - Thanks to Sean for putting forth a serious dent in automating this. He wrote an R script to handle this sort of thing. I’m not entirely sure if he’s done testing it, but it seems to work so far. Next will be incorporating usage instructions of this R script into the DMP so that others can utilize it. On that note, I need to figure out where Sean is keeping this script (can’t seem to locate in his notebook."
  },
  {
    "objectID": "posts/2017/2017-07-05-sample-annotation-olympia-oyster-histology-blocks-from-laura-spencer/index.html",
    "href": "posts/2017/2017-07-05-sample-annotation-olympia-oyster-histology-blocks-from-laura-spencer/index.html",
    "title": "Sample Annotation - Olympia oyster histology blocks (from Laura Spencer)",
    "section": "",
    "text": "I’ve been asked to isolate RNA from some paraffin-embedded Olympia oyster gonad tissue.\nDespite some excellent documentation by Laura Spencer (images of tissue layouts in histology cassettes and a corresponding cassette mapping key file), the histology facility seems to have flipped some things around and/or repositioned/split the contents of each cassette. This makes ID-ing the proper tissues tedious and, at times, difficult.\nThe list of tissues that needs to be processed is listed in this GitHub Issue #648. I’ve also added the list below:\nNF-10 22 NF-10-23 NF-10-24 NF-10-26 NF-10-28 NF-10-30 SN-10-16 SN-10-17 SN-10-20 SN-10-25 SN-10-26 SN-10-31\nPrior to beginning RNA isolations, I have annotated images of the histology blocks and will be waiting for Laura to confirm that my annotations are correct. I will be posting a link to this notebook entry in the GitHub issue listed above for her to view and wait for her confirmation.\nUPDATE 201700707 - Laura has indicated that many of my annotations are incorrect. Katie has gone through and made proper identification: https://github.com/sr320/LabDocs/issues/648#issuecomment-313792588\nAdditionally, as indicated in the GitHub Issue above, histology block “Oly 14” does not have a corresponding tissue cassette photo (containing sample NF-10 26). Without the original image, I don’t think I can make an accurate guess on how the tissues are oriented in the resulting two histo blocks (see below).\nBLOCKS 5\n(http://eagle.fish.washington.edu/Arabidopsis/Oly5_histo_block.png)\nBLOCK 6\n(http://eagle.fish.washington.edu/Arabidopsis/Oly6_histo_block.png)\nBLOCK 9\n(http://eagle.fish.washington.edu/Arabidopsis/Oly9_histo_block.png)\nBLOCK 10\n(http://eagle.fish.washington.edu/Arabidopsis/Oly10_histo_block.png)\nBLOCKS 14 (unable to annotate at time of posting)\n(http://eagle.fish.washington.edu/Arabidopsis/Oly14_histo_blocks_no_annotation.jpg)\nBLOCK 15\n(http://eagle.fish.washington.edu/Arabidopsis/Oly15_histo_block.png)\nBLOCK 21\n(http://eagle.fish.washington.edu/Arabidopsis/Oly21_histo_block.png)\nBLOCK 22\n(http://eagle.fish.washington.edu/Arabidopsis/Oly22_histo_block.png)"
  },
  {
    "objectID": "posts/2017/2017-03-14-computing-oly-bgi-gbs-reproducibility-fail-but-less-so-than-last-time/index.html",
    "href": "posts/2017/2017-03-14-computing-oly-bgi-gbs-reproducibility-fail-but-less-so-than-last-time/index.html",
    "title": "Computing – Oly BGI GBS Reproducibility Fail (but, less so than last time)…",
    "section": "",
    "text": "Well, my previous attempt at reproducing the demultiplexing that BGI performed was an exercise in futility. BGI got back to me with the following message:\n\nHi Sam,\nWe downloaded it and it seems fine when compiling. You can compile it with the below command under Linux system.\ntar -zxvf ReSeqTools_XXX.tar.gz ; cd iTools_Code; chmod 775 iTools ; ./ iTools -h\n\nI gave that whirl and got the following message:\n<code>Error opening terminal: xterm</code>\nSome internet searching got me sucked into a useless black hole about 64 bit systems running 32 bit programs and enabling the 64 bit kernel on Mac OS X 10.7.5 (Lion) since it’s not enabled by default and on and on. In the end, I can’t seem to enable the 64 bit kernel on my Mac Pro, likely due to hardware limitations related to the graphics card and/or displays that are connected.\nAnyway, I decided to try getting this program installed again, using a Docker container (instead of trying to install locally on my Mac).\nResults:\nIt didn’t work again, but for a different reason! Despite the instructions in the readme file provided with iTools, you don’t actually need to run make! All that has to be done is unzipping the tarball!! However, despite figuring this out, the program fails with the following error message: “Warming : sample double in this INDEX Files. Sample ID: OYSzenG1AAD96FAAPEI-109; please renamed it diff” (note: this is copied/pasted - the spelling errors are note mine). So, I think there’s something wrong with the formatting of the index file that BGI provided me with.\nI’ve contacted them for more info.\nSee the Jupyter notebook linked below to see what I tried.\nJupyter notebook (GitHub): 20170314_docker_Oly_BGI_GBS_demultiplexing_reproducibility.ipynb"
  },
  {
    "objectID": "posts/2017/2017-05-12-dna-methylation-quantification-acropora-cervicornis-staghorn-coral-dna-from-javier-casariego-fiu/index.html",
    "href": "posts/2017/2017-05-12-dna-methylation-quantification-acropora-cervicornis-staghorn-coral-dna-from-javier-casariego-fiu/index.html",
    "title": "DNA Methylation Quantification - Acropora cervicornis (Staghorn coral) DNA from Javier Casariego (FIU)",
    "section": "",
    "text": "Used the MethylFlash Methylated DNA Quantification Kit (Colorimetric) from Epigentek to quantify methylation in these coral DNA samples.\nAll samples were run in duplicate except 2h Block 1 due to insufficient DNA.\nThe following samples were used in a 1:10 dilution (2uL DNA : 18uL NanoPure H2O), due to their relatively high concentrations, to ensure accurate pipetting:\n\n72h Block 4\nD14 Block 1\nD14 Block 2\nD14 Block 3\nD14 Block 4\nD14 Block 5\nD14 Block 6\nD14 Block 8\nD14 Block 10\n\nAll samples were diluted to a final concentration of 9.645ng/uL (154.24ng total; 17.6uL) in NanoPure water, which is equal to 77.12ng of DNA per assay replicate. These numbers were chosen based off of the sample with the lowest concentration.\nThe following samples were used in their entirety:\n\n2h Block 8\nD35 Block 8\n\nCalculations were added to the spreadsheet provided by Javier (Google Sheet): A.cervicornis_DNA_Extractions(May_2017).xlsx\nThe spreadsheet became overly complicated because I initially forgot to account for the need to run each sample in duplicate.\nThe kit reagent dilutions were as follows:\n\nDiluted ME1: 52mL of ME1 + 464mL of distilled water\nDiluted ME4: 10uL of ME4 + 10uL of TE Buffer (pH=8.0; made by me on 20130408).\nStandard curve: Prepped per instruction manual, with double volumes for two plates.\nDiluted ME5: 50uL/well x 152well = 7600uL; 7600uL/1000 = 7.6uL; 7.6uL ME5 + 7592.4uL Diluted ME1\nDiluted ME6: 50uL/well x 152well = 7600uL; 7600uL/2000 = 3.8uL; 3.8uL ME6 + 7596.2uL Diluted ME1\nDiluted ME7: 50uL/well x 152well = 7600uL; 7600uL/5000 = 1.52uL; 1.52uL ME7 + 7598.48uL Diluted ME1\n\nAll diluted solutions were stored on ice for duration of procedure.\nThe remaining Diluted ME1 solution was stored at 4C (FTR 209), and is stable for 6 months, per the manufacturer’s instructions.\nSee the Results section below for plate layouts.\nPlates were read at 450nm on the Seeb Lab Victor 1420 Plate Reader (Perkin Elmer) and the amount of DNA methylation was determined.\nResults:\nIndividual sample methylation quantification (Google Sheet): A.cervicornis_DNA_Extractions(May_2017).xlsx\nPlate Reader Output File Plate #1 (Google Sheet): 20170511_coral_DNA_methylation_plate01.xls\nPlate Reader Output File Plate #2 (Google Sheet): 20170511_coral_DNA_methylation_plate02.xls\nI’m not familiar with the experimental design, so I’m not going to spend time handling any of the in-depth analysis at this point in time. However, here’s the background on how methylation quantification and percent methylation were determined.\n\nMean absorbance (450nm) was determined for all samples and standard curve samples. It’s important to note that the standard deviation between replicates was not evaluated and there appears to be consistent variability between samples, but I’m not certain how much variation is “acceptable” with and assay of this nature.\nThe mean absorbance of the standard curve samples were plotted against their corresponding DNA amounts and a linear trendline was fitted to the points.\nPer the manufacturer’s recommendations, the four points (including the zero point) that yielded the best linear fit (i.e. best R^2 value) were used and the slope of best fit line for those four points was determined.\nThis slope was then utilized in the equation provided by the manufacturer (see pg. 8 of the MethylFlash Kit manual)."
  },
  {
    "objectID": "posts/2017/2017-07-10-rna-isolation-olympia-oyster-gonad-tissue-in-paraffin-histology-blocks/index.html",
    "href": "posts/2017/2017-07-10-rna-isolation-olympia-oyster-gonad-tissue-in-paraffin-histology-blocks/index.html",
    "title": "RNA Isolation - Olympia oyster gonad tissue in paraffin histology blocks",
    "section": "",
    "text": "UPDATE 20170712: The RNA I isolated below is from incorrect regions of tissue. I misunderstood exactly what this tissue was, and admittedly, jumped the gun. The tissue is actually collected from the visceral mass - which contains gonad (a small amount) and digestive gland (a large amount). The RNA isolated below will be stored in one of the Shellfish RNA boxes and I will isolate RNA from the correct regions indicated by Grace\nIsolated RNA from Olympia oyster gonad previously preserved with the PAXgene Tissue Fixative and Stabilizer and then embedded in paraffin blocks. See Laura’s notebook for full details on samples and preservation.\nRNA was isolated from the following samples using the PAXgene Tissue RNA Kit (Qiagen). Gouged samples from the blocks weighing ~10mg from each of the tissues and processed according the protocol for isolating RNA from blocks of paraffin-embedded tissues.\nTissue identification is available in this GitHub Issue\nNF-10-22 NF-10-23 NF-10-24 NF-10-26 NF-10-28 NF-10-30 SN-10-16 SN-10-17 SN-10-20 SN-10-25 SN-10-26 SN-10-31\nIMPORTANT:\n\nPrior to beginning, I prepared an aliquot of Buffer TR1 by adding 40μL of β-mercaptoethanol (β-ME) to 4000μL of Buffer TR1).\nReconstituted DNase I with 550μL of RNase-free H2O. Aliquoted in 100μL volumes and stored @ -20C in the “-20C Kit Components” box.\n\nIsolated RNA according to the PAXgene Tissue RNA Kit protocol with the following alterations:\n\n“Max speed” spins were performed at 20,000g.\nTissue disruption was performed by adding ~25-50 glass beads (425 - 600μm diameter) with the Disruptor Genie @ 45C for 15mins (in the Friedman Lab).\nShaking incubation step was performed with Disruptor Genie\nSamples were eluted with 27μL of Buffer TR4 x 2, incubated @ 65C for 5mins, immediately placed on ice and quantified on the Roberts Lab Qubit 3.0 with the RNA High Sensitivity Assay (ThermoFisher Scientific) using 5μL of each sample.\n\n(http://eagle.fish.washington.edu/Arabidopsis/20170710_oly_histo_blocks.jpg)\nResults:\nConcentrations (Google Sheet): 20170710_RNA_qubit_oly_histo_blocks\nWell, the good news is that there’s RNA from all the samples and it seems to be in relatively high concentrations!\nThe bad news is that the concentrations for 10 of the 12 samples were too high and outside the range of the Qubit RNA HS Assay! Since we don’t have the broad range RNA assay, I can’t properly quantify the remaining samples. However, these samples are being sent to Katherine Silliman at some point, so I’ll leave it up to her to quantify the samples. I’m also guessing that she’ll run them on a Bioanalyzer to assess their integrity prior to beginning library construction, so that will also yield concentrations for the samples.\nSamples were stored at -80C temporarily.\nSamples will be sent to Katherine Silliman for high-throughput library construction and sequencing once I hear back from her regarding her availability to receive the samples."
  },
  {
    "objectID": "posts/2017/2017-10-18-fail-directory-contents-deleted/index.html",
    "href": "posts/2017/2017-10-18-fail-directory-contents-deleted/index.html",
    "title": "Fail - Directory Contents Deleted!",
    "section": "",
    "text": "Uh, not sure what happened here:\n(http://owl.fish.washington.edu/Athaliana/20171018_directory_deletion_01.png)\nI was running Canu via a Docker container with a Jupyter Notebook. I previously checked on the status by looking at the Canu logs. A couple of hours later, I noticed an error message in the Jupyter terminal output. I decided to check the progress of Canu to make sure it was still running.\nIt turns out everything in that directory was deleted! EVERYTHING! Including the Jupyter notebook, which must be why it threw the error on the screen. Kinda scary, actually…\nI guess I’ll give it another go and see what happens…"
  },
  {
    "objectID": "posts/2017/2017-04-19-manuscript-writing-submitted/index.html",
    "href": "posts/2017/2017-04-19-manuscript-writing-submitted/index.html",
    "title": "Manuscript Writing - Submitted!",
    "section": "",
    "text": "(http://eagle.fish.washington.edu/Arabidopsis/20170419_Overleaf_sci_data_oly_gbs_submission.png)\nHere are some useful links:\ndata records repo-URL: https://osf.io/j8rc2/ draft: https://www.authorea.com/users/4974/articles/149442 preprint (Overleaf): https://www.overleaf.com/read/mqbbvmwxhncg preprint (PDF): https://osf.io/cdj7m/"
  },
  {
    "objectID": "posts/2017/2017-11-14-assembly-comparison-oly-assemblies-using-quast/index.html",
    "href": "posts/2017/2017-11-14-assembly-comparison-oly-assemblies-using-quast/index.html",
    "title": "Assembly Comparison - Oly Assemblies Using Quast",
    "section": "",
    "text": "I ran Quast to compare all of our current Olympia oyster genome assemblies.\nSee Jupyter Notebook in Results section for Quast execution.\n\nResults:\nOutput folder: https://owl.fish.washington.edu/Athaliana/quast_results/results_2017_11_14_12_30_25/\nHeatmapped table of results: https://owl.fish.washington.edu/Athaliana/quast_results/results_2017_11_14_12_30_25/report.html\nVery enlightening!\n\nBEST OF:\nLargest Contig: redundans_sjw_02 (322,397bp) Total Length: soap_bgi_01 & pbjelly_sjw_01 (697,528,655bp) Total Length (>=50,000bp): redundans_sjw_03 (17,006,058bp) N50: redundans_sjw_03 (17,679bp)\nInteresting tidbit: The pbjelly_sjw_01 assembly is EXACTLY the same as the soap_bgi_01. Looking at the output messages from that PB Jelly assembly, one can see why. The messages indicate that no gaps were filled on the BGI scaffold reference! That means the PB Jelly output is just the BGI scaffold reference assembly!\nJupyter Notebook (GitHub): 20171114_swoose_oly_assembly_comparisons_quast.ipynb"
  },
  {
    "objectID": "posts/2017/2017-01-05-dna-isolation-geoduck-gdna-for-illumina-initiated-sequencing-project/index.html",
    "href": "posts/2017/2017-01-05-dna-isolation-geoduck-gdna-for-illumina-initiated-sequencing-project/index.html",
    "title": "DNA Isolation - Geoduck gDNA for Illumina-initiated Sequencing Project",
    "section": "",
    "text": "We were previously approached by Cindy Lawley (Illumina Market Development) for possible participation in an Illumina product development project, in which they wanted to have some geoduck tissue and DNA on-hand in case Illumina green-lighted the use of geoduck for testing out the new sequencing platform on non-model organisms. Well, guess what, Illumina has give the green light for sequencing our geoduck! However, they need at least 4μg of gDNA, so I’m isolating more.\nIsolated DNA from ctenidia tissue from the same Panopea generosa individual used for the BGI sequencing efforts. Tissue was collected by Brent & Steven on 20150811.\nUsed the E.Z.N.A. Mollusc Kit (Omega) to isolate DNA from five separate ~60mg pieces of ctenidia tissue according to the manufacturer’s protocol, with the following changes:\n\nSamples were homogenized with plastic, disposable pestle in 350μL of ML1 Buffer\nIncubated homogenate at 60C for 1hr\nNo optional steps were used\nPerformed three rounds of 24:1 chloroform:IAA treatment\nEluted each in 50μL of Elution Buffer and pooled into a single sample\n\nQuantified the DNA using the Qubit dsDNA BR Kit (Invitrogen). Used 1μL of DNA sample.\nConcentration = 162ng/μL (Quant data is here [Google Sheet]: 20170105_gDNA_geoduck_qubit_quant\nYield is great (total = ~32μg).\nEvaluated gDNA quality (i.e. integrity) by running 162ng (1μL) of sample on 0.8% agarose, low-TAE gel stained with ethidium bromide.\nUsed 5μL of O’GeneRuler DNA Ladder Mix (ThermoFisher).\nResults:\n(https://github.com/sr320/LabDocs/blob/master/protocols/Commercial_Protocols/ThermoFisher_OgeneRuler_DNA_Ladder_Mix_F100439.jpg?raw=true)\n(http://eagle.fish.washington.edu/Arabidopsis/20170105_gel_geoduck_gDNA.jpg)\nDNA looks good: bright high molecular weight band, minimal smearing, and minimal RNA carryover (seen as more intense “smear” at ~500bp).\nWill send off 10μg (they only requested 4μg) so that they have extra to work with in case they come across any issues."
  },
  {
    "objectID": "posts/2017/2017-10-23-fail-missing-data-on-owl/index.html",
    "href": "posts/2017/2017-10-23-fail-missing-data-on-owl/index.html",
    "title": "FAIL - Missing Data on Owl!",
    "section": "",
    "text": "Uh oh. There appears to be some data that’s been removed from Owl. I noticed this earlier when trying to look at some of Sean’s data. His data should be in a folder with his name in Owl/scaphapoda\n(http://owl.fish.washington.edu/Athaliana/20171023_scaphapoda_directory.png)\nLuckily, things are backed up using UW Google Drive:\n(http://owl.fish.washington.edu/Athaliana/20171023_scaphapoda_directory_drive.png)\nI’ll restore the data using the backup from Google Drive, but this highlights a major issue - have we lost other data from Owl and how would we ever know??!!\nI guess we need to look into some sort of solution for identifying deleted files. The Synology NAS does have a built-in app called Log Center that might offer some options. I’ll look into this.\nBut, speaking of using Log Center, I can’t find any record of files being removed. Oddly, the existing logs only have information for activity from this morning. Maybe because the server was upgraded over the weekend and an upgrade deletes existing logs???!!! I don’t know, but I can’t find any records about activity on scaphapoda using Log Center.\nRegardless, I need to figure out a way to evaluate differences between what currently exists on Owl and what has been backed up. I think I can use just use bash to create a file list of everything on Owl and then compare it to a file list of everything on the UW Google Drive. I think…"
  },
  {
    "objectID": "posts/2017/2017-12-11-dna-sonication-bioanalzyer-c-virginica-gdna-for-medip/index.html",
    "href": "posts/2017/2017-12-11-dna-sonication-bioanalzyer-c-virginica-gdna-for-medip/index.html",
    "title": "DNA Sonication & Bioanalzyer - C. virginica gDNA for MeDIP",
    "section": "",
    "text": "I transferred 8ug (136uL) of Crassotrea virginica gDNA (isolated earlier today) to two separate 1.7mL snap cap tubes for sonication/shearing.\nI performed shearing at the NOAA Northwest Fisheries Science Center, using the Qsonica Q800R. Mackenzie Gavery assisted me.\nTarget fragment size was ~500bp.\nSamples were run at the same time with the following settings:\n\n10 minutes\n30 seconds on, 30 seconds off\n25% power\n\n\n\n\nQsonica settings\n\n\nAfter sonication, fragmentation was assessed using the Seeb Lab’s Bioanlyzer 2100 (Agilent) and the DNA 12000 Chip Kit (Agilent). NOTE: All of the reagents and the chips were past their expiration dates (most in June 2016).\n\n\n\nBioanlyzer DNA chip used\n\n\nResults:\nAgilent 2100 Bioanalyzer Expert file (XAD): 2100 expert_DNA 12000_DE72902486_2017-12-11_13-45-31.xad\nFragmentation was successful, and pretty consistent.\nBoth samples appear to have an average fragment size of ~420bp. Will proceed with MeDIP, once reagents are received.\n\n\n\nSample 1 sheared electropherogram\n\n\n\n\n\nSample 2 sheared electropherogram\n\n\nUnsheared gDNA:\n\n\n\nUnsheared DNA electropherogram"
  },
  {
    "objectID": "posts/2017/2017-07-05-data-management-olympia-oyster-uw-pacbio-data-from-20170323-to-nightingales/index.html",
    "href": "posts/2017/2017-07-05-data-management-olympia-oyster-uw-pacbio-data-from-20170323-to-nightingales/index.html",
    "title": "Data Management - OLYMPIA OYSTER UW PACBIO DATA (FROM 20170323) TO NIGHTINGALES",
    "section": "",
    "text": "Added UW PacBio FASTQ files to our nightingales Google Sheet for keeping track of our high-throughput sequencing projects."
  },
  {
    "objectID": "posts/2017/2017-10-18-genome-assembly-olympia-oyster-pacbio-canu-v1-6/index.html",
    "href": "posts/2017/2017-10-18-genome-assembly-olympia-oyster-pacbio-canu-v1-6/index.html",
    "title": "Genome Assembly - Olympia oyster PacBio Canu v1.6",
    "section": "",
    "text": "I decided to run Canu myself, since documentation for Sean’s Canu run is a bit lacking. Additionally, it looks like he specified a genome size of 500Mbp, which is probably too small. For this assembly, I set the genome size to 1.9Gbp (based on the info in the BGI assembly report, using 17-mers for calculating genome size), which is probably on the large size.\nAdditionally, I remembered we had an old PacBio run that we had been forgetting about and thought it would be nice to have incorporated into an assembly.\nSee all the messy details of this in the Jupyter Notebook below, but here’s the core info about this Canu assembly.\nPacBio Input files (available on Owl/nightingales/O_lurida:\n<code>m170308_163922_42134_c101174252550000001823269408211742_s1_p0_filtered_subreads.fastq.gz                                                               m170308_230815_42134_c101174252550000001823269408211743_s1_p0_filtered_subreads.fastq.gz\nm130619_081336_42134_c100525122550000001823081109281326_s1_p0.fastq                       m170315_001112_42134_c101169372550000001823273008151717_s1_p0_filtered_subreads.fastq.gz\nm170211_224036_42134_c101073082550000001823236402101737_s1_X0_filtered_subreads.fastq.gz  m170315_063041_42134_c101169382550000001823273008151700_s1_p0_filtered_subreads.fastq.gz\nm170301_100013_42134_c101174162550000001823269408211761_s1_p0_filtered_subreads.fastq.gz  m170315_124938_42134_c101169382550000001823273008151701_s1_p0_filtered_subreads.fastq.gz\nm170301_162825_42134_c101174162550000001823269408211762_s1_p0_filtered_subreads.fastq.gz  m170315_190851_42134_c101169382550000001823273008151702_s1_p0_filtered_subreads.fastq.gz\nm170301_225711_42134_c101174162550000001823269408211763_s1_p0_filtered_subreads.fastq.gz</code>\nCanu execution command (see the Jupyter Notebook below for more info):\n<code>$time canu \\\nuseGrid=false \\\n-p 20171009_oly_pacbio \\\n-d /home/data/20171018_oly_pacbio_canu/ \\\ngenomeSize=1.9g \\\ncorrectedErrorRate=0.075 \\\n-pacbio-raw m*</code>\nResults:\nWell, this took a LONG time to run; a bit over two days!\nThe report file contains some interesting tidbits. For instance:\n\nUnitgigging calculates only 1.84x coverage\nTrimming removed >5 billion (!!) bases: 867850 reads 5755379456 bases (reads with no overlaps, deleted)\nUnitigging unassembled: unassembled: 479693 sequences, total length 2277137864 bp\n\nI’ll compare this Canu assembly against Sean’s Canu assembly and see how things look.\nReport file (text file): https://owl.fish.washington.edu/Athaliana/20171018_oly_pacbio_canu/20171018_oly_pacbio.report\nContigs Assembly (FASTA): https://owl.fish.washington.edu/Athaliana/20171018_oly_pacbio_canu/20171018_oly_pacbio.contigs.fasta\nComplete Canu output directory: https://owl.fish.washington.edu/Athaliana/20171018_oly_pacbio_canu/\nJupyter Notebook (GitHub): 20171018_docker_oly_canu.ipynb"
  },
  {
    "objectID": "posts/2017/2017-02-28-manuscript-writing-more-nuances-using-authorea/index.html",
    "href": "posts/2017/2017-02-28-manuscript-writing-more-nuances-using-authorea/index.html",
    "title": "Manuscript Writing - More “Nuances” Using Authorea",
    "section": "",
    "text": "I previously highlighted some of the issues I was having using Authorea.com as an writing platform.\nAs a collaborative writing platform, it also has issues.\nI found this out by using the chat feature that’s built into Authorea. This feature is great and support is pretty quick to respond:"
  },
  {
    "objectID": "posts/2017/2017-11-21-troubleshooting-pb-jelly-install-on-emu/index.html",
    "href": "posts/2017/2017-11-21-troubleshooting-pb-jelly-install-on-emu/index.html",
    "title": "Troubleshooting - PB Jelly Install on Emu",
    "section": "",
    "text": "I previously installed and ran PB Jelly. Despite no error messages being output, I noticed something odd during my quick post-assembly stats check: The PB Jelly numbers were identical to the input reference file. This seemed very strange and made me decide to look a bit deeper in the PB Jelly output files.\nAs it turns out, PB Jelly did not complete successfully! Here’s a look at one of the output files (notice the error messages!):\n(http://owl.fish.washington.edu/Athaliana/20171120_pbjellly_error.png)\nLooking around the internet seemed to suggest that the issue could be that the blasr program wasn’t in my system PATH (blasr is located in: /home/shared/bin). So, I updated that, since /home/shared/bin wasn’t in the system PATH!:\n(http://owl.fish.washington.edu/Athaliana/20171120_update_etc_environment.png)\n(http://owl.fish.washington.edu/Athaliana/20171120_updated_PATH.png)\nAfter doing this, I noticed that the PATH assignment in the /etc/environment file is incorrect - it has the $PATH variable appended to the front of the list. This results in the system PATH appending itself to itself over and over again, resulting in a ridiculously long list (like in the screen cap directly above this text). So, I removed that portion and re-sourced the /etc/environment file to tidy things up.\nFingers crossed this will resolve the issue…"
  },
  {
    "objectID": "posts/2017/2017-10-31-software-crash-olympia-oyster-genome-assembly-with-masurca-on-mox/index.html",
    "href": "posts/2017/2017-10-31-software-crash-olympia-oyster-genome-assembly-with-masurca-on-mox/index.html",
    "title": "Software Crash - Olympia oyster genome assembly with Masurca on Mox",
    "section": "",
    "text": "Ah, the joys of bioinformatics. I just received an email from Mox indicating that [the Masurca assembly I started 11 DAYS AGO (!!)(2017/10/19/genome-assembly-olympia-oyster-illumina-pacbio-reads-using-masurca.html) crashed.\n(http://owl.fish.washington.edu/Athaliana/20171031_masurca_failed.png)\nI’m probably not going to put much effort in to trying to figure out what went wrong, but here’s some log file snippets for reference. I’ll probably drop a line to the developers and see if they have any easy ways to address whatever caused the problems, but that’s about as much effort as I’m willing to put into troubleshooting this assembly.\nAdditionally, since this crashed, I’m not going to bother moving any of the files off of Mox. That means they will be deleted automatically by the system around Nov. 9th, 2017.\n\nslurm-94620.out (tail)\n[code lang=text] compute_psa 6601202 2632582819 Refining alignments Joining Generating assembly input files Coverage of the mega-reads less than 5 – using the super reads as well Coverage threshold for splitting unitigs is 138 minimum ovl 63 Running assembly /gscratch/srlab/programs/MaSuRCA-3.2.3/bin/deduplicate_unitigs.sh: line 85: 24330 Aborted (core dumped) overlapStoreBuild -o \\(ASM_DIR/\\)ASM_PREFIX.ovlStore -M 65536 -g \\(ASM_DIR/\\)ASM_PREFIX.gkpStore $ASM_DIR/overlaps_dedup.ovb.gz > $ASM_DIR/overlapStore.rebuild.err 2>&1 Assembly stopped or failed, see CA.mr.41.15.17.0.029.log [Mon Oct 30 23:19:37 PDT 2017] Assembly stopped or failed, see CA.mr.41.15.17.0.029.log [/code]\n\nCA.mr.41.15.17.0.029.log (tail)\n[code lang=text] number of threads = 28 (OpenMP default)\nERROR: overlapStore ‘/gscratch/scrubbed/samwhite/20171019_masurca_oly_assembly/CA.mr.41.15.17.0.029/genome.ovlStore’ is incomplete; previous overlapStoreBuild probably crashed.\n\nFailure message:\nfailed to unitig [/code]\n\noverlapStore.rebuild.err\n[code lang=text] Scanning overlap files to count the number of overlaps. Found 277.972 million overlaps. Memory limit 65536MB supplied. Ill put 3246167525 IIDs (3435.97 million overlaps) into each of 1 buckets. bucketizing CA.mr.41.15.17.0.029/overlaps_dedup.ovb.gz bucketizing DONE! overlaps skipped: 0 OBT - low quality 0 DUP - non-duplicate overlap 0 DUP - different library 0 DUP - dedup not requested terminate called after throwing an instance of std::bad_alloc what(): std::bad_alloc\nFailed with Aborted\nBacktrace (mangled):\noverlapStoreBuild[0x40523a] /usr/lib64/libpthread.so.0(+0xf100)[0x2af83b3c0100] /usr/lib64/libc.so.6(gsignal+0x37)[0x2af83c0395f7] /usr/lib64/libc.so.6(abort+0x148)[0x2af83c03ace8] /usr/lib64/libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0x165)[0x2af83b62d9d5] /usr/lib64/libstdc++.so.6(+0x5e946)[0x2af83b62b946] /usr/lib64/libstdc++.so.6(+0x5e973)[0x2af83b62b973] /usr/lib64/libstdc++.so.6(+0x5eb93)[0x2af83b62bb93] /usr/lib64/libstdc++.so.6(_Znwm+0x7d)[0x2af83b62c12d] /usr/lib64/libstdc++.so.6(_Znam+0x9)[0x2af83b62c1c9] overlapStoreBuild[0x402e10] /usr/lib64/libc.so.6(__libc_start_main+0xf5)[0x2af83c025b15] overlapStoreBuild[0x403089]\nBacktrace (demangled):\n[0] overlapStoreBuild() [0x40523a] [1] /usr/lib64/libpthread.so.0::(null) + 0xf100 [0x2af83b3c0100] [2] /usr/lib64/libc.so.6::(null) + 0x37 [0x2af83c0395f7] [3] /usr/lib64/libc.so.6::(null) + 0x148 [0x2af83c03ace8] [4] /usr/lib64/libstdc++.so.6::__gnu_cxx::__verbose_terminate_handler() + 0x165 [0x2af83b62d9d5] [5] /usr/lib64/libstdc++.so.6::(null) + 0x5e946 [0x2af83b62b946] [6] /usr/lib64/libstdc++.so.6::(null) + 0x5e973 [0x2af83b62b973] [7] /usr/lib64/libstdc++.so.6::(null) + 0x5eb93 [0x2af83b62bb93] [8] /usr/lib64/libstdc++.so.6::operator new(unsigned long) + 0x7d [0x2af83b62c12d] [9] /usr/lib64/libstdc++.so.6::operator new + 0x9 [0x2af83b62c1c9] [10] overlapStoreBuild() [0x402e10] [11] /usr/lib64/libc.so.6::(null) + 0xf5 [0x2af83c025b15] [12] overlapStoreBuild() [0x403089]\nGDB: [/code]"
  },
  {
    "objectID": "posts/2017/2017-12-13-tissue-sampling-crassostrea-virginica-tissues-for-archiving/index.html",
    "href": "posts/2017/2017-12-13-tissue-sampling-crassostrea-virginica-tissues-for-archiving/index.html",
    "title": "Tissue Sampling - Crassostrea virginica Tissues for Archiving",
    "section": "",
    "text": "I figured it’d be prudent to collect some Eastern oyster (Crassotrea virginica) to have around the lab.\nI used one of the C.virginica oysters that I picked up Taylor on 20171210 for sampling.\nSampled:\n\nUpper mantle (avoided area that was near gonad/white-ish)\nCtenidia\nLower mantle\nMuscle\nGonad\n\nSamples were transferred to 1.7mL snap cap tubes, frozen on dry ice, and stored @ -80C in Rack 13, Col 1, Row 5.\n\n\n\nWhole Olympia oyster, with ruler\n\n\n\n\n\nOpened Olympia oyster with ruler\n\n\n\n\n\nFreezer box label and tube locations"
  },
  {
    "objectID": "posts/2017/2017-06-22-github-curation/index.html",
    "href": "posts/2017/2017-06-22-github-curation/index.html",
    "title": "GitHub Curation",
    "section": "",
    "text": "Updated a couple of GitHub Wikis:\n\nCreated a new repo in the RobertsLab Organization GitHub account with a wiki to provide an overview of how to use of Hyak (mox) computing node. This was lightly modified from what Sean already had in his personal repo.\n\nAs a quick test, I updated all the md files in  the sr320/LabDocs/code md files to format headers for GitHub’s newest interpretation of headers. The headers (represented by a series of ‘#’) require a space between them and the subsequent text.  I used the following command in bash:\nfor i in *.md; do sed -i.bak 's/^#*/& /g' \"$i\"; done\nThe code works as follows:\n\nRun for loop on all .md files in the directory\nUse sed to edit the files in place: -i.bak (this command structure is needed for Mac OS X).\n's/^#*/&amp; /g': Performs a substitution by identifying all lines beginning (^) with a pound symbol (#) and match zero or more occurrences of the pound symbol (*), then substituting the same pattern that was matched and adding a space at the end of the pattern (& ). Do this for all occurrences found within the document (g).\n\nSince this worked, I’ll probably run this through all of the md files in all of our various repos to quickly and easily fix header formatting issues.\n\nWorking on updating the Genome-sequencing-December-2016-(UW-PacBio) wiki, but need to work out the kinks on any easy, documentable way to rename and move some files around in order to make files/organization compliant with our [data management plan (DMP)(https://github.com/sr320/LabDocs/wiki/Data-Management#ngs-data-management-plan).\nCurrent strategy:\n\nGenerate MD5 checksums for fastq files for each of the SMRT cell runs.\nCopy file names from the the .xml file in the top level of each SMRT cell run folder to an array.\nUse parameter substitution (in bash) to strip path and suffix from each index of the array (results likely stored in a secondary or tertiary array).\nUse bash find command to copy the filtered_subreads.fastq.gz from each SMRT cell run folder, and append each of the corresponding stripped filenames in the final array to the beginning of the fastq file, to the owl/nightingales/O_lurida directory.\nGenerate new MD5 checksums on the copied files and compare to original MD5 checksums. This will confirm two things: 1 - The data did not get corrupted when copied. 2 - The new filenames correspond to the correct, original filtered_subreads.fastq.gz file (renaming a file doesn’t alter the MD5 checksum).\nArchive the original SMRT cell run folders (which contain a ton of metdata files)"
  },
  {
    "objectID": "posts/2017/2017-01-05-sample-submission-geoduck-gdna-for-illumina-pilot-sequencing-project/index.html",
    "href": "posts/2017/2017-01-05-sample-submission-geoduck-gdna-for-illumina-pilot-sequencing-project/index.html",
    "title": "Sample Submission – Geoduck gDNA for Illumina Pilot Sequencing Project",
    "section": "",
    "text": "Sent 10μg of the geoduck gDNA I isolated earlier today to Illumina on dry ice via FedEx Standard Overnight service."
  },
  {
    "objectID": "posts/2017/2017-03-20-data-management-sra-submission-oly-gbs-batch-submission-fail/index.html",
    "href": "posts/2017/2017-03-20-data-management-sra-submission-oly-gbs-batch-submission-fail/index.html",
    "title": "Data Management - SRA Submission Oly GBS Batch Submission Fail",
    "section": "",
    "text": "[I had previously submitted the two non-demultiplexed genotype-by-sequencing (GBS) files provided by BGI to the NCBI short read archive (SRA)(2017/02/08/data-management-sra-submission-of-ostrea-lurida-gbs-fastq-files.html).\nHe noticed that the SRA no longer wants “raw data dumps” (i.e. the type of submission I made before). So, that means I had to prepare the demultiplexed files provided by BGI to actually submit to the SRA.\nLast week, I uploaded all 192 of the files via FTP. It took over 10hrs.\n(FTP tips: - Use ftp -i to initiate FTP. - Then use open ftp.address.IP to connect. - Then can use mput with regular expressions to upload multiple files)\nToday, I created a batch BioSample submission:\n(http://eagle.fish.washington.edu/Arabidopsis/20170320_SRA_oly_gbs_demultiplex_SUB2505455.png)\nInitiated the submission process (Ummm, this looks like it’s going to take awhile…):\n(http://eagle.fish.washington.edu/Arabidopsis/20170320_SRA_oly_gbs_demultiplex_SUB2495017.png)\nAaaaaand, it failed:\n(http://eagle.fish.washington.edu/Arabidopsis/20170320_SRA_oly_gbs_demultiplex_SUB2495017_fail.png)\nIt seems like the FTP failed at some point, as there’s nothing about those seven files that would separate them from the remaining 185 files. Additional support for FTP failure is that the 1SN_1A_1.fq.gz error message makes it sound like only part of the file got transferred.\nI’ll retrieve those files from our UW Google Drive (since their original home on Owl is still down) and get them trasnferred to the SRA."
  },
  {
    "objectID": "posts/2017/2017-10-03-samples-received-c-virginica-gonad-tissue-from-katie-lotterhos/index.html",
    "href": "posts/2017/2017-10-03-samples-received-c-virginica-gonad-tissue-from-katie-lotterhos/index.html",
    "title": "Samples Received - C.virginica gonad tissue from Katie Lotterhos",
    "section": "",
    "text": "Received and stored @-80C in rack 8, row 5, column 5.\nThe following information was sent with the samples:\n\n\nSample.ID Date Temp pCO2 Notes\n\n\n\n\n\n031\n\n\n26-Aug-2016\n\n\n15\n\n\n400\n\n\n\n\n\n\n032\n\n\n26-Aug-2016\n\n\n15\n\n\n400\n\n\n\n\n\n\n033\n\n\n26-Aug-2016\n\n\n15\n\n\n400\n\n\n\n\n\n\n034\n\n\n26-Aug-2016\n\n\n15\n\n\n400\n\n\n\n\n\n\n035\n\n\n26-Aug-2016\n\n\n15\n\n\n400\n\n\nAll sample sent; it will be in 2mL screw-cap vial\n\n\n\n\n036\n\n\n26-Aug-2016\n\n\n15\n\n\n400\n\n\n\n\n\n\n103\n\n\n26-Aug-2016\n\n\n15\n\n\n2800\n\n\n\n\n\n\n104\n\n\n26-Aug-2016\n\n\n15\n\n\n2800\n\n\n\n\n\n\n105\n\n\n26-Aug-2016\n\n\n15\n\n\n2800\n\n\n\n\n\n\n106\n\n\n26-Aug-2016\n\n\n15\n\n\n2800\n\n\nAll sample sent; it will be in 2mL screw-cap vial\n\n\n\n\n108\n\n\n26-Aug-2016\n\n\n15\n\n\n2800\n\n\n\n\n\n\n\nKatie sent this additional info in an email to Steven and me:\n\nThese C. virginica samples were exposed to control (400, 6 samples) and OA (2800, 5 samples) conditions for ~4 weeks at 15C. Gonad was carefully extracted by peeling back the outer membrane, flash frozen in liquid N, and placed in -80C (until today when we removed it). During sampling, it was difficult to get a lot of what we considered “pure” gonadal tissue. We sent you ~1/2 of the amount of tissue we have for all samples except for the two samples which were very low and we sent you all the tissue sample we have. Each should be about 10-20 mg of tissue, which I’m worried is not enough for MBD-BS seq. Fingers crossed."
  },
  {
    "objectID": "posts/2017/2017-11-14-dna-isolation-quantification-c-virginica-gonad-gdna/index.html",
    "href": "posts/2017/2017-11-14-dna-isolation-quantification-c-virginica-gonad-gdna/index.html",
    "title": "DNA Isolation & Quantification - C. virginica Gonad gDNA",
    "section": "",
    "text": "I isolated DNA from the Crassotrea virginica gonad samples sent by Katie Lotterhos using the E.Z.N.A. Mollusc Kit with the following modifications:\n\nSamples were homogenized with plastic, disposable pestle in 350μL of ML1 Buffer\nNo optional steps were used\nEluted each in 100μL of Elution Buffer and pooled into a single sample\n\nNOTE: Sample 034 did not process properly (no phase separation after 24:1 chlorform:IAA addition - along with suggested additions of ML1 Buffer) and was discarded.\nQuantified the DNA using the Qubit dsDNA BR Kit (Invitrogen). Used 2μL of DNA sample.\nSamples were stored in the same box the tissue was delivered in and stored in the same location in our -80C: rack 8, row 5, column 4.\n\nResults:\nQubit (Google Sheet): 20171114_qubit_Cvirginica_gDNA\nAmple DNA in all samples for MBDseq. (Refer to “Original Sample Conc.” column in spreadsheet.)\nWill let Steven & Katie know."
  },
  {
    "objectID": "posts/2017/2017-03-18-troubleshooting-synology-nas-owl-down-after-update/index.html",
    "href": "posts/2017/2017-03-18-troubleshooting-synology-nas-owl-down-after-update/index.html",
    "title": "Troubleshooting - Synology NAS (Owl) Down After Update",
    "section": "",
    "text": "TL;DR - Server didn’t recover after firmware update last night. “Repair” is an option listed in the web interface, but I want to confirm with Synology what will happen if/when I click that button…\nThe data on Owl is synced here (Google Drive): UW Google Drive\nHowever, not all of Owl was fully synced at the time of this failure, so it seems like a decent amount of data is not accessible. Inaccessible data is mostly from individual user directories.\nAll high-throughput sequencing is also backed up to Amazon Glacier, so we do have all of that data.\nHere is what happened, in chronological order:\n\nUpdated DSM via web interface in “Update & Restore”. Did NOT perform manual install.\nSystem became inaccessible via web interface and Synology Assistant.\nThe physical unit showed blue, flashing power light and green flashing LAN1 light.\nNo other lights were illuminated (this includes no lights for any of the drive bays).\nThe attached expansion unit (DX513) showed steady blue power light, steady green lights on all drive bays, and steady green eSATA light.\nI powered down both units via the DS1812+ power button.\nI turned on the both units via the DS1812+ power button.\nBoth units returned to their previous status and were still inaccessible via the web interface and Synology Assistant.\nI powered down both units via the DS1812+ power button.\nI removed all drives from both units.\nI turned on the both units via the DS1812+ power button.\nI connected to the DS1812+ via Synology Assistant. A message indicated “No Hard Disk Found on 1812+”.\nI powered down both units via the DS1812+ power button.\nI added a single HDD to the DS1812+.\nI turned on the both units via the DS1812+ power button.\nI connected to the DS1812+ via Synology Assistant. I was prompted to install the latest DSM. I followed the steps and created a new admin account. Now the system shows 7 drives in the DS1812+ with a message: “System Partition Failed; Healthy”. Disk 1 shows a “Normal” status; this is the disk that I used to re-install DSM in Step 14. Additionally, the system shows one unused disk in the DX513.\nI powered down both units via the web interface.\nI removed Disk 1 from DS1812+.\nI turned on the both units via the DS1812+ power button.\nThe DS1812+ returns to its initial state as described in Step 3.\nI powered down both units via the DS1812+ power button.\nI returned Disk 1 to its bay.\nI turned on the both units via the DS1812+ power button.\nThere’s an option to “Repair” the Volume, but I’m not comfortable doing so until I discuss the in/outs of this with Synology. Submitted a tech support ticket with Synology.\n\nBelow are pictures of the entire process, for reference.\n[caption id=“” align=“alignnone” width=“700”](http://eagle.fish.washington.edu/Arabidopsis/IMG_20170318_082611.jpg) Server status when I arrived to lab this morning.[/caption]\n[caption id=“” align=“alignnone” width=“699”](http://eagle.fish.washington.edu/Arabidopsis/IMG_20170318_073022.jpg) Pulled the HDDs from both units, in an attempt to be able to connect via Synology Assistant.[/caption]\n[caption id=“” align=“alignnone” width=“700”] Units w/o HDDs.[/caption]\n[caption id=“” align=“alignnone” width=“700”](http://eagle.fish.washington.edu/Arabidopsis/Synology_Assistant_and_synology_flashing_power_light_-_Google_Search.png) No HDDs in units made the server detectable via Synology Assistant, but it indicates “Not installed” in the “Status” column…[/caption]\n[caption id=“” align=“alignnone” width=“700”](http://eagle.fish.washington.edu/Arabidopsis/Synology_Web_Assistant_no_disk.png) Successfully connected, but the DS1812+ indicates no HDDs installed.[/caption]\n[caption id=“” align=“alignnone” width=“700”](http://eagle.fish.washington.edu/Arabidopsis/IMG_20170318_073622.jpg) Added a single HDD back to the DS1812+. Notice, the drive light is green and the “Status” light is amber. This is actually an improvement over what I saw when I arrived.[/caption]\n[caption id=“” align=“alignnone” width=“522”](http://eagle.fish.washington.edu/Arabidopsis/Synology_Web_Assistant_welcome.png) Added back a single HDD to the DS1812+ and now have this setup menu.[/caption]\n[caption id=“” align=“alignnone” width=“699”](http://eagle.fish.washington.edu/Arabidopsis/Synology_Web_Assistant_install.png) I’m prompted to install the Synology DSM.[/caption]\n[caption id=“” align=“alignleft” width=“701”](http://eagle.fish.washington.edu/Arabidopsis/Synology_Web_Assistant_dsm_install.png) Installing DSM. This “Formatting system partition” message might be related to the eventual error message that I see (“System Partition Failed”) after this is all set up…[/caption]\n[caption id=“” align=“alignnone” width=“701”](http://eagle.fish.washington.edu/Arabidopsis/DiskStation%c2%a0-%c2%a0Synology%c2%a0DiskStation_new_admin.png) Prompted to create an admin account. This does not bode well, since this is behaving like a brand new installation (i.e. no record of the previous configuration, users, etc.).[/caption]\n[caption id=“” align=“alignnone” width=“700”](http://eagle.fish.washington.edu/Arabidopsis/Owl%c2%a0-%c2%a0Synology%c2%a0DiskStation_setup.png) Continuing set up.[/caption]\n[caption id=“” align=“alignnone” width=“699”](http://eagle.fish.washington.edu/Arabidopsis/Owl%c2%a0-%c2%a0Synology%c2%a0DiskStation_new_admin_set.png) All set up…[/caption]\n[caption id=“” align=“alignnone” width=“700”](http://eagle.fish.washington.edu/Arabidopsis/Synology_Assistant_and_installed_synology_DSM_working.png) Added all the HDDs back and detected via Synology Assistant.[/caption]\n[caption id=“” align=“alignnone” width=“700”](http://eagle.fish.washington.edu/Arabidopsis/Owl%c2%a0-%c2%a0Synology%c2%a0DiskStation_users_gone.png) This shows that there are no other users - i.e. previous configuration is not detected.[/caption]\n[caption id=“” align=“alignnone” width=“700”](http://eagle.fish.washington.edu/Arabidopsis/Owl%c2%a0-%c2%a0Synology%c2%a0DiskStation_crash_disk.png) After putting all the HDDs back in, got this message after logging in.[/caption]\n[caption id=“” align=“alignnone” width=“700”](http://eagle.fish.washington.edu/Arabidopsis/Owl%c2%a0-%c2%a0Synology%c2%a0DiskStation_failed_partition.png) Looking at the Storage info in DSM; seems bad.[/caption]\n[caption id=“” align=“alignnone” width=“700”](http://eagle.fish.washington.edu/Arabidopsis/IMG_20170318_085956.jpg) Physically, the drives all look fine (green lights on all drive bays), despite the indication in the DSM about “System Partition Failed” for all of them (except Disk 1). The expansion unit’s bay lights are actually all green, but were actively being read at the time of picture (i.e. flashing) so the image didn’t capture all of them being green. Amber light on expansion unit reflects what was seen in the DSM - the middle drive is “Not initialized”. Note, the drive is actually inserted, but the handle has been released.[/caption]\n[caption id=“” align=“alignnone” width=“700”](http://eagle.fish.washington.edu/Arabidopsis/Owl%c2%a0-%c2%a0Synology%c2%a0DiskStation_storage_manager.png) This is how I left the system. Notice that after rebooting, the expansion unit no longer shows that “Not initialized” message for Disk 3. Instead, Disk 3 is now detected as installed, but not used…[/caption]"
  },
  {
    "objectID": "posts/2017/2017-08-28-project-progress-olympia-oyster-genome-assemblies-by-sean-bennett/index.html",
    "href": "posts/2017/2017-08-28-project-progress-olympia-oyster-genome-assemblies-by-sean-bennett/index.html",
    "title": "Project Progress - Olympia Oyster Genome Assemblies by Sean Bennett",
    "section": "",
    "text": "Here’s a brief overview of what Sean has done with the Oly genome assembly front.\nMetassembler\n\nAssemble his BGI assembly and Platanus assembly? Confusing terms here; not sure what he means.\nFailed due to 32-bit vs. 64-bit installation of MUMmer. He didn’t have the chance to re-compile MUMmer as 64-bit. However, a recent MUMmer announcement suggests that MUMmer can now handle genomes of unlimited size.\nI believe he was planning on using (or was using?) GARM, which relies upon MUMmer and may also include a version of MUMmer (outdated version that led to Sean’s error message?).\nNotebook entry\n\nCanu\n\nAssemble UW PacBio data (filenames beginning with m170211, m170315, m170308, and m170301).\nFiles (including Mox scripts, Pilon contig polishing, & output FASTA files) are here: http://owl.fish.washington.edu/scaphapoda/Sean/Oly_Canu_Output/\nNotebook entry\n\nRedundans\n\nAssembled raw Illumina reads provided by BGI (filenames beginning with 15114 and 16103) & UW PacBio data (filenames beginning with m170211, m170315, m170308, and m170301).\nRan this two times.\nFirst run\n\nFiles (does NOT include Mox scripts!) are here: https://owl.fish.washington.edu/scaphapoda/Sean/Oly_Redundans_Output/\nNotebook entry\n\nSecond run\n\nFiles (including Mox scripts & output FASTA files) are here: https://owl.fish.washington.edu/scaphapoda/Sean/Oly_Redundans_Output_Try_2/\nNotebook entry\n\n\nPlatanus\n\nAssembled raw Illumina reads provided by BGI (beginning with 151114 and 160103).\nRan this two times.\nFirst run\n\nFiles (including Mox scripts & output FASTA files) are here: https://owl.fish.washington.edu/scaphapoda/Sean/Oly_Illumina_Platanus_Assembly/\nNotebook entry\n\nSecond run\n\nFiles (including Mox scripts & output FASTA files) are here: https://owl.fish.washington.edu/scaphapoda/Sean/Oly_Platanus_Assembly_Kmer-22/\nNotebook entry"
  },
  {
    "objectID": "posts/2017/2017-05-10-dna-concentration-acropora-cervicornis-staghorn-coral-dna-from-javier-casariego-fiu/index.html",
    "href": "posts/2017/2017-05-10-dna-concentration-acropora-cervicornis-staghorn-coral-dna-from-javier-casariego-fiu/index.html",
    "title": "DNA Concentration - Acropora cervicornis (Staghorn coral) DNA from Javier Casariego (FIU)",
    "section": "",
    "text": "Three samples (of the 62 total) that were quantified earlier today, had concentrations too low for use in the methylation assay:\n\n2h Block 1\n2h Block 8\nD35 Block 8\n\nThese samples were dried to completion in a SpeedVac.\nThey will be allowed to rehydrate O/N in 10uL of Buffer EB (Qiagen) and will be re-quantified tomorrow morning."
  },
  {
    "objectID": "posts/2017/2017-03-07-computing-oly-bgi-gbs-reproducibility-fail/index.html",
    "href": "posts/2017/2017-03-07-computing-oly-bgi-gbs-reproducibility-fail/index.html",
    "title": "Computing - Oly BGI GBS Reproducibility Fail",
    "section": "",
    "text": "Since we’re preparing a manuscript that relies on BGI’s manipulation/handling of the genotype-by-sequencing data, I attempted to could reproduce the demultiplexing steps that BGI used in order to perform the SNP/genotyping on these samples.\nThe key word in the above sentence is “attempted.” Ugh, what a massive waste of time it turned out to be. I’ve contacted BGI to get some help on this.\nIn the meantime, here’s a brief (actually, not as brief as I’d like) rundown of my struggles.\nThe demultiplexing software that BGI used is something called “iTools” which is bundled in this GitHub repo: Resqtools\nTo demutliplex, they ran a script called: split.sh\nThe script seems fairly straightforward. Here is what it contains:\n<code>iTools Fqtools splitpool \\\n-InFq1 160123_I132_FCH3YHMBBXX_L4_OYSzenG1AAD96FAAPEI-109_1.fq.gz \\\n-InFq2 160123_I132_FCH3YHMBBXX_L4_OYSzenG1AAD96FAAPEI-109_2.fq.gz \\\n-Index index.lst \\\n-Flag enzyme.txt \\\n-MisMatch \\\n-OutDir split\n</code>\nIt tells the iTools program to use the Fqtools tool “splitpool” to operate on a pair of gzipped FASTQ files. It also utilizes an index file (index.lst) which contains all the barcodes needed to identify, and separate, the individual samples that were combined prior to sequencing.\nThe first bump in the road is the -Flag enzyme.txt portion of the code. BGI did not provide me with this file. I recently requested them to send me it (or its contents, since I suspected it was only a single line text file). They sent me the contents of the file:\n<code>CAGC\nCTGC</code>\nThe next problem is neither of those two sequences are the recognition site for the enzyme that was (supposedly) used: ApeKI. The recognition site for ApeKI is: GCWGC\nRegardless, I decided to see if I could reproduce the demultiplexing using the info they’d provided me.\nI cloned the Resqtools repo, changed into the Reseqtools/iTools directory and typed make.\nThis resulted in an error informing me that it could not find boost/spirit/core.hpp\nI tracked down the Boost library junk, downloaded the newest version and untarred it in /usr/local/bin.\nTried to run make in the Reseqtools/iTools directory and got the same error. Realized iTools might not be searching the system $PATH (this turned out to be correct), so I moved the contents of the Boost folder to the iTools, ran make and got the same error. Turns out, the newest version of Boost doesn’t have that core.hpp file any more. Looking at the iTools documentation, iTools was built around Boost 1.44. OMG…\nDownloaded Boost 1.44 and went through the same steps as above. This eliminated the missing core.hpp error!\nBut, of course, led to another error. The error:\n<code>\"Threading support unavaliable: it has been explicitly disabled with BOOST_DISABLE_THREADS\"</code>\nThat was related to something with newer versions of the GCC compiler (this is, essentially, built into the computer; it’s not worth trying to install/use old versions of GCC) trying to work with old versions of Boost. Found a patch for a config file here: libstdcpp3.hpp.patch\nI made the appropriate edits to the file as shown in that link and ran make and it almost worked!\nThe current error is:\n<code>./src/Variants/soapsv-v1.02/include.h:15:16: fatal error: gd.h: No such file or directory</code>\nI gave up and contacted BGI to see if they can get me a functional version of iTools…"
  },
  {
    "objectID": "posts/2017/2017-03-17-computing-oly-bgi-gbs-reproducibility-fail-2/index.html",
    "href": "posts/2017/2017-03-17-computing-oly-bgi-gbs-reproducibility-fail-2/index.html",
    "title": "Computing – Oly BGI GBS Reproducibility; fail?",
    "section": "",
    "text": "OK, so things have improved since the last attempt at getting this BGI script to run and demultiplex the raw data.\nI played around with the index.lst file format (based on the error I received last time, it seemed like a good possibility that the file formatting was incorrect) and actually got the script to run to completion! Granted, it took over 16hrs (!!), but it completed!\nSee the Jupyter notebook link below.\nResults:\nWell, although the script finished and kicked out all the demultiplexed FASTQ files, the contents of the FASTQ files don’t match (the read counts differ between these results and the BGI files) the original set of demultiplexed files. I’m not entirely sure if this is to be expected or not, since the script allows for a single nucleotide mismatch when demultiplexing. Is it possible that the mismatch could be interpreted slightly differently each time this is run? I’m not certain.\nTheoretically, you should get the same results every time…\nMaybe I’ll re-run this again over the weekend and see how the results compare to this run and the original BGI demultiplexing…\nJupyter notebook (GitHub): 20170314_docker_Oly_BGI_GBS_demultiplexing_reproducibility.ipynb\nJupyter notebook (may be easier to view in GitHub link above):"
  },
  {
    "objectID": "posts/2017/2017-06-01-goals-june-2017/index.html",
    "href": "posts/2017/2017-06-01-goals-june-2017/index.html",
    "title": "Goals - June 2017",
    "section": "",
    "text": "Well, my previous goal was to tidy up an existing manuscript and get it re-submitted to PeerJ. That’s pretty much done, as Steven will be giving a final once over and formatting the rebuttal letter prior to resubmission.\nJune will be a bit of a short month for me, due to some travel, but here’re some things on the agenda:\n\nUpdate the Oly Genome Wiki to accurately reflect the most recent PacBio Sequencing we had done.\nRelated to the above goal is updating Nightingales to house just the raw sequencing data files for the Oly PacBio sequencing, while archiving the associated meta data (QC files, reports, etc).\nRelated to THAT goal is then updating our Nightingales spreadsheet to reflect, and provide links to, the raw sequencing files.\nEstablish (and build out) an “On Boarding” repo in the Roberts Lab GitHub Page. This should make it easier for new lab members to find the various resources they need. More importantly, it should make it easier for us to direct people to find that info!"
  },
  {
    "objectID": "posts/2017/2017-09-18-genome-assembly-olympia-oyster-pacbio-minimapminiasmracon-3/index.html",
    "href": "posts/2017/2017-09-18-genome-assembly-olympia-oyster-pacbio-minimapminiasmracon-3/index.html",
    "title": "Genome Assembly - Olympia oyster PacBio minimap/miniasm/racon",
    "section": "",
    "text": "In this GitHub Issue, Steven had suggested I try out the minimap/miniasm/racon pipeline for assembling our Olympia oyster PacBio data.\nI followed the pipeline described by this paper: https://matzlab.weebly.com/uploads/7/6/2/2/76229469/racon.pdf.\nThis notebook entry just contains the racon execution. This produced this assembly:\nhttps://owl.fish.washington.edu/Athaliana/201709_oly_pacbio_assembly_minimap_asm_racon/20170918_oly_pacbio_racon1_consensus.fasta\nAll intermediate files generated from this pipeline are here:\nhttps://owl.fish.washington.edu/Athaliana/201709_oly_pacbio_assembly_minimap_asm_racon/\nI’ll put together a TL;DR post that provides an overview of the pipeline and an assessment of the final assembly.\nPreviously ran minimap and then miniasm.\nJupyter Notebook (GitHub): 20170918_docker_pacbio_oly_racon0.5.0.ipynb"
  },
  {
    "objectID": "posts/2017/2017-11-13-samples-received-tanner-crab-hemolymph-in-rna-later-from-pam-jensen/index.html",
    "href": "posts/2017/2017-11-13-samples-received-tanner-crab-hemolymph-in-rna-later-from-pam-jensen/index.html",
    "title": "Samples Received - Tanner Crab Hemolymph in RNA Later from Pam Jensen",
    "section": "",
    "text": "Pam Jensen stopped by and dropped off Tanner crab (Chionoecetes bairdi) hemolymph samples (~300) stored in RNA Later (Ambion). Samples were stored at 4C.\n(http://owl.fish.washington.edu/Athaliana/20171113_tanner_crab_samples.jpg)"
  },
  {
    "objectID": "posts/2017/2017-05-03-goals-may-2017/index.html",
    "href": "posts/2017/2017-05-03-goals-may-2017/index.html",
    "title": "Goals - May 2017",
    "section": "",
    "text": "A day late, but definitely not a dollar short!\nNo goals posted last month because I didn’t want anyone to think they were just an April Fool’s joke. ;)\nThis month my goal is to continue my domination of Pub-a-Thon 2017!\nI plan on doing so by getting a second paper submitted this month! That’s right! I’m working on getting the following paper re-submitted:\n[Differential response to stress in Ostrea lurida (Carpenter 1864)(https://github.com/RobertsLab/paper-Olurida-gene)"
  },
  {
    "objectID": "posts/2017/2017-10-19-software-installation-masurca-v3-2-3-assembler-on-mox-hyak/index.html",
    "href": "posts/2017/2017-10-19-software-installation-masurca-v3-2-3-assembler-on-mox-hyak/index.html",
    "title": "Software Installation - MaSuRCA v3.2.3 Assembler on Mox (Hyak)",
    "section": "",
    "text": "Saw this tweet this morning and thought this would be good to try out for our Olympia oyster genome assemblies, as it will handle “hybrid” assemblies (i.e. short-reads and long reads):\n\n\nThe latest verison of the MaSuRCA assembler supports @nanopore reads and it is super easy to use. Check it out! https://t.co/ByKUCpAoIf pic.twitter.com/KulviJhmMh\n— Darrin Schultz (@conchoecia) October 18, 2017\n\n\nAdditionally, I was excited by the “…super easy to use.” part in the description. As it turns out, that part of the Tweet is totally untrue. Here are some of the things that make it difficult to use:\n\nNo pre-install readme file. Without readme file there are no instructions/info on:\n\nNecessary dependencies\nInstall command(s)\n\nInitial install attempt failed with error message. Message suggests trying:\n\nBOOST_ROOT=install ./install.sh\n\nNo post-install readme file. How do I even get started without any documentation??!!\n\nI managed to track down the guide for this, but didn’t get it via searching the internet. I noticed that the link for the software in the original Tweet had a parent directory, so I navigated there and spotted this:\nQuick start guide (PDF): ftp://ftp.genome.umd.edu/pub/MaSuRCA/MaSuRCA_QuickStartGuide.pdf\nAlthough not a big deal, this quick start guide is for the previous version (v.3.2.2).\nSo, is this where we get to the “super easy to use” part? Uh, no. Check it out:\n\nModify a config file (luckily, a template is created during install)\n\n* Illumina paired-end (PE) reads: Aribtrary two letter prefix, mean read length, and read length standard deviation need to be supplied (!!!)\n\n\n* Illumina mate-paired (MP) reads: Called \"JUMP\" in config file and needs the same type of info supplied as PE reads.\n\n\n* PacBio reads: Need to be in a single FASTA file (ugh)!\n\n\n* A bunch of other stuff that I can probably leave alone.\n\nRun the masurca script (located here: MaSuRCA-3.2.3/bin/masurca). This will generate a new script (called assemble.sh).\nRun the assemble.sh script that was created in the previous step.\n\nAlthough not specifically related to the MaSuRCA install, I did encounter problems trying to install this on our Mox (hyak) computing node.\n\nBuild node fail (ironically, this is the specific type of node that’s supposed to be used for compiling software):\n(http://owl.fish.washington.edu/Athaliana/20171019_mox_build_masurca_fail.png)\nOK, so I decided to try compiling it using the login node (which is not what the login node is supposed to be used for):\n\n\nLogin node fail:\n(http://owl.fish.washington.edu/Athaliana/20171019_mox_login_masurca_fail.png)\nI really didn’t want to have to put together an SBATCH script just to compile this software (which compiled without issue, except for that initial BOOST error thingy, on my local Ubuntu 16.04 LTS system), so I just tried running an interactive node and it worked!\nNow, on to trying to actually run this thing…"
  },
  {
    "objectID": "posts/2017/2017-03-02-goals-march-2017/index.html",
    "href": "posts/2017/2017-03-02-goals-march-2017/index.html",
    "title": "Goals - March 2017",
    "section": "",
    "text": "Oh, actually, there is another, smaller goal that will be very difficult to achieve: win Pub-a-Thon. Jay’s taken a massive lead and has a nearly complete manuscript ready for submission. His manuscript is pretty well fleshed out, so it’ll be very difficult to surpass  him at this point. However, I’m always up for a challenge, so I’ll see what I can do…\nAnyway, back to my main goal of completing my manuscript.\nThis should be do-able. I’ve completed the SRA submission process for the raw sequencing data. The stuff that remains is as follows:\n\nGenerate FASTQC analysis on FASTQ files (this is currently running - takes awhile)\nTry to replicate BGI’s FASTQ demultiplexing pipeline to verify that it is functional\nMake decisions with Steven (and Brent?) about what information tables should contain\nWrite\n\nThe beauty of submitting this to the journal Scientific Data, is that it doesn’t require in-depth analysis of your data sets. It merely requires an examination of the data to ensure its integrity, as well as a cursory assessment of the data to evaluate it’s usefulness to the scientific community. No need to delve deeper into the data and attempt to interpret, or draw conclusions about, what the data might mean; that can be left to other researchers who deem this data worthwhile to explore."
  },
  {
    "objectID": "posts/2017/2017-10-03-assembly-comparisons-olympia-oyster-genome-assemblies/index.html",
    "href": "posts/2017/2017-10-03-assembly-comparisons-olympia-oyster-genome-assemblies/index.html",
    "title": "Assembly Comparisons - Olympia oyster genome assemblies",
    "section": "",
    "text": "— UPDATE 20171009 —\nHaving run through this a bunch of times now, I realized that the analysis below incorrectly identifies the outputs from Sean’s Redundans runs. The correct output from each of those runs should be the “scaffolds.reduced.fa” FAST files. The “contigs.fa” files that I linked to below are actually the assemblies produced by other programs; which are required as an input for Redudans.\n\nI recently completed an assembly of the UW PacBio sequencing data using Racon and wanted some assembly stats, as well as a way to compare this assembly to the assemblies Sean had completed.\nAdditionally, Steven recently performed an assembly comparison and I noticed he got some odd results. Specifically, of the three assemblies he compared (PacBio x 1, Illumina x 2), both of the Illumina assemblies had a large quantity of “Ns” in the assemblies. This didn’t seem right and the comparison program he used (QUAST) spit out a message indicating that it seemed like scaffolds were used, instead of contigs. So, I thought I’d give it a shot and see if I could track down non-scaffolded assemblies produced by Sean.\nJupyter notebook (GitHub): 20171003_docker_oly_assembly_comparisons.ipynb\nFirst, I compared the following six assemblies (FASTA files) using QUAST:\nSean’s Assemblies:\n\nPacBio (Canu): https://owl.fish.washington.edu/scaphapoda/Sean/Oly_Canu_Output/oly_pacbio_.contigs.fasta\nIllumina (Platanus): https://owl.fish.washington.edu/scaphapoda/Sean/Oly_Illumina_Platanus_Assembly/Oly_Out__contig.fa\nIllumina (Platanus): https://owl.fish.washington.edu/scaphapoda/Sean/Oly_Platanus_Assembly_Kmer-22/Oly_Out__contig.fa\nIllumina/PacBio (Redundans): https://owl.fish.washington.edu/scaphapoda/Sean/Oly_Redundans_Output/contigs.fa\nIllumina/PacBio (Redundans): https://owl.fish.washington.edu/scaphapoda/Sean/Oly_Redundans_Output_Try_2/contigs.fa\n\nSam’s Assembly:\n\nPacBio (Racon): https://owl.fish.washington.edu/Athaliana/201709_oly_pacbio_assembly_minimap_asm_racon/20170918_oly_pacbio_racon1_consensus.fasta\n\nQUAST output directory: https://owl.fish.washington.edu/Athaliana/20171003_quast_oly_genome_assemblies/\nHere’s the assembly comparison of all assemblies (click on image for larger view):\n(http://owl.fish.washington.edu/Athaliana/20171003_oly_assemblies_00.png)\nInteractive version of that graphic is here: https://owl.fish.washington.edu/Athaliana/20171003_quast_oly_genome_assemblies/report.html\nThe first thing that jumps out to me is the fact that two of the Illumina assemblies, which used different assemblers(!!) have the EXACT same assembly stats. This occurrence seems extremely unlikely. I’ve double-checked my Jupyter notebook to make sure that I didn’t assign the same file by accident (see Input #6)\n(http://owl.fish.washington.edu/Athaliana/20171003_oly_assemblies_01.png)\nVery strange!\nI also noticed that the first Redundans assembly of Sean’s has a ton of “Ns”, suggesting that it’s actually a scaffolded assembly. As with Steven’s QUAST run, QUAST spits out the messages suggesting to use the “–scaffold” option for this file.\nThe other thing I noticed is the two PacBio assemblies (Canu & Racon) have a huge difference in the total number of bp (~13,000,000)! I ran a QUAST assembly comparison between just those two for easier viewing/comparison (https://owl.fish.washington.edu/Athaliana/20171003_quast_oly_pacbio_assemblies/):\n(http://owl.fish.washington.edu/Athaliana/20171003_oly_assemblies_03.png)\nInteractive version of that graphic is here: https://owl.fish.washington.edu/Athaliana/20171003_quast_oly_pacbio_assemblies/report.html\nThe fact that there is such a large discrepancy in the total number of bps between these two assemblies really leaves me to believe that I am missing a FASTQ file from my assembly. I’m going to go back and see if that is indeed the case or if this difference in the assemblies is real.\nHere’s an embedded version of my Jupyter notebook:"
  },
  {
    "objectID": "posts/2017/2017-03-03-fastqc-oly-bgi-gbs-raw-illumina-data/index.html",
    "href": "posts/2017/2017-03-03-fastqc-oly-bgi-gbs-raw-illumina-data/index.html",
    "title": "FASTQC - Oly BGI GBS Raw Illumina Data",
    "section": "",
    "text": "Below, is the Jupyter notebook I used to run the FastQC analysis on the two files. I’ve embedded for quick viewing, but it might be easier to view the notebook via the GitHub link.\nResults:\nWell, I realized that running FastQC on the raw data might not reveal anything all too helpful. The reason for this is that the adaptor and barcode sequences are still present on all the reads. This will lead to over-representation of these sequences in all of the samples, which, in turn, will skew FastQC’s intepretation of the read qualities. For comparison, I’ll run FastQC on the demultiplexed data provided by BGI and see what the FastQC report looks like on trimmed data.\nHowever, I’ll need to discuss with Steven about whether or not providing the FastQC analysis is worthwhile as part of the “technical validation” aspect of the manuscript. I guess it can’t hurt to provide it, but I’m not entirely sure that the FastQC report provides any real information regarding the quality of the sequencing reads that we received…\nJupyter notebook (GitHub): 20170301_docker_fastqc_nondemultiplexed_bgi_oly_gbs.ipynb"
  },
  {
    "objectID": "posts/2017/2017-05-09-samples-received-olympia-oyster-histology-blocks-and-slides-for-laura-spencer/index.html",
    "href": "posts/2017/2017-05-09-samples-received-olympia-oyster-histology-blocks-and-slides-for-laura-spencer/index.html",
    "title": "Samples Received - Olympia oyster Histology Blocks and Slides (for Laura Spencer)",
    "section": "",
    "text": "Received histology blocks and slides for Laura Spencer.\nSamples were stored in glass cabinet in FTR 213 (see images below).\n(http://eagle.fish.washington.edu/Arabidopsis/20170509_laura_oly_histo_01.jpg)\n(http://eagle.fish.washington.edu/Arabidopsis/20170509_laura_oly_histo_02.jpg)"
  },
  {
    "objectID": "posts/2017/2017-07-06-data-management-tarball-of-olympia-oyster-uw-pacbio-data-from-20170323/index.html",
    "href": "posts/2017/2017-07-06-data-management-tarball-of-olympia-oyster-uw-pacbio-data-from-20170323/index.html",
    "title": "Data Management – Tarball of Olympia oyster UW PacBio Data from 20170323",
    "section": "",
    "text": "I’d previously attempted to archive this data set on multiple occasions, across multiple days, but network dropouts kept killing my connection to the server (Owl) and, in turn, interrupting the tarball operation.\nToday, I came in to a successful creation of the tarball of this PacBio data set (it only took 10hrs)! And, it’s a big file: 162GB!! Remember, that’s the compressed size!\nNow, we’ll have to decide where we want to keep the tarball. I guess this’ll be part of our next data management plan discussions.\n(http://eagle.fish.washington.edu/Arabidopsis/20170706_uw_pacbio_tarball.png)"
  },
  {
    "objectID": "posts/2017/2017-04-18-manuscript-oly-gbs-14-day-plan/index.html",
    "href": "posts/2017/2017-04-18-manuscript-oly-gbs-14-day-plan/index.html",
    "title": "Manuscript - Oly GBS 14 Day Plan",
    "section": "",
    "text": "For Pub-a-thon 2017, Steven has asked us to put together a 14 day plan for our manuscripts.\nMy manuscript is accessible in three locations:\nCurrent: Overleaf for final editing/formatting before submission Scientific Data.\nAdditionally, I have established a data repository with a Digital Object Identifier (DOI) at Open Science Framework\nHere’s what I have going on:\n\nDay 1\n\nConvert .xls data records to .csv to see if they will render in OSF repo.\nAssemble figure: phylogenetic tree.\nAdd figure to manuscript.\nDeal with any minor edits.\n\n\n\nDay 2\n\nAssemble figure: Puget Sound map.\nAdd figure to manuscript.\nDeal with any minor edits.\n\n\n\nDay 3\n\nSubmit? Depends on what Steven’s availability is to finish of Background & Summary and write up Abstract."
  },
  {
    "objectID": "posts/2017/2017-07-03-data-management-olympia-oyster-uw-pacbio-data-from-20170323/index.html",
    "href": "posts/2017/2017-07-03-data-management-olympia-oyster-uw-pacbio-data-from-20170323/index.html",
    "title": "Data Management - Olympia oyster UW PacBio Data from 20170323",
    "section": "",
    "text": "Due to other priorities, getting this PacBio data sorted and prepped for our [next gen sequencing data management plan (DMP)(https://github.com/sr320/LabDocs/wiki/Data-Management#ngs-data-management-plan) was put on the back burner. I finally got around to this, but it wasn’t all successful.\nThe primary failure is the inability to get the original data file archived as a gzipped tarball. The problem lies in loss of connection to Owl during the operation. This connection issue was recently noticed by Sean in his dealings with Hyak (mox). According to Sean, the Hyak (mox) people or UW IT ran some tests of their own on this connection and their results suggested that the connection issue is related to a network problem in FTR, and is not related to Owl itself. Whatever the case is, we need to have this issue addressed sometime soon…\nAnyway, below is the Jupyter notebook that demonstrates the file manipulations I used to find, copy, rename, and verify data integrity of all the FASTQ files from this sequencing run.\nNext up is to get these FASTQ files added to the DMP spreadsheets.\nJupyter notebook (GitHub): 20170622_oly_pacbio_data_management.ipynb\nI’ve also embedded the notebook below, but it might be easier to view at the GitHub link provided above."
  },
  {
    "objectID": "posts/2017/2017-11-21-samples-submitted-geoduck-tissues-to-illumina-for-more-10x-genomics-sequencing/index.html",
    "href": "posts/2017/2017-11-21-samples-submitted-geoduck-tissues-to-illumina-for-more-10x-genomics-sequencing/index.html",
    "title": "Samples Submitted - Geoduck Tissues to Illumina for More 10x Genomics Sequencing",
    "section": "",
    "text": "Continuing Illumina’s generous efforts to use our geoduck samples to test out the robustness of their emerging sequencing technologies, they have requested we send them some more geoduck tissue so that they can try to isolate higher molecular weight DNA to complete the genome sequencing efforts using the 10x genomics sequencing platform.\nI sent three frozen pieces of geoduck foot, ctenidia, & adductor muscle tissue on dry ice. Tissue was collected by Brent & Steven on 20150811.\nFedEx tracking: 770796037903"
  },
  {
    "objectID": "posts/2017/2017-08-08-data-management-illumina-geoduck-hiseq-miseq-data/index.html",
    "href": "posts/2017/2017-08-08-data-management-illumina-geoduck-hiseq-miseq-data/index.html",
    "title": "Data Management - Illumina Geoduck HiSeq & MiSeq Data",
    "section": "",
    "text": "The HDD we received from Illumina last week only had data (i.e. fastq files) from the NovaSeq runs they performed - nothing from either the MiSeq, nor the HiSeq runs.\nWe contacted them about the missing data, they confirmed it was missing, and uploaded the remaining data to BaseSpace.\nBegan downloading the data - will take awhile…\n(http://eagle.fish.washington.edu/Arabidopsis/20170808_BaseSpace_Downloader_geoduck_illumina_data.png)\nFiles will be temporarily stored in these locations:\n/volume1/web/nightingales/Geoduck_MiSeq/170317_M03814_0172_000000000-B2K79/Data/GeoDuckRNAMiSeq-35978947\n/volume1/web/nightingales/Geoduck_HiSeq/170228_ST-K00104_0382_BHHGTLBBXX/Data/Ironman-35682656\n/volume1/web/nightingales/Geoduck_HiSeq/170228_ST-K00104_0381_AHHHWNBBXX/Data/Ironman-35682656"
  },
  {
    "objectID": "posts/2017/2017-08-03-goals-august-2017/index.html",
    "href": "posts/2017/2017-08-03-goals-august-2017/index.html",
    "title": "Goals - August 2017",
    "section": "",
    "text": "Data, data, data! That is the theme for this month.\nOlympia oyster data - Going to assess and continue working on assembly the Olympia oyster genome we have from our BGI sequencing project, along with the PacBio data we have. To-date, it’s been difficult to get these two datasets to play nicely with one another. I’ll take a look to see what’s worked, and what hasn’t, as well as try out some other means by which to get a decent assembly.\nGeoduck data - We just got back an insane amount of RNAseq and genome sequencing data from an Illumina pilot project. This data needs to be properly documented and catalogued.\nHackweek 2017 - Although this is only a brief period during this month, it’s designed to tackle some lower priority tasks that will help streamline lab operations. Check out the GtiHub repo issues for Hackweek 2017 to get an idea of some of the projects."
  },
  {
    "objectID": "posts/2017/2017-09-07-genome-assembly-olympia-oyster-pacbio-minimapminiasmracon/index.html",
    "href": "posts/2017/2017-09-07-genome-assembly-olympia-oyster-pacbio-minimapminiasmracon/index.html",
    "title": "Genome Assembly - Olympia oyster PacBio minimap/miniasm/racon",
    "section": "",
    "text": "In this GitHub Issue, Steven had suggested I try out the minimap/miniasm/racon pipeline for assembling our Olympia oyster PacBio data.\nI followed the pipeline described by this paper: https://matzlab.weebly.com/uploads/7/6/2/2/76229469/racon.pdf.\nThis notebook entry just contains the initial minimap execution. Followed up with miniasm and then racon.\nJupyter Notebook (GitHub): 20170907_docker_pacbio_oly_minimap2.ipynb"
  },
  {
    "objectID": "posts/2017/2017-10-02-goals-october-2017/index.html",
    "href": "posts/2017/2017-10-02-goals-october-2017/index.html",
    "title": "Goals - October 2017",
    "section": "",
    "text": "I guess one of my primary goals is to make sure I actually write my monthly goals each month.\nIs it bad that I’m writing goals about writing goals? Or, is it meta?\nRegardless, I’m actually going to put a lot down on paper, as much has happened since my last set of goals were posted.\nWe had a “hack week” back in August. For us, “hacking” means organizing and updating lab documentation.\nWe took on the following tasks:\n\n“Decommission” the LabDocs GitHub repo. This had been the canonical location for all of our online lab resources and had served as the starting point. However, it was not organized particularly well for what we were using it for, and was out of date in a number of places. Additionally, this is a personal GitHub repository of Steven’s and it didn’t make logical sense to use it as a dedicated lab repo.\n\nAs part of the decommission, we migrated all of the open issues (we used this great little web-based tool: Issue Mover for GitHub to our organization’s GitHub repository: Roberts Lab @ SAFS\n\nA massive reorganization, updating, and cleansing of files. We now have separate repositories for our onboarding practices(including an official Lab Code of Conduct), laboratory resources, and [code language=“snippets”][/code](https://github.com/RobertsLab/code). Wiki pages have been created for each of these repos, and readme files have been created/updated to improve instructions on how to locate needed information. Overall, we feel it simplifies the ability for lab members to find the information they need.\n\nHere’s a graphic of the amount of love that went into the old LabDocs repo since it’s inception (337,000 additions to files!):\n(http://eagle.fish.washington.edu/Arabidopsis/20171002_labdocs_stats.png)\nAnyway, on to the current stuff.\nPrimary goal will be to perform a comparison of Olympia oyster genome assemblies.\nNext will be to continue generating a joint assembly of Illumina and PacBio sequencing data for the Olympia oyster genome. This will take over from where Sean Bennett left off.\nAfter that, writing my November 2017 goals…"
  },
  {
    "objectID": "posts/2017/2017-10-31-software-installation-alpaca-on-roadrunner/index.html",
    "href": "posts/2017/2017-10-31-software-installation-alpaca-on-roadrunner/index.html",
    "title": "Software Installation - ALPACA on Roadrunner",
    "section": "",
    "text": "List of software that needed installing to run ALPACA:\n\nALPACA\nCelera Assembler\nsamtools\nbowtie2\nECtools\n\nInstalled all software in:\n/home/shared/\nHad to change permissions on /home/shared/. Used the following to change permissions recursively (-R) to allow all admin (i.e. sudo group) users to read/write in this directory:\n<code>$sudo chown -R :sudo /home/shared</code>\nCompiled Celera Assembler from source (per the ALPACA requirements). This is the source file that I used: https://sourceforge.net/projects/wgs-assembler/files/wgs-assembler/wgs-8.3/wgs-8.3rc2.tar.bz2/download\nAdded all software to my system PATH by adding the following to my ~./bashrc file:\n[code lang=text] ## Add bioinformatics softwares to PATH\nexport PATH=${PATH}: /home/shared/alpaca: /home/shared/Bismark: /home/shared/bowtie2-2.3.3.1-linux-x86_64: /home/shared/ectools-0.1: /home/shared/PBSuite_15.8.24/bin: /home/shared/pecan/bin: /home/shared/samtools-1.6/bin: /home/shared/wgs-assembler/Linux-amd64/bin [/code]\nAfter adding that info to the bottom of my ~./bashrc file, I re-loaded the file into system memory by sourcing the file:\n<code>$source ~/.bashrc</code>\nFollowed the ALPACA test instructions to confirm proper installation. More specific test instructions are actually located at the top of this file: /home/shared/alpaca/scripts/run_example.sh\nChanged Celera Assembler directory name:\n<code>$mv /home/shared/wgs-8.3rc2 /home/shared/wgs-assembler</code>\n\nStep 1.\n<code>$mkdir /home/shared/test</code>\n\n\nStep 2.\n<code>$cd /home/shared/test/</code>\n\n\nStep 3.\n<code>$../alpaca/scripts/run_example.sh</code>\nStep three failed (which executes the run_example.sh script) due to permission problems.\nRealized the script file didn’t have execute perimssions so I added execute permissions with the following command:\n<code>$sudo chmod +x /home/shared/alpaca/scripts/run_example.sh</code>\n\n\nStep 4. Continued with ALPACA Tests 2 & 3.\nEverything tested successfully. Will try to get an assembly running with our PacBio and Illumina data."
  },
  {
    "objectID": "posts/2017/2017-01-23-manuscript-writing-the-nuances-of-using-authorea/index.html",
    "href": "posts/2017/2017-01-23-manuscript-writing-the-nuances-of-using-authorea/index.html",
    "title": "Manuscript Writing - The “Nuances” of Using Authorea",
    "section": "",
    "text": "PROBLEM: Authorea spits out a browser-crashing “unresponsive script” message (actually, lots and lots of them; clicking “Stop script” or “Continue” just results in additional messages) in Firefox (haven’t tried any other browsers). This renders the browser inoperable and I have to force quit. It doesn’t happen all of the time, so it’s hard to pinpoint what triggers this.\n(http://eagle.fish.washington.edu/Arabidopsis/20170123_authorea_script_bug.png)\n\nPROBLEM: Authorea remains in a perpetual “saving…” state after inserting a citation. It also renders the page strangely, with HTML  tags (see the “Methods” section in the screen cap below).\n(http://eagle.fish.washington.edu/Arabidopsis/20170123_authorea_saving_bug.png)\nSOLUTION: Type additional text somewhere, anywhere. This is an OK solution, but is particularly annoying if I just want to go through and add citations and have no intentions of doing any writing.\n\nPROBLEM: Multi-author citations don’t get formatted with “et al.” By default, Authorea inserts all citations using the following LaTeX format:\n\\cite{Elshire_2011}\nResult: (Elshire 2011).\nThis is a problem because this reference has multiple authors and should be written as: (Elshire et al., 2011).\nSOLUTION: Change citation format to:\n\\citep{Elshire_2011}\nOther citation formatting options can be found here (including multiple citations within one set of parentheses, and referring in-text author name with only publication year in parentheses):\nHow to add and manage citations and references in Authorea\n\nPROBLEM: When a citation no longer exists in the manuscript, it still persists in the bibliography.\nSOLUTION: A known bug with no current solution. Currently, have to delete them from the bibliography by hand (or, maybe figure out a way to do it programatically)…\n(http://eagle.fish.washington.edu/Arabidopsis/20170123_authorea_bib_bug.png)\n\nPROBLEM: Cannot click-and-drag some references from Mendeley (haven’t tested other reference managers) without getting an error. To my knowledge, the BibTeX is valid, as it appears to be the same formatting as other references that can be inserted via the click-and-drag method. There are some references it won’t work for…\n(http://eagle.fish.washington.edu/Arabidopsis/20170123_authorea_bibtex_bug.png)\nSOLUTION: Use the search bar in the citation insertion dialogue box. Not as convenient and slows down the workflow for citation insertion, but it works…"
  },
  {
    "objectID": "posts/2017/2017-07-31-data-received-geoduck-genome-sequencing-by-illumina/index.html",
    "href": "posts/2017/2017-07-31-data-received-geoduck-genome-sequencing-by-illumina/index.html",
    "title": "Data Received - Geoduck Genome Sequencing by Illumina",
    "section": "",
    "text": "We previously sent some geoduck samples to Illumina, as part of a pilot project for them to test out a new sequencing platform. The data has finally arrived!\nIt was sent on a 4TB Seagate external hard drive.\nDue to weird connection issues we’ve recently encountered with our server, Owl (Synology DS1812+), I connected the HDD directly to Owl via USB (instead of connecting to a computer and transferring). I transferred the data using the Synology web interface to avoid any computer/NAS connection issues that might interrupt the transfer.\nWe have a meeting with the Illumina people tomorrow afternoon to review the data they’ve provided (looks like it’s going to take awhile, though). Once that meeting takes place, we’ll figure out how to document this project in our data management plan.\n(http://eagle.fish.washington.edu/Arabidopsis/20170731_geoduck_illumina_data.png)\n(http://eagle.fish.washington.edu/Arabidopsis/20170731_geoduck_illumina_data_transfer.png)"
  },
  {
    "objectID": "posts/2017/2017-07-03-manuscript-re-submission-oly-stress-response-to-peerj-for-review/index.html",
    "href": "posts/2017/2017-07-03-manuscript-re-submission-oly-stress-response-to-peerj-for-review/index.html",
    "title": "Manuscript Re-submission - Oly Stress Response to PeerJ for Review",
    "section": "",
    "text": "Last August, we made our initial submission of this paper to PeeJ.\nToday, we re-submitted the revised manuscript.\nThe repo for this paper is here.\nI’ve also submitted an updated pre-print. I will update this post when it is publicly accessible (it has to be approved by PeerJ staff before it becomes public).\nUPDATE 20170703 - Updated pre-print is now available: https://peerj.com/preprints/1595/"
  },
  {
    "objectID": "posts/2017/2017-08-28-samples-submitted-geoduck-ctenidia-to-illumina-for-10x-genomics-sequencing/index.html",
    "href": "posts/2017/2017-08-28-samples-submitted-geoduck-ctenidia-to-illumina-for-10x-genomics-sequencing/index.html",
    "title": "Samples Submitted - Geoduck Ctenidia to Illumina for 10x Genomics Sequencing",
    "section": "",
    "text": "Continuing Illumina’s generous efforts to use our geoduck samples to test out the robustness of their emerging sequencing technologies, they have requested we send them some geoduck tissue so that they can try to complete the genome sequencing efforts using the 10x genomics sequencing platform.\nI sent two frozen pieces (~28mg each) of geoduck ctendia tissue on dry ice. Tissue was collected by Brent & Steven on 20150811.\nFedEx tracking: 770129114978"
  },
  {
    "objectID": "posts/2017/2017-01-04-data-management-replacement-of-corrupt-bgi-oly-genome-fastq-files/index.html",
    "href": "posts/2017/2017-01-04-data-management-replacement-of-corrupt-bgi-oly-genome-fastq-files/index.html",
    "title": "Data Management - Replacement of Corrupt BGI Oly Genome FASTQ Files",
    "section": "",
    "text": "Previously, Sean and Steven identified two potentially corrupt FASTQ files. I contacted BGI about getting replacement files and they informed me that all versions of the FASTQ files they have delivered on three separate occasions are all the same file (despite having different file names). As such, I could use one of these versions to replace the corrupt FASTQ files. So, that’s what I did!\nSee the Jupyter Notebook below for the deets!\nJupyter Notebook (GitHub): 20170104_docker_oly_BGI_genome_corruption_solved.ipynb"
  },
  {
    "objectID": "posts/2017/2017-07-20-rna-isolation-olympia-oyster-gonad-tissue-in-paraffin-histology-blocks-2/index.html",
    "href": "posts/2017/2017-07-20-rna-isolation-olympia-oyster-gonad-tissue-in-paraffin-histology-blocks-2/index.html",
    "title": "RNA Isolation - Olympia oyster gonad tissue in paraffin histology blocks",
    "section": "",
    "text": "My previous go at this was a little premature - I didn’t wait for Laura to fully annotate her slides/blocks. Little did I know, the tissue was mostly visceral mass and, as such, I didn’t hit much in the way of actual gonad tissue. So, I’m redoing this, now that Grace has gone through and annotated the blocks to point out gonad tissue. SN-10-16 was sent to Katherine Silliman on 20170720.\nIsolated RNA from Olympia oyster gonad previously preserved with the PAXgene Tissue Fixative and Stabilizer and then embedded in paraffin blocks. See Laura’s notebook for full details on samples and preservation.\nRNA was isolated from the following samples using the PAXgene Tissue RNA Kit (Qiagen). Gouged samples from the blocks weighing ~10mg from each of the tissues and processed according the protocol for isolating RNA from blocks of paraffin-embedded tissues.\nBackground on all of this is in this GitHub Issue\n\nNF-10-22\nNF-10-23\nNF-10-24\nNF-10-26\nNF-10-28\nNF-10-30\nSN-10-16\nSN-10-17\nSN-10-20\nSN-10-25\nSN-10-26\nSN-10-31\n\nIMPORTANT:\n\nPrior to beginning, I prepared an aliquot of Buffer TR1 by adding 40μL of β-mercaptoethanol (β-ME) to 4000μL of Buffer TR1)\n\nIsolated RNA according to the PAXgene Tissue RNA Kit protocol with the following alterations:\n\n“Max speed” spins were performed at 20,000g.\nTissue disruption was performed by adding ~25-50 glass beads (425 - 600μm diameter) with the Disruptor Genie @ 45C for 15mins (in the Friedman Lab).\nShaking incubation step was performed with Disruptor Genie\nSamples were eluted with 27μL of Buffer TR4 x 2, incubated @ 65C for 5mins, immediately placed on ice.\n\n(http://eagle.fish.washington.edu/Arabidopsis/20170719_histo_blocks_laura_oly_gonad.jpg)\nResults:\nSamples were not quantified due to lack of proper RNA Qubit assay AND the computer that our NanoDrop1000 is hooked up to is dead. Will have Katherine Silliman perform quantification.\nSamples were stored at -80C temporarily.\nSamples will be sent to Katherine Silliman for high-throughput library construction and sequencing once I hear back from her regarding her availability to receive the samples."
  },
  {
    "objectID": "posts/2017/2017-05-10-dna-quantification-acropora-cervicornis-staghorn-coral-dna-from-javier-casariego-fiu/index.html",
    "href": "posts/2017/2017-05-10-dna-quantification-acropora-cervicornis-staghorn-coral-dna-from-javier-casariego-fiu/index.html",
    "title": "DNA Quantification - Acropora cervicornis (Staghorn coral) DNA from Javier Casariego (FIU)",
    "section": "",
    "text": "DNA samples received yesterday were quantified using the Roberts Lab Qubit 3.0 to improve quantification accuracy (samples provided by Javier were quantified via NanoDrop, which generally overestimates DNA concentration) prior to performing methylation assessment.\nQuantification was performed using the dsDNA Broad Range Kit.\nUsed 1uL of each sample.\nResults:\nThree samples are too dilute for immediate use in the MethylFlash Methylated DNA Quantification Kit (Colorimetric) - max sample volume is 8uL. Will have to concentrate them (will likely use SpeedVac to prevent sample loss).\nValues were added to the spreadsheet provided by Javier (Google Sheet): A.cervicornis_DNA_Extractions(May_2017).xlsx\nQubit output file (Google Sheet): 20170510_qubit_A_cervicornis_DNA"
  },
  {
    "objectID": "posts/2017/2017-11-07-rna-isolation-quantification-tanner-crab-hemolymph/index.html",
    "href": "posts/2017/2017-11-07-rna-isolation-quantification-tanner-crab-hemolymph/index.html",
    "title": "RNA Isolation & Quantification - Tanner crab hemolymph",
    "section": "",
    "text": "We received three Tanner crab (Chionoecetes bairdi)hemolymph samples from Pam Jensen (NOAA) yesterday. From her email to Steven:\n\nHi Steven, I am sending: tube #1 crab 3859/3656: 300 ul blood + 1300 ul RNAlater​\ntube #2 crab 3665/3873: 300 ul blood + 1300 ul RNAlater ​tube #3 crab 3665/3873: 200 ul blood + 1400 ul RNAlater​\nThe tubes hold max of 1600 ul. Will know on Sun or Mon if either crab is infected w Hematodinium.\nTracking info to follow. Pam\n\nSamples were stored at 4C O/N.\nHere’s what the samples looked like before processing:\n(http://owl.fish.washington.edu/Athaliana/20171107_RNA_isoaltion_crab_01.jpg)\nThe samples are extremely cloudy. I’m not sure if this is expected.\nProcessed samples using RNAzol RT (MRC) according to the manufacturer’s protocol for Total RNA Isolation.\nPelleted samples at 5000g for 5 mins and the samples looked like this:\n(http://owl.fish.washington.edu/Athaliana/20171107_RNA_isoaltion_crab_02.jpg)\nDecided to pellet samples for an additional 10mins. The pellet was more compact. Transferred supernatant to clean tube, since it seemed to contain “debris” (maybe cells?). Processed pellet with RNAzol RT. Brief rundown of procedure (all steps at room temp):\n\nTransferred supe to clean tube.\nAdded 1mL RNAzol RT to pellet and mixed by repeated pipetting (solution was cloudy and slightly viscous).\nAdded 400uL of 0.1% DEPC-treated H2O and mixed vigorously by hand.\nIncubated for 10mins.\nCentrifuged 12,000g for 15mins.\n\nSamples looked like this:\n(http://owl.fish.washington.edu/Athaliana/20171107_RNA_isoaltion_crab_03.jpg)\n\nThis is not normal. Usually the supernatant is the clear portion, while the blue layer is below that.\n\nTransferred 750uL of the clear portion to clean 1.7mL tube.\nAdded equal volume of isopropanol, mixed by inversion. Appeared to be a very high amount of genomic DNA precipitation visible in the tube.\nIncubated for 10mins.\nCentrifuged 12,000g, 15mins.\n\nSamples looked like this:\n(http://owl.fish.washington.edu/Athaliana/20171107_RNA_isoaltion_crab_04.jpg)\n\n\nIt appears that the nucleotides (the white interphase) are suspended on a “cushion” of higher density solution, instead of pelleted at the bottom of the tube.\n\nRemoved/discarded higher density solution, leaving the white layer on the bottom of the tube.\nCentrifuged 12,000g, 15mins.\nDiscarded supe.\nWashed pellet with 75% ethanol.\nCentrifuged 8,000g, 3mins.\nRepeated Steps 12, 13, & 14, 1x.\nDiscarded ethanol.\nResuspended RNA in 50uL 0.1% DEPC-treated H2O. Pellets did not solubilize on their own. I dispersed the pellets by repeated pipetting (P200). Remaining insoluble material was pelleted (12,000g, 30s) and supernatant was transferred to a new 1.6mL tube.\n\nRNA was quantified using the Qubit 3.0 and the Qubit HS RNA Assay. Used 5uL of each sample.\nResults:\n20171107_qubit_tanner_crab_hemo (Google Sheet)\n\n\nSample ID Conc. (ng/uL) Total Yield (ng)\n\n\n\n\n\n3859/3656\n\n\n0.44\n\n\n22\n\n\n\n\n3665/3873\n\n\n1.66\n\n\n83\n\n\n\n\n3665/3873\n\n\n2.04\n\n\n102\n\n\n\n\n\nInterestingly, both samples from the same crab had similar/decent yields.\nSamples were labeled and stored at -80C in Shellfish RNA Box #6"
  },
  {
    "objectID": "posts/2017/2017-05-09-samples-received-acropora-cervicornis-staghorn-coral-dna-from-javier-casariego-fiu/index.html",
    "href": "posts/2017/2017-05-09-samples-received-acropora-cervicornis-staghorn-coral-dna-from-javier-casariego-fiu/index.html",
    "title": "Samples Received - Acropora cervicornis (Staghorn coral) DNA from Javier Casariego (FIU)",
    "section": "",
    "text": "Received 62 coral (Acropora cervicornis) DNA samples from Javier Casariego at FIU.\nSpreadsheet of samples and NanoDrop concentrations provided by Javier (converted to Google Sheet): A.cervicornis_DNA_Extractions(May_2017).xlsx\nSamples were temporarily stored at 4c (in FTR 213) until I can perform global methylation assessment on them tomorrow.\n(http://eagle.fish.washington.edu/Arabidopsis/20170509_javier_DNA_samples.jpg)"
  },
  {
    "objectID": "posts/2017/2017-03-21-data-management-sra-submission-oly-gbs-batch-submission/index.html",
    "href": "posts/2017/2017-03-21-data-management-sra-submission-oly-gbs-batch-submission/index.html",
    "title": "Data Management – SRA Submission Oly GBS Batch Submission",
    "section": "",
    "text": "An earlier attempt at submitting these files failed.\nI re-uploaded the failed files (indicated in my previous notebook entry linked above) and tried again.\n(http://eagle.fish.washington.edu/Arabidopsis/20170321_SRA_oly_gbs_demultiplex_SUB2495017_01.png)\nIt failed again, despite having successfully uploaded just minutes before.\nI re-uploaded that “missing” file and tried again.\nThis time, it succeeded (and no end-of-stream error for the 1SN_1A file!)!\nWill post here with the SRA accession number once it goes live!"
  },
  {
    "objectID": "posts/2017/2017-10-06-genome-assembly-olympia-oyster-redundanscanu-vs-redundansracon/index.html",
    "href": "posts/2017/2017-10-06-genome-assembly-olympia-oyster-redundanscanu-vs-redundansracon/index.html",
    "title": "Genome Assembly - Olympia oyster Redundans/Canu vs. Redundans/Racon",
    "section": "",
    "text": "Decided to compare the Redundans using Canu as reference and Redundans using Racon as reference. Both reference assemblies were just our PacBio data.\nJupyter notebook (GitHub): 20171005_docker_oly_redundans.ipynb\nNotebook is also embedded at the end of this post.\n\nRedundans/Canu assembly (scaffolded assembly; FASTA): https://owl.fish.washington.edu/Athaliana/20171004_redundans/scaffolds.reduced.fa\nRacon PacBio assembly (contigs: FASTA): https://owl.fish.washington.edu/Athaliana/201709_oly_pacbio_assembly_minimap_asm_racon/20170918_oly_pacbio_racon1_consensus.fasta\n\nResults:\n\nRedundans/Racon Output folder: https://owl.fish.washington.edu/Athaliana/20171005_redundans/\nRedundans/Racon assembly (scaffolded assembly; FASTA): https://owl.fish.washington.edu/Athaliana/20171005_redundans/scaffolds.reduced.fa\nQUAST output folder (default settings): https://owl.fish.washington.edu/Athaliana/quast_results/results_2017_10_06_22_21_06/\nQUAST output folder (–scaffolds setting): https://owl.fish.washington.edu/Athaliana/quast_results/results_2017_10_06_22_27_26/\n\nIt should be noted that the paired reads for each of the BGI mate-pair Illumina data did not assemble, just like last time I used them:\n\n160103_I137_FCH3V5YBBXX_L3_WHOSTibkDCABDLAAPEI-62_2.fq.gz\n160103_I137_FCH3V5YBBXX_L3_WHOSTibkDCACDTAAPEI-75_2.fq.gz\n160103_I137_FCH3V5YBBXX_L4_WHOSTibkDCABDLAAPEI-62_2.fq.gz\n160103_I137_FCH3V5YBBXX_L4_WHOSTibkDCACDTAAPEI-75_2.fq.gz\n160103_I137_FCH3V5YBBXX_L5_WHOSTibkDCAADWAAPEI-74_2.fq.gz\n160103_I137_FCH3V5YBBXX_L6_WHOSTibkDCAADWAAPEI-74_2.fq.gz\n\nRedundans with Canu is better, suggesting that the Canu assembly is the better of the two PacBio assemblies (which we had already suspected).\nQUAST comparison using default settings:\nInteractive link:https://owl.fish.washington.edu/Athaliana/quast_results/results_2017_10_06_22_21_06/report.html\n(http://owl.fish.washington.edu/Athaliana/20171005_%20quast_redundans_01.png)\nQUAST comparison using –scaffolds setting:\nInteractive link: https://owl.fish.washington.edu/Athaliana/quast_results/results_2017_10_06_22_27_26/report.html\n(http://owl.fish.washington.edu/Athaliana/20171005_%20quast_redundans_02.png)"
  },
  {
    "objectID": "posts/2017/2017-07-06-data-management-sra-submission-olympia-oyster-uw-pacbio-data-from-20170323/index.html",
    "href": "posts/2017/2017-07-06-data-management-sra-submission-olympia-oyster-uw-pacbio-data-from-20170323/index.html",
    "title": "Data Management - SRA Submission Olympia Oyster UW PacBio Data from 20170323",
    "section": "",
    "text": "Submitted the FASTQ files from the UW PacBio Data from 20170323 to the [NCBI sequence read archive (SRA)(https://www.ncbi.nlm.nih.gov/sra).\nFTP’d the data to NCBI’s servers, following their instructions. Briefly,\nChange to the directory where the FASTQ files are (Owl/web/nightingales/O_lurida) and then initiate an FTP session:\n<code>ftp -i ftp-private.ncbi.nlm.nih.gov</code>\nEnter provided username/password, change to my designated uploads directory, create new folder dedicate to this particular upload. Then, upload all the files using the mput command:\n<code>mput *filtered_subreads*</code>\nSRA deets are below (assigned FASTQ files to existing BioProject and created a new BioSample). Will update post with SRA number when processing is complete on the NCBI end.\nSRA: SRS2339870 Study: SRR5809355 BioProject: PRJNA316624 BioSample: SAMN07326085"
  },
  {
    "objectID": "posts/2017/2017-12-12-samples-submitted-pulverized-geoduck-tissues-to-illumina-for-more-10x-genomics-sequencing/index.html",
    "href": "posts/2017/2017-12-12-samples-submitted-pulverized-geoduck-tissues-to-illumina-for-more-10x-genomics-sequencing/index.html",
    "title": "Samples Submitted - Pulverized Geoduck Tissues to Illumina for More 10x Genomics Sequencing",
    "section": "",
    "text": "Continuing Illumina’s generous efforts to use our geoduck samples to test out the robustness of their emerging sequencing technologies, they have requested we send them some more geoduck tissue so that they can try to isolate higher molecular weight DNA to complete the genome sequencing efforts using the 10x genomics sequencing platform.\nThe previous set of tissues sent did not yield DNA with high enough molecular weight.\nThis time, I pulverized ctenidia and foot tissues under liquid nitrogen with mortar and pestle, in hopes of improving the efficiency of the extraction process they’re using.\nI sent pulverized tissue on dry ice. Tissue was collected by Brent & Steven on 20150811.\nFedEx tracking: 770975522511"
  },
  {
    "objectID": "posts/2017/2017-11-14-genome-assembly-olympia-oyster-illumina-pacbio-using-pb-jelly-wbgi-scaffold-assembly/index.html",
    "href": "posts/2017/2017-11-14-genome-assembly-olympia-oyster-illumina-pacbio-using-pb-jelly-wbgi-scaffold-assembly/index.html",
    "title": "Genome Assembly - Olympia Oyster Illumina & PacBio Using PB Jelly w/BGI Scaffold Assembly",
    "section": "",
    "text": "Yesterday, I ran PB Jelly using Sean’s Platanus assembly, but that didn’t produce an assembly because PB Jelly was expecting gaps in the Illumina reference assembly (i.e. scaffolds, not contigs).\nRe-ran this using the BGI Illumina scaffolds FASTA.\n\nPB Jelly Documentation\n\nHere’s a brief rundown of how this was run:\n\nDefault PB Jelly settings (including default settings for blasr).\nIllumina reference FASTA: BGI Illumina scaffolds FASTA\nPacBio reads for mapping\nProtocol.xml file needed for PB Jelly to run\n\nSee the Jupyter Notebook for full details of run (see Results section below).\n\nResults:\nOutput folder: https://owl.fish.washington.edu/Athaliana/20171114_oly_pbjelly/\nOutput FASTA file: https://owl.fish.washington.edu/Athaliana/20171114_oly_pbjelly/jelly.out.fasta\nOK! This seems to have worked (and it was quick, like less than an hour!), as it actually produced a FASTA file! Will run QUAST with this and some assemblies to compare assembly stats. Have added this assembly to our Olympia oyster genome assemblies table.\nJupyter Notebook (GitHub): 20171114_emu_pbjelly_BGI_scaffold.ipynb"
  },
  {
    "objectID": "posts/2017/2017-10-24-genome-assembly-olympia-oyster-illumina-pacbio-reads-using-redundans/index.html",
    "href": "posts/2017/2017-10-24-genome-assembly-olympia-oyster-illumina-pacbio-reads-using-redundans/index.html",
    "title": "Genome Assembly - Olympia oyster Illumina & PacBio Reads Using Redundans",
    "section": "",
    "text": "Had problems with Docker and Jupyter Notebook inexplicably dying and deleting all the files in the working directory of the Jupyter Notebook (which also happened to be the volume mounted in the Docker container).\nSo, I ran this on my computer, but didn’t have Jupyter installed (yet).\nThis utilized [the Canu contigs file (FASTA)(https://owl.fish.washington.edu/Athaliana/20171018_oly_pacbio_canu/20171018_oly_pacbio.contigs.fasta) that I generated on 20171018.\nHere’s the input command:\n<code>sudo python /home/sam/software/redundans/redundans.py -t 24 -l m130619_081336_42134_c100525122550000001823081109281326_s1_p0.fastq.gz m170211_224036_42134_c101073082550000001823236402101737_s1_X0_filtered_subreads.fastq.gz m170301_100013_42134_c101174162550000001823269408211761_s1_p0_filtered_subreads.fastq.gz m170301_162825_42134_c101174162550000001823269408211762_s1_p0_filtered_subreads.fastq.gz m170301_225711_42134_c101174162550000001823269408211763_s1_p0_filtered_subreads.fastq.gz m170308_163922_42134_c101174252550000001823269408211742_s1_p0_filtered_subreads.fastq.gz m170308_230815_42134_c101174252550000001823269408211743_s1_p0_filtered_subreads.fastq.gz m170315_001112_42134_c101169372550000001823273008151717_s1_p0_filtered_subreads.fastq.gz m170315_063041_42134_c101169382550000001823273008151700_s1_p0_filtered_subreads.fastq.gz m170315_124938_42134_c101169382550000001823273008151701_s1_p0_filtered_subreads.fastq.gz m170315_190851_42134_c101169382550000001823273008151702_s1_p0_filtered_subreads.fastq.gz -i 151114_I191_FCH3Y35BCXX_L1_wHAIPI023992-37_1.fq.gz 151114_I191_FCH3Y35BCXX_L1_wHAIPI023992-37_2.fq.gz 151114_I191_FCH3Y35BCXX_L2_wHAMPI023991-66_1.fq.gz 151114_I191_FCH3Y35BCXX_L2_wHAMPI023991-66_2.fq.gz 151118_I137_FCH3KNJBBXX_L5_wHAXPI023905-96_1.fq.gz 151118_I137_FCH3KNJBBXX_L5_wHAXPI023905-96_2.fq.gz 160103_I137_FCH3V5YBBXX_L3_WHOSTibkDCABDLAAPEI-62_1.fq.gz 160103_I137_FCH3V5YBBXX_L3_WHOSTibkDCABDLAAPEI-62_2.fq.gz 160103_I137_FCH3V5YBBXX_L3_WHOSTibkDCACDTAAPEI-75_1.fq.gz 160103_I137_FCH3V5YBBXX_L3_WHOSTibkDCACDTAAPEI-75_2.fq.gz 160103_I137_FCH3V5YBBXX_L4_WHOSTibkDCABDLAAPEI-62_1.fq.gz 160103_I137_FCH3V5YBBXX_L4_WHOSTibkDCABDLAAPEI-62_2.fq.gz 160103_I137_FCH3V5YBBXX_L4_WHOSTibkDCACDTAAPEI-75_1.fq.gz 160103_I137_FCH3V5YBBXX_L4_WHOSTibkDCACDTAAPEI-75_2.fq.gz 160103_I137_FCH3V5YBBXX_L5_WHOSTibkDCAADWAAPEI-74_1.fq.gz 160103_I137_FCH3V5YBBXX_L5_WHOSTibkDCAADWAAPEI-74_2.fq.gz 160103_I137_FCH3V5YBBXX_L6_WHOSTibkDCAADWAAPEI-74_1.fq.gz 160103_I137_FCH3V5YBBXX_L6_WHOSTibkDCAADWAAPEI-74_2.fq.gz -f 20171018_oly_pacbio.contigs.fasta -o /home/data/20171024_docker_oly_redundans_01/</code>\nThis completed in just over 19hrs.\nCopied output files to Owl: https://owl.fish.washington.edu/Athaliana/20171024_docker_oly_redundans_01/\nHere’s the desired output file (FASTA): scaffolds.reduced.fa\nWill add to our genome assemblies table.\nRan Quast on 20171103 for some assembly stats.\nQuast output is here: https://owl.fish.washington.edu/Athaliana/quast_results/results_2017_11_03_22_43_06/\n(http://owl.fish.washington.edu/Athaliana/20171103_quast_redundans_20171024.png)"
  },
  {
    "objectID": "posts/2017/2017-10-05-genome-assembly-olympia-oyster-redundans-with-illumina-pacbio/index.html",
    "href": "posts/2017/2017-10-05-genome-assembly-olympia-oyster-redundans-with-illumina-pacbio/index.html",
    "title": "Genome Assembly - Olympia Oyster Redundans with Illumina + PacBio",
    "section": "",
    "text": "Redundans should assemble both Illumina and PacBio data, so let’s do that.\nSean had previously performed this - twice actually:\n\nRedundans 1\nRedundans 2\n\nIt wasn’t entirely clear how he had run Redundans the first time and the second time he used his Platinus contig FASTA file as the necessary reference assembly when running Redundans.\nSince he had produced a good looking assembly from PacBio data using Canu, I decided to give Redundans a rip using that assembly.\nI then compared all three Redundans runs using QUAST.\nJupyter notebook (GitHub): 20171004_docker_oly_redundans.ipynb\nNotebook is also embedded at the bottom of this notebook entry (but, it should be easier to view at the link provided above).\n\nSean’s Canu assembly (FASTA): https://owl.fish.washington.edu/scaphapoda/Sean/Oly_Canu_Output/oly_pacbio_.contigs.fasta\nSean’s first Redundans assembly (scaffolded assembly; FASTA): https://owl.fish.washington.edu/scaphapoda/Sean/Oly_Redundans_Output/scaffolds.reduced.fa\nSean’s second Redundans assembly (scaffolded assembly; FASTA): https://owl.fish.washington.edu/scaphapoda/Sean/Oly_Redundans_Output_Try_2/scaffolds.reduced.fa\nRedundans Output folder: https://owl.fish.washington.edu/Athaliana/20171004_redundans/\nRedundans assembly (scaffolded assembly; FASTA): https://owl.fish.washington.edu/Athaliana/20171004_redundans/scaffolds.reduced.fa\nQuast Output folder (default settings): https://owl.fish.washington.edu/Athaliana/quast_results/results_2017_10_05_14_21_50/\nQuast Output folder (–scaffolds option): https://owl.fish.washington.edu/Athaliana/quast_results/results_2017_10_05_14_28_51/\n\nOf note, is that Redundans didn’t find any alignments for the paired reads for each of the BGI mate-pair Illumina data:\n\n160103_I137_FCH3V5YBBXX_L3_WHOSTibkDCABDLAAPEI-62_2.fq.gz\n160103_I137_FCH3V5YBBXX_L3_WHOSTibkDCACDTAAPEI-75_2.fq.gz\n160103_I137_FCH3V5YBBXX_L4_WHOSTibkDCABDLAAPEI-62_2.fq.gz\n160103_I137_FCH3V5YBBXX_L4_WHOSTibkDCACDTAAPEI-75_2.fq.gz\n160103_I137_FCH3V5YBBXX_L5_WHOSTibkDCAADWAAPEI-74_2.fq.gz\n160103_I137_FCH3V5YBBXX_L6_WHOSTibkDCAADWAAPEI-74_2.fq.gz\n\nFirst, I ran QUAST with the default settings:\nInteractive link: https://owl.fish.washington.edu/Athaliana/quast_results/results_2017_10_05_14_21_50/report.html\n(http://owl.fish.washington.edu/Athaliana/20171005_oly_assemblies_01.png)\nUsing that Canu assembly with Redundans certainly seems to results in a better assembly.\nDecided to run QUAST with the –scaffolds option to see what happened:\nInteractive link: https://owl.fish.washington.edu/Athaliana/quast_results/results_2017_10_05_14_28_51/report.html\n(http://owl.fish.washington.edu/Athaliana/20171005_oly_assemblies_02.png)\nThe scaffolds with the “Ns” removed from them are appended with “_broken” - meaning the scaffolds were broken apart into contigs. Things are certainly cleaner when using the --scaffolds option, however, as far as I can tell, QUAST doesn’t actually generate a FASTA file with the “_broken” scaffolds!"
  },
  {
    "objectID": "posts/2017/2017-11-14-genome-assembly-olympia-oyster-illumina-pacbio-using-pb-jelly-wplatanus-assembly/index.html",
    "href": "posts/2017/2017-11-14-genome-assembly-olympia-oyster-illumina-pacbio-using-pb-jelly-wplatanus-assembly/index.html",
    "title": "Genome Assembly - Olympia Oyster Illumina & PacBio Using PB Jelly w/Platanus Assembly",
    "section": "",
    "text": "Sean had previously attempted to run PB Jelly, but ran into some issues running on Hyak, so I decided to try this on Emu.\n\nPB Jelly Documentation\n\nHere’s a brief rundown of how this was run:\n\nDefault PB Jelly settings (including default settings for blasr).\nIllumina reference FASTA: Sean’s Platanus kmer=22 assembly\nPacBio reads for mapping\nProtocol.xml file needed for PB Jelly to run\n\nSee the Jupyter Notebook for full details of run (see Results section below).\n\nResults:\nOutput folder: https://owl.fish.washington.edu/Athaliana/20171113_oly_pbjelly/\nThis completed very quickly (like, just a couple of hours). I also didn’t experience the woes of multimillion temp file production that [killed Sean’s attempt at running this on Mox (Hyak)(https://genefish.wordpress.com/2017/05/04/lots-of-moving-files-and-output-stuff/).\nHowever, it doesn’t seem to have produced an assembly!\nLooking through the output, it seems as though it didn’t produce an assembly because there weren’t any gaps to fill in the reference. This makes sense (in regards to the lack of gaps in the reference Illumina assembly) because I used the Platanus contig FASTA file (i.e. not a scaffolds file). I didn’t realize PB Jelly was just designed for gap filling. Guess I’ll give this another go using the BGI scaffold FASTA file and see what we get.\nJupyter Notebook (GitHub): 20171113_emu_pbjelly_22mer_plat.ipynb"
  },
  {
    "objectID": "posts/2017/2017-11-30-genome-assembly-olympia-oyster-illumina-pacbio-using-pb-jelly-wbgi-scaffold-assembly-2/index.html",
    "href": "posts/2017/2017-11-30-genome-assembly-olympia-oyster-illumina-pacbio-using-pb-jelly-wbgi-scaffold-assembly-2/index.html",
    "title": "Genome Assembly – Olympia Oyster Illumina & PacBio Using PB Jelly w/BGI Scaffold Assembly",
    "section": "",
    "text": "After another attempt to fix PB Jelly, I ran it again.\nWe’ll see how it goes this time…\nRe-ran this using the BGI Illumina scaffolds FASTA.\n\nPB Jelly Documentation\n\nHere’s a brief rundown of how this was run:\n\nDefault PB Jelly settings (including default settings for blasr).\nIllumina reference FASTA: BGI Illumina scaffolds FASTA\nPacBio reads for mapping\nProtocol.xml file needed for PB Jelly to run\n\nSee the Jupyter Notebook for full details of run (see Results section below).\n\nResults:\nOutput folder: https://owl.fish.washington.edu/Athaliana/20171130_oly_pbjelly/\nOutput FASTA file: https://owl.fish.washington.edu/Athaliana/20171130_oly_pbjelly/jelly.out.fasta\nQuast assessment of output FASTA:\n\n\nAssembly jelly.out\n\n\n\n\n\n\n\ncontigs (>= 0 bp)\n\n\n696946\n\n\n\n\n\n\ncontigs (>= 1000 bp)\n\n\n159429\n\n\n\n\n\n\ncontigs (>= 5000 bp)\n\n\n68750\n\n\n\n\n\n\ncontigs (>= 10000 bp)\n\n\n35320\n\n\n\n\n\n\ncontigs (>= 25000 bp)\n\n\n7048\n\n\n\n\n\n\ncontigs (>= 50000 bp)\n\n\n894\n\n\n\n\nTotal length (>= 0 bp)\n\n\n1253001795\n\n\n\n\nTotal length (>= 1000 bp)\n\n\n1140787867\n\n\n\n\nTotal length (>= 5000 bp)\n\n\n932263178\n\n\n\n\nTotal length (>= 10000 bp)\n\n\n691523275\n\n\n\n\nTotal length (>= 25000 bp)\n\n\n261425921\n\n\n\n\nTotal length (>= 50000 bp)\n\n\n57741906\n\n\n\n\n\n\ncontigs\n\n\n213264\n\n\n\n\nLargest contig\n\n\n194507\n\n\n\n\nTotal length\n\n\n1180563613\n\n\n\n\nGC (%)\n\n\n36.57\n\n\n\n\nN50\n\n\n12433\n\n\n\n\nN75\n\n\n5983\n\n\n\n\nL50\n\n\n26241\n\n\n\n\nL75\n\n\n60202\n\n\n\n\n\n\nN’s per 100 kbp\n\n\n6580.58\n\n\n\n\n\nHave added this assembly to our Olympia oyster genome assemblies table.\nThis took an insanely long time to complete (nearly six weeks)!!! After some internet searching, I’ve found a pontential solution to this and have initiated another PB Jelly run to see if it will run faster. Regardless, it’ll be interesting to see how the results compare from two independent runs of PB Jelly.\nJupyter Notebook (GitHub): 20171130_emu_pbjelly.ipynb"
  },
  {
    "objectID": "posts/2017/2017-10-30-software-installation-pb-jelly-suite-and-blasr-on-emu/index.html",
    "href": "posts/2017/2017-10-30-software-installation-pb-jelly-suite-and-blasr-on-emu/index.html",
    "title": "Software Installation - PB Jelly Suite and Blasr on Emu",
    "section": "",
    "text": "I followed along with what Sean previously did when installing on Emu, but it appears he didn’t install it in the shared location to make it accessible to all users. So, I’m installing it in the /home/shared/ directory.\n\nFirst, I need to install legacy blasr from PacBio:\nInstalled in\n<code>cd /home/shared\ngit clone https://github.com/PacificBiosciences/pitchfork.git\ncd pitchfork\ngit checkout legacy_blasr\nmake init PREFIX=/home/shared\nmake blasr  PREFIX=/home/shared</code>\nRan into this error:\n<code>make[1]: Leaving directory '/home/shared/pitchfork/ports/thirdparty/zlib'\nmake -C ports/thirdparty/hdf5 do-install\nmake[1]: Entering directory '/home/shared/pitchfork/ports/thirdparty/hdf5'\n/home/shared/pitchfork/bin/pitchfork fetch --url https://support.hdfgroup.org/ftp/HDF5/releases/hdf5-1.8.16/src/hdf5-1.8.16.tar.gz\nfetching https://support.hdfgroup.org/ftp/HDF5/releases/hdf5-1.8.16/src/hdf5-1.8.16.tar.gz\ntar zxf hdf5-1.8.16.tar.gz -C /home/shared/pitchfork/workspace\n\ngzip: stdin: not in gzip format\ntar: Child returned status 1\ntar: Error is not recoverable: exiting now\nMakefile:23: recipe for target '/home/shared/pitchfork/workspace/hdf5-1.8.16' failed\nmake[1]: *** [/home/shared/pitchfork/workspace/hdf5-1.8.16] Error 2\nmake[1]: Leaving directory '/home/shared/pitchfork/ports/thirdparty/hdf5'\nMakefile:211: recipe for target 'hdf5' failed\nmake: *** [hdf5] Error 2</code>\nLuckily, I came across this GitHub Issue that addresses this exact problem.\nI found the functional URL and downloaded the hdf5-1.8.16.tar.gz file to pitchfork/ports/thirdparty/hdf5. Re-ran make blasr  PREFIX=/home/shared and things proceeded without issue. As Sean noted, this part takes a long time.\nLoad the setup-env.sh (this is located here: /home/shared/pitchfork/setup-env.sh\n<code>source setup-env.sh</code>\nBlasr install is complete!\n\n\nThen, install networkx v1.1, per the PB Jelly documentation:\npython pip -m install networkx==1.1\n\n\nOn to PB Jelly!\nEdited the setup.sh file and entered in the path to the PB Jelly install on Emu (/home/shared/PBSuite_15.8.24/):\n[code lang=text] #/bin/bash\n#If you use a virtual env - source it here #source /hgsc_software/PBSuite/pbsuiteVirtualEnv/bin/activate\n#This is the path where you’ve install the suite. export SWEETPATH=/home/shared/PBSuite_15.8.24/ #for python modules export PYTHONPATH=\\(PYTHONPATH:\\)SWEETPATH #for executables export PATH=\\(PATH:\\)SWEETPATH/bin/ [/code]\nTest it out with the test data:\n\nEdit the following file to reflect the paths on Emu to find this test data: /home/shared/PBSuite_15.8.24/docs/jellyExample/Protocol.xml\n\n<code>\n<jellyProtocol>\n    <reference>/home/shared/PBSuite_15.8.24/docs/jellyExample/data/reference/lambda.fasta</reference>\n    <outputDir>/home/shared/PBSuite_15.8.24/docs/jellyExample/</outputDir>\n    <blasr>-minMatch 8 -minPctIdentity 70 -bestn 1 -nCandidates 20 -maxScore -500 -nproc 4 -noSplitSubreads</blasr>\n    <input baseDir=\"/home/shared/PBSuite_15.8.24/docs/jellyExample/data/reads/\">\n        <job>filtered_subreads.fastq</job>\n    </input>\n</jellyProtocol>\n</code>\nI went through all the stages of the test data and got through it successfully. Seems ready to roll!"
  },
  {
    "objectID": "posts/2017/2017-12-13-software-install-msmtp-for-email-notices-of-bash-job-completion-on-emu-ubuntu/index.html",
    "href": "posts/2017/2017-12-13-software-install-msmtp-for-email-notices-of-bash-job-completion-on-emu-ubuntu/index.html",
    "title": "Software Install - MSMTP For Email Notices of Bash Job Completion on Emu (Ubuntu)",
    "section": "",
    "text": "After I finally resolved the installation of PB Jelly on Emu (running Ubuntu 16.04), I’ve had a PB Jelly assembly running for the past two weeks! I’ve gotten tired of checking on its status (i.e. is it still running?) every day, so I dove in and figured out how to set up Emu to email me when the job is complete!\nTo get this going, I mainly followed this msmtp ArchWiki guide., but here are the specifics of how I set it up.\n\nStep 1. Installed a mail server:\nsudo apt-get install sendmail\n\n\nStep 2. Installed msmtp:\nsudo apt-get install msmtp\n\n\nStep 3. Created the following file in my home directory (/home/sam/): ~/.msmtprc\nThe original contents of the file for testing were:\n\n       # Example for a user configuration file ~/.msmtprc\n       #\n       # This file focuses on TLS and authentication. Features not used here include\n       # logging, timeouts, SOCKS proxies, TLS parameters, Delivery Status Notification\n       # (DSN) settings, and more.\n\n       # Set default values for all following accounts.\n       defaults\n\n       # Use the mail submission port 587 instead of the SMTP port 25.\n       port 587\n\n       # Always use STARTTLS.\n       tls on\n       tls_starttls on\n       tls_certcheck off\n       # A freemail service\n       account uw\n\n       # Host name of the SMTP server\n       host smtp.washington.edu\n\n       # Envelope-from address\n       from emu@uw.edu\n\n       # Authentication. The password is given using one of five methods, see below.\n       auth on\n       user samwhite\n\n       # Password method 3: Store the password directly in this file. Usually it is not\n       # a good idea to store passwords in plain text files. If you do it anyway, at\n       # least make sure that this file can only be read by yourself.\n       password myuwpassword\n\n       account default : uw\n\nThis is a configuration to allow emails to get sent via the Univ. of Washington email servers. Yes, I currently had UW password saved in this file, but will be addressing this issue below.\n\n\nStep 4. Changed permissions on ~/.msmtprc to be readable/writable only by me (important, particularly if you’ve stored your password in this file!):\nchmod 600 ~/.msmtprc\n\n\nStep 5. Assigned sendmail to use msmtp with the set command (this sets the following command as a positional parameter by adding to the /etc/mail.rc file:\necho “set sendmail=/usr/bin/msmtp” | sudo tee -a /etc/mail.rc\nThis command pipers the output of echo to sudo and uses tee -a to append to our desired file (/etc/mail.rc).\n\n\nStep 5. Send a test email:\necho “Job complete!” | msmtp myuwemail@uw.edu\nThat will send an email with no subject and the body of the email will contain “Job complete!”.\nThat’s the basic set up for this.\nTo use it in your workflow, you’d append that command to the end of any Bash command or in a separate Jupyter notebook cell that is queued to run after a previous cell completes it’s job.\nExample:\necho “This counts as a command”; echo “Job complete!” | msmtp myuwemail@uw.edu\nThis will run the first echo command. When that finishes, then the email command will run. You can get fancy and have different emails in response to how the running program exits (i.e. fails or is successful) and send different email responses, but I’m not going to get into that.\nAnyway, not bad! However, we want to make this a bit nicer and more secure.\n\n\n\nImprove security:\n\nStep 1. Generate a GPG Key:\nFollow the instructions under the Creating an Encryption Key section at this link.\nDO NOT CREATE A PASSWORD! JUST HIT ENTER WHEN AT THAT STEP.\nTechnically, this is does not follow proper security protocols, but this is better than having a plain text password, and setting it up this way is the only way the mail program will send without prompting the user for a password (which kills the automation we’re trying to achieve).\n\n\nStep 2. Create an encrypted password file:\ngpg –encrypt -o ~/.msmtp-password.gpg -r youremailaddress -\nAfter entering that, type your UW email password(NOTE: You will not receive a new prompt, so just type it in), and then Enter. Then, press Ctrl-d.\n\n\nStep 3. Add the following line to your ~/.msmtprc file:\npasswordeval “gpg –quiet –for-your-eyes-only –no-tty –decrypt ~/.msmtp-password.gpg”\nHere’s what the file looks like now:\n\n       # Example for a user configuration file ~/.msmtprc\n       #\n       # This file focuses on TLS and authentication. Features not used here include\n       # logging, timeouts, SOCKS proxies, TLS parameters, Delivery Status Notification\n       # (DSN) settings, and more.\n\n       # Set default values for all following accounts.\n       defaults\n\n       # Use the mail submission port 587 instead of the SMTP port 25.\n       port 587\n\n       # Always use STARTTLS.\n       tls on\n       tls_starttls on\n       tls_certcheck off\n\n       # Email account nickname\n       account uw\n\n       # Host name of the SMTP server\n       host smtp.washington.edu\n\n       # Envelope-from address\n       from emu@uw.edu\n\n       # Authentication. The password is given using one of five methods, see below.\n       auth on\n       user samwhite\n\n\n       # Password method 2: Store the password in an encrypted file, and tell msmtp\n       # which command to use to decrypt it. This is usually used with GnuPG, as in\n       # this example. Usually gpg-agent will ask once for the decryption password.\n       passwordeval    \"gpg --quiet --for-your-eyes-only --no-tty --decrypt ~/.msmtp-password.gpg\"\n\n       account default : uw\n\n\n\n\nStep 4. Change permissions on ~/.msmtp-password.gpg so it’s only readable/writable by you:\nchmod 600 ~/.msmtp-password.gpg\n\n\nStep 5. Send a test email like before:\necho “Job complete!” | msmtp myuwemail@uw.edu\nThat’s it for security.\n\n\n\n\nAdd a subject to the emails:\n\nStep 1. Create ~/.default_subject.mail and add the following lines to the file (substitute your own email address):\n\nTo: myuwemail@uw.edu\nFrom: [EMU]\nSubject: JOB COMPLETE!\n\n\nFeel free to change the Subject and/or From info to whatever you’d like.\n\n\nStep 2. Send message using ~/.default_subject.mail:\ncat ~/.default_subject.mail | msmtp myuwemail@uw.edu\nTo use this in your workflow, you’ll do just like before (but using the command immediately above) and append to the end of any Bash command.\n\n\n\n\nMake it short & sweet\nAppending those lines is going to be difficult to remember, is annoying to type out, and displays your email address (particularly if using a publicly hosted Jupyter notebook like most of us in lab do). Here’s a nice way to remedy that.\n\nStep 1. Add email address as variable in ~/.bashrc:\nAdd the following lines to the end of your ~/.bashrc file:\n\n# Email address\nexport EMAIL=myuwemail@uw.edu\n\nYour email address is now saved in the variable $EMAIL. You will need to use the following command to load that information:\nsource ~/.bashrc\nVerify that it worked:\necho “$EMAIL”\nThat should spit out your email address and is ready to be used!\n\n\nStep 2. Add alias for full mail command to ~/.bash_aliases file:\necho “alias emailme=‘cat ~/.default_subject.mail | msmtp “$EMAIL”’” >> ~/.bash_aliases\nVerify that it worked:\nsource ~/.bash_aliases\nemailme\nSo, from now on, all you have to do is append the command emailme to the end of any Bash commands and you’ll get email when the job is finished!!! You can edit Steps 1 & 2 to use a variable other than “EMAIL” and an alias other than “emailme” - use whatever you’d like."
  },
  {
    "objectID": "posts/2017/2017-02-08-data-management-sra-submission-of-ostrea-lurida-gbs-fastq-files/index.html",
    "href": "posts/2017/2017-02-08-data-management-sra-submission-of-ostrea-lurida-gbs-fastq-files/index.html",
    "title": "Data Management - SRA Submission of Ostrea lurida GBS FASTQ Files",
    "section": "",
    "text": "Prepared a short read archive (SRA) submission for archiving our Olympia oyster genotype-by-sequencing (GBS) data in NCBI. This is in preparation for submission of the mansucript we’re putting together.\nI followed my outline/guideline for navigating the SRA submission process, as it’s a bit of a pain in the neck. Glad my notes were actually useful!\nThe following two files are currently being uploaded via FTP; the process will take about 3hrs, as each file is ~18GB in size:\n\n160123_I132_FCH3YHMBBXX_L4_OYSzenG1AAD96FAAPEI-109_1.fq.gz\n160123_I132_FCH3YHMBBXX_L4_OYSzenG1AAD96FAAPEI-109_2.fq.gz\n\nThey are being submitted under the following accession numbers (note: a final accession number will be provided once this is publicly available; I will update this post when that happens):\n(http://eagle.fish.washington.edu/Arabidopsis/20170208_SRA_submission_oly_gbs.png)"
  },
  {
    "objectID": "posts/2018/2018-01-08-mbd-enrichment-crassostrea-virginica-sheared-dna-day-1/index.html",
    "href": "posts/2018/2018-01-08-mbd-enrichment-crassostrea-virginica-sheared-dna-day-1/index.html",
    "title": "MBD Enrichment - Crassostrea virginica Sheared DNA Day 1",
    "section": "",
    "text": "As part of a project with Qiagen to have them try out some of our DNA with their newest DNA bisulfite conversion kit, I previously [isolated DNA from Crassotrea virginica (Eastern oyster)(2017/12/11/dna-isolation-quantification-crassotrea-virginica-mantle-gdna.html) and sheared to ~420bp.\nNext, I needed to enrich the samples for methylated DNA. Did this using the MethylMiner Methylated DNA Enrichment Kit (Invitrogen). Followed the manufacturer’s protocol for input DNA amounts of 1 -10ug (I am using 8ug in each of two samples). Below are the exact volumes used for various steps:\nMade 1x Bind/Wash Buffer\n\n2.88mL 5x Bind/Wash Buffer\n720uL molecular biology grade H2O\n\nBeads:\n\n80uL beads per sample\n\nMBD-biotion protein:\n\n56uL per sample\n\nDiluted the two sheared DNA samples to 25ng/uL:\n\nCiVi = CfVf\n(58.4ng/uL)(136uL) = (25ng/uL)(Vf)\nVf = 317.7\nAdd 181.7uL H2O to DNA to get 317.7ul (i.e. 25ng/uL)\n\nSamples were incubated O/N in the 4C in the rotator."
  },
  {
    "objectID": "posts/2015/2015-05-28-bioanalyzer-geoduck-gonad-rna-quality-assessment/index.html",
    "href": "posts/2015/2015-05-28-bioanalyzer-geoduck-gonad-rna-quality-assessment/index.html",
    "title": "Bioanalyzer - Geoduck Gonad RNA Quality Assessment",
    "section": "",
    "text": "Before proceeding with transcriptomics for this project, we need to assess the integrity of the RNA via Bioanalyzer.\nRNA that was previously isolated on 20150508, 20150505, 20150427, and 20150424 (those notebook entries have been updated to report this consolidation and have a link to this notebook entry) were consolidated into single samples (if there had been multiple isolations of the same sample) and spec’d on the Roberts Lab NanoDrop1000:\n(http://eagle.fish.washington.edu/Arabidopsis/20150528_geoduck_histo_RNA_ODs.JPG)\n(http://eagle.fish.washington.edu/Arabidopsis/20150528_geoduck_histo_RNA_plots.JPG)\nGoogle Sheet: 20150528_geoduck_histo_RNA_ODs\nNOTE: Screwed up consolidation of Geoduck Block 03 sample (added one of the 04 dupes to the tube, so discarded 03).\nRNA was stored in Shellfish RNA Box #5.\nRNA was submitted to to Jesse Tsai at University of Washington Department of Environmental and Occupational Health Science Functional Genomics Laboratory for running on the Agilent Bioanalyzer 2100, using either the RNA Pico or RNA Nano chips, depending on RNA concentration (Pico for lower concentrations and Nano for higher concentrations - left decision up to Jesse).\nResults:\nBioanalzyer 2100 Pico Data File (XAD): SamWhite_Eukaryote Total RNA Pico_2015-05-28_12-50-00.xad Bioanalzyer 2100 Nano Data File (XAD): SamWhite_Eukaryote Total RNA Nano_2015-05-28_13-22-53.xad\n\nPico Gel Representation\n(http://eagle.fish.washington.edu/Arabidopsis/Bioanalyzer%20Data/20150528_bioanalyzer_RNA_pico_geoduck_gel.jpg)\n\n\nPico Electropherogram\n(http://eagle.fish.washington.edu/Arabidopsis/Bioanalyzer%20Data/20150528_bioanalyzer_RNA_pico_geoduck_electropherogram.jpg)\n\n\nNano Gel Representation\n(http://eagle.fish.washington.edu/Arabidopsis/Bioanalyzer%20Data/20150528_bioanalyzer_RNA_nano_geoduck_gel.jpg)\n\n\nNano Electropherogram\n(http://eagle.fish.washington.edu/Arabidopsis/Bioanalyzer%20Data/20150528_bioanalyzer_RNA_nano_geoduck_electropherogram.jpg)\nJesse alerted me to the fact that they did not have any ladder to use on the Nano chip, as someone had used the remainder, but failed to order more. I OK’d him to go ahead with the Nano chip despite lacking ladder, as we primarily needed to assess RNA integrity.\nBad Samples:\n\nGeo 04 - No RNA detected\nGeo 65, 67, 68 - These three samples show complete degradation of the RNA (i.e. no ribosomal band present, significant smearing on the gel representation).\n\nAll other samples look solid. Will discuss with Steven and Brent on how they want to proceed.\nFull list of samples for this project (including the Block 03 sample not included in this analysis; see above). Grace’s notebook will have details on what the numbering indicates (e.g. developmental stage).\n\nblock 02\nblock 03 (no RNA)\nblock 04 (no RNA)\nblock 07\nblock 08\nblock 09\nblock 34\nblock 35\nblock 38\nblock 41\nblock 42\nblock 46\nblock 51\nblock 65 (degraded RNA)\nblock 67 (degraded RNA)\nblock 68 (degraded RNA)\nblock 69\nblock 70"
  },
  {
    "objectID": "posts/2018/2018-06-06-library-construction-geoduck-water-filter-metagenome-with-nextera-dna-flex-kit-illumina/index.html",
    "href": "posts/2018/2018-06-06-library-construction-geoduck-water-filter-metagenome-with-nextera-dna-flex-kit-illumina/index.html",
    "title": "Library Construction - Geoduck Water Filter Metagenome with Nextera DNA Flex Kit (Illumina)",
    "section": "",
    "text": "Made Illumina libraries with goeduck metagenome water filter DNA I previously isolated on:\n\n20180411\n20180426\n\nWe used a free Nextera DNA Flex Kit (Illumina) that we won in a contest held by Illumina!\nFollowed the manufacturer’s protocol for input DNA quantities <10ng with the following changes/notes:\n\nPCR steps performed in 200uL thin-walled PCR tubes.\nMagnetic separations were performed in 1.7mL snap cap tubes.\nThermalcycler: PTC-200 (MJ Research)\nMagnet: DynaMag 2 (Invitrogen)\n\nSee the Library Calcs sheet (link below) for original sample names and subsequent library sample names.\n\nIMPORTANT!\nThe sheet also contains the indexes used for each library. This info will be necessary for sequencing facility.\nLibrary Calcs (Google Sheet):\n\n20180606_nextera_library_geoduck_metagenome_calcs\n\nLinks to the Illumina manuals are below:\n\nNextera DNA Flex Kit Manual (PDF)\nIllumina Index Adapters Pooling Guide (PDF)\n\nAfter library construction was completed, individual libraries were quantified on the Roberts Lab Qubit 3.0 (Invitrogen) with the Qubit 1x dsDNA HS Assay Kit.\n2uL of each sample was used for each assay.\nLibrary quality was assessed using the Seeb Lab 2100 Bioanalyzer (Agilent) with a High Sensitivity DNA Kit, using 1uL of each sample.\nLibraries were stored in the small -20C in FTR213:\n\nSam’s gDNA Box #2\nSlots H6 - I3\n\n\n\n\nResults:\nQubit Raw Data (Google Sheet):\n\n20180606_qubit_geoduck_metagenome_libraries\n\nBioanalyzer File (XAD):\n\n20180606_133725.xad\n\nAll libraries have DNA in them, so that’s good!\nExcept for one library (Library Geoduck MG #04 is bad), the other libraries look OK (i.e. not great). Compared to the example on Pg. 12 in the manual, these libraries all have some extra high molecular weight stuff.\nWhen selecting the range listed in the Nextera Kit manual, the average fragment size is ~530bp - the expected size should be ~600bp.\n\nSpoke with Steven about Library Geoduck MG #04 and we’ve opted to just leave it out.\nAll other samples were pooled into a single samples according to the manufacturer’s protocol.\nThis pooled sample was stored in the same -20C box as above, in position I4.\n\nUPDATE 20180808\nAfter some confusion with the sequencing facility, I contacted Illumina regarding adapter sequences. I used the sequences provided for the Nextera DNA 24 CD Indexes (which was the index kit we used) on p.18 of the Illumina Index Adapter Pooling Guide.\nAs it turns out, these sequences are incorrect. The correct sequences are on p.12 of that document (the Nextera DNA 96 CD Indexes).\nI’ve updated the Google Sheet (linked above) to reflect the correct index sequences.\nEmail from Illumina is below. Even though he specifically references the H705 adapter, the correct sequence information for all i7 index adapters is found on p.12.\n\nHi Sam,\nThanks for the clarification! For the index sequence H705, this sequence is incorrect in the Index Adapters Pooling Guide. The correct information is found on page 12 of the same document and should be:\nH705 “AGGAGTCC” (Bases in Adapter) and “GGACTCCT” (bases for sample sheet.\nThis is also consistent with the Illumina Adapters letter.\nWe have provided this feed back to our colleagues to update the document so that all the information is consistent.\nThanks for your patience and understanding while we evaluated this issue. If we do have any other questions or concerns, please let us know and we would be happy to discuss this further.\nBest,\nRussell\nRussell Chan, Ph.D.\nTechnical Applications Scientist\nIllumina Technical Support\nTelephone available 24 hours\nMonday through Friday\nTechnical Bulletins: https://support.illumina.com/bulletins.html\nTrainings: https://support.illumina.com/traidexes"
  },
  {
    "objectID": "posts/2018/2018-05-16-trimgalorefastqcmultiqc-trimgalore-rrbs-geoduck-bs-seq-fastq-data-directional/index.html",
    "href": "posts/2018/2018-05-16-trimgalorefastqcmultiqc-trimgalore-rrbs-geoduck-bs-seq-fastq-data-directional/index.html",
    "title": "TrimGalore/FastQC/MultiQC – TrimGalore! RRBS Geoduck BS-seq FASTQ data (directional)",
    "section": "",
    "text": "Earlier this week, I ran TrimGalore!, but set the trimming, incorrectly - due to a copy/paste mistake, as --non-directional, so I re-ran with the correct settings.\nSteven requested that I trim the Geoduck RRBS libraries that we have, in preparation to run them through Bismark.\nThese libraries were originally created by Hollie Putnam using the TruSeq DNA Methylation Kit (Illumina):\n\nproject_juvenile_geoduck_OA/Sample_Processing (GitHub)\n\nAll analysis is documented in a Jupyter Notebook; see link below.\nOverview of process:\n\nRun TrimGalore! with --paired and --rrbs settings.\nRun FastQC and MultiQC on trimmed files.\nCopy all data to owl (see Results below for link).\nConfirm data integrity via MD5 checksums.\n\nJupyter Notebook:\n\n20180516_roadrunner_geoduck_RRBS_trimming.ipynb (GitHub)\n\n\n\nResults:\n\nTrimGalore! output folder:\n\n20180516_geoduck_trimgalore_rrbs\n\n\n\nFastQC output folder:\n\n20180516_geoduck_trimgalore_rrbs/20180514_geoduck_trimmed_fastqc/\n\n\n\nMultiQC output folder:\n\n20180516_geoduck_trimgalore_rrbs/20180516_geoduck_trimmed_fastqc/multiqc_data\n\n\n\nMultiQC report (HTML):\n\nmultiqc_report.html"
  },
  {
    "objectID": "posts/2018/2018-08-28-transposable-element-mapping-crassostrea-virginica-genome-cvirginica_v300-using-repeatmasker-4-07/index.html",
    "href": "posts/2018/2018-08-28-transposable-element-mapping-crassostrea-virginica-genome-cvirginica_v300-using-repeatmasker-4-07/index.html",
    "title": "Transposable Element Mapping – Crassostrea virginica Genome, Cvirginica_v300, using RepeatMasker 4.07",
    "section": "",
    "text": "Per this GitHub issue, I’m IDing transposable elements (TEs) in the Crassostrea virginica genome.\nGenome used:\n\nCvirginica_v300.fa\n\nI ran RepeatMasker (v4.07) with RepBase-20170127 and RMBlast 2.6.0 four times:\n\nSpecies = all\nSpecies = Crassostrea gigas (Pacific oyster)\nSpecies = Crassostrea virginica (Eastern oyster)\nDefault settings (i.e. no species select - will use human genome).\n\nThe idea with running this with four different settings was to get a sense of how the analyses would differ with species specifications.\nAll runs were performed on roadrunner.\nAll commands were documented in a Jupyter Notebook (GitHub):\n\n20180822_roadrunner_virginica_TEs_repeatmasker.ipynb\n\n_NOTE: RepeatMasker writes the desired output files (.out, .cat.gz, and *.gff) to the same directory that the genome is located in! If you conduct multiple runs with the same genome in the same directory, it will overwrite those files, as they are named using the genome assembly filename._ Be sure to move files out of the genome directory after each run!\n\n\nRESULTS:\n\nRUN 1 (species - all)\nOutput folder:\n\n20180822_virginica_repeatmasker_all\n\nSummary table (text):\n\nCvirginica_v300.fa.tbl\n\nOutput table (GFF):\n\nCvirginica_v300.fa.out.gff\n\n\n\n\nSUMMARY TABLE\n<code>\n==================================================\nfile name: Cvirginica_v300.fa       \nsequences:            11\ntotal length:  684741128 bp  (684675328 bp excl N/X-runs)\nGC level:         34.83 %\nbases masked:  113771462 bp ( 16.62 %)\n==================================================\n               number of      length   percentage\n               elements*    occupied  of sequence\n--------------------------------------------------\nRetroelements        97003     27946871 bp    4.08 %\n   SINEs:            48145      9242559 bp    1.35 %\n   Penelope           1429       256929 bp    0.04 %\n   LINEs:            27022     10570154 bp    1.54 %\n    CRE/SLACS           28         2219 bp    0.00 %\n     L2/CR1/Rex       2160       316660 bp    0.05 %\n     R1/LOA/Jockey    3058       386611 bp    0.06 %\n     R2/R4/NeSL        511       226938 bp    0.03 %\n     RTE/Bov-B        7377      3276312 bp    0.48 %\n     L1/CIN4          1331        95476 bp    0.01 %\n   LTR elements:     21836      8134158 bp    1.19 %\n     BEL/Pao          1807       936488 bp    0.14 %\n     Ty1/Copia        3046       296183 bp    0.04 %\n     Gypsy/DIRS1     12789      6060883 bp    0.89 %\n       Retroviral     2369       152228 bp    0.02 %\n\nDNA transposons     180693     29492426 bp    4.31 %\n   hobo-Activator    12869      1114188 bp    0.16 %\n   Tc1-IS630-Pogo    17233      2485049 bp    0.36 %\n   En-Spm                0            0 bp    0.00 %\n   MuDR-IS905            0            0 bp    0.00 %\n   PiggyBac           2388       405926 bp    0.06 %\n   Tourist/Harbinger  9302       992476 bp    0.14 %\n   Other (Mirage,      238        15946 bp    0.00 %\n    P-element, Transib)\n\nRolling-circles          0            0 bp    0.00 %\n\nUnclassified:       137707     45460608 bp    6.64 %\n\nTotal interspersed repeats:   102899905 bp   15.03 %\n\n\nSmall RNA:           45243      9057873 bp    1.32 %\n\nSatellites:           3852       760316 bp    0.11 %\nSimple repeats:     203542      8946510 bp    1.31 %\nLow complexity:      26205      1281043 bp    0.19 %\n==================================================\n\n* most repeats fragmented by insertions or deletions\n  have been counted as one element\n  Runs of >=20 X/Ns in query were excluded in % calcs\n\n\nThe query species was assumed to be root          \nRepeatMasker Combined Database: Dfam_Consensus-20170127, RepBase-20170127\n        \nrun with rmblastn version 2.6.0+\n\n</code>\n\n\nRUN 2 (species - Crassostrea gigas)\nOutput folder:\n\n20180822_virginica_repeatmasker_Cgigas\n\nSummary table (text):\n\nCvirginica_v300.fa.tbl\n\nOutput table (GFF):\n\nCvirginica_v300.fa.out.gff\n\n\n\n\nSUMMARY TABLE\n<code>\n==================================================\nfile name: Cvirginica_v300.fa       \nsequences:            11\ntotal length:  684741128 bp  (684675328 bp excl N/X-runs)\nGC level:         34.83 %\nbases masked:   93923386 bp ( 13.72 %)\n==================================================\n               number of      length   percentage\n               elements*    occupied  of sequence\n--------------------------------------------------\nRetroelements        26397     15008601 bp    2.19 %\n   SINEs:                4          722 bp    0.00 %\n   Penelope            675       190160 bp    0.03 %\n   LINEs:            17645      8922188 bp    1.30 %\n    CRE/SLACS            0            0 bp    0.00 %\n     L2/CR1/Rex         70        39188 bp    0.01 %\n     R1/LOA/Jockey       0            0 bp    0.00 %\n     R2/R4/NeSL          4         5110 bp    0.00 %\n     RTE/Bov-B        6194      2718955 bp    0.40 %\n     L1/CIN4             0            0 bp    0.00 %\n   LTR elements:      8748      6085691 bp    0.89 %\n     BEL/Pao           933       788887 bp    0.12 %\n     Ty1/Copia          47        82743 bp    0.01 %\n     Gypsy/DIRS1      6819      4822734 bp    0.70 %\n       Retroviral        0            0 bp    0.00 %\n\nDNA transposons     163945     26422122 bp    3.86 %\n   hobo-Activator     7742       720623 bp    0.11 %\n   Tc1-IS630-Pogo    15615      2328538 bp    0.34 %\n   En-Spm                0            0 bp    0.00 %\n   MuDR-IS905            0            0 bp    0.00 %\n   PiggyBac           2246       393498 bp    0.06 %\n   Tourist/Harbinger  8431       876020 bp    0.13 %\n   Other (Mirage,        0            0 bp    0.00 %\n    P-element, Transib)\n\nRolling-circles          0            0 bp    0.00 %\n\nUnclassified:       160681     41266796 bp    6.03 %\n\nTotal interspersed repeats:    82697519 bp   12.08 %\n\n\nSmall RNA:             214        40811 bp    0.01 %\n\nSatellites:           1396       217317 bp    0.03 %\nSimple repeats:     216869      9637447 bp    1.41 %\nLow complexity:      27520      1418990 bp    0.21 %\n==================================================\n\n* most repeats fragmented by insertions or deletions\n  have been counted as one element\n  Runs of >=20 X/Ns in query were excluded in % calcs\n\n\nThe query species was assumed to be crassostrea gigas\nRepeatMasker Combined Database: Dfam_Consensus-20170127, RepBase-20170127\n        \n</code>\n\n\nRUN 3 (species - Crassostrea virginica)\nOutput folder:\n\n20180822_virginica_repeatmasker_Cvirginica\n\nSummary table (text):\n\nCvirginica_v300.fa.tbl\n\nOutput table (GFF):\n\nCvirginica_v300.fa.out.gff\n\n\n\n\nSUMMARY TABLE\n<code>\n==================================================\nfile name: Cvirginica_v300.fa       \nsequences:            11\ntotal length:  684741128 bp  (684675328 bp excl N/X-runs)\nGC level:         34.83 %\nbases masked:   46637065 bp ( 6.81 %)\n==================================================\n               number of      length   percentage\n               elements*    occupied  of sequence\n--------------------------------------------------\nRetroelements        43139      8952068 bp    1.31 %\n   SINEs:            43139      8952068 bp    1.31 %\n   Penelope              0            0 bp    0.00 %\n   LINEs:                0            0 bp    0.00 %\n    CRE/SLACS            0            0 bp    0.00 %\n     L2/CR1/Rex          0            0 bp    0.00 %\n     R1/LOA/Jockey       0            0 bp    0.00 %\n     R2/R4/NeSL          0            0 bp    0.00 %\n     RTE/Bov-B           0            0 bp    0.00 %\n     L1/CIN4             0            0 bp    0.00 %\n   LTR elements:         0            0 bp    0.00 %\n     BEL/Pao             0            0 bp    0.00 %\n     Ty1/Copia           0            0 bp    0.00 %\n     Gypsy/DIRS1         0            0 bp    0.00 %\n       Retroviral        0            0 bp    0.00 %\n\nDNA transposons       3538      1564942 bp    0.23 %\n   hobo-Activator        0            0 bp    0.00 %\n   Tc1-IS630-Pogo        0            0 bp    0.00 %\n   En-Spm                0            0 bp    0.00 %\n   MuDR-IS905            0            0 bp    0.00 %\n   PiggyBac              0            0 bp    0.00 %\n   Tourist/Harbinger     0            0 bp    0.00 %\n   Other (Mirage,        0            0 bp    0.00 %\n    P-element, Transib)\n\nRolling-circles          0            0 bp    0.00 %\n\nUnclassified:        65151     23982146 bp    3.50 %\n\nTotal interspersed repeats:    34499156 bp    5.04 %\n\n\nSmall RNA:           43353      8992879 bp    1.31 %\n\nSatellites:              1          222 bp    0.00 %\nSimple repeats:     232627     10544162 bp    1.54 %\nLow complexity:      29762      1561018 bp    0.23 %\n==================================================\n\n* most repeats fragmented by insertions or deletions\n  have been counted as one element\n  Runs of >=20 X/Ns in query were excluded in % calcs\n\n\nThe query species was assumed to be crassostrea virginica\nRepeatMasker Combined Database: Dfam_Consensus-20170127, RepBase-20170127\n        \nrun with rmblastn version 2.6.0+\n</code>\n\n\nRUN 4 (default settings - human genome)\nOutput folder:\n\n20180822_virginica_repeatmasker_defaults/\n\nSummary table (text):\n\nCvirginica_v300.fa.tbl\n\nOutput table (GFF):\n\nCvirginica_v300.fa.out.gff\n\n\n\n\nSUMMARY TABLE\n<code>\n==================================================\nfile name: Cvirginica_v300.fa       \nsequences:            11\ntotal length:  684741128 bp  (684675328 bp excl N/X-runs)\nGC level:         34.83 %\nbases masked:   13461422 bp ( 1.97 %)\n==================================================\n               number of      length   percentage\n               elements*    occupied  of sequence\n--------------------------------------------------\nSINEs:             2056       120820 bp    0.02 %\n      ALUs            0            0 bp    0.00 %\n      MIRs          240        14635 bp    0.00 %\n\nLINEs:             3408       331585 bp    0.05 %\n      LINE1         240        16835 bp    0.00 %\n      LINE2         728        69177 bp    0.01 %\n      L3/CR1       1369       135234 bp    0.02 %\n\nLTR elements:       704       236625 bp    0.03 %\n      ERVL           14          944 bp    0.00 %\n      ERVL-MaLRs     12          892 bp    0.00 %\n      ERV_classI    272        36695 bp    0.01 %\n      ERV_classII     4          206 bp    0.00 %\n\nDNA elements:      1088       100026 bp    0.01 %\n     hAT-Charlie     27         1543 bp    0.00 %\n     TcMar-Tigger   142         9891 bp    0.00 %\n\nUnclassified:        57         6096 bp    0.00 %\n\nTotal interspersed repeats:   795152 bp    0.12 %\n\n\nSmall RNA:         3698       279669 bp    0.04 %\n\nSatellites:          73         5524 bp    0.00 %\nSimple repeats:  247957     10848509 bp    1.58 %\nLow complexity:   30084      1536314 bp    0.22 %\n==================================================\n\n* most repeats fragmented by insertions or deletions\n  have been counted as one element\n  Runs of >=20 X/Ns in query were excluded in % calcs\n\n\nThe query species was assumed to be homo sapiens  \nRepeatMasker Combined Database: Dfam_Consensus-20170127, RepBase-20170127\n        \nrun with rmblastn version 2.6.0+\n</code>"
  },
  {
    "objectID": "posts/2018/2018-08-08-genome-annotation-olympia-oyster-genome-annotation-results-02/index.html",
    "href": "posts/2018/2018-08-08-genome-annotation-olympia-oyster-genome-annotation-results-02/index.html",
    "title": "Genome Annotation – Olympia oyster genome annotation results #02",
    "section": "",
    "text": "Yesterday, I annotated our Olympia oyster genome using WQ-MAKER in just 7hrs!.\nSee that link for run setup and configuration. They are essentially the same, except for the change I’ll discuss below.\nThe results from that run can be seen here:\n\nGenome Annotation – Olympia oyster genome annotation results #01\n\nIn that previous run, I neglected to provide a transposable elements FastA file for use with RepeatMasker.\nI remedied that and re-ran it. I modified maker_opts.ctl to include the following:\n<code>repeat_protein=../../opt/maker/data/te_proteins.fasta #provide a fasta file of transposable element proteins for RepeatRunner</code>\nThis TEs file is part of RepeatMasker.\n\n\nRESULTS\nOutput folder:\n\n20180807_wqmaker_run_oly_02\n\nAnnotated genome file (GFF):\n\n[20180807_wqmaker_run_oly_02/Olurida_v081.all.gff (1GB)(https://owl.fish.washington.edu/Athaliana/20180807_wqmaker_run_oly_02/Olurida_v081.all.gff)\n\n\n\n\nThis run took about an hour longer than the previous run, but for some reason it ran with only 21 workers, instead of 22. This is probably the reason for the increased run time.\nI’d like to post a snippet of the GFF file here, but the line lengths are WAY too long and will be virtually impossible to read in this notebook. The GFF consists of listing a “parent” contig and its corresponding info (start/stop/length). Then, there are “children” of this contig that show various regions that are matched within the various databases that were queried, i.e. repeatmasker annotations for identifying repeat regions, protein2genome for full/partial protein matches, etc. Thus, a single scaffold (contig) can have dozens or hundreds of corresponding annotations!\nProbably the easiest and most logical to start working with will be those scaffolds that are annotated with a “protein_match”, as these have a corresponding GenBank ID. Parsing these out and then doing a join with NCBI protein IDs will give us a basic annotaiton of “functional” portions of the genome.\nAdditionally, we should probably do some sort of comparison of this run with the previous run where I did not provide the transposable elements FastA file."
  },
  {
    "objectID": "posts/2018/2018-02-28-ubuntu-installation-convert-apple-xserve-bigfish-to-ubuntu/index.html",
    "href": "posts/2018/2018-02-28-ubuntu-installation-convert-apple-xserve-bigfish-to-ubuntu/index.html",
    "title": "Ubuntu Installation - Convert Apple Xserve “bigfish” to Ubuntu",
    "section": "",
    "text": "Due to hardware limitations on the Apple Xserves we have, we can’t use drives >2TB in size. “Bigfish” was set up to be RAID’d and, as such, has three existing HDDs installed.\nWe wanted to upgrade the HDD size and convert over to Linux (Ubuntu) so that we could utilize the Linux operating system for some of our bioinformatics programs that won’t run on OSX.\nI installed Ubuntu 16.04LTS to the SSD boot drive (128GB) and installed three, 2TB HDDs. However, it cannot detect the HDDs due to the Apple hardware RAID controller! Searching the internet has revealed that this is a commonly encountered issue with RAID’d Apple Xserves and Linux installs.\nI haven’t come across a means by which to remedy this. Will likely have to install an OS X version in order to make this computer usable. Although, that won’t limit us too terribly in regards to program usage. Most programs will run fine on OSX."
  },
  {
    "objectID": "posts/2018/2018-01-10-mbd-enrichment-crassostrea-virginica-sheared-dna-day-2/index.html",
    "href": "posts/2018/2018-01-10-mbd-enrichment-crassostrea-virginica-sheared-dna-day-2/index.html",
    "title": "MBD Enrichment – Crassostrea virginica Sheared DNA Day 2",
    "section": "",
    "text": "Continued MBD enrichment for C.virginica and Qiagen project from yesterday.\nFollowed the MethylMiner Methylated DNA Enrichment Kit (Invitrogen) manufacturer’s protocol for input DNA amounts of 1 -10ug (I am using 8ug in each of two samples).\nPerformed a single, high-salt elution.\nSamples were precipitated O/N @ -80C."
  },
  {
    "objectID": "posts/2018/2018-08-07-genome-annotation-olympia-oyster-genome-using-wq-maker-instance-on-jetstream/index.html",
    "href": "posts/2018/2018-08-07-genome-annotation-olympia-oyster-genome-using-wq-maker-instance-on-jetstream/index.html",
    "title": "Genome Annotation - Olympia oyster genome using WQ-MAKER Instance on Jetstream",
    "section": "",
    "text": "Yesterday, our Xsede Startup Application (Google Doc) got approval for 100,000 Service Units (SUs) and 1TB of disk space on Xsede/Atmosphere/Jetstream (or, whatever it’s actually called!). The approval happened within an hour of submitting the application!\nHere’s a copy of the approval notice:\n\nDear Dr. Roberts:\nYour recently submitted an XSEDE Startup request has been reviewed and approved.\nPI: Steven Roberts, University of Washington\nRequest: Annotation of Olympia oyster (Ostrea lurida) and Pacific geoduck (Panopea generosa) genomes using WQ_MAKER on Jetstream cloud.\nRequest Number: MCB180124 (New)\nStart Date: N/A\nEnd Date: 2019-08-05\nAwarded Resources: IU/TACC (Jetstream): 100,000.0 SUs\nIU/TACC Storage (Jetstream Storage): 1,000.0 GB\nAllocations Admin Comments:\nThe estimated value of these awarded resources is $14,890.00. The allocation of these resources represents a considerable investment by the NSF in advanced computing infrastructure for U.S. The dollar value of your allocation is estimated from the NSF awards supporting the allocated resources.\nIf XSEDE Extended Collaborative Support (ECSS) assistance was recommended by the review panel, you will be contacted by the ECSS team within the next two weeks to begin discussing this collaboration.\nBy default the PI and all co-PIs will be added to the resources awarded. If this is an award on a renewal request, current users will have their account end dates modified to reflect the new end date of this award. PIs, co-PIs, or Allocation Managers can add users to or remove users from resources on this project by logging into the portal (https://portal.xsede.org) and using the ‘Add/Remove User’ form.\nShare the impact of XSEDE! In exchange for access to the XSEDE ecosystem, we ask that all users let us know what XSEDE has helped you achieve:\n\n\n\n\n\nFor all publications, please acknowledge use of XSEDE and allocated resources by citing the XSEDE paper (https://www.xsede.org/how-to-acknowledge-xsede) and also add your publications to your user profile.\n\n\n\n\nTell us about your achievements (https://www.xsede.org/group/xup/science-achievements).\n\n\n\n\nHelp us improve our reporting by keeping your XSEDE user profile up to date and completing the demographic fields (https://portal.xsede.org/group/xup/profile).\n\n\nFor question regarding this decision, please contact help@xsede.org.\nBest regards, XSEDE Resource Allocations Service\n===========================\nREVIEWER COMMENTS\n===========================\nReview #0 - Excellent\nAssessment and Summary: Maker is a well-known and fitting workflow for Jetstream. This should be a good use of resources.\nAppropriateness of Methodology:\nAfter each user on the allocation has logged in, the PI will need to open a ticket via help@xsede.org and request the quota be set per the allocation to 1TB. Please provide the XSEDE portal ID of each user.\nAppropriateness of Computational Research Plan:\nWe request that any publications stemming from work done using Jetstream cite us - https://jetstream-cloud.org/research/citing-jetstream.php\nEfficient Use of Resources:\n\n\nWe had a tremendous amount of help from Upendra Devisetty at CyVerse in getting the Xsede Startup Application written, as well as running WQ-MAKER on Xsede/Atmosphere/Jetstream (or, whatever it’s called!).\n\nNow, on to how I got the run going…\nI initiated the Olympia oyster genome annotation using a WQ-MAKER instance (MAKER 2.31.9 with CCTools v3.1) on Jetstream:\n\n\nI followed the excellent step-by-step directions here:\n\nMAKER 2.31.9 Jetstream Tutorial\n\nThe “MASTER” machine was a “m1.xlarge” machine (i.e. CPU: 24, Mem: 60 GB, Disk: 60 GB).\nI attached a 1TB volume to the MASTER machine.\nI set up the run using 21 “WORKER” machines. Twenty WORKERS were “m1.large” machines (i.e. CPU: 10, Mem: 30 GB, Disk: 60 GB). The remaining WORKER was set at “m1.xlarge” (i.e. CPU: 24, Mem: 60 GB, Disk: 60 GB) to use up the rest of our allocated memory.\n\n\nMASTER machine was initialized with the following command:\n<code>nohup wq_maker -contigs-per-split 1 -cores 1 -memory 2048 -disk 4096 -N wq_maker_oly${USER} -d all -o master.dbg -debug_size_limit=0 -stats test_out_stats.txt > log_file.txt 2>&1 &</code>\nEach WORKER was started with the following command:\n<code>nohup work_queue_worker -N wq_maker_oly${USER} --cores all --debug-rotate-max=0 -d all -o worker.dbg > log_file_2.txt 2>&1 &</code>\nWhen starting each WORKER, an error message was generated, but this doesn’t seem to have any impact on the ability of the program to run:\n\n\nI checked on the status of the run and you can see that there are 22 WORKERS and 15,568 files “WAITING”. BUT, there are 159,429 contigs in our genome FastA!\nWhy don’t these match??!!\nThis is because WQ-MAKER splits the genome FastA into smaller FastA files containg only 10 sequences each. This is why we see 10-fold fewer files being processed than sequences in our genome file.\n\n\nHere is the rest of the nitty gritty details:\n\nGenome file:\n\nOlurida_v081.fa\n\nSee our Genomic Resources GtiHub wiki for deets\n\n\n\n\nTranscriptome file:\n\nOlurida_transcriptome_v3.fasta\n\n\n\nProteome files (NCBI):\nThe two FastA files below were concatenated into a single FastA file (gigas_virginica_ncbi_proteomes.fasta) for use in WQ-MAKER.\n\nCrassostrea gigas\n\nGCA_000297895.1_oyster_v9_protein.faa.gz\n\nCrassostrea virginica\n\nGCF_002022765.2_C_virginica-3.0_protein.faa.gz\n\n\n\n\nMaker options control file (maker_opts.ctl):\nThis is a bit difficult to read in this notebook; copy and paste in text editor for easier viewing.\nNOTE: Paths to files (e.g. genome FastA) have to be relative paths; cannot be absolute paths!\n<code>\n#-----Genome (these are always required)\ngenome=../data/oly_genome/Olurida_v081.fa #genome sequence (fasta file or fasta embeded in GFF3 file)\norganism_type=eukaryotic #eukaryotic or prokaryotic. Default is eukaryotic\n\n#-----Re-annotation Using MAKER Derived GFF3\nmaker_gff= #MAKER derived GFF3 file\nest_pass=0 #use ESTs in maker_gff: 1 = yes, 0 = no\naltest_pass=0 #use alternate organism ESTs in maker_gff: 1 = yes, 0 = no\nprotein_pass=0 #use protein alignments in maker_gff: 1 = yes, 0 = no\nrm_pass=0 #use repeats in maker_gff: 1 = yes, 0 = no\nmodel_pass=0 #use gene models in maker_gff: 1 = yes, 0 = no\npred_pass=0 #use ab-initio predictions in maker_gff: 1 = yes, 0 = no\nother_pass=0 #passthrough anyything else in maker_gff: 1 = yes, 0 = no\n\n#-----EST Evidence (for best results provide a file for at least one)\nest=../data/oly_transcriptome/Olurida_transcriptome_v3.fasta #set of ESTs or assembled mRNA-seq in fasta format\naltest= #EST/cDNA sequence file in fasta format from an alternate organism\nest_gff= #aligned ESTs or mRNA-seq from an external GFF3 file\naltest_gff= #aligned ESTs from a closly relate species in GFF3 format\n\n#-----Protein Homology Evidence (for best results provide a file for at least one)\nprotein=../data/gigas_virginica_ncbi_proteomes.fasta  #protein sequence file in fasta format (i.e. from mutiple oransisms)\nprotein_gff=  #aligned protein homology evidence from an external GFF3 file\n\n#-----Repeat Masking (leave values blank to skip repeat masking)\nmodel_org=all #select a model organism for RepBase masking in RepeatMasker\nrmlib= #provide an organism specific repeat library in fasta format for RepeatMasker\nrepeat_protein= #provide a fasta file of transposable element proteins for RepeatRunner\nrm_gff= #pre-identified repeat elements from an external GFF3 file\nprok_rm=0 #forces MAKER to repeatmask prokaryotes (no reason to change this), 1 = yes, 0 = no\nsoftmask=1 #use soft-masking rather than hard-masking in BLAST (i.e. seg and dust filtering)\n\n#-----Gene Prediction\nsnaphmm= #SNAP HMM file\ngmhmm= #GeneMark HMM file\naugustus_species= #Augustus gene prediction species model\nfgenesh_par_file= #FGENESH parameter file\npred_gff= #ab-initio predictions from an external GFF3 file\nmodel_gff= #annotated gene models from an external GFF3 file (annotation pass-through)\nest2genome=0 #infer gene predictions directly from ESTs, 1 = yes, 0 = no\nprotein2genome=0 #infer predictions from protein homology, 1 = yes, 0 = no\ntrna=0 #find tRNAs with tRNAscan, 1 = yes, 0 = no\nsnoscan_rrna= #rRNA file to have Snoscan find snoRNAs\nunmask=0 #also run ab-initio prediction programs on unmasked sequence, 1 = yes, 0 = no\n\n#-----Other Annotation Feature Types (features MAKER doesn't recognize)\nother_gff= #extra features to pass-through to final MAKER generated GFF3 file\n\n#-----External Application Behavior Options\nalt_peptide=C #amino acid used to replace non-standard amino acids in BLAST databases\ncpus=1 #max number of cpus to use in BLAST and RepeatMasker (not for MPI, leave 1 when using MPI)\n\n#-----MAKER Behavior Options\nmax_dna_len=100000 #length for dividing up contigs into chunks (increases/decreases memory usage)\nmin_contig=1 #skip genome contigs below this length (under 10kb are often useless)\n\npred_flank=200 #flank for extending evidence clusters sent to gene predictors\npred_stats=0 #report AED and QI statistics for all predictions as well as models\nAED_threshold=1 #Maximum Annotation Edit Distance allowed (bound by 0 and 1)\nmin_protein=0 #require at least this many amino acids in predicted proteins\nalt_splice=0 #Take extra steps to try and find alternative splicing, 1 = yes, 0 = no\nalways_complete=0 #extra steps to force start and stop codons, 1 = yes, 0 = no\nmap_forward=0 #map names and attributes forward from old GFF3 genes, 1 = yes, 0 = no\nkeep_preds=0 #Concordance threshold to add unsupported gene prediction (bound by 0 and 1)\n\nsplit_hit=10000 #length for the splitting of hits (expected max intron size for evidence alignments)\nsingle_exon=0 #consider single exon EST evidence when generating annotations, 1 = yes, 0 = no\nsingle_length=250 #min length required for single exon ESTs if 'single_exon is enabled'\ncorrect_est_fusion=0 #limits use of ESTs in annotation to avoid fusion genes\n\ntries=2 #number of times to try a contig if there is a failure for some reason\nclean_try=0 #remove all data from previous run before retrying, 1 = yes, 0 = no\nclean_up=0 #removes theVoid directory with individual analysis files, 1 = yes, 0 = no\nTMP= #specify a directory other than the system default temporary directory for temporary files\n</code>\nAfter the run finishes, it will have produced a corresponding GFF file for each scaffold. This is unwieldly, so the GFFs will be merged using the following code:\n<code>$ gff3_merge -n -d Olurida_v081.maker.output/Olurida_v081_master_datastore_index.log</code>\nAll WORKERS were running as of 07:45 today. As of this posting (~3hrs later), WQ-MAKER had already processed ~45% of the files! Annotation will be finished by the end of today!!! Crazy!"
  },
  {
    "objectID": "posts/2018/2018-04-01-trimgalorefastqcmultiqc-illumina-hiseq-genome-sequencing-data-continued/index.html",
    "href": "posts/2018/2018-04-01-trimgalorefastqcmultiqc-illumina-hiseq-genome-sequencing-data-continued/index.html",
    "title": "TrimGalore!/FastQC/MultiQC - Illumina HiSeq Genome Sequencing Data Continued",
    "section": "",
    "text": "The previous attempt at this was interrupted by a random glitch with our Mox HPC node.\nI removed the last files processed by TrimGalore!, just in case they were incomplete. I updated the slurm script to process only the remaining files that had not been processed when the Mox glitch happened (including the files I deemed “incomplete”).\nAs in the initial run, I kept the option in TrimGalore! to automatically run FastQC on the trimmed output files.\nTrimGalore! slurm script: 20180401_trim_galore_illumina_geoduck_hiseq_slurm.sh\nMultiQC was run locally once the files were copied to Owl.\n\nResults:\nJob completed on 20180404.\nTrimmed FASTQs: 20180328_trim_galore_illumina_hiseq_geoduck/\nMD5 checksums: 20180328_trim_galore_illumina_hiseq_geoduck/checksums.md5\n\nMD5 checksums were generated on Mox node and verified after copying to Owl.\n\nSlurm output file: 20180401_trim_galore_illumina_geoduck_hiseq_slurm.sh\nTrimGalore! output: 20180328_trim_galore_illumina_hiseq_geoduck/20180404_trimgalore_reports/\nFastQC output: 20180328_trim_galore_illumina_hiseq_geoduck/20180328_fastqc_trimmed_hiseq_geoduck/\nMultiQC output: 20180328_trim_galore_illumina_hiseq_geoduck/20180328_fastqc_trimmed_hiseq_geoduck/multiqc_data/\nMultiQC HTML report: 20180328_trim_galore_illumina_hiseq_geoduck/20180328_fastqc_trimmed_hiseq_geoduck/multiqc_data/multiqc_report.html\n\n\nTrimming completed and the FastQC results look much better than before.\nWill proceed with full-blown assembly!"
  },
  {
    "objectID": "posts/2018/2018-03-20-titrations-hollies-seawater-samples-3/index.html",
    "href": "posts/2018/2018-03-20-titrations-hollies-seawater-samples-3/index.html",
    "title": "Titrations - Hollie’s Seawater Samples",
    "section": "",
    "text": "All data is deposited in the following GitHub repo:\n\nRobertsLab/titrator\n\nSample sizes: ~50g\nLabX Method:\n\nTA_titration.pdf\n\nDaily pH calibration data file:\n\n2018-03-20T07_27_30_pH_calibration_7_4_10_T324.csv\n\nDaily pH log file:\n\ndaily_calibration_log.csv\n\nTitrant batch:\n\nA10\n\nCRM Batch:\n\n168\n\nDaily CRM data file:\n\n2018-03-20T08_23_37_CRM_TA_titration_T326.csv\n\nSample data file(s):\n\n2018-03-20T10_25_54_TA_titration_T327.csv\n2018-03-20T14_06_06_TA_titration_T328.csv\n\nSee metadata file for sample info (including links to master samples sheets):\n\nfile_metadata.csv"
  },
  {
    "objectID": "posts/2018/2018-05-12-assembly-geoduck-hi-c-assembly-subsetting/index.html",
    "href": "posts/2018/2018-05-12-assembly-geoduck-hi-c-assembly-subsetting/index.html",
    "title": "Assembly - Geoduck Hi-C Assembly Subsetting",
    "section": "",
    "text": "Steven asked me to create a couple of subsets of our Phase Genomics Hi-C geoduck genome assembly (pga_02):\n\nContigs >10kbp\nContigs >30kbp\n\nI used pyfaidx on Roadrunner and the following commands:\nfaidx --size-range 10000,100000000 PGA_assembly.fasta > PGA_assembly_10k_plus.fasta\n\nfaidx --size-range 30000,100000000 PGA_assembly.fasta > PGA_assembly_30k_plus.fasta\nRan Quast afterwards to get stats on the new FastA files just to confirm that the upper cutoff value was correct and didn’t get rid of the largest contig(s).\n\nResults:\nfaidx Output folder: 20180512_geoduck_fasta_subsets/\n\n10kbp contigs (FastA): 20180512_geoduck_fasta_subsets/PGA_assembly_10k_plus.fasta\n30kbp contigs (FastA): 20180512_geoduck_fasta_subsets/PGA_assembly_30k_plus.fasta\n\nQuast output folder: results_2018_05_14_06_26_26/\nQuast report (HTML): results_2018_05_14_06_26_26/report.html\nEverything looks good. The main thing I wanted to confirm by running Quast was that the largest contig in each subset was the same as the original PGA assembly (95,480,635bp."
  },
  {
    "objectID": "posts/2018/2018-09-27-transcriptome-alignment-bedgraph-olympia-oyster-transcriptome-with-olurida_v080-genome-assembly/index.html",
    "href": "posts/2018/2018-09-27-transcriptome-alignment-bedgraph-olympia-oyster-transcriptome-with-olurida_v080-genome-assembly/index.html",
    "title": "Transcriptome Alignment & Bedgraph – Olympia oyster transcriptome with Olurida_v080 genome assembly",
    "section": "",
    "text": "Yesterday, I produced a bedgraph file of our Olympia oyster RNAseq data coverage using our Olurida_v081 genome.\nI decided that I wanted to use the Olurida_v080 version instead (or, in addtion to?), as the Olurida_v080 version has not been size restricted (the Olurida v081 version is only contigs >1000bp). I feel like we could miss some important regions, so wanted to run this analysis using all of the genome data we currently have available. Additionally, this will be consistent with [my previous Bismark (DNA methylation analysis)(2018/09/13/dna-methylation-analysis-olympia-oyster-whole-genome-bsseq-bismark-pipeline-comparison.html).\nUsed HISAT2 on our HPC Mox node to align our RNAseq reads to our Olurida_v080 genome assembly:\n\nOlurida_v080.fa\n\nSBATCH script file:\n\n20180926_oly_RNAseq_bedgraphs.sh\n\nNOTE: For brevity sake, I have not listed all of the input RNAseq files below. Please see the full script, which is linked above.\n<code>\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=20180926_oly_hisat2\n## Allocation Definition \n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=5-00:00:00\n## Memory per node\n#SBATCH --mem=500G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --workdir=/gscratch/scrubbed/samwhite/20180926_oly_RNAseq_genome_hisat2_bedgraph\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\ndate >> system_path.log\necho \"\" >> system_path.log\necho \"System PATH for $SLURM_JOB_ID\" >> system_path.log\necho \"\" >> system_path.log\nprintf \"%0.s-\" {1..10} >> system_path.log\necho ${PATH} | tr : \\\\n >> system_path.log\n\n\n# Set genome assembly path\noly_genome_path=/gscratch/srlab/sam/data/O_lurida/oly_genome_assemblies\n\n# Set sorted transcriptome assembly bam file\noly_transcriptome_bam=20180926_Olurida_v080.sorted.bam\n\n# Set hisat2 basename\nhisat2_basename=Olurida_v080\n\n# Set program paths\n## hisat2\nhisat2=/gscratch/srlab/programs/hisat2-2.1.0\n\n## bedtools\nbedtools=/gscratch/srlab/programs/bedtools-2.27.1/bin\n\n## samtools\nstools=/gscratch/srlab/programs/samtools-1.9/samtools\n\n# Build hisat2 genome index\n${hisat2}/hisat2-build \\\n-f ${oly_genome_path}/Olurida_v080.fa \\\nOlurida_v080 \\\n-p 28\n\n# Align reads to oly genome assembly\n${hisat2}/hisat2 \\\n--threads 28 \\\n-x \"${hisat2_basename}\" \\\n-q \\\n-1 \\\n-2 \\\n-S 20180926_\"${hisat2_basename}\".sam\n\n# Convert SAM file to BAM\n\"${stools}\" view \\\n--threads 28 \\\n-b 20180926_\"${hisat2_basename}\".sam > 20180926_\"${hisat2_basename}\".bam\n\n# Sort BAM\n\"${stools}\" sort \\\n--threads 28 \\\n20180926_\"${hisat2_basename}\".bam \\\n-o 20180926_\"${hisat2_basename}\".sorted.bam\n\n# Index for use in IGV\n##-@ specifies thread count; --thread option not available in samtools index\n\"${stools}\" index \\\n-@ 28 \\\n20180926_\"${hisat2_basename}\".sorted.bam\n\n\n# Create bedgraph\n## Reports depth at each position (-bg in bedgraph format) and report regions with zero coverage (-a).\n## Screens for portions of reads coming from exons (-split).\n## Add genome browser track line to header of bedgraph file.\n${bedtools}/genomeCoverageBed \\\n-ibam ${oly_transcriptome_bam} \\\n-bga \\\n-split \\\n-trackline \\\n> 20180926_oly_RNAseq.bedgraph\n</code>\nThe script performs the following functions:\n\nGenome indexing\nRNAseq alignment to genome\nConvert SAM to BAM\nSort and index BAM\nDetermine RNAseq coverage\n\n\n\nRESULTS\nOutput folder:\n\n20180926_oly_RNAseq_genome_hisat2_bedgraph/\n\nBedgraph file (1.9GB):\n\n20180926_oly_RNAseq_genome_hisat2_bedgraph/20180926_oly_RNAseq.bedgraph\n\nLoaded in to IGV to verify things looked OK:"
  },
  {
    "objectID": "posts/2018/2018-05-22-software-installation-repeatmasker-v4-0-7-on-emuroadrunner/index.html",
    "href": "posts/2018/2018-05-22-software-installation-repeatmasker-v4-0-7-on-emuroadrunner/index.html",
    "title": "Software Installation - RepeatMasker v4.0.7 on Emu/Roadrunner",
    "section": "",
    "text": "Steven asked that I re-run some Olympia oyster transposable elements analysis using RepeatMasker and a newer version of our Olympia oyster genome assembly.\nInstalled the software on both of the Apple Xserves (Emu and Roadrunner) running Ubuntu 16.04.\nFollowed the instructions outlined here:\n\nRepeatMasker Download page\n\nStarting with the prerequisites:\n\nDownload and install RMBlast\n\n\nNCBI Blast 2.6.0 source\nisb 2.6.0 patch\n\nUnfortunately, the make command continually failed:\n<code>cd /home/shared/ncbi-blast-2.6.0+-src/c++\nmake</code>\n\nWhile trying to troubleshoot this issue, continued with the other prerequisites:\n\nDownloaded Tandem Repeat Finder v.4.09\n\n\nSaved file (trf409.linux64) to /home/shared/bin. NOTE: /home/shared/bin is part of the system PATH. See the /etc/environment file.\nChanged permissions to be executable:\nsudo chmod 775 trf409.linux64\n\n\nDownloaded RepBase RepeatMasker Edition 20170127 (NOTE: This requires registration in order to obtain a username/password to download the file).\n\nInstalled RepeatMasker:\n\nDownloaded RepeatMasker 4.0.7\n\n\nSaved to /home/shared/RepeatMasker-4.0.7\n\n\nInstalled RepBase RepeatMasker Edition 20170127 in /home/shared//home/shared/RepeatMasker-4.0.7/Libraries\n\nCurrently re-building RMBlast and it takes forever… Will report back when I have it running."
  },
  {
    "objectID": "posts/2018/2018-09-20-transcriptome-alignment-olympia-oyster-trinity-transcriptome-aligned-to-genome-with-bowtie2/index.html",
    "href": "posts/2018/2018-09-20-transcriptome-alignment-olympia-oyster-trinity-transcriptome-aligned-to-genome-with-bowtie2/index.html",
    "title": "Transcriptome Alignment - Olympia oyster Trinity transcriptome aligned to genome with Bowtie2",
    "section": "",
    "text": "Progress on generating bedgraphs from our Olympia oyster transcriptome continues.\nTranscriptome assembly with Trinity completed 20180919.\nNext up, align transcriptome to Olympia oyster genome.\nAlignment and creation of BAM files was done using Bowtie2 on our HPC Mox node.\nSBATCH script file:\n\n20180919_oly_transcriptome_bowtie2.sh\n\nAlignment was done using the following version of the Olympia oyster genome assembly:\n\nOlurida_v081.fa\n\n\n\nRESULTS:\nOutput folder:\n\n20180919_oly_transcriptome_bowtie2/\n\nSorted BAM file:\n\n20180919_Olurida_v081.sorted.bam\n\nSorted & indexed BAM file (for IGV):\n\n20180919_Olurida_v081.sorted.bam.bai\n\nWill get the sorted BAM file converted to a bedgraph for use in IGV."
  },
  {
    "objectID": "posts/2018/2018-04-09-fastqcmultiqc-c-virginica-mbd-bs-seq-data/index.html",
    "href": "posts/2018/2018-04-09-fastqcmultiqc-c-virginica-mbd-bs-seq-data/index.html",
    "title": "FastQC/MultiQC - C. virginica MBD BS-seq Data",
    "section": "",
    "text": "Per Steven’s GitHub Issues request, I ran FastQC on the Eastern oyster MBD bisulfite sequencing data we recently got back from ZymoResearch.\nRan FastQC locally with the following script: 20180409_fastqc_Cvirginica_MBD.sh\n<code>\n#!/bin/bash\n/home/sam/software/FastQC/fastqc \\\n--threads 18 \\\n--outdir /home/sam/20180409_fastqc_Cvirginica_MBD \\\n/mnt/owl/nightingales/C_virginica/zr2096_10_s1_R1.fastq.gz \\\n/mnt/owl/nightingales/C_virginica/zr2096_10_s1_R2.fastq.gz \\\n/mnt/owl/nightingales/C_virginica/zr2096_1_s1_R1.fastq.gz \\\n/mnt/owl/nightingales/C_virginica/zr2096_1_s1_R2.fastq.gz \\\n/mnt/owl/nightingales/C_virginica/zr2096_2_s1_R1.fastq.gz \\\n/mnt/owl/nightingales/C_virginica/zr2096_2_s1_R2.fastq.gz \\\n/mnt/owl/nightingales/C_virginica/zr2096_3_s1_R1.fastq.gz \\\n/mnt/owl/nightingales/C_virginica/zr2096_3_s1_R2.fastq.gz \\\n/mnt/owl/nightingales/C_virginica/zr2096_4_s1_R1.fastq.gz \\\n/mnt/owl/nightingales/C_virginica/zr2096_4_s1_R2.fastq.gz \\\n/mnt/owl/nightingales/C_virginica/zr2096_5_s1_R1.fastq.gz \\\n/mnt/owl/nightingales/C_virginica/zr2096_5_s1_R2.fastq.gz \\\n/mnt/owl/nightingales/C_virginica/zr2096_6_s1_R1.fastq.gz \\\n/mnt/owl/nightingales/C_virginica/zr2096_6_s1_R2.fastq.gz \\\n/mnt/owl/nightingales/C_virginica/zr2096_7_s1_R1.fastq.gz \\\n/mnt/owl/nightingales/C_virginica/zr2096_7_s1_R2.fastq.gz \\\n/mnt/owl/nightingales/C_virginica/zr2096_8_s1_R1.fastq.gz \\\n/mnt/owl/nightingales/C_virginica/zr2096_8_s1_R2.fastq.gz \\\n/mnt/owl/nightingales/C_virginica/zr2096_9_s1_R1.fastq.gz \\\n/mnt/owl/nightingales/C_virginica/zr2096_9_s1_R2.fastq.gz\n</code>\nMultiQC was then run on the FastQC output files.\nAll files were moved to Owl after the jobs completed.\n\nResults:\nFastQC Output folder: 20180409_fastqc_Cvirginica_MBD/\nMultiQC Output folder: 20180409_fastqc_Cvirginica_MBD/multiqc_data/\nMultiQC report (HTML): 20180409_fastqc_Cvirginica_MBD/multiqc_data/multiqc_report.html\nEverything looks good to me.\nSteven’s interested in seeing what the trimmed output would look like (and, how it would impact mapping efficiencies). Will initiate trimming.\nSee the GitHub issue linked above for the full discussion."
  },
  {
    "objectID": "posts/2018/2018-01-10-mbd-enrichment-crassostrea-virginica-sheared-dna-day-3/index.html",
    "href": "posts/2018/2018-01-10-mbd-enrichment-crassostrea-virginica-sheared-dna-day-3/index.html",
    "title": "MBD Enrichment – Crassostrea virginica Sheared DNA Day 3",
    "section": "",
    "text": "Continued MBD enrichment of C.virginica DNA from yesterday for Qiagen project.\nFollowed the MethylMiner Methylated DNA Enrichment Kit (Invitrogen) manufacturer’s protocol for input DNA amounts of 1 -10ug (I am using 8ug in each of two samples).\nSince the protocol has two elution steps that are each saved separately from each other for each sample, I did the following to combine the two elution fractions into a single sample:\n\nPelleted one elution fraction from each sample\nDiscarded supernatant from pelleted sample\nTransferred second elution fraction to the pellet from the first elution fraction\nPelleted second elution fraction\n\nThe rest of the ethanol precipitation procedure was followed per the manufacturer’s protocol.\nFinal pellets were resuspended in 25μL of Buffer EB (Qiagen) and stored temporarily on ice for quantification."
  },
  {
    "objectID": "posts/2018/2018-07-31-rna-cleanup-tanner-crab-rna/index.html",
    "href": "posts/2018/2018-07-31-rna-cleanup-tanner-crab-rna/index.html",
    "title": "RNA Cleanup - Tanner Crab RNA",
    "section": "",
    "text": "In a continued attempt to figure out what we can do about the tanner crab RNA, Steven tasked me with using an RNeasy Kit to cleanup some existing RNA.\nHere’re the samples grace provided:\n\n\n\nAll of the RNA had some sort of undissolved/insoluble material present. Here’s an example (this is the worts of the bunch - others did not have such large/dense pellets):\n\n\nSamples were cleaned up using the [RNeasy Plus Mini Kit (Qiagen). Added 350uL of Buffer RLT Plus (no beta-mercaptoethanol added) to each sample, vortexed, and then processed according to the manufacturer’s protocol (skipped gDNA Eliminator spin column step).\nSamples were eluted with 30uL of nuclease-free water.\nSamples were quantified using the Roberts Lab Qubit 3.0 with the RNA High Sensitivity asssay (Invitrogen). Used 5uL of sample for measurements.\nSamples were also assessed with the Roberts Lab NandoDrop1000.\nSamples were recovered from the pedestal after measurement.\nRNA was given to Grace for storage at -80C.\n\n\nRESULTS\nQubit measurements (Google Sheet): - 20180731_qubit_RNA_crab_cleanup\n\nNanoDrop Table:\n\n\nAll concentrations were too low for detection via NanoDrop.\nQubit quantification indicate yields ranging from ~25ng to ~192.5ng.\nWill share info with Grace and let her compare these numbers to her original concentrations to see if there’s any differences.\nRegardless, based on my earlier RNA isolation today, these samples should now be much cleaner and we should be able to trust the Qubit quantifications."
  },
  {
    "objectID": "posts/2018/2018-03-06-progress-report-titrator/index.html",
    "href": "posts/2018/2018-03-06-progress-report-titrator/index.html",
    "title": "Progress Report - Titrator",
    "section": "",
    "text": "I’ll begin this entry with a TL;DR (becuase it’s definitely a very long read):\n\nSample weight (i.e. volume) appears to have an effect on total alkalinity (TA) determination, despite the fact that sample weight is taken into account when calculating TA.\nReplicates are relatively consistent.\nOur TA measurements of CO2 Reference Materials (CRMs) do not match TA info supplied with CRMs.\nConclusions?\n\nThe only thing that actually matters is consistent replicates.\nUse 50g (i.e. 50mL) sample weights - will greatly conserve reagents (CRMs, acid)\nCalculate offset from CRMs or just report our TA measurements and the corresponding CRM TA value(s)?\nAsk Hollie Putnam what she thinks.\n\n\nWith that out of the way, here’s a fairly lengthy overview of what has been done to date with the titrator. In essence, this is a cumulative notebook entry of all the entries I should have been doing on a daily/weekly basis (I actually feel much shame for neglecting this - it’s a terrible practice and an even worse example for other lab members).\n\nTeaser: there are graphs!\nAnyway, I’ve spent a lot of time getting our titrator, protocols, and scripts to a point where we can not only begin collecting real data, but also actually analyze the data in a semi-automated way.\nMore recently, I’ve finally started taking some measurements to assess the consistency of the actual titrator and stumbled across an interesting observation that may (may not) have an impact on how we proceed with sample/data handling.\n\n\n\nProtocols\nTitrator SOP is the primary protocol that encompasses setting up/shutting down the titrator, use of the LabX software needed for recording/exporting data from the titrator, and how to implement the necessary scripts to handle the exported data is still in early stages.\nIn theory, the SOP should be rather straightforward, but due to the sensitivity involved with these measurements, the SOP needs to carefully address how to set things up properly, provide a means for documenting startup/shutdown procedures, and provide troubleshooting assistance (e.g. how to empty/remove burette if/when air bubbles develop).\nOverall, it’s a bit of a beast, albeit and important one, but I’ve put it on the back burner in order to focus my efforts/time on getting to the point of being able to collect data from the titrator and feel confident that we’re getting good readings.\nOnce I get to that point and am able to begin running samples, I’ll be able to dedicate more time to fleshing out the SOP, including adding pictures of all the components.\n\n\n\nScripts\nparsing_TA_output.R is the script that has consumed the majority of my titrator-related time in the last couple of weeks. It is fully functional (it only requires manual entry of the exported LabX data file location). However, I’m hoping to eventually automate this as well - i.e. when new LabX export file appears, this script will execute. I won’t be spending much time on this aspect of the script until I\nThis has been my highest priority. Without having this script in a usable state, it has been a MAJOR slog to manually retrieve the appropriate data necessary to use in TA determination.\nThis also has been my biggest challenge with the titrator process. Here are just some of the hurdles I’ve had to deal with in putting this script together:\n\n“learning” R\nhandling “dynamic” titrator output data\n\nthis is not an easy task for a non-programmer!\nthe output data is of differing numbers of rows from sample to sample, so the script had to be able to handle this aspect automatically\nmaking the script “flexible” (i.e. no “magic numbers”) to handle any number of samples without the user having to manually modify the script\nmaking th script “flexible” by operating on column names instead of column numbers, since column numbers were/are not constant, depending on changes to the script\n\ncalculations resulting from two-part titration\n\nstill not sure if I ever would’ve figured this out if I hadn’t taken the intro computer science class at UW a couple of years ago!\n\n\nDespite all of this, I also feel like it’s one of my biggest accomplishments! It’s super satisfying to have this script functioning with virtually no user input required!\npH_calibration_check.R is still a work in progess, but is easily usable. Currently, it still has some hard-coded values (row numbers) in it for parsing data, but that should be easy to fix after what I went through with the TA parsing script!\nEventually, these two scripts will work in tandem, with the pH_calibration_check script exporting data to a daily “log” file, which the parsing_TA_output script will use to read-in the necessary pH data.\nTA_calculation.R will calculate the TA values, but currently requires fully manual data entry. It desperately needs attention and will likely be my primary focus in the immediate future, due to the need to have TA values for actual samples, as well as daily quality control checks (e.g. verify CRM measurements look OK before measuring actual samples).\n\n\n\nMeasurements\n\nConsistency checks with Instant Ocean\n\nInstant Ocean Tests\nI ran nine replicates of Instant Ocean (36g/L in deionized water) at two different samples weights/volume (50g, 75g) to make sure the titrator was producing consistent results.\nHere’s the R Studio Project folder with all the data/scripts used to gather the data and produce the plots:\n\n20180301_titrator_instant_ocean_tests\n\nTA values were determined using the seacarb R package. I used a salinity of 35 (seacarb default value?), but this has not been determined for this batch of Instant Ocean.\n\n\n\nSample Volume Mean TA Standard Deviation\n\n\n\n\n\n50mL\n\n\n669.4\n\n\n11.14\n\n\n\n\n75mL\n\n\n645.0\n\n\n11.96\n\n\n\n\n\nThe first thing I noticed was the low TA values when using Instant Ocean. I expected these to be more similar to sea water, but the Instant Ocean hasn’t been aerated, so maybe that could account for the low TA values. Regardless, this shouldn’t be too much of an issue, since I only wanted to use this to see if we were getting consistent measurements.\nThe second thing I noticed was the difference in TA values between the 50mL and 75mL samples. This is/was odd, as sample weight is taken into account with the seacarb package.\nSo, I decided to explore this a bit further, using the CRMs that we have. I felt that this would provide more informative data regarding measurement accuracy (i.e. do our measurements match a known value?), in addition to further evaluation of the effects of sample volume on TA determination.\n\n\n\nConsistency checks with CRMs\n\nCRM Tests\nI ran five replicates of [CRM Batch 168 (PDF)(https://github.com/RobertsLab/titrator/blob/master/data/crm_certifications/Batch168.pdf) at three different sample weights/volume (50g, 75g, 100g) to make sure the titrator was producing consistent results and evaulate how accurate our measurements are.\nHere’s the R Studio Project folder with all the data/scripts used to gather the data and produce the plots:\n\n20180305_titrator_crm_tests\n\nHere’s a bunch of graphs to consider:\n\n\n\n\n\n\nSample Mean TA Standard Deviation\n\n\n\n\n\nCRM 168\n\n\n2071.47\n\n\nNA\n\n\n\n\n50mL\n\n\n2259.66\n\n\n7.35\n\n\n\n\n75mL\n\n\n2236.22\n\n\n19.96\n\n\n\n\n100mL\n\n\n2226.73\n\n\n14.49\n\n\n\n\n\nFirst thing to notice is that all sample measurements, regardless of volume, produce a TA value that is ~10% higher than what the CRM is certified to be. I’ve previously discussed this with Hollie and she’s indicated that there are two options:\n\nCalculate an offset relative to what the CRM is supposed to be and apply this offset to any sample measurements.\nDo not determine offset and just report calculated values, while providing CRM info.\n\nThe next thing that I noticed is the 50mL (g) samples produced the most consistent measurements.\nThere also seems to be a pattern where fluctuations in TA values across replicates are mirrored by changes in weight for each corresponding replicate.\nFinally, although it isn’t explicitly addressed, there is a time element in play here. As sample number increases, the longer those samples sat in the sample changer before titration. Oddly, it appears that there could be an effect on samples as they sit (e.g. sample evaporation prior to titration) when one considers the 75mL and 100mL samples, but both of those result in opposing trends, while the 50mL samples do not seem to suffer from any sort of time-related changes…\n\n\n\n\n\nThe Wrap Up\nWhew! We made it! I’ll wait to get some feedback from lab members and Hollie before cranking through all of Hollie’s samples, but I feel pretty good about proceeding with a 50mL sample volume. If we decide to calculate an offset later on, it should only be a relatively minor tweak to our script.\nNext up, figure out a way to pull out all of Hollie’s salinity data for the samples I’m going to measure and incorporate that into the TA_calculation.R script."
  },
  {
    "objectID": "posts/2018/2018-04-22-assembly-sparseassembler-k-131-on-geoduck-sequence-data/index.html",
    "href": "posts/2018/2018-04-22-assembly-sparseassembler-k-131-on-geoduck-sequence-data/index.html",
    "title": "Assembly – SparseAssembler (k 131) on Geoduck Sequence Data",
    "section": "",
    "text": "After some runs with kmergenie, I’ve decided to try re-running SparseAssembler using a kmer setting of 131.\nThe job was run on our Mox HPC node.\n\nSlurm script: 20180422_sparse_assembler_kmer131_geoduck_slurm.sh\n\n\nResults:\nOutput folder:\n\n20180422_sparseassembler_kmer131_geoduck/\n\nSlurm output file:\n\n20180422_sparseassembler_kmer131_geoduck/slurm-163406.out\n\nThis failed with the following error message:\nError! K-mer size too large!\nLooking into this, it’s because the maximum kmer size for kmergenie is 127! Doh!\nIt’d be nice if the program looked at that setting first before processign all the data files…\nA bit disappointing, but I’ll give this a go with a lower kmer setting and see how it goes."
  },
  {
    "objectID": "posts/2018/2018-09-13-dna-methylation-analysis-olympia-oyster-whole-genome-bsseq-bismark-pipeline-comparison/index.html",
    "href": "posts/2018/2018-09-13-dna-methylation-analysis-olympia-oyster-whole-genome-bsseq-bismark-pipeline-comparison/index.html",
    "title": "DNA Methylation Analysis - Olympia Oyster Whole Genome BSseq Bismark Pipeline Comparison",
    "section": "",
    "text": "Ran Bismark using our high performance computing (HPC) node, Mox, with two different bowtie2 settings:\n\nDefault settings\n–score_min L,0,-0.6\n\nThe second setting is a bit less stringent than the default settings and should result in a higher percentage of reads mapping. However, not entirely sure what the actual implications will be (if any) for interpreting the resulting data.\nInput data was previously trimmed per Bismark’s recommendation for Illumina TruSeq libraries (TrimGalore! 5’ 10bp):\n\nSam’s Notebook 20180830\n\nList of input files and Bismark configurations can be seen in the SLURM scripts:\n\n20180912_oly_WGBSseq_bismark.sh (default settings)\n20180913_oly_WGBSseq_bismark.sh (relaxed settings)\n\n\n\nRESULTS\nOutput folders:\n\n20180912_oly_WGBSseq_bismark/ (default settings)\n20180913_oly_WGBSseq_bismark/ (relaxed settings)"
  },
  {
    "objectID": "posts/2018/2018-10-16-qpcr-c-gigas-primer-and-gdna-tests-with-18s-and-ef1-primers/index.html",
    "href": "posts/2018/2018-10-16-qpcr-c-gigas-primer-and-gdna-tests-with-18s-and-ef1-primers/index.html",
    "title": "qPCR – C.gigas primer and gDNA tests with 18s and EF1 primers",
    "section": "",
    "text": "The qPCR I ran earlier today to check for residual gDNA in Ronit’s DNased RNA turned out terribly, due to a combination of bad primers and, possibly, bad gDNA.\nI tracked down some different primers for testing:\n\nCg_18s_1644_F (SRID 1168)\nCg_18s_1750_R (SRID 1169)\nEF1_qPCR_5’ (SRID 309)\nEF1_qPCR_3’ (SRID 310)\n\nIn addition to BB15 from 20090519, I decided to test out BB16 from 20090519 as a positive control.\nSamples were run on Roberts Lab CFX Connect (BioRad). All samples were run in duplicate. See qPCR Report (Results section) for plate layout, cycling params, etc.\nqPCR master mix calcs (Google Sheet):\n\n20181016_qPCR_Cgigas_gDNA_primer_test\n\n\n\nResults\nqPCR Report (PDF):\n\nsam_2018-10-16 2013-42-43_BR006896.pdf\n\nqPCR File (PCRD):\n\nsam_2018-10-16 2013-42-43_BR006896.pcrd\n\nqPCR Data (CSV):\n\nsam_2018-10-16_13-42-43_BR006896_-_Quantification_Cq_Results.csv\n\nLooks like the elongation factor (EF1) primers and BB16 gDNA as a positive control are the way to go.\nIn the plots below, the black lines are BB16, the green lines are BB15, and the red lines are no template controls (NTC).\nThe amplification plots show that the EF1 primers do not amplify with BB15, but do amplify with BB16 (black lines Cq ~34). The 18s primers amplify with both BB15 & BB16 (Cq ~16 & ~18, respecitively), but produce primer dimers (red lines in amplification and melt curve plots).\n\n\nAmplification Plots\n\n\n\n\nMelt Curves"
  },
  {
    "objectID": "posts/2018/2018-09-11-trimgalorefastqcmultiqc-c-virginica-oil-spill-mbdseq-concatenated-sequences/index.html",
    "href": "posts/2018/2018-09-11-trimgalorefastqcmultiqc-c-virginica-oil-spill-mbdseq-concatenated-sequences/index.html",
    "title": "TrimGalore/FastQC/MultiQC - C.virginica Oil Spill MBDseq Concatenated Sequences",
    "section": "",
    "text": "Previously concatenated and analyzed our Crassostrea virginica oil spill MBDseq data with FastQC.\nWe decided to try improving things by running them through TrimGalore! to remove adapters and poor quality sequences.\nProcessed the samples on Roadrunner (Apple Xserve; Ubuntu 16.04) using default TrimGalore! settings.\nAfter trimming, TrimGalore! output was summarized using MultiQC. Trimmed FastQ files were then analyzed with FastQC and followed up with MultiQC.\nDocumented in Jupyter Notebook (see below).\nJupyter Notebook (GitHub):\n\n20180911_roadrunner_virginica_trimgalore.ipynb\n\n\n\nRESULTS\nTrimGalore! output folder:\n\n20180911_virginica_oil_trimgalore_01/\n\nTrimGalore! MultiQC report (HTML):\n\n20180911_virginica_oil_trimgalore_01/multiqc_report.html\n\nTrimGalore! FastQC output folder:\n\n20180911_virginica_oil_trimgalore_01/20180911_virginica_oil_trimmed_fastqc/\n\nFastQC MultiQC report (HTML:\n\n20180911_virginica_oil_trimgalore_01/20180911_virginica_oil_trimmed_fastqc/multiqc_report.html\n\nOverall, things look a bit better, but there are still some issues. Will likely eliminate sample 2112_lane_1_TGACCA from analysis and apply some additional sequence filtering, based on sequence length.\n\n\nSEQUENCE CONTENT PLOT\n\n\n\n\nSHORT SEQUENCE CONTAMINATION"
  },
  {
    "objectID": "posts/2018/2018-05-09-read-mapping-mapping-illumina-data-to-geoduck-genome-assemblies-with-bowtie2/index.html",
    "href": "posts/2018/2018-05-09-read-mapping-mapping-illumina-data-to-geoduck-genome-assemblies-with-bowtie2/index.html",
    "title": "Read Mapping - Mapping Illumina Data to Geoduck Genome Assemblies with Bowtie2",
    "section": "",
    "text": "We have an upcoming meeting with Illumina to discuss how the geoduck genome project is coming along and to decide how we want to proceed.\nSo, we wanted to get a quick idea of how well our geoduck assemblies are by performing some quick alignments using Bowtie2.\nUsed the following assemblies as references:\n\nsn_ph_01 : SuperNova assembly of 10x Genomics data\nsparse_03 : SparseAssembler assembly of BGI and Illumina project data\npga_02 : Hi-C assembly of Phase Genomics data\n\nThe analysis is documented in a Jupyter Notebook.\nJupyter Notebook (GitHub):\n\n20180508_roadrunner_geoduck_bowtie2_genome_mapping.ipynb\n\nNOTE: Due to large amount of stdout from first genome index command, the notebook does not render well on GitHub. I recommend downloading and opening notebook on a locally install version of Jupyter.\nHere’s a brief overview of the process:\n\nGenerate Bowtie2 indexes for each of the genome assemblies.\nMap 1,000,000 reads from the following Illumina NovaSeq FastQ files:\n\n\nNR013_AD013_S2_L001_R1_001_val_1_val_1.fq.gz\nNR013_AD013_S2_L001_R2_001_val_2_val_2.fq.gz\n\n\n\nResults:\nBowtie2 Genome Indexes:\n\n20180508_geoduck_assemblies_bowtie2_indexes/\n\nBowtie2 sn_ph_01 alignment folder:\n\n20180508_geoduck_mapping_nova_to_10x/\n\nBowtie2 sparse_03 alignment folder:\n\n20180508_geoduck_mapping_nova_to_sparse/\n\nBowtie2 pga_02 alignment folder:\n\n20180508_geoduck_mapping_nova_to_Hi-C/\n\n\n\n\nMAPPING SUMMARY TABLE\n_All mapping data was pulled from the respective *.err file in the Bowtie2 alignment folders._\n\n\nsequence_ID Assembler Alignment Rate (%)\n\n\n\n\n\nsn_ph_01\n\n\nSuperNova (10x)\n\n\n79.89\n\n\n\n\nsparse_03\n\n\nSparseAssembler\n\n\n85.83\n\n\n\n\npga_02\n\n\nHi-C (Phase Genomics)\n\n\n79.90|\n\n\n\n\n\nMapping efficiency is similar for all assemblies. After speaking with Steven, we’ve decided we’ll begin exploring genome annotation pipelines."
  },
  {
    "objectID": "posts/2018/2018-05-23-software-installation-repeatmasker-v4-0-7-on-emuroadrunner-continued/index.html",
    "href": "posts/2018/2018-05-23-software-installation-repeatmasker-v4-0-7-on-emuroadrunner-continued/index.html",
    "title": "Software Installation – RepeatMasker v4.0.7 on Emu/Roadrunner Continued",
    "section": "",
    "text": "After yesterday’s difficulties getting RMblast to compile, I deleted the folder and went through the build process again.\nThis time it worked, but it did not put rmblastn in the specified location (/home/shared/rmblast).\nThis fact took me a fair amount of time to figure out. Finally, after a couple of different re-builds, I ran find to see if rmblastn existed somewhere I wasn’t looking:\n\nAdditionally, I couldn’t find the location of the various BLAST executables. Some internet sleuthing led me to the NCBI page on installing BLAST+ from source, which indicates that the executables are stored in:\n<code>ncbi-blast-VERSION+-src/c++/ReleaseMT/bin/</code>\nHow intuitive! /s\nIn order to improve readability and usability of the /home/shared/ directory, I renamed the /home/shared/rmblast directory to reflect the BLAST version and created a symbolic link in that directory to the rmlbastn executable:\n\nSymbolic link to RMBLAST\n\n\n\nInitiate RepeatMasker configuration\n\n\nConfirm perl install location:\n\n\n\n\nConfirm RepeatMasker install location:\n\n\n\n\nSpecify TRF install location:\n\n\n\n\nHmmm, TRF error. Looking for file called trf:\n\n\n\n\nRenamed TRF file to trf and now it’s automatically found:\n\n\n\n\nSet RMBlast as search engine:\n\n\n\n\nSet RMBlast install location:\n\n\n\n\nSet RMBlast as default search engine:\n\n\n\n\nConfirmation of RMBlast as default search engine and successful installation of RepeatMasker:"
  },
  {
    "objectID": "posts/2018/2018-04-03-dna-isolation-quantification-geoduck-larvae-metagenome-filter-rinses-2/index.html",
    "href": "posts/2018/2018-04-03-dna-isolation-quantification-geoduck-larvae-metagenome-filter-rinses-2/index.html",
    "title": "DNA Isolation & Quantification – Geoduck larvae metagenome filter rinses",
    "section": "",
    "text": "This is another attempt to isolate DNA from two more of the geoduck hatchery metagenome samples Emma delivered on 20180313.\nThe previous attempt, using DNAzol, did not yield any DNA.\nI isolated DNA from the following two samples:\n\nMG 5/19 #4\nMG 5/26 #4\n\nI used the DNA Stool Kit (Qiagen), following the “Stool Human DNA” protocol with the following changes:\n\nIncubated @ 95oC for 5mins after initial addition of Buffer ASL. This is a lysis step that might help increase yields (see the “Stool Pathogen Detection” protocol)\nDid not add InhibitEX Tablet. Deemed unnecessary, since these weren’t stool samples.\nEluted in 50μL of Buffer AE\n\nI opted to follow the “Stool Human DNA” protocol, as it processes a larger portion of the initial sample, compared to the “Stool Pathogen Detection” protocol (600μL vs. 200μl)\nSamples were quantified using the Roberts Lab Qubit 3.0 with the Qubit High Sensitivity dsDNA Kit (Invitrogen).\n10μL of each sample were used.\n\nResults:\nNeither sample yielded any detectable DNA. Will discuss with Steven."
  },
  {
    "objectID": "posts/2018/2018-08-07-genome-annotation-olympia-oyster-genome-complete-brief-note/index.html",
    "href": "posts/2018/2018-08-07-genome-annotation-olympia-oyster-genome-complete-brief-note/index.html",
    "title": "Genome Annotation – Olympia oyster genome complete - brief note",
    "section": "",
    "text": "Whoa! Genome annotation using Jetstream/WQ-MAKER that I started this morning is complete!! Only 7hrs!\nMore detailed entry coming once I move files off of Jetstream and have a chance to look at things."
  },
  {
    "objectID": "posts/2018/2018-09-25-transcriptome-alignment-olympia-oyster-rnaseq-reads-aligned-to-genome-with-hisat2/index.html",
    "href": "posts/2018/2018-09-25-transcriptome-alignment-olympia-oyster-rnaseq-reads-aligned-to-genome-with-hisat2/index.html",
    "title": "Transcriptome Alignment – Olympia oyster RNAseq reads aligned to genome with HISAT2",
    "section": "",
    "text": "Yesterday’s attempt at producing a bedgraph was a failure and a prodcuct of a major brain fart. The worst part is that I was questioning what I was doing the entire time, but still went through with the process! Yeesh!\nThe problem was that I tried to take our Trinity-assembled transcriptome and somehow align that to our genome. This can’t work because each of those assemblies don’t know the coordinates used by the other. So, as was the case, you end up with a bedgraph that shows zero coverage for all genome contigs.\nAnyway, here’s the correct procedure!\nUsed HISAT2 on our HPC Mox node to align our RNAseq reads to our Olurida_v081 genome assembly:\n\nOlurida_v081.fa\n\nSBATCH script files:\nPERFORM GENOME INDEXING & ALIGNMENT - 20180925_oly_RNAseq_genome_hisat2.sh\nSORT & INDEX ALIGNMENT OUTPUT - 20180925_oly_RNAseq_genome_sort_bam.sh\n\n\nRESULTS\nOutput folder:\n\n20180925_oly_RNAseq_genome_hisat2/\n\nSorted BAM file (58GB):\n\n20180925_Olurida_v081.sorted.bam\n\nWill get the sorted BAM file converted to a bedgraph showing genome coverage for use in IGV."
  },
  {
    "objectID": "posts/2018/2018-05-16-data-management-illumina-novaseq-geoduck-genome-sequencing/index.html",
    "href": "posts/2018/2018-05-16-data-management-illumina-novaseq-geoduck-genome-sequencing/index.html",
    "title": "Data Management - Illumina NovaSeq Geoduck Genome Sequencing",
    "section": "",
    "text": "As part of the Illumina collaborative geoduck genome sequencing project, their end goal has always been to sequence the genome in a single run.\nThey’ve finally attempted this by running 10x Genomics, Hi-C, Nextera, and TruSeq libraries in a single run of the NovaSeq.\nI downloaded the data using the BaseSpace downloader using Chrome on a Windows 7 computer (this is not available on Ubuntu and the command line tools that are available from Illumina are too confusing for me to bother spending the time on to figure out how to use them just to download the data).\nData was saved here:\n\nnightingales/P_generosa/\n\nGenerated MD5 checksums (using md5sum on Ubuntu) and appended to the checksums file:\n\nnightingales/P_generosa/checksums.md5\n\nIllumina was unable to provide MD5 checksums on their end, so I was unable to confirm data integrity post-download.\nIllumina sample info is here:\n\n[20180403GeoDuckSamples.csv (GitHub)(https://github.com/RobertsLab/project-geoduck-genome/blob/master/docs/20180403GeoDuckSamples.csv)\n\nWill add info to:\n\n[Geoduck Genome Wiki (GitHub)(https://github.com/RobertsLab/project-geoduck-genome/wiki/Illumina-Effort)\nnightingales/P_generosa/readme.md\n[Nightingales spreadsheet (Google Sheet)(https://docs.google.com/spreadsheets/d/1_XqIOPVHSBVGscnjzDSWUeRL7HUHXfaHxVzec-I-8Xk/edit?usp=sharing)\n\nList of files received:\n10x-Genomics-Libraries-Geo10x5-A3-MultipleA_S10_L001_R1_001.fastq.gz\n10x-Genomics-Libraries-Geo10x5-A3-MultipleA_S10_L001_R2_001.fastq.gz\n10x-Genomics-Libraries-Geo10x5-A3-MultipleA_S10_L002_R1_001.fastq.gz\n10x-Genomics-Libraries-Geo10x5-A3-MultipleA_S10_L002_R2_001.fastq.gz\n10x-Genomics-Libraries-Geo10x5-A3-MultipleB_S11_L001_R1_001.fastq.gz\n10x-Genomics-Libraries-Geo10x5-A3-MultipleB_S11_L001_R2_001.fastq.gz\n10x-Genomics-Libraries-Geo10x5-A3-MultipleB_S11_L002_R1_001.fastq.gz\n10x-Genomics-Libraries-Geo10x5-A3-MultipleB_S11_L002_R2_001.fastq.gz\n10x-Genomics-Libraries-Geo10x5-A3-MultipleC_S12_L001_R1_001.fastq.gz\n10x-Genomics-Libraries-Geo10x5-A3-MultipleC_S12_L001_R2_001.fastq.gz\n10x-Genomics-Libraries-Geo10x5-A3-MultipleC_S12_L002_R1_001.fastq.gz\n10x-Genomics-Libraries-Geo10x5-A3-MultipleC_S12_L002_R2_001.fastq.gz\n10x-Genomics-Libraries-Geo10x5-A3-MultipleD_S13_L001_R1_001.fastq.gz\n10x-Genomics-Libraries-Geo10x5-A3-MultipleD_S13_L001_R2_001.fastq.gz\n10x-Genomics-Libraries-Geo10x5-A3-MultipleD_S13_L002_R1_001.fastq.gz\n10x-Genomics-Libraries-Geo10x5-A3-MultipleD_S13_L002_R2_001.fastq.gz\n10x-Genomics-Libraries-Geo10x6-B3-MultipleA_S14_L001_R1_001.fastq.gz\n10x-Genomics-Libraries-Geo10x6-B3-MultipleA_S14_L001_R2_001.fastq.gz\n10x-Genomics-Libraries-Geo10x6-B3-MultipleA_S14_L002_R1_001.fastq.gz\n10x-Genomics-Libraries-Geo10x6-B3-MultipleA_S14_L002_R2_001.fastq.gz\n10x-Genomics-Libraries-Geo10x6-B3-MultipleB_S15_L001_R1_001.fastq.gz\n10x-Genomics-Libraries-Geo10x6-B3-MultipleB_S15_L001_R2_001.fastq.gz\n10x-Genomics-Libraries-Geo10x6-B3-MultipleB_S15_L002_R1_001.fastq.gz\n10x-Genomics-Libraries-Geo10x6-B3-MultipleB_S15_L002_R2_001.fastq.gz\n10x-Genomics-Libraries-Geo10x6-B3-MultipleC_S16_L001_R1_001.fastq.gz\n10x-Genomics-Libraries-Geo10x6-B3-MultipleC_S16_L001_R2_001.fastq.gz\n10x-Genomics-Libraries-Geo10x6-B3-MultipleC_S16_L002_R1_001.fastq.gz\n10x-Genomics-Libraries-Geo10x6-B3-MultipleC_S16_L002_R2_001.fastq.gz\n10x-Genomics-Libraries-Geo10x6-B3-MultipleD_S17_L001_R1_001.fastq.gz\n10x-Genomics-Libraries-Geo10x6-B3-MultipleD_S17_L001_R2_001.fastq.gz\n10x-Genomics-Libraries-Geo10x6-B3-MultipleD_S17_L002_R1_001.fastq.gz\n10x-Genomics-Libraries-Geo10x6-B3-MultipleD_S17_L002_R2_001.fastq.gz\nHiC-Libraries-GeoHiC-C3-N701_S18_L001_R1_001.fastq.gz\nHiC-Libraries-GeoHiC-C3-N701_S18_L001_R2_001.fastq.gz\nHiC-Libraries-GeoHiC-C3-N701_S18_L002_R1_001.fastq.gz\nHiC-Libraries-GeoHiC-C3-N701_S18_L002_R2_001.fastq.gz\nNextera-Mate-Pair-Library-GeoNMP10-B2-AD013_S7_L001_R1_001.fastq.gz\nNextera-Mate-Pair-Library-GeoNMP10-B2-AD013_S7_L001_R2_001.fastq.gz\nNextera-Mate-Pair-Library-GeoNMP10-B2-AD013_S7_L002_R1_001.fastq.gz\nNextera-Mate-Pair-Library-GeoNMP10-B2-AD013_S7_L002_R2_001.fastq.gz\nNextera-Mate-Pair-Library-GeoNMP11-C2-AD014_S8_L001_R1_001.fastq.gz\nNextera-Mate-Pair-Library-GeoNMP11-C2-AD014_S8_L001_R2_001.fastq.gz\nNextera-Mate-Pair-Library-GeoNMP11-C2-AD014_S8_L002_R1_001.fastq.gz\nNextera-Mate-Pair-Library-GeoNMP11-C2-AD014_S8_L002_R2_001.fastq.gz\nNextera-Mate-Pair-Library-GeoNMP12-D2-AD015_S9_L001_R1_001.fastq.gz\nNextera-Mate-Pair-Library-GeoNMP12-D2-AD015_S9_L001_R2_001.fastq.gz\nNextera-Mate-Pair-Library-GeoNMP12-D2-AD015_S9_L002_R1_001.fastq.gz\nNextera-Mate-Pair-Library-GeoNMP12-D2-AD015_S9_L002_R2_001.fastq.gz\nNextera-Mate-Pair-Library-GeoNMP9-A2-AD002_S6_L001_R1_001.fastq.gz\nNextera-Mate-Pair-Library-GeoNMP9-A2-AD002_S6_L001_R2_001.fastq.gz\nNextera-Mate-Pair-Library-GeoNMP9-A2-AD002_S6_L002_R1_001.fastq.gz\nNextera-Mate-Pair-Library-GeoNMP9-A2-AD002_S6_L002_R2_001.fastq.gz\nTrueseq-stranded-mRNA-libraries-GeoRNA1-A1-NR006_S1_L001_R1_001.fastq.gz\nTrueseq-stranded-mRNA-libraries-GeoRNA1-A1-NR006_S1_L001_R2_001.fastq.gz\nTrueseq-stranded-mRNA-libraries-GeoRNA1-A1-NR006_S1_L002_R1_001.fastq.gz\nTrueseq-stranded-mRNA-libraries-GeoRNA1-A1-NR006_S1_L002_R2_001.fastq.gz\nTrueseq-stranded-mRNA-libraries-GeoRNA3-C1-NR012_S2_L001_R1_001.fastq.gz\nTrueseq-stranded-mRNA-libraries-GeoRNA3-C1-NR012_S2_L001_R2_001.fastq.gz\nTrueseq-stranded-mRNA-libraries-GeoRNA3-C1-NR012_S2_L002_R1_001.fastq.gz\nTrueseq-stranded-mRNA-libraries-GeoRNA3-C1-NR012_S2_L002_R2_001.fastq.gz\nTrueseq-stranded-mRNA-libraries-GeoRNA5-E1-NR005_S3_L001_R1_001.fastq.gz\nTrueseq-stranded-mRNA-libraries-GeoRNA5-E1-NR005_S3_L001_R2_001.fastq.gz\nTrueseq-stranded-mRNA-libraries-GeoRNA5-E1-NR005_S3_L002_R1_001.fastq.gz\nTrueseq-stranded-mRNA-libraries-GeoRNA5-E1-NR005_S3_L002_R2_001.fastq.gz\nTrueseq-stranded-mRNA-libraries-GeoRNA7-G1-NR019_S4_L001_R1_001.fastq.gz\nTrueseq-stranded-mRNA-libraries-GeoRNA7-G1-NR019_S4_L001_R2_001.fastq.gz\nTrueseq-stranded-mRNA-libraries-GeoRNA7-G1-NR019_S4_L002_R1_001.fastq.gz\nTrueseq-stranded-mRNA-libraries-GeoRNA7-G1-NR019_S4_L002_R2_001.fastq.gz\nTrueseq-stranded-mRNA-libraries-GeoRNA8-H1-NR021_S5_L001_R1_001.fastq.gz\nTrueseq-stranded-mRNA-libraries-GeoRNA8-H1-NR021_S5_L001_R2_001.fastq.gz\nTrueseq-stranded-mRNA-libraries-GeoRNA8-H1-NR021_S5_L002_R1_001.fastq.gz\nTrueseq-stranded-mRNA-libraries-GeoRNA8-H1-NR021_S5_L002_R2_001.fastq.gz"
  },
  {
    "objectID": "posts/2018/2018-05-23-dna-received-sea-lice-dna-from-cris-gallardo-escarate-at-universidad-de-concepcion/index.html",
    "href": "posts/2018/2018-05-23-dna-received-sea-lice-dna-from-cris-gallardo-escarate-at-universidad-de-concepcion/index.html",
    "title": "DNA Received - Sea lice DNA from Cris Gallardo-Escarate at Universidad de Concepción",
    "section": "",
    "text": "Received Caligus tape DNA - two samples:\n\nFemale 1 .\nFemale 2 .\n\nStored in slots H4 and H5 in “Sam’s gDNA Box #2” in the FTR 213 -20oC freezer.\nGoogle Sheet: Sam’s gDNA Box #2"
  },
  {
    "objectID": "posts/2018/2018-01-11-restriction-digestion-mspi-on-crassotrea-virginica-gdna/index.html",
    "href": "posts/2018/2018-01-11-restriction-digestion-mspi-on-crassotrea-virginica-gdna/index.html",
    "title": "Restriction Digestion - MspI on Crassotrea virginica gDNA",
    "section": "",
    "text": "Digested two 1.5μg aliquots of Crassostrea virginica isolated 20171211, as part of the project we’re doing with Qiagen.\nDigestion reactions:\n\n\nComponent Volume(μL)\n\n\n\n\n\nDNA (1.5μg)\n\n\n25.7\n\n\n\n\n10x CutSmart Buffer (NEB)\n\n\n5.0\n\n\n\n\nWater\n\n\n17.3\n\n\n\n\nMspI (NEB)\n\n\n2\n\n\n\n\nTOTAL\n\n\n50\n\n\n\n\n\nMspI info:\n\nNEB R0106T (100,000U/mL; rec’d 20171214)\n\nReactions were carried out in 0.5mL snap-cap PCR tubes and incubated for 15mins @ 37oC in a PTC-200 thermalcycler (MJ Research), no heated lid.\nSamples will be subjected to a phenol:chloroform extraction for cleanup."
  },
  {
    "objectID": "posts/2018/2018-04-15-assembly-stats-quast-stats-for-geoduck-sparseassembler-job-from-20180405/index.html",
    "href": "posts/2018/2018-04-15-assembly-stats-quast-stats-for-geoduck-sparseassembler-job-from-20180405/index.html",
    "title": "Assembly Stats - Quast Stats for Geoduck SparseAssembler Job from 20180405",
    "section": "",
    "text": "The geoduck genome assembly started 20180405 completed this weekend.\nThis assembly utilized the BGI data and all of the Illumina project data (NMP and NovaSeq) with a kmer 101 setting.\nI ran Quast to gather some assembly stats, using the following command:\n<code>python /home/sam/software/quast-4.5/quast.py -t 24 /mnt/owl/Athaliana/20180405_sparseassembler_kmer101_geoduck/Contigs.txt</code>\n\nResults:\nQuast output folder: results_2018_04_15_13_45_03/\nQuast report (HTML): results_2018_04_15_13_45_03/report.html\nI’ve embedded the Quast HTML report below, but it may be easier to view by using the link above."
  },
  {
    "objectID": "posts/2018/2018-07-30-mox-over-quota-olympia-oyster-genome-annotation-progress-using-maker-2-31-10/index.html",
    "href": "posts/2018/2018-07-30-mox-over-quota-olympia-oyster-genome-annotation-progress-using-maker-2-31-10/index.html",
    "title": "Mox – Over quota: Olympia oyster genome annotation progress (using Maker 2.31.10)",
    "section": "",
    "text": "UPDATE 20180730\nPer this GitHub Issue, Steven has cleared out files.\nAdditionally, it appears that my job has just continued from where it was stuck. Very nice!\nORIGINAL POST IS BELOW\n\nWell, this is an issue. Checked in on job progress and noticed that we’ve exceeded our storage quota on Mox:\n\n\n\n\nWill have post an issue on GitHub to help get unnecessary files cleaned out. Kind of shocking that we’re using >6TB of space already…"
  },
  {
    "objectID": "posts/2018/2018-05-23-transposable-element-mapping-olympia-oyster-genome-assembly-using-repeatmasker-4-07/index.html",
    "href": "posts/2018/2018-05-23-transposable-element-mapping-olympia-oyster-genome-assembly-using-repeatmasker-4-07/index.html",
    "title": "Transposable Element Mapping - Olympia Oyster Genome Assembly using RepeatMasker 4.07",
    "section": "",
    "text": "Steven wanted transposable elements (TEs) in the Olympia oyster genome identified.\nAfter some minor struggles, I was able to get RepeatMasker installed on on both of our Apple Xserves (emu & roadrunner; running Ubuntu 16.04LTS).\nGenome used: pbjelly_sjw_01\nI ran RepeatMasker (v4.07) with RepBase-20170127 and RMBlast 2.6.0 four times:\n\nDefault settings (i.e. no species select - will use human genome).\nSpecies = Crassostrea gigas (Pacific oyster)\nSpecies = Crassostrea virginica (Eastern oyster)\nSpecies = Ostrea lurida (Olympia oyster)\n\nThe idea was to get a sense of how the analyses would differ with species specifications. However, it’s likely that the only species setting that will make any difference will be Run #2 (Crassostrea gigas).\nThe reason I say this is that RepeatMasker has a built in tool to query which species are available in the RepBase database (e.g.):\n<code>RepeatMasker-4.0.7/util/queryRepeatDatabase.pl -species \"crassostrea virginica\" -stat</code>\nHere’s a very brief overview of what that yields:\n\nCrassotrea gigas: 792 specific repeats\nCrassostrea virginica: 4 Crassostrea virginica specific repeats\nOstrea lurida: 0 Ostrea lurida specific repeats\n\nAll runs were performed on roadrunner.\nAll commands were documented in a Jupyter Notebook (GitHub):\n\n20180523_roadrunner_oly_TEs_repeatmasker.ipynb\n\n_NOTE: RepeatMasker writes the desired output files (.out, .cat.gz, and *.gff) to the same directory that the genome is located in! If you conduct multiple runs with the same genome in the same directory, it will overwrite those files, as they are named using the genome assembly filename._\n\n\nRESULTS:\n\nRUN 1 (default settings - human genome)\nOutput folder:\n\n20180523_oly_repeatmasker_pbjelly_sjw_01-01\n\nSummary table (text):\n\njelly.out.fasta.tbl\n\nOutput table (GFF):\n\njelly.out.fasta.out.gff\n\n\n\n\nSUMMARY TABLE\n<code>\n==================================================\nfile name: jelly.out.fasta          \nsequences:        696946\ntotal length: 1253001795 bp  (1172226648 bp excl N/X-runs)\nGC level:         36.51 %\nbases masked:   20002806 bp ( 1.71 %)\n==================================================\n               number of      length   percentage\n               elements*    occupied  of sequence\n--------------------------------------------------\nSINEs:            17794      1061170 bp    0.09 %\n      ALUs          363        31340 bp    0.00 %\n      MIRs         1166        92129 bp    0.01 %\n\nLINEs:             4456       888114 bp    0.08 %\n      LINE1         976       103929 bp    0.01 %\n      LINE2         813        82891 bp    0.01 %\n      L3/CR1        699        63627 bp    0.01 %\n\nLTR elements:      1187       199118 bp    0.02 %\n      ERVL          155        15828 bp    0.00 %\n      ERVL-MaLRs    200        20737 bp    0.00 %\n      ERV_classI    379        42833 bp    0.00 %\n      ERV_classII    66         6896 bp    0.00 %\n\nDNA elements:      2290       196866 bp    0.02 %\n     hAT-Charlie    190        15468 bp    0.00 %\n     TcMar-Tigger   732        37473 bp    0.00 %\n\nUnclassified:       101        12946 bp    0.00 %\n\nTotal interspersed repeats:  2358214 bp    0.20 %\n\n\nSmall RNA:         5954       433422 bp    0.04 %\n\nSatellites:         366        55705 bp    0.00 %\nSimple repeats:  310641     14322152 bp    1.22 %\nLow complexity:   47381      2844279 bp    0.24 %\n==================================================\n\n* most repeats fragmented by insertions or deletions\n  have been counted as one element\n  Runs of >=20 X/Ns in query were excluded in % calcs\n\n\nThe query species was assumed to be homo sapiens  \nRepeatMasker Combined Database: Dfam_Consensus-20170127, RepBase-20170127\n        \nrun with rmblastn version 2.6.0+\n</code>\n\n\nRUN 2 (species - Crassostrea gigas)\nOutput folder:\n\n20180523_oly_repeatmasker_pbjelly_sjw_01-02\n\nSummary table (text):\n\njelly.out.fasta.tbl\n\nOutput table (GFF):\n\njelly.out.fasta.out.gff\n\n\n\n\nSUMMARY TABLE\n<code>\n==================================================\nfile name: jelly.out.fasta          \nsequences:        696946\ntotal length: 1253001795 bp  (1172226648 bp excl N/X-runs)\nGC level:         36.51 %\nbases masked:  160759267 bp ( 13.71 %)\n==================================================\n               number of      length   percentage\n               elements*    occupied  of sequence\n--------------------------------------------------\nRetroelements       213132     69887654 bp    5.96 %\n   SINEs:             2374       311974 bp    0.03 %\n   Penelope         171792     57862186 bp    4.94 %\n   LINEs:           195605     63430615 bp    5.41 %\n    CRE/SLACS            0            0 bp    0.00 %\n     L2/CR1/Rex        731       357995 bp    0.03 %\n     R1/LOA/Jockey       0            0 bp    0.00 %\n     R2/R4/NeSL         13        11377 bp    0.00 %\n     RTE/Bov-B        8085      1948581 bp    0.17 %\n     L1/CIN4             0            0 bp    0.00 %\n   LTR elements:     15153      6145065 bp    0.52 %\n     BEL/Pao          2119       955773 bp    0.08 %\n     Ty1/Copia         101        75372 bp    0.01 %\n     Gypsy/DIRS1     11776      4815361 bp    0.41 %\n       Retroviral        0            0 bp    0.00 %\n\nDNA transposons     256292     35689117 bp    3.04 %\n   hobo-Activator    19847      2059651 bp    0.18 %\n   Tc1-IS630-Pogo    43269      6806311 bp    0.58 %\n   En-Spm                0            0 bp    0.00 %\n   MuDR-IS905            0            0 bp    0.00 %\n   PiggyBac           7935      1060296 bp    0.09 %\n   Tourist/Harbinger  9503       887332 bp    0.08 %\n   Other (Mirage,        0            0 bp    0.00 %\n    P-element, Transib)\n\nRolling-circles          0            0 bp    0.00 %\n\nUnclassified:       174943     38299211 bp    3.27 %\n\nTotal interspersed repeats:   143875982 bp   12.27 %\n\n\nSmall RNA:             280        78768 bp    0.01 %\n\nSatellites:           7383      1362194 bp    0.12 %\nSimple repeats:     278809     12982714 bp    1.11 %\nLow complexity:      44078      2622506 bp    0.22 %\n==================================================\n\n* most repeats fragmented by insertions or deletions\n  have been counted as one element\n  Runs of >=20 X/Ns in query were excluded in % calcs\n\n\nThe query species was assumed to be crassostrea gigas\nRepeatMasker Combined Database: Dfam_Consensus-20170127, RepBase-20170127\n        \nrun with rmblastn version 2.6.0+\n</code>\n\n\nRUN 3 (species - Crassostrea virginica)\nOutput folder:\n\n20180523_oly_repeatmasker_pbjelly_sjw_01-03\n\nSummary table (text):\n\njelly.out.fasta.tbl\n\nOutput table (GFF):\n\njelly.out.fasta.out.gff\n\n\n\n\nSUMMARY TABLE\n<code>\n==================================================\nfile name: jelly.out.fasta          \nsequences:        696946\ntotal length: 1253001795 bp  (1172226648 bp excl N/X-runs)\nGC level:         36.51 %\nbases masked:   39598953 bp ( 3.38 %)\n==================================================\n               number of      length   percentage\n               elements*    occupied  of sequence\n--------------------------------------------------\nRetroelements        63882     10327611 bp    0.88 %\n   SINEs:            63882     10327611 bp    0.88 %\n   Penelope              0            0 bp    0.00 %\n   LINEs:                0            0 bp    0.00 %\n    CRE/SLACS            0            0 bp    0.00 %\n     L2/CR1/Rex          0            0 bp    0.00 %\n     R1/LOA/Jockey       0            0 bp    0.00 %\n     R2/R4/NeSL          0            0 bp    0.00 %\n     RTE/Bov-B           0            0 bp    0.00 %\n     L1/CIN4             0            0 bp    0.00 %\n   LTR elements:         0            0 bp    0.00 %\n     BEL/Pao             0            0 bp    0.00 %\n     Ty1/Copia           0            0 bp    0.00 %\n     Gypsy/DIRS1         0            0 bp    0.00 %\n       Retroviral        0            0 bp    0.00 %\n\nDNA transposons       9433      2307292 bp    0.20 %\n   hobo-Activator        0            0 bp    0.00 %\n   Tc1-IS630-Pogo        0            0 bp    0.00 %\n   En-Spm                0            0 bp    0.00 %\n   MuDR-IS905            0            0 bp    0.00 %\n   PiggyBac              0            0 bp    0.00 %\n   Tourist/Harbinger     0            0 bp    0.00 %\n   Other (Mirage,        0            0 bp    0.00 %\n    P-element, Transib)\n\nRolling-circles          0            0 bp    0.00 %\n\nUnclassified:        51558      9836468 bp    0.84 %\n\nTotal interspersed repeats:    22471371 bp    1.92 %\n\n\nSmall RNA:           64164     10406776 bp    0.89 %\n\nSatellites:             10         5985 bp    0.00 %\nSimple repeats:     298612     14185090 bp    1.21 %\nLow complexity:      47510      2866522 bp    0.24 %\n==================================================\n\n* most repeats fragmented by insertions or deletions\n  have been counted as one element\n  Runs of >=20 X/Ns in query were excluded in % calcs\n\n\nThe query species was assumed to be crassostrea virginica\nRepeatMasker Combined Database: Dfam_Consensus-20170127, RepBase-20170127\n        \nrun with rmblastn version 2.6.0+\n</code>\n\n\nRUN 4 (species - Ostrea lurida)\nOutput folder:\n\n20180523_oly_repeatmasker_pbjelly_sjw_01-04\n\nSummary table (text):\n\njelly.out.fasta.tbl\n\nOutput table (GFF):\n\njelly.out.fasta.out.gff\n\n\n\n\nSUMMARY TABLE\n<code>\n==================================================\nfile name: jelly.out.fasta          \nsequences:        696946\ntotal length: 1253001795 bp  (1172226648 bp excl N/X-runs)\nGC level:         36.51 %\nbases masked:   17617763 bp ( 1.50 %)\n==================================================\n               number of      length   percentage\n               elements*    occupied  of sequence\n--------------------------------------------------\nRetroelements            0            0 bp    0.00 %\n   SINEs:                0            0 bp    0.00 %\n   Penelope              0            0 bp    0.00 %\n   LINEs:                0            0 bp    0.00 %\n    CRE/SLACS            0            0 bp    0.00 %\n     L2/CR1/Rex          0            0 bp    0.00 %\n     R1/LOA/Jockey       0            0 bp    0.00 %\n     R2/R4/NeSL          0            0 bp    0.00 %\n     RTE/Bov-B           0            0 bp    0.00 %\n     L1/CIN4             0            0 bp    0.00 %\n   LTR elements:         0            0 bp    0.00 %\n     BEL/Pao             0            0 bp    0.00 %\n     Ty1/Copia           0            0 bp    0.00 %\n     Gypsy/DIRS1         0            0 bp    0.00 %\n       Retroviral        0            0 bp    0.00 %\n\nDNA transposons          0            0 bp    0.00 %\n   hobo-Activator        0            0 bp    0.00 %\n   Tc1-IS630-Pogo        0            0 bp    0.00 %\n   En-Spm                0            0 bp    0.00 %\n   MuDR-IS905            0            0 bp    0.00 %\n   PiggyBac              0            0 bp    0.00 %\n   Tourist/Harbinger     0            0 bp    0.00 %\n   Other (Mirage,        0            0 bp    0.00 %\n    P-element, Transib)\n\nRolling-circles          0            0 bp    0.00 %\n\nUnclassified:            3          189 bp    0.00 %\n\nTotal interspersed repeats:         189 bp    0.00 %\n\n\nSmall RNA:             282        79165 bp    0.01 %\n\nSatellites:             10         5985 bp    0.00 %\nSimple repeats:     313082     14662647 bp    1.25 %\nLow complexity:      47785      2878201 bp    0.25 %\n==================================================\n\n* most repeats fragmented by insertions or deletions\n  have been counted as one element\n  Runs of >=20 X/Ns in query were excluded in % calcs\n\n\nThe query species was assumed to be ostrea lurida \nRepeatMasker Combined Database: Dfam_Consensus-20170127, RepBase-20170127\n        \nrun with rmblastn version 2.6.0+\n</code>"
  },
  {
    "objectID": "posts/2018/2018-08-08-genome-annotation-olympia-oyster-genome-annotation-results-01/index.html",
    "href": "posts/2018/2018-08-08-genome-annotation-olympia-oyster-genome-annotation-results-01/index.html",
    "title": "Genome Annotation - Olympia oyster genome annotation results #01",
    "section": "",
    "text": "Yesterday, I annotated our Olympia oyster genome using WQ-MAKER in just 7hrs!.\nSee that link for run setup and configuration.\n\n\nRESULTS\nBefore proceeding further, it should be noted that I neglected to provide Maker with a transposable elements FastA file for RepeatMasker to use.\nThe following line in the maker_opts.ctl file was originally populated with an absolute path to data I didn’t recognize, so I removed it:\n<code>repeat_protein= #provide a fasta file of transposable element proteins for RepeatRunner</code>\nI’m not entirely sure what the impacts will be on annotation, so I’ve re-run Maker with that line restored (using a relative path). You can find the results of that run here:\n\nGenome Annotation – Olympia oyster genome annotation results #02\n\nOutput folder:\n\n20180807_wqmaker_run_oly_01\n\nAnnotated genome file (GFF):\n\n[20180807_wqmaker_run_oly_01/Olurida_v081.all.gff (1GB)(https://owl.fish.washington.edu/Athaliana/20180807_wqmaker_run_oly_01/Olurida_v081.all.gff)\n\nI’d like to post a snippet of the GFF file here, but the line lengths are WAY too long and will be virtually impossible to read in this notebook. The GFF consists of listing a “parent” contig and its corresponding info (start/stop/length). Then, there are “children” of this contig that show various regions that are matched within the various databases that were queried, i.e. repeatmasker annotations for identifying repeat regions, protein2genome for full/partial protein matches, etc. Thus, a single scaffold (contig) can have dozens or hundreds of corresponding annotations!\nProbably the easiest and most logical approach from here is to start working with scaffolds that are annotated with a “protein_match”, as these have a corresponding GenBank ID. Parsing these out and then doing a join with a database of NCBI protein IDs will give us a basic annotation of “functional” portions of the genome.\nAdditionally, we should probably do some sort of comparison of this run with the follow up run where I provided the transposable elements FastA file to see what impacts the exclusion/inclusion of that info had on annotation."
  },
  {
    "objectID": "posts/2018/2018-04-23-assembly-sparseassembler-k-111-on-geoduck-sequence-data/index.html",
    "href": "posts/2018/2018-04-23-assembly-sparseassembler-k-111-on-geoduck-sequence-data/index.html",
    "title": "Assembly – SparseAssembler (k 111) on Geoduck Sequence Data",
    "section": "",
    "text": "Continuing to try to find the best kmer setting to work with SparseAssemlber after the last attempt failed due to a kmer size that was too large (k 131; which happens to be outside the max kmer size [127] for SparseAssembler), I re-ran SparseAssembler with an arbitrarily selected kmer size < 131 (picked k 111).\nThe job was run on our Mox HPC node.\n\nSlurm script: 20180423_sparse_assembler_kmer111_geoduck_slurm.sh\n\n\nResults:\nOutput folder:\n\n20180423_sparseassembler_kmer111_geoduck/\n\nSlurm output file:\n\n20180423_sparseassembler_kmer111_geoduck/slurm-164530.out\n\nThis failed with the following error message:\nError! K-mer size too large!\nWell, this is disappointing. Not entirely sure why this is the case, as it’s below the max kmer setting for SparseAssembler. However, I’m not terribly surprised, as this happened previously (only using NovaSeq data) with a kmer setting of 117.\nI’ve posted an issue on the kmergenie GitHub page; we’ll see what happens."
  },
  {
    "objectID": "posts/2018/2018-04-10-trimgalorefastqcmultiqc-14bp-trim-c-virginica-mbd-bs-seq-fastq-data/index.html",
    "href": "posts/2018/2018-04-10-trimgalorefastqcmultiqc-14bp-trim-c-virginica-mbd-bs-seq-fastq-data/index.html",
    "title": "TrimGalore/FastQC/MultiQC - 14bp Trim C.virginica MBD BS-seq FASTQ data",
    "section": "",
    "text": "Yesterday, I ran TrimGalore/FastQC/MultiQC on the Crassostrea virginica MBD BS-seq data from ZymoResearch with the default settings (i.e. “auto-trim”). There was still some variability in the first ~15bp of the reads and Steven wanted to see how a hard trim would change things.\nI ran TrimGalore (using the built-in FastQC option), with a hard trim of the first 14bp of each read and followed up with MultiQC for a summary of the FastQC reports.\nTrimGalore job script:\n\n20180410_trimgalore_trim14bp_Cvirginica_MDB.sh\n\nStandard error was redirected on the command line to this file:\n\n20180410_trimgalore_trim14bp_Cvirginica_MBD/stderr.log\n\nMD5 checksums were generated on the resulting trimmed FASTQ files:\n\n20180410_trimgalore_trim14bp_Cvirginica_MBD/checksums.md5\n\nAll data was copied to my folder on Owl.\nChecksums for FASTQ files were verified post-data transfer (data not shown).\n\nResults:\nOutput folder:\n\n20180410_trimgalore_trim14bp_Cvirginica_MBD/\n\nFastQC output folder:\n\n20180410_trimgalore_trim14bp_Cvirginica_MBD/20180410_fastqc_trimgalore_trim14bp_Cvirginica_MBD/\n\nMultiQC output folder:\n\n20180410_trimgalore_trim14bp_Cvirginica_MBD/20180410_fastqc_trimgalore_trim14bp_Cvirginica_MBD/multiqc_data/\n\nMultiQC HTML report:\n\n20180410_trimgalore_trim14bp_Cvirginica_MBD/20180410_fastqc_trimgalore_trim14bp_Cvirginica_MBD/multiqc_data/multiqc_report.html\n\nOK, this trimming definitely took care of the variability seen in the first ~15bp of all the reads.\nHowever, I noticed that the last 2bp of each of the Read 1 seqs all have some wonky stuff going on. I’m guessing I should probably trim that stuff off, too…"
  },
  {
    "objectID": "posts/2018/2018-03-16-titrations-hollies-seawater-samples/index.html",
    "href": "posts/2018/2018-03-16-titrations-hollies-seawater-samples/index.html",
    "title": "Titrations - Hollie’s Seawater Samples",
    "section": "",
    "text": "Performed total alkalinity (TA) titrations on Hollie’s samples using our T5 Excellence titrator (Mettler Toledo) and Rondolino sample changer.\nAll data is deposited in the following GitHub repo:\n\nRobertsLab/titrator\n\nSample sizes: ~50g\nLabX Titration Method:\n\nTA_titration.pdf\n\nDaily pH calibration data file:\n\n2018-03-16T10_19_31_pH_calibration_7_4_10_T303.csv\n\nDaily pH log file:\n\ndaily_calibration_log.csv\n\nTitrant batch:\n\nA10\n\nCRM Batch:\n\n168\n\nDaily CRM data file:\n\n2018-03-16T10_52_57_CRM_TA_titration_T305.csv\n\nSample data file(s):\n\n2018-03-16T12_55_28_TA_titration_T306.csv\n2018-03-16T14_58_45_TA_titration_T307.csv\n\nSee metadata file for sample info (including links to master sample info sheets):\n\nfile_metadata.csv"
  },
  {
    "objectID": "posts/2018/2018-10-15-data-received-chionoecetes-bairdi-rnaseq-fastqc-analysis/index.html",
    "href": "posts/2018/2018-10-15-data-received-chionoecetes-bairdi-rnaseq-fastqc-analysis/index.html",
    "title": "Data Received - Chionoecetes bairdi RNAseq & FastQC Analysis",
    "section": "",
    "text": "We received Grace’s 100bp PE NovaSeq (Illumian) RNAseq data from the Northwest Genomics Center today.\nData was downloaded via their Aspera browser plugin and rsynced to:\n\nOwl/nightingales/C_bairdi\n\nMD5 checksums were generated (md5sum on Ubuntu):\n\nchecksums.md5\n 321ec408ba7e0f0be1929ca44871f963 304428_S1_L001_R1_001.fastq.gz b95c69f755c9c42d9203429119d4234d 304428_S1_L001_R2_001.fastq.gz a0fd8db312057dedd480231d4d125fd3 304428_S1_L002_R1_001.fastq.gz c6e70ef7f3c8a866851a1b9453aef36a 304428_S1_L002_R2_001.fastq.gz \n\nFastQC analysis was run, followed by MultiQC.\nOutput folder (gannet/Atumefaciens):\n\n20181015_Cbairdi_fastqc/\n\nMultiQC Report (HTML):\n\n20181015_Cbairdi_fastqc/multiqc_report.html\n\nNightingales spreadsheet was updated with file info and FastQC info:\n\n[Nightingales (Google Sheet)(https://docs.google.com/spreadsheets/d/1_XqIOPVHSBVGscnjzDSWUeRL7HUHXfaHxVzec-I-8Xk/edit?usp=sharing)"
  },
  {
    "objectID": "posts/2018/2018-01-11-dna-quantification-mspi-digested-crassostrea-virginica-gdna/index.html",
    "href": "posts/2018/2018-01-11-dna-quantification-mspi-digested-crassostrea-virginica-gdna/index.html",
    "title": "DNA Quantification - MspI-digested Crassostrea virginica gDNA",
    "section": "",
    "text": "Quantified the two MspI-digested DNA samples for the Qiagen project from earlier today with the Qubit 3.0 (ThermoFisher).\nUsed the Qubit dsDNA Broad Range (BR) Kit (ThermoFisher).\nUsed 1μL of DNA from each sample (including undigested gDNA from initial isolation 20171211\nResults:\nQuantification (Google Sheet): 20180111_qubit_DNA_MspI_virginica\nYields are good and are sufficient for submission to Qiagen:\nMspI_virginica_01 - 53.4ng/μL (1335ng; 89% recovery after phenol/chloroform/EtOH precip) MspI_virginca_02 - 31.0ng/μL (775ng; ~52% recovery after phenol/chloroform/EtOH precip)"
  },
  {
    "objectID": "posts/2018/2018-10-09-rna-isolation-tanner-crab-hemolymph-pellet-in-rnalater-using-trireagent/index.html",
    "href": "posts/2018/2018-10-09-rna-isolation-tanner-crab-hemolymph-pellet-in-rnalater-using-trireagent/index.html",
    "title": "RNA Isolation - Tanner Crab Hemolymph Pellet in RNAlater using TriReagent",
    "section": "",
    "text": "I previously isolated RNA from crab hemolymp from a lyophilized sample using TriReagent and Grace recently tried isolating RNA from crab hemolyph pellet (non-lyophilized) using TriReagent. The results for her extractions weren’t so great, so I’m giving it a shot with the following samples:\n\ncrab 424\ncrab 429\ncrab 438\n\nIsolated RNA using TriReagent, according to manufacturer’s protocol:\nAdded 1mL TriReagent to each tube, vortexed to mix/dissolve solute, incubated 5mins at RT, added 200uL of chloroform, vortexed 15s to mix, incubated at RT for 5mins, centrifuged 15mins, 12,000g, 4oC, transferred aqueous phase to new tube, added 500uL isopropanol to aqueous phase, mixed, incubated at RT for 10mins, centrifuged 8mins, 12,000g, at RT, discarded supernatant, added 1mL 75% ethanol, centrifuged 5mins, 12,000g at RT, discarded supernatant and resuspended in 10uL of 0.1% DEPC-treated H2O.\nPhase separation after chloroform addition was not particularly good. Aqueous phases in sample 424 was a bit cloudy (salty?) with no defined interphase. The remaining two samples did exhibit a defined interphase and were the aqueous phases were less cloudy than sample 424, but were far from ideal.\nQuantified RNA using Roberts Lab Qubit 3.0 with the Qubit RNA high sensitivity kit. Used 5uL of each sample.\n\n\nRESULTS\nNo detectable RNA in any samples. Samples were discarded.\nAs has been the case for all samples in this project, RNA isolation methodologies have produced wildly inconsistent results."
  },
  {
    "objectID": "posts/2018/2018-09-04-dna-methylation-analysis-olympia-oyster-bsseq-methylkit-analysis/index.html",
    "href": "posts/2018/2018-09-04-dna-methylation-analysis-olympia-oyster-bsseq-methylkit-analysis/index.html",
    "title": "DNA Methylation Analysis - Olympia oyster BSseq MethylKit Analysis",
    "section": "",
    "text": "NOTE: IMPORTANT CAVEATS - READ POST BEFORE USING DATA.\n\n\nI’m posting this for posterity and to provide an overview of what (and whatnot) to do. Plus, this has a good R script for using MethylKit that can be used for subsequent analyses.\nThe goal of this analysis was to compare the methylation profiles of Olympia oysters originating from a common population (Fidalgo Bay) that were raised in two different locations (Fidalgo Bay & Oyster Bay).\nAn overview of the experiment can be viewed here:\n\nGitHub Wiki: Whole-genome-BSseq-December-2015\n\nI previously ran all of Olympia oyster DNA methylation sequencing data through the Bismark pipeline, and then processed them using the MethylKit R library.\nFirst mistake (Bismark):\n\nTrimmed FastQ files “incorrectly”.\n\nBismark provides an excellent user guide and provides a handy table on how to decide on trimming parameters, but I mistakenly trimmed these according to the recommendations for a different library preparation technique. I trimmed based on the Zymo Pico-Methyl Kit (which was used for the other group of data that I processed simultaneously), instead of the TruSeq library prep.\nSo, “incorrectly” isn’t necessarily the proper term here. The analysis can still be used, however, it’s likely that the excessive trimming results in reducing sequencing coverage, and, in turn, making the downstream analysis result in a highly conservative output. Thus, the data isn’t wrong or bad, it is just very limited.\nAnd, this leads to the second mistake (Bismark):\n\nBowtie alignment score too strict\n\nThere’s a bit of a weird “battle” between Bismark and bowtie2. Bismark uses bowtie2 for generating alignments, but bowtie2’s default cutoff score overrides Bismark’s. So, to adjust the score value, you have to explicitly add the scoring parameters to your Bismark parameters during the alignment step. I did not do this.\nAgain, it’s not wrong, per se, but leads to a significantly limited set of data in the final analysis.\nThe data were analyzed based on a minimum of:\n\n3x coverage\n25% difference in methylation\n\n\n\n\nRESULTS:\nMethylkit analysis (R project; GitHub):\n\n20180827_oly_methylkit\n\nBedGraph file (BED):\n\nOlyFbOb_3xCov_25percentDiff.bed\n\nThe analysis resulted in a total of seven (yes, 7) differentially methylated loci (DML) between the two groups. It was this result that made Steven and me revisit the initial Bismark analysis. He has done this previously (but differently) and gotten significantly greater numbers of DML.\nKnowing all of this, I will re-trim the data and adjust Bismark alignment score thresholds and then re-analyze with MethylKit.\nRegardless here’re some plots to add some visual flair to this notebook entry (these, and more, are available in the GitHub repo):\n\nCLUSTERING DENDROGRAM\n\n\n\n\nPCA PLOT"
  },
  {
    "objectID": "posts/2018/2018-05-01-assembly-stats-sparseassembler-k95-on-geoduck-sequence-data-quast-for-stats/index.html",
    "href": "posts/2018/2018-05-01-assembly-stats-sparseassembler-k95-on-geoduck-sequence-data-quast-for-stats/index.html",
    "title": "Assembly & Stats - SparseAssembler (k95) on Geoduck Sequence Data > Quast for Stats",
    "section": "",
    "text": "Had a successful assembly with SparseAssembler k101, but figured I’d just tweak the kmer setting and throw it in the queue and see how it compares; minimal effort/time needed.\nInitiatied an assembly run using SparseAssembler on our Mox HPC node on all of our geoduck genomic sequencing data:\n\nBGI HiSeq Data\nIllumina Mate Pair HiSeq Data\nIllumina NovaSeq Data\n\nKmer size set to 95.\nSlurm script: 20180423_sparse_assembler_kmer95_geoduck_slurm.sh\nAfter the run finished, I copied the files to our server (Owl) and then ran Quast on my computer to gather some assembly stats, using the following command:\n<code>\n/home/sam/software/quast-4.5/quast.py \\\n-t 24 \\\n--labels 20180423_sparse_k95 \\\n/mnt/owl/Athaliana/20180423_sparseassembler_kmer95_geoduck/Contigs.txt \\\n</code>\n\n\nResults:\nSparseAssembler output folder: 20180423_sparseassembler_kmer95_geoduck/\nSparseAsembler assembley (FastA; 15GB): 20180423_sparseassembler_kmer95_geoduck/Contigs.txt\nQuast output folder: quast_results/results_2018_05_10_15_04_07\nQuast report (HTML): quast_results/results_2018_05_10_15_04_07/report.html\nI’ve embedded the Quast HTML report below, but it may be easier to view by using the link above.\nWell, it’s remarkable how different this is than the previous SparseAssembler with k101 setting!\nThis assembly doesn’t have a single contig >50,000bp, while the previous one has four contigs over that threshold!\nDefinitely shows what a large impact the kmer setting in assembly software can have on the final assembly!"
  },
  {
    "objectID": "posts/2018/2018-04-21-data-management-geoduck-phase-genomics-hi-c-data/index.html",
    "href": "posts/2018/2018-04-21-data-management-geoduck-phase-genomics-hi-c-data/index.html",
    "title": "Data Management - Geoduck Phase Genomics Hi-C Data",
    "section": "",
    "text": "We received sequencing/assembly data from Phase Genomics.\nThe data contains two assemblies, produced on two different dates.\nAll data is here: 20180421_geoduck_hi-c\nAll FASTQ files (four files; Geoduck_HiC*.gz) were copied to Nightingales:\n\nhttps://owl.fish.washington.edu/nightingales/P_generosa/\n\nMD5 checksums were verified and appended to the Nightingales checksum file:\n\nhttps://owl.fish.washington.edu/nightingales/P_generosa/checksums.md5\n\nNightingales sequencing inventory was updated (Google Sheet):\n\nNightingales inventory\n\nThe two assemblies (and assembly stats) they provided are here:\n\n20180403 assembly (FASTA)\n\n20180403 assembly stats (TXT)\n\n20180421 assembly (FASTA)\n\n20180421 assembly stats (TXT)\n\n\nI’ve updated the project-geoduck-genome GitHub wiki with this info."
  },
  {
    "objectID": "posts/2018/2018-04-19-kmer-estimation-kmergenie-on-geoduck-sequence-data-default-settings/index.html",
    "href": "posts/2018/2018-04-19-kmer-estimation-kmergenie-on-geoduck-sequence-data-default-settings/index.html",
    "title": "Kmer Estimation - Kmergenie on Geoduck Sequence Data (default settings)",
    "section": "",
    "text": "After the last SparseAssembler assembly completed, I wanted to do another run with a different kmer size (last time was arbitrarily set at 101). However, I didn’t really know how to decide, particularly since this assembly consisted of mixed read lenghts (50bp and 100bp). So, I ran kmergenie on all of our geoduck (Panopea generosa) sequencing data in hopes of getting a kmer determination to apply to my next assembly.\nThe job was run on our Mox HPC node.\nSlurm script: 20180419_kmergenie_geoduck_slurm.sh\nInput files list (needed for kmergenie command - see Slurm script linked above): geoduck_fastq_list.txt\n\nResults:\nOutput folder: 20180419_kmergenie_geoduck/\nSlurm output file: 20180419_kmergenie_geoduck/slurm-161551.out\nKmer histograms (HTML): 20180419_kmergenie_geoduck/histograms_report.html\nScreen cap from Kmer report:\n\nThis data estimates the best kmer size for this data to be 121.\nHowever, based on the kmergenie documentation, this is likely to be inaccurate. This inaccuracy is based on the fact that our kmer graph should be concave. Our graph, instead, is only partial - we haven’t reached a kmer size where the number of kmers is decreasing.\nAs such, I’ll try re-running with a different maximum kmer settting (default max is 121)."
  },
  {
    "objectID": "posts/2018/2018-04-19-kmer-estimation-kmergenie-tweaks-on-geoduck-sequence-data/index.html",
    "href": "posts/2018/2018-04-19-kmer-estimation-kmergenie-tweaks-on-geoduck-sequence-data/index.html",
    "title": "Kmer Estimation – Kmergenie Tweaks on Geoduck Sequence Data",
    "section": "",
    "text": "Earlier today, I ran kmergenie on our all of geoduck DNA sequencing data to see what it would spit out for an ideal kmer setting, which I would then use in another assembly attempt using SparseAssembler; just to see how the assembly might change.\nThe output from that kmergenie run suggested that the ideal kmer size exceeded the default maximum (k = 121), so I decided to run kmergenie a few more times, with some slight changes.\nAll jobs were run on our Mox HPC node.\n\nRun 1\n\nDiploid\nSlurm script: 20180419_kmergenie_diploid_geoduck_slurm.sh\n\n\n\nRun 2\n\nDiploid\nk 301\nSlurm script: 20180419_kmergenie_diploid_k301_geoduck_slurm.sh\n\n\n\nResults:\nOutput folders:\n\n20180419_kmergenie_diploid_geoduck/\n20180419_kmergenie_diploid_k301_geoduck/\n\nSlurm output files:\n\n20180419_kmergenie_diploid_geoduck/slurm-162003.out\n20180419_kmergenie_diploid_k301_geoduck/slurm-162004.out\n\nKmer histogram (HTML) reports:\n\n20180419_kmergenie_diploid_geoduck/histograms_report.html\n20180419_kmergenie_diploid_k301_geoduck/histograms_report.html\n\n\n\nDiploid\n\n\n\nDiploid, k 301\n\nOkay, well, these graphs clearly show that the diploid setting is no good.\nWe should be getting a nice, smooth, concave curve.\nWill try running again, without diploid setting and just increasing the max kmer size."
  },
  {
    "objectID": "posts/2018/2018-04-11-dna-isolation-quantification-metagenomics-water-filters/index.html",
    "href": "posts/2018/2018-04-11-dna-isolation-quantification-metagenomics-water-filters/index.html",
    "title": "DNA Isolation & Quantification - Metagenomics Water Filters",
    "section": "",
    "text": "Isolated DNA from the following two filters:\n\nDNA was isolated with the DNeasy Blood & Tissue Kit (Qiagen), following a modified version of the Gram-Positive Bacteria protocol:\n\nfilters were unfolded and unceremoniously stuffed into 1.7mL snap cap tubes\ndid not perform enzymatic lysis step\nfilters were incubated with 400μL of Buffer AL and 50μL of Proteinase K (both are double the volumes listed in the kit and are necessary to fully coat the filter in a 1.7mL snap cap tube)\n56oC incubations were performed overnight\n400μL of 100% ethanol was added to each after the 56oC incubation\nsamples were eluted in 50μL of Buffer AE\nall spins were performed at 20,000g\n\nSamples were quantified with the Roberts Lab Qubit 3.0 and the Qubit 1x dsDNA HS Assay Kit.\nUsed 10μL of each sample for measurement (see Results for update).\n\nResults:\nRaw data (Google Sheet): 20180411_qubit_metagenomics_filters\n\n\nSample Concentration(ng/μL) Initial_volume(μL) Yield(ng)\n\n\n\n\n\nfilter 5/22 #7 pH8.2\n\n\n20.8\n\n\n50\n\n\n1040\n\n\n\n\nfilter 5/26 #7 pH8.2\n\n\n11.6\n\n\n50\n\n\n580\n\n\n\n\n\nNOTE: For “filter 5/22 #7 pH8.2” the initial quantification using 10μL ended up being too concentrated. Re-ran using 5μL.\nBoth samples have yielded DNA. This is, obviously, an improvement over the previous attempts to isolate DNA from ammonium bicarbonate filter rinses that Emma supplied me with.\nWill discuss with Steven and get an idea of which filters to isolate additional DNA from.\nSamples were stored Sam gDNA Box #2, positions G6 & G7. (FTR 213, #27 (small -20oC frezer)"
  },
  {
    "objectID": "posts/2018/2018-07-11-mox-password-less-ssh/index.html",
    "href": "posts/2018/2018-07-11-mox-password-less-ssh/index.html",
    "title": "Mox - Password-less SSH!",
    "section": "",
    "text": "The high performance computing (HPC) cluster (called Mox) at Univ. of Washington (UW) frustratingly requires a password when SSH-ing, even when SSH keys are in use. I have a lengthy, unintelligible password that I use for my UW account, so having to type this in any time I want to initiate a new SSH session on Mox is a painful process.\nToday, I finally got fed up with how much time I was wasting (granted, it’s minor in the grand scheme of my day) just logging in to Mox, so I spent some time figuring out how to automate password entry for a new SSH session with Mox.\nI tried to handle this using the program sshpass, but I couldn’t get it to read my password from a file - it would just hang in limbo after executing the command.\nIn the end, I came across a bash script that does this perfectly. Steps to implement this on Ubuntu 16.04 LTS:\n\nInstall expect:\n\n<code>sudo apt install expect</code>\n\nCreate following script (taken from this StackExchange solution):\n\n<code>\n#!/usr/bin/expect\n\nspawn ssh mox\nexpect \"Password:\"\nsend \"<UW_password>\\r\"\ninteract\n</code>\nNOTES:\n* I have an ~/.ssh/config file that allows me to use \"mox\" as an alias for my full SSH command\n\n\n\n* Replace  with your own UW password.\n\nChange access to script (set read, write, execute for user only):\n\n<code>chmod u=rwx,go-rwx</code>\n\nRun script from home directory (saved in home directory):\n\n<code>./mox.sh</code>\nBoom! No having to track down password, copy, and paste!"
  },
  {
    "objectID": "posts/2018/2018-08-01-bioanalyzer-tanner-crab-rna-isolated-with-rneasy-plus-mini-kit/index.html",
    "href": "posts/2018/2018-08-01-bioanalyzer-tanner-crab-rna-isolated-with-rneasy-plus-mini-kit/index.html",
    "title": "Bioanalyzer - Tanner Crab RNA Isolated with RNeasy Plus Mini Kit",
    "section": "",
    "text": "Ran the four Tanner crab RNA samples that I isolated yesterday on the Seeb Lab Bioanalyzer 2100 (Agilent) using the RNA Pico 6000 Kit.\nSamples were run following kit protocol:\n\nChip priming station in Position C with syringe clip at top position\nRNA denatured at 70C for 2mins and stored on ice.\nRNA ladder aliquot was from 20160826 by Hollie Putnam.\n\n\n\nRESULTS\nBioanalyzer data file (XAD):\n\nEukaryote Total RNA Pico_2018-08-01_11-45-07.xad\n\nELECTROPHEROGRAMS:\n\n\nGEL REPRESENATATIONS \n\nThese results look great to me. Clear, defined peaks/bands, representing ribosomal RNA.\nOddly, one sample (crab_506) appears to be shifted, relative to the other three, despite exhibiting the same peak/banding pattern. Not sure what would cause something like this; contaminants?\nRegardless, we finally have clean RNA and have a usable Bioanalyzer profile to use for reference for crab RNA.\nNOTE: The lanes marked with red on the gel representation image indicate that a ribosomal integrity number (RIN) could not be calculated. This is to be expected! The RIN is based on the expectation of two rRNA bands. The anomaly is sample crab_451 - a RIN was actually determined for that sample!\nWill likely move forward with additional RNA isolations using the RNeasy Plus Kit (Qiagen)."
  },
  {
    "objectID": "posts/2018/2018-04-05-genome-assembly-sparseassembler-geoduck-genomic-data-kmer101/index.html",
    "href": "posts/2018/2018-04-05-genome-assembly-sparseassembler-geoduck-genomic-data-kmer101/index.html",
    "title": "Genome Assembly - SparseAssembler Geoduck Genomic Data, kmer=101",
    "section": "",
    "text": "UPDATE 20180413\nAssembly complete. See end of post for data locations.\n\n\n\nUPDATE 20180410\nReceived a status update email:\n\nSLURM Job_id=156637 Name=20180405_sparse_assembler_kmer101_geo Ended, Run time 4-20:17:08, CANCELLED, ExitCode 0\n\nAfter talking to Steven, it turns out Mox was taken offline for maintenance, which killed all jobs (and access). Ugh.\nWill restart tonight once Mox is back online.\n\nOK, here we go! Initiatied an assembly run using SparseAssembler on our Mox HPC node on all of our geoduck genomic sequencing data:\n\nBGI HiSeq Data\nIllumina Mate Pair HiSeq Data\nIllumina NovaSeq Data\n\nKmer size set to 101.\nThis is 118 files of sequencing data!! Fingers crossed…\nSlurm script: 20180405_sparse_assembler_kmer101_geoduck_slurm.sh\n<code>\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=20180405_sparse_assembler_kmer101_geo\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes (We only get 1, so this is fixed)\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=30-00:00:00\n## Memory per node\n#SBATCH --mem=500G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --workdir=/gscratch/scrubbed/samwhite/20180405_sparseassembler_kmer101_geoduck\n\n/gscratch/srlab/programs/SparseAssembler/SparseAssembler \\\nLD 0 \\\nNodeCovTh 1 \\\nEdgeCovTh 0 \\\nk 101 \\\ng 15 \\\nPathCovTh 100 \\\nGS 2200000000 \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/AD002_S9_L001_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/AD002_S9_L001_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/AD002_S9_L002_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/AD002_S9_L002_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR005_S4_L001_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR005_S4_L001_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR005_S4_L002_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR005_S4_L002_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR006_S3_L001_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR006_S3_L001_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR006_S3_L002_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR006_S3_L002_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR012_S1_L001_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR012_S1_L001_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR012_S1_L002_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR012_S1_L002_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR013_AD013_S2_L001_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR013_AD013_S2_L001_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR013_AD013_S2_L002_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR013_AD013_S2_L002_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR014_AD014_S5_L001_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR014_AD014_S5_L001_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR014_AD014_S5_L002_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR014_AD014_S5_L002_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR015_AD015_S6_L001_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR015_AD015_S6_L001_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR015_AD015_S6_L002_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR015_AD015_S6_L002_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR019_S7_L001_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR019_S7_L001_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR019_S7_L002_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR019_S7_L002_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR021_S8_L001_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR021_S8_L001_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR021_S8_L002_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimgalore_geoduck_novaseq/NR021_S8_L002_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/bgi_geoduck/151114_I191_FCH3Y35BCXX_L1_wHAIPI023989-79_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/bgi_geoduck/151114_I191_FCH3Y35BCXX_L1_wHAIPI023989-79_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/bgi_geoduck/151114_I191_FCH3Y35BCXX_L2_wHAMPI023988-81_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/bgi_geoduck/151114_I191_FCH3Y35BCXX_L2_wHAMPI023988-81_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/bgi_geoduck/151122_I136_FCH3L2FBBXX_L7_wHAXPI023990-97_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/bgi_geoduck/151122_I136_FCH3L2FBBXX_L7_wHAXPI023990-97_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/bgi_geoduck/160103_I137_FCH3V5YBBXX_L3_WHPANwalDDAADWAAPEI-101_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/bgi_geoduck/160103_I137_FCH3V5YBBXX_L3_WHPANwalDDAADWAAPEI-101_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/bgi_geoduck/160103_I137_FCH3V5YBBXX_L4_WHPANwalDDAADWAAPEI-101_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/bgi_geoduck/160103_I137_FCH3V5YBBXX_L4_WHPANwalDDAADWAAPEI-101_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/bgi_geoduck/160103_I137_FCH3V5YBBXX_L5_WHPANwalDDABDLAAPEI-100_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/bgi_geoduck/160103_I137_FCH3V5YBBXX_L5_WHPANwalDDABDLAAPEI-100_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/bgi_geoduck/160103_I137_FCH3V5YBBXX_L5_WHPANwalDDACDTAAPEI-102_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/bgi_geoduck/160103_I137_FCH3V5YBBXX_L5_WHPANwalDDACDTAAPEI-102_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/bgi_geoduck/160103_I137_FCH3V5YBBXX_L6_WHPANwalDDABDLAAPEI-100_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/bgi_geoduck/160103_I137_FCH3V5YBBXX_L6_WHPANwalDDABDLAAPEI-100_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/bgi_geoduck/160103_I137_FCH3V5YBBXX_L6_WHPANwalDDACDTAAPEI-102_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/bgi_geoduck/160103_I137_FCH3V5YBBXX_L6_WHPANwalDDACDTAAPEI-102_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-1_S1_L001_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-1_S1_L001_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-2_S5_L002_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-2_S5_L002_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-2to4kb-1_S2_L001_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-2to4kb-1_S2_L001_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-2to4kb-2_S6_L002_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-2to4kb-2_S6_L002_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-2to4kb-3_S10_L003_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-2to4kb-3_S10_L003_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-2to4kb-4_S14_L004_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-2to4kb-4_S14_L004_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-2to4kb-5_S18_L005_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-2to4kb-5_S18_L005_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-2to4kb-6_S22_L006_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-2to4kb-6_S22_L006_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-2to4kb-7_S26_L007_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-2to4kb-7_S26_L007_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-2to4kb-8_S30_L008_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-2to4kb-8_S30_L008_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-3_S9_L003_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-3_S9_L003_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-4_S13_L004_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-4_S13_L004_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-5_S17_L005_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-5_S17_L005_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-5to7kb-1_S3_L001_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-5to7kb-1_S3_L001_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-5to7kb-2_S7_L002_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-5to7kb-2_S7_L002_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-5to7kb-3_S11_L003_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-5to7kb-3_S11_L003_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-5to7kb-4_S15_L004_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-5to7kb-4_S15_L004_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-5to7kb-5_S19_L005_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-5to7kb-5_S19_L005_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-5to7kb-6_S23_L006_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-5to7kb-6_S23_L006_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-5to7kb-7_S27_L007_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-5to7kb-7_S27_L007_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-5to7kb-8_S31_L008_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-5to7kb-8_S31_L008_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-6_S21_L006_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-6_S21_L006_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-7_S25_L007_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-7_S25_L007_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-8_S29_L008_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-8_S29_L008_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-8to10kb-1_S4_L001_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-8to10kb-1_S4_L001_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-8to10kb-2_S8_L002_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-8to10kb-2_S8_L002_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-8to10kb-3_S12_L003_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-8to10kb-3_S12_L003_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-8to10kb-4_S16_L004_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-8to10kb-4_S16_L004_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-8to10kb-5_S20_L005_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-8to10kb-5_S20_L005_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-8to10kb-6_S24_L006_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-8to10kb-6_S24_L006_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-8to10kb-7_S28_L007_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-8to10kb-7_S28_L007_R2_001_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-8to10kb-8_S32_L008_R1_001_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/Geoduck-NMP-gDNA-8to10kb-8_S32_L008_R2_001_val_2.fastq\n</code>\n\n\nResults:\nOutput folder: 20180405_sparseassembler_kmer101_geoduck/\nSlurm output files:\n\n20180405_sparseassembler_kmer101_geoduck/slurm-156637.out\n20180405_sparseassembler_kmer101_geoduck/slurm-158691.out\n\nSparseAssembler Assembly (FASTA): Contigs.txt\nAdded this to the GitHub wiki for our geoduck genome assemblies."
  },
  {
    "objectID": "posts/2018/2018-04-30-assembly-stats-geoduck-hi-c-assembly-comparison/index.html",
    "href": "posts/2018/2018-04-30-assembly-stats-geoduck-hi-c-assembly-comparison/index.html",
    "title": "Assembly Stats - Geoduck Hi-C Assembly Comparison",
    "section": "",
    "text": "Ran the following Quast command to compare the two geoduck assemblies provided to us by Phase Genomics:\n<code>/home/sam/software/quast-4.5/quast.py \\\n-t 24 \\\n--labels 20180403_pga,20180421_pga \\\n/mnt/owl/Athaliana/20180421_geoduck_hi-c/Results/geoduck_roberts\\ results\\ 2018-04-03\\ 11\\:05\\:41.596285/PGA_assembly.fasta \\\n/mnt/owl/Athaliana/20180421_geoduck_hi-c/Results/geoduck_roberts\\ results\\ 2018-04-21\\ 18\\:09\\:04.514704/PGA_assembly.fasta</code>\n\nResults:\nQuast Output folder: results_2018_04_30_11_16_04/\nQuast report (HTML): results_2018_04_30_11_16_04/report.html\n\nThe two assemblies are nearly identical. Interesting…"
  },
  {
    "objectID": "posts/2018/2018-10-16-rna-quantification-ronits-c-gigas-ploidydessication-rna/index.html",
    "href": "posts/2018/2018-10-16-rna-quantification-ronits-c-gigas-ploidydessication-rna/index.html",
    "title": "RNA Quantification - Ronit’s C.gigas Ploidy/Dessication RNA",
    "section": "",
    "text": "Last Friday, Ronit quantified 1:10 dilutions of the RNA I isolated on 20181003 and the RNA he finished isolating on 20181011, but two of the samples (D11-C, T10-C) were still too concentrated.\nI made 1:20 dilutions (1uL RNA in 19uL 0.1% DEPC-treated H2O) and quantified them using the Roberts Lab Qubit 3.0, with the RNA HS assay. Used 1uL of the diluted RNA.\n\n\nRESULTS\nQubit data (Google Sheet):\n\n20181016_qubit_Cgigas_RNA\n\nEverything looks good. Added final concentration values (Qubit data x 20, to account for dilution factor) to Ronit’s master sheet (Google Sheet):\n\nExposure 8/29-8/30 C.Gigas\n\nWill proceed with DNasing."
  },
  {
    "objectID": "posts/2018/2018-03-13-samples-received-geoduck-larvae-metagenome-filter-rinses/index.html",
    "href": "posts/2018/2018-03-13-samples-received-geoduck-larvae-metagenome-filter-rinses/index.html",
    "title": "Samples Received - Geoduck larvae metagenome filter rinses",
    "section": "",
    "text": "Received geoduck hatchery metagenome samples from Emma. These samples are intended for DNA isolation.\nAdmittedly, I’m a bit skeptical that we’ll be able to recover any DNA from these samples, as they had been initially stored as frozen liquid, then thawed, and “supernatant” removed. I’m concerned that the freezing step would result in cell lysis; thus the subsequent removal of “supernatant” would actually be removing the majority of cellular contents that would be released during freezing/lysis.\nHere’s the sample prep history, per Emma’s email:\n\nHi! Here are the relevant details from my lab notebook:\nFilters with bacteria to be extracted for proteomics: https://sr320.github.io/Geoduck-larvae-filters/\nEach filter was rinsed and cells sonicated:\n\n\n\n\n\nPut filter on petri dish on ice\n\n\n\n\nUse 1-4 mL total to wash front (and back if not obvious where biol material is) of filter while holding with forceps over dish - Use 2 pairs of forceps; I used 4 mL ice cold 50 mM NH4HCO3 to wash inside of filter (filters were folded in half). Washed filters returned to bags and stored at -80C.\n\n\n\n\nPut wash collected in dish in eppendorf tubes - at this point, remove the amount that will be used for metagenomics (~1/4 of wash) - put 1 mL in metagenome tube (mg) and the remaining was split between 2 tubes for metaproteomics (mp)\n\n\nThese are bacterial cells in ammonium bicarbonate. I spun them down and removed most of the supernatant from each tube.\nLet me know if you need any other info!\n\nBox of samples (containing ~38uL of liquid) were stored in FTR209 -20C (top shelf)."
  },
  {
    "objectID": "posts/2018/2018-04-11-trimgalorefastqcmultiqc-trim-10bp-53-ends-c-virginica-mbd-bs-seq-fastq-data/index.html",
    "href": "posts/2018/2018-04-11-trimgalorefastqcmultiqc-trim-10bp-53-ends-c-virginica-mbd-bs-seq-fastq-data/index.html",
    "title": "TrimGalore/FastQC/MultiQC - Trim 10bp 5’/3’ ends C.virginica MBD BS-seq FASTQ data",
    "section": "",
    "text": "Steven found out that the Bismarck documentation (Bismarck is the bisulfite aligner we use in our BS-seq pipeline) suggests trimming 10bp from both the 5’ and 3’ ends. Since this is the next step in our pipeline, we figured we should probably just follow their recommendations!\nTrimGalore job script:\n\n20180410_trimgalore_trim14bp_Cvirginica_MDB.sh\n\nStandard error was redirected on the command line to this file:\n\n20180411_trimgalore_10bp_Cvirginica_MBD/stderr.log\n\nMD5 checksums were generated on the resulting trimmed FASTQ files:\n\n20180411_trimgalore_10bp_Cvirginica_MBD/checksums.md5\n\nAll data was copied to my folder on Owl.\nChecksums for FASTQ files were verified post-data transfer (data not shown).\n\nResults:\nOutput folder:\n\n20180411_trimgalore_10bp_Cvirginica_MBD\n\nFastQC output folder:\n\n20180411_trimgalore_10bp_Cvirginica_MBD/20180411_fastqc_trim_10bp_Cvirginica_MBD\n\nMultiQC output folder:\n\n20180411_trimgalore_10bp_Cvirginica_MBD/20180411_fastqc_trim_10bp_Cvirginica_MBD/multiqc_data/\n\nMultiQC HTML report:\n\n20180411_trimgalore_10bp_Cvirginica_MBD/20180411_fastqc_trim_10bp_Cvirginica_MBD/multiqc_data/multiqc_report.html\n\nHey! Look at that! Everything is much better! Thanks for the excellent documentation and suggestions, Bismarck!"
  },
  {
    "objectID": "posts/2018/2018-02-21-novaseq-assembly-the-struggle-is-real-real-annoying/index.html",
    "href": "posts/2018/2018-02-21-novaseq-assembly-the-struggle-is-real-real-annoying/index.html",
    "title": "NovaSeq Assembly - The Struggle is Real - Real Annoying!",
    "section": "",
    "text": "Well, I continue to struggle to makek progress on assembling the geoduck Illumina NovaSeq data. Granted, there is a ton of data (374GB!!!!), but it’s still frustrating that we can’t get an assembly anywhere…\nHere are some of the struggles so far:\nMeraculous:\n\nCan’t run locally because:\n\nRan out of hard drive space - due to hardware limitations of our Apple Xserve\nFixed HDD space issue, but Roadrunner locks up and has to be restarted; no error message(s) in log files to help troubleshoot\n\nCan’t run on Mox because:\n\nCan’t figure out how to install needed dependencies that don’t already exist on Mox. More specifically, friggin’ Boost libraries! Trying to install these properly has been an issue in the past for non-Mox computers, too. I remember a few times discussing the pain of installing Boost with Sean Bennett.\n\n\nSOAPdenovo2\n\nOur Mox node can’t handle the memory requirements needed for assembly.\n\nJR-Assembler\n\nCan’t install one of the dependencies (SOAP error correction)\nActually, I need to try the binary version of this, instead of the source version (the source version fails at the make step)\n\nSo, next up will trying the following two assemblers:\n\nJR-Assembler: Will see if SOAPec binary will work, and then run an assembly.\nAllPaths-LG: I was able to install this successfully on Mox.\n\nAdditionally, we’ve ordered some additional hard drives and will be converting the old head/master node on the Apple Xserve cluster to Linux. The old master node is a little better equipped than the other Apple Xserve “birds”, so will try to re-run Meraculous on it once we get it converted."
  },
  {
    "objectID": "posts/2018/2018-10-17-reverse-transcription-ronits-c-gigas-dnased-ctenidia-rna/index.html",
    "href": "posts/2018/2018-10-17-reverse-transcription-ronits-c-gigas-dnased-ctenidia-rna/index.html",
    "title": "Reverse Transcription - Ronit’s C.gigas DNased ctenidia RNA",
    "section": "",
    "text": "Proceeded with reverse transcription of [Ronit’s DNased ctenidia RNA (from 20181016)(2018-10-16-dnase-treatment-ronits-c-gigas-ploiyddessication-ctenidia-rna.html).\nReverse transcription was performed using 100ng of each sample with M-MMLV Reverse Transcriptase from Promega.\nBriefly, 100ng of DNased RNA was combined with oligo dT primers and brought up to a final volume of 15uL. Tubes were incubated for 5mins at 70oC in a PTC-200 thermal cycler (MJ Research), using a heated lid. Samples were immediately placed on ice.\nA master mix of buffer, dNTPs, water, and M-MMLV reverse transcriptase was made, 10uL of the master mix was added to each sample, and mixed via finger flicking. Samples were incubated for 1hr at 42oC in a PTC-200 thermal cycler (MJ Research), using a heated lid, followed by a 5min incubation at 65oC.\nSamples were stored on ice for use later this afternoon by Ronit.\nSamples will be stored in Ronit’s -20oC box.\nReverse transcription calcs (Google Sheet):\n\n20181017_Cgigas_ploidy_cDNA_calcs"
  },
  {
    "objectID": "posts/2018/2018-09-17-RNA-Isolation---Lyophilized-Tanner-Crab-Hemolymph-in-RNAlater/index.html",
    "href": "posts/2018/2018-09-17-RNA-Isolation---Lyophilized-Tanner-Crab-Hemolymph-in-RNAlater/index.html",
    "title": "RNA Isolation - Lyophilized Tanner Crab Hemolymph in RNAlater",
    "section": "",
    "text": "Due to difficulties getting RNA from hemolymph samples stored in RNAlater, Grace is testing out lyophilizing samples before extraction. Who knows what impact this will have on RNA, but it’s worth a shot!\nIsolated RNA from three crab hemolymph samples preserved in RNAlater (Test 1, Test 2, Test 3) that had been lyophilized overnight last week.\nSamples were provided by Grace.\nI believe the primary purpose for this particular test was to verify that the freeze dryer was a feasible tool, since Grace experienced a minor mishap when she attempted the lyohpilization initially.\nLyophilization was successful, without any mess.\n\nTEST 3 LYOPHILIZATION\n\n\nIsolated RNA using TriReagent, according to manufacturer’s protocol:\nAdded 1mL TriReagent to each tube, vortexed to mix/dissolve solute, incubated 5mins at RT, added 200uL of chloroform, vortexed 15s to mix, incubated at RT for 5mins, centrifuged 15mins, 12,000g, 4oC, transferred aqueous phase to new tube, added 500uL isopropanol to aqueous phase, mixed, incubated at RT for 10mins, centrifuged 8mins, 12,000g, at RT, discarded supernatant, added 1mL 75% ethanol, centrifuged 5mins, 12,000g at RT, discarded supernatant and resuspended in 10uL of 0.1% DEPC-treated H2O.\nQuantified RNA using Roberts Lab Qubit 3.0 with the Qubit RNA high sensitivity kit. Used 5uL of each sample.\n\n\n\nRESULTS\nQubit (Google Sheet):\n\n20180912_qubit_RNA_lyophilized_crab_hemo\n\nOnly one sample (Test 3) had detectable levels of RNA (20.4ng/uL).\nSo, this little test demonstrates that RNA can be isolated from lyophilized samples and extracted with TriReagent. However, I have not evaluated RNA integrity on the Bioanalyzer. I think Grace has some additional samples she wanted to test this method on, so I think we’ll wait until there are more samples before we use the Bioanalyzer.\nWill give sample to Grace for -80oC storage."
  },
  {
    "objectID": "posts/2018/2018-09-18-dna-methylation-analysis-olympia-oyster-whole-genome-bsseq-bismark-pipeline-methylkit-comparison/index.html",
    "href": "posts/2018/2018-09-18-dna-methylation-analysis-olympia-oyster-whole-genome-bsseq-bismark-pipeline-methylkit-comparison/index.html",
    "title": "DNA Methylation Analysis – Olympia Oyster Whole Genome BSseq Bismark Pipeline MethylKit Comparison",
    "section": "",
    "text": "I previously ran two variations on the Bismark analysis for our Olympia oyster whole genome bisulfite sequencing data:\n\n20180913 Bismark tweaks\n\nI followed this up using the MethylKit R package to identify differentially modified loci (DML), based on differing amounts of coverage (1x, 3x, 5x, & 10x) and percent methylation differences between the two groups of oysters (25%, 50%, & 75%).\nSee the project wiki for experimental design info).\nBoth sets of analyses were documented in R Projects:\n\nDefault Bismark settings:\n\n[20180912_oly_methylkit (GitHub)(https://github.com/RobertsLab/code/tree/master/r_projects/sam/20180912_oly_methylkit)\n\n\n\n“Relaxed” Bismark settings\n\n20180913_oly_methylkit\n\n\n\n\nRESULTS\nBedGraphs (1x coverage, 25% diff in methylation):\n\nDefault Bismark settings:\n\n20180912_oly_methylkit/analyses/OlyFbOb_1x_cov_25percentDiff.bed\n\n\n\n“Relaxed” Bismark settings:\n\n20180913_oly_methylkit/analyses/OlyFbOb_1x_cov_25percentDiff.bed\n\nThe BedGraph outputs from the least stringent coverage/percent difference in methylation for both Bismark pipelines yield suprisingly low numbers of DML.\nThey yield 22 and 21 DML, respectively. Of course, more stringent BedGraphs have fewer DML, but may be more believable due to having a more robust set of data.\nInterestingly, the two analyses reveal that a single contig contains the majority of DML, all within a 1000bp range.\nWill continue to examine this data by examining Bismark BedGraphs in IGV, and running some additional MethylKit analysis looking at differentially modified regions(DMRs) to see what we can gleen from this."
  },
  {
    "objectID": "posts/2018/2018-10-15-vcf-splitting-with-bcftools/index.html",
    "href": "posts/2018/2018-10-15-vcf-splitting-with-bcftools/index.html",
    "title": "VCF Splitting with bcftools",
    "section": "",
    "text": "Steven asked for some help trying to split a VCF in to individual VCF files.\nVCF file (15GB): SNP.TRSdp5g95FnDNAmaf05.vcf.gz\nSkip to the Results section if you don’t want to read through the tials and tribulations of getting this to work.\nHere’s an overview of how I managed to get this to work and what didn’t work.\n\nInstalled bcftools, htslib, and set up the bcftools plugins\n\nFigured out the VCF file needed to be sorted, bgzipped (part of htslib), and indexed with tabix, due to the following error when initially trying to process with VCF file using bcftools:\n[W::vcf_parse] contig '' is not defined in the header. (Quick workaround: index the file with tabix.) Undefined tags in the header, cannot proceed in the sample subset mode.\nSo, I did that:\n\nSort and bgzip:\ncat SNP.TRSdp5g95FnDNAmaf05.vcf |\nawk ‘$1 ~ /^#/ {print $0;next} {print $0 | “sort -k1,1 -k2,2n”}’ |\nbgzip –threads 20 > SNP.TRSdp5g95FnDNAmaf05.sorted.vcf.gz\nIndex with tabix:\ntabix –preset vcf SNP.TRSdp5g95FnDNAmaf05.sorted.vcf.gz\n\nThis produced a separate file:\n\nSNP.TRSdp5g95FnDNAmaf05.sorted.vcf.gz.tbi.\n\nIt seems as though this file must exist in the same directory as the source VCF for it to be utilized, although no commands work directly with this index file.\nThen, tried biostars solution, but produces an error\n<code>\n#!/bin/bash\nfor file in *.vcf.gz; do\n  for sample in `bcftools query -l $file`; do\n    bcftools view -c1 -Oz -s $sample -o ${file/.vcf*/.$sample.vcf.gz} $file\n  done\ndone\n</code>\nResulting error:\n<code>[E::bcf_calc_ac] Incorrect AN/AC counts at NC_035780.1:26174</code>\nAnd empty split VCF files…\nTried tabix on unsorted bgzipped file yields this error:\n<code>[E::hts_idx_push] chromosome blocks not continuous</code>\nTried modified sort:\n<code>\ncat SNP.TRSdp5g95FnDNAmaf05.vcf | \\\nawk '$1 ~ /^#/ {print $0;next} {print $0 | \"sort -k1,1V -k2,2n\"}' | \\\nbgzip --threads 20 > SNP.TRSdp5g95FnDNAmaf05.sorted.vcf.gz\n</code>\nProduces this error:\n<code>[E::bcf_calc_ac] Incorrect AN/AC counts at NC_035780.1:26174</code>\nAnd empty split VCF files…\nChanged to new version of “view” - trying “call” instead (it seems that bcftools view is deprecated?):\n<code>\n#!/bin/bash\nfor file in *.vcf.gz; do\n  for sample in `bcftools query -l $file`; do\n    bcftools call \\\n    --consensus-caller \\\n    --output-type z \\\n    --threads 18 \\\n    --samples $sample \n    --output-file ${file/.vcf.gz/.$sample.vcf.gz} \\\n    $file\n  done\ndone\n</code>\nStill results in empty output files.\nBased off of the repeated error about AN/AC counts, tried to fill AN/AC values…\n<code>\nbcftools plugin fill-AN-AC SNP.TRSdp5g95FnDNAmaf05.sorted.vcf.gz \\\n--output-type z \\\n--threads 18 \\\n--output SNP.TRSdp5g95FnDNAmaf05.sorted.ANACfill.vcf.gz\n</code>\nAnd, ran this code:\n<code>\n#!/bin/bash\nfor file in SNP.TRSdp5g95FnDNAmaf05.sorted.ANACfill.vcf.gz; do\n  for sample in `bcftools query -l $file`; do\n    bcftools call \\\n    --consensus-caller \\\n    --output-type z \\\n    --threads 18 \\\n    --samples $sample \n    --output-file ${file/.vcf.gz/.$sample.vcf.gz} \\\n    $file\n  done\ndone\n</code>\nStill results in empty files…\nTry original code again (expanded shortened arguments to improve readability):\n<code>\n#!/bin/bash\nfor file in SNP.TRSdp5g95FnDNAmaf05.sorted.ANACfill.vcf.gz; do\n  for sample in `bcftools query -l $file`; do\n    bcftools view \\\n    --min-ac 1 \\\n    --output-type z \\\n    --samples $sample \\\n    --output-file ${file/.vcf*/.$sample.vcf.gz} \\\n    --threads 18 \\\n    $file\n  done\ndone\n</code>\nP.S. I realize the outermost for loop is not necessary, but it was faster/easier to just quickly modify the code from that Biostars solution.\n\n\nRESULTS\nThat worked! Or, at least it is producing non-empty, split VCF files! I’ll let Steven know and let him decide what impact (if any) the fill-AN-AC plugin had on the file(s)!\nBTW, running with 18 threads on my computer, this took ~30mins to split each sample into its own VCF file. However, checking performance via htop, it certainly does not appear to be using 18 threads…\nOutput folder: 20181015_vcf_split"
  },
  {
    "objectID": "posts/2018/2018-07-11-mox-olympia-oyster-genome-annotation-progress-using-maker-2-31-10/index.html",
    "href": "posts/2018/2018-07-11-mox-olympia-oyster-genome-annotation-progress-using-maker-2-31-10/index.html",
    "title": "Mox - Olympia oyster genome annotation progress (using Maker 2.31.10)",
    "section": "",
    "text": "TL;DR - It appears to be continuing where it left off!\nI decided to spend some time to figure out what was actually happening, as it’s clear that the annotation process is going to need some additional time to run and may span an additional monthly maintenance shutdown.\nThis is great, because, otherwise, this will take an eternity to actually complete (particularly because we’d have to move the job to run on one of our lab’s computers - which pale in comparison to the specs of our Mox nodes).\nHowever, it’s a bit shocking that this is taking this long, even on a Mox node!\nI started annotating the Olympia oyster genome on 20180529. Since then, the job has been interrupted twice by monthly Mox maintenance (which happens on the 2nd Tuesday of each month). Additionally, when this happens, the SLURM output file is overwritten, making it difficult to assess whether or not Maker continues where it left off or if it’s starting over from scratch.\nAnyway, here’s how I deduced that the program is continuing where it left off.\n\nI figured out that it produces a generic feature format (GFF) file for each contig.\nDecided to search for the first contig GFF and look at it’s last modified date. This would tell me if it was newly generated (i.e. on the date that the job was restarted after the maintenance shutdown) or if it was old. Additionally, if there were more than one of these files, then I’d also know that Maker was just starting at the beginning and writing data to a different location.\n\n\nThis shows:\n1. Only one copy of Contig0.gff exists.\n\n\n\n2. Last modified date is 20180530.\n\nCheck the slurm output file for info.\n\n\nThis reveals this important piece of info:\n\nMAKER WARNING: The file 20180529_oly_annotation_01.maker.output/20180529_oly_annotation_01_datastore/AC/68/Contig215522//theVoid.Contig215522/0/Contig215522.0.all.rb.out did not finish on the last run\n\nAll of these taken together lead me to confidently conclude that Maker is not restarting from the beginning and is, indeed, continuing where it left off. WHEW!\nJust for kicks, I also ran a count of GFF files to see where this stands so far:\n\nWow! 622,010 GFFs!!!\nFinally, for posterity, here’s the SLURM script I used to submit this job, back in May! I’ll have all of the corresponding genome files, proteome files, transcriptome files, etc. on one of our servers once the job completes.\n<code>\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=20180529_oly_maker_genome_annotation\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=30-00:00:00\n## Memory per node\n#SBATCH --mem=500G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --workdir=/gscratch/srlab/sam/outputs/20180529_oly_maker_genome_annotation\n\n## Establish variables for more readable code\n\n### Path to Maker executable\nmaker=/gscratch/srlab/programs/maker-2.31.10/bin/maker\n\n### Path to Olympia oyster genome FastA file\noly_genome=/gscratch/srlab/sam/data/O_lurida/oly_genome_assemblies/jelly.out.fasta\n\n### Path to Olympia oyster transcriptome FastA file\noly_transcriptome=/gscratch/srlab/sam/data/O_lurida/oly_transcriptome_assemblies/Olurida_transcriptome_v3.fasta\n\n### Path to Crassotrea gigas NCBI protein FastA\ngigas_proteome=/gscratch/srlab/sam/data/C_gigas/gigas_ncbi_protein/GCA_000297895.1_oyster_v9_protein.faa\n\n### Path to Crassostrea virginica NCBI protein FastA\nvirginica_proteome=/gscratch/srlab/sam/data/C_virginica/virginica_ncbi_protein/GCF_002022765.2_C_virginica-3.0_protein.faa\n\n## Create Maker control files needed for running Maker\n$maker -CTL\n\n## Store path to options control file\nmaker_opts_file=./maker_opts.ctl\n\n## Create combined proteome FastA file\ntouch gigas_virginica_ncbi_proteomes.fasta\ncat \"$gigas_proteome\" >> gigas_virginica_ncbi_proteomes.fasta\ncat \"$virginica_proteome\" >> gigas_virginica_ncbi_proteomes.fasta\n\n## Edit options file\n\n### Set paths to O.lurida genome and transcriptome.\n### Set path to combined C. gigas and C.virginica proteomes.\n## The use of the % symbol sets the delimiter sed uses for arguments.\n## Normally, the delimiter that most examples use is a slash \"/\".\n## But, we need to expand the variables into a full path with slashes, which screws up sed.\n## Thus, the use of % symbol instead (it could be any character that is NOT present in the expanded variable; doesn't have to be \"%\").\nsed -i \"/^genome=/ s% %$oly_genome %\" \"$maker_opts_file\"\nsed -i \"/^est=/ s% %$oly_transcriptome %\" \"$maker_opts_file\"\nsed -i \"/^protein=/ s% %$gigas_virginica_ncbi_proteomes %\" \"$maker_opts_file\"\n\n## Run Maker\n### Set basename of files and specify number of CPUs to use\n$maker \\\n-base 20180529_oly_annotation_01 \\\n-cpus 24\n</code>"
  },
  {
    "objectID": "posts/2018/2018-01-11-phenolchloroform-extractions-and-etoh-precipitations-mspi-digestions-of-c-virginica-dna-from-earlier-today/index.html",
    "href": "posts/2018/2018-01-11-phenolchloroform-extractions-and-etoh-precipitations-mspi-digestions-of-c-virginica-dna-from-earlier-today/index.html",
    "title": "Phenol:Chloroform Extractions and EtOH Precipitations - MspI Digestions of C.virginica DNA from Earlier Today",
    "section": "",
    "text": "The two MspI restriction digestions from earlier today for our project with Qiagen were subjected to phenol:chloroform cleanup and subsequent ethanol precipitations.\nPhenol:chloroform clean up procedure:\n\nAdded equal volume (50μL) of phenol:chloroform:IAA (25:24:1) to each sample.\nVortexed.\nCentrifuged 5mins, 16,000g at room temperature.\nTransferred aqueous phase (top layer) to clean 0.5mL snap-cap PCR tube.\nAdded equal volume of chloroform (50μL) to aqueous phase.\nVortexed.\nCentrifuged 5mins, 16,000g at room temperature.\nTransferred aqueous phase (top layer) to clean 0.5mL snap-cap PCR tube.\n\nPerformed ethanol precipitation on both samples according to lab protocol.\nResuspended precipitated DNA in 25μL Buffer EB (Qiagen).\nWill quantify with Qubit 3.0."
  },
  {
    "objectID": "posts/2018/2018-03-27-fastqcmultiqc-bgi-geoduck-genome-sequencing-data/index.html",
    "href": "posts/2018/2018-03-27-fastqcmultiqc-bgi-geoduck-genome-sequencing-data/index.html",
    "title": "FastQC/MultiQC - BGI Geoduck Genome Sequencing Data",
    "section": "",
    "text": "Since running SparseAssembler seems to be working and actually able to produce assemblies, I’ve decided I’ll try to beef up the geoduck genome assembly with the rest of our existing genomic sequencing data.\nI transferred our BGI geoduck FASTQ files to our Mox node (/gscratch/scrubbed/samwhite/bgi_geoduck/).\nI ran FASTQC on them to actually check them out and see if they needed any trimming, as I don’t believe this has been done!\nFASTQC slurm script: 20180327_fastqc_bgi_geoduck_slurm.sh\nSide note: Initial FASTQC failed on one file. Turns out, it got corrupted during transfer! Serves as good reminder about the importance of verifying MD5 checksums after file transfer, prior to attempting to work with files!\nThis was followed up with MultiQC (run locally from my computer on the files hosted on Owl). This was performed the following day (20180328).\n\nResults:\nFASTQC output: 20180327_bgi_fastqc\nMultiQC output: 20180328_bgi_multiqc\nMultiQC HTML report: 20180328_bgi_multiqc/multiqc_report.html\nEverything looks nice and clean! Waiting on transfer and FASTQC of Illumina NMP data before proceeding to next assembly attempt."
  },
  {
    "objectID": "posts/2018/2018-03-19-titrations-hollies-seawater-samples-2/index.html",
    "href": "posts/2018/2018-03-19-titrations-hollies-seawater-samples-2/index.html",
    "title": "Titrations - Hollie’s Seawater Samples",
    "section": "",
    "text": "Performed total alkalinity (TA) titrations on Hollie’s samples using our T5 Excellence titrator (Mettler Toledo) and Rondolino sample changer.\nAll data is deposited in the following GitHub repo:\n\nRobertsLab/titrator\n\nSample sizes: ~50g\nLabX Method:\n\nTA_titration.pdf\n\nDaily pH calibration data file:\n\n2018-03-19T08_20_01_pH_calibration_7_4_10_T319.csv\n\nDaily pH log file:\n\ndaily_calibration_log.csv\n\nTitrant batch:\n\nA10\n\nCRM Batch:\n\n168\n\nDaily CRM data file:\n\n2018-03-19T10_59_34_CRM_TA_titration_T321.csv\n\nSample data file(s):\n\n2018-03-19T13_06_12_TA_titration_T323.csv\n\nSee metadata file for sample info (including links to master samples sheets):\n\nfile_metadata.csv"
  },
  {
    "objectID": "posts/2018/2018-10-16-dnase-treatment-ronits-c-gigas-ploiyddessication-ctenidia-rna/index.html",
    "href": "posts/2018/2018-10-16-dnase-treatment-ronits-c-gigas-ploiyddessication-ctenidia-rna/index.html",
    "title": "DNase Treatment - Ronit’s C.gigas Ploiyd/Dessication Ctenidia RNA",
    "section": "",
    "text": "After quantifying Ronit’s RNA earlier today, I DNased them using the Turbo DNA-free Kit (Ambion), according to the manufacturer’s standard protocol.\nUsed 1000ng of RNA in a 50uL reaction in a 0.5mL thin-walled snap cap tube. Samples were mixed by finger flicking and then incubated 30mins @ 37oC in a PTC-200 thermal cylcer (MJ Research), without a heated lid.\nDNase inactivation was performed (0.1 volumes of inactivation reagent; 5uL), pelleted, and supe transferred to new 1.7mL snap cap tube.\nSamples were stored on ice in preparation for qPCR to test for residual gDNA.\nDNase calculations are here:\n\n20181016_DNase_calcs\n\nSamples will be permanently stored here (Google Sheet):\n\nRonit’s Ploidy/Dessication RNA Box #1 - Rack 15, Column 4, Row 4 in -80oC"
  },
  {
    "objectID": "posts/2018/2018-07-31-rna-isolation-tanner-crab-hemolymph-using-rneasy-plus-mini-kit/index.html",
    "href": "posts/2018/2018-07-31-rna-isolation-tanner-crab-hemolymph-using-rneasy-plus-mini-kit/index.html",
    "title": "RNA Isolation - Tanner Crab Hemolymph Using RNeasy Plus Mini Kit",
    "section": "",
    "text": "Tanner crab RNA has proved a bit troublesome. As such, [Steven asked me to try isolating some RNA using the RNeasy Plus Mini Kit (Qiagen)(https://github.com/RobertsLab/resources/issues/327) to see how things would turn out.\nGrace provided me with the following samples:\n\n\nCrab hemolymph had been collected (100uL?) and preserved with 1mL (?) of RNAlater. Grace pelleted the samples, removed the supernatant, and stored the pelleted material at -80C. Here’s what that looked like:\n\n\nRNA was isolated according to the manufacturer’s protocol - following guideline for samples with < 1 x 106 cells.\nOne interesting thing that happened is a precipitate formed after adding the initial buffer to the sample:\n\nA solid precipitate formed in each of the tubes that could not be dispersed - it actually looked like a small piece of paper was now present in each tube.\nSamples were spun and the supernatant was utilized (this was the normal progression of the protocol, regardless of this precipitate forming).\nSamples were eluted with 30uL of nuclease-free water.\nSamples were quantified using the Roberts Lab Qubit 3.0 with the RNA High Sensitivity asssay (Invitrogen). Used 5uL of sample for measurements.\nSamples were also assessed with the Roberts Lab NandoDrop1000. Samples were recovered from the pedestal after measurement.\nRNA was given to Grace for storage at -80C.\n\n\nRESULTS\nQubit measurements (Google Sheet): - 20180731_qubit_RNA_crab_isos\n\nNanoDrop Spec Curves:\n\n\nNanoDrop Table:\n\n\nOverall, the isolation looks pretty good. The purity looks good (NanoDrop 260/280 ratios) and the absorbance peak at 260nm is exactly where we would want/expect it to be.\nThe yields (according to the Qubit) are OK. They range from ~37ng - 350ng.\nThe important part is that this method produced clean RNA, which means the quantification is believable. I think Grace’s earlier RNA isolations using RNAzol RT had too much contamination carried over, leading to incorrect quantification measurements.\nGoing forward, I think we need to use some sort of isolation kit, however, we will be testing out good, old TriReagent as well."
  },
  {
    "objectID": "posts/2018/2018-09-04-transcriptome-assembly-geoduck-rnaseq-data/index.html",
    "href": "posts/2018/2018-09-04-transcriptome-assembly-geoduck-rnaseq-data/index.html",
    "title": "Transcriptome Assembly - Geoduck RNAseq data",
    "section": "",
    "text": "Used all of our current geoduck RNAseq data to assemble a transcriptome using Trinity.\nTrinity was run our our Mox HPC node. Specifically, I had to use just a single node with 500GB of RAM. Trinity could not run with much less than that. Initially, I attempted to run with two nodes, but our smaller node (120GB) ended up limiting the available RAM (the system only uses the RAM available on the smallest node; it cannot combine RAM or dynamically allocate computing to a node with larger RAM when needed) and Trinity consistently crashed due to memory limitations.\nReads were trimmed using the built-in version of Trimmomatic with the default settings.\nSBATCH script:\n\n20180827_geo_trinity.sh\n\nDue to the huge number of input files, I won’t post the entire script contents here. Instead, here’s a snippet of the script showing the commands used to start the Trinity run:\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=20180829_trinity\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=30-00:00:00\n## Memory per node\n#SBATCH --mem=500G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --workdir=/gscratch/scrubbed/samwhite/20180827_trinity_geoduck_RNAseq\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\ndate >> system_path.log\necho \"\" >> system_path.log\necho \"System PATH for $SLURM_JOB_ID\" >> system_path.log\necho \"\" >> system_path.log\nprintf \"%0.s-\" {1..10} >> system_path.log\necho ${PATH} | tr : \\\\n >> system_path.log\n\n\n# Run Trinity\n/gscratch/srlab/programs/trinityrnaseq-Trinity-v2.8.3/Trinity \\\n--trimmomatic \\\n--seqType fq \\\n--max_memory 500G \\\n--CPU 28 \\\nDespite the naming conventions, this job was submitted to the Mox scheduler on 20180829 and finished on 20180901.\nAfter job completion, the entire folder was gzipped (the following method of gzipping is SUPER fast, btw):\ntar -c 20180827_trinity_geoduck_RNAseq | pigz > 20180827_trinity_geoduck_RNAseq.tar.gz\n\n\nRESULTS:\nOutput folder:\n\n20180827_trinity_geoduck_RNAseq/\n\nTrinity assembly (FastA):\n\n20180827_trinity_geoduck_RNAseq/Trinity.fasta\n\nNext up, I’ll get some annotations going by running through TransDecoder and blastx."
  },
  {
    "objectID": "posts/2018/2018-03-28-fastqcmultiqc-illumina-hiseq-genome-sequencing-data/index.html",
    "href": "posts/2018/2018-03-28-fastqcmultiqc-illumina-hiseq-genome-sequencing-data/index.html",
    "title": "FastQC/MultiQC – Illumina HiSeq Genome Sequencing Data",
    "section": "",
    "text": "Since running SparseAssembler seems to be working and actually able to produce assemblies, I’ve decided I’ll try to beef up the geoduck genome assembly with the rest of our existing genomic sequencing data.\nYesterday, I transferred our BGI geoduck data to our Mox node and ran it through FASTQC\nI transferred our [Illumina HiSeq data sets (NMP.fastq.gz)(https://owl.fish.washington.edu/nightingales/P_generosa/) to our Mox node (/gscratch/scrubbed/samwhite/illumina_geoduck_hiseq). These were part of the Illumina-sponsored sequencing project.\nI verified the MD5 checksums (not documented) and then ran FASTQC, followed by MultiQC.\nFastQC slurm script: 20180328_fastqc_illumina_geoduck_hiseq_slurm.sh\nThis was followed with MultiQC (locally, after copying the the FastQC output to Owl).\n\nResults:\nFASTQC output: 20180328_illumina_hiseq_geoduck_fastqc\nMultiQC output: 20180328_illumina_hiseq_geoduck_fastqc/multiqc_data\nMultiQC HTML report: 20180328_illumina_hiseq_geoduck_fastqc/multiqc_data/multiqc_report.html\nWell, lots of fails. I high level of “Per Base N Content” (these are only warnings, but we also haven’t received data with these warnings before). Also, they all fail in the “Overrepresented sequences” analysis.\nI’ll run these through TrimGalore! (probably twice), and see how things change."
  },
  {
    "objectID": "posts/2018/2018-01-25-adapter-trimming-and-fastqc-illumina-geoduck-novaseq-data/index.html",
    "href": "posts/2018/2018-01-25-adapter-trimming-and-fastqc-illumina-geoduck-novaseq-data/index.html",
    "title": "Adapter Trimming and FASTQC - Illumina Geoduck Novaseq Data",
    "section": "",
    "text": "We would like to get an assembly of the geoduck NovaSeq data that Illumina provided us with.\nSteven previously ran the raw data through FASTQC and there was a significant amount of adapter contamination (up to 44% in some libraries) present (see his FASTQC report here).\nSo, I trimmed them using TrimGalore and re-ran FASTQC on them.\nThis required two rounds of trimming using the “auto-detect” feature of Trim Galore.\n\nRound 1: remove NovaSeq adapters\nRound 2: remove standard Illumina adapters\n\nSee Jupyter notebook below for the gritty details.\n\nResults:\nAll data for this NovaSeq assembly project can be found here: https://owl.fish.washington.edu/Athaliana/20180125_geoduck_novaseq/.\nRound 1 Trim Galore reports: [20180125_trim_galore_reports/](https://owl.fish.washington.edu/Athaliana/20180125_geoduck_novaseq/20180125_trim_galore_reports/] Round 1 FASTQC: 20180129_trimmed_multiqc_fastqc_01 Round 1 FASTQC MultiQC overview: 20180129_trimmed_multiqc_fastqc_01/multiqc_report.html\n\n\n\nRound 2 Trim Galore reports: 20180125_geoduck_novaseq/20180205_trim_galore_reports/ Round 2 FASTQC: 20180205_trimmed_fastqc_02/ Round 2 FASTQC MultiQC overview: 20180205_trimmed_multiqc_fastqc_02/multiqc_report.html\n\n\nFor the astute observer, you might notice the “Per Base Sequence Content” generates a “Fail” warning for all samples. Per the FASTQC help, this is likely expected (due to the fact that NovaSeq libraries are prepared using transposases) and doesn’t have any downstream impacts on analyses.\nJupyter Notebook (GitHub): 20180125_roadrunner_trimming_geoduck_novaseq.ipynb"
  },
  {
    "objectID": "posts/2018/2018-04-26-dna-isolation-quantification-metagenomics-water-filters-2/index.html",
    "href": "posts/2018/2018-04-26-dna-isolation-quantification-metagenomics-water-filters-2/index.html",
    "title": "DNA Isolation & Quantification - Metagenomics Water Filters",
    "section": "",
    "text": "After discussing the preliminary DNA isolation attemp with Steven & Emma, we decided to proceed with DNA isolations on the remaining 0.22μm filters.\nIsolated DNA from the following five filters:\n\nDNA was isolated with the DNeasy Blood & Tissue Kit (Qiagen), following a modified version of the Gram-Positive Bacteria protocol:\n\nfilters were unfolded and unceremoniously stuffed into 1.7mL snap cap tubes\ndid not perform enzymatic lysis step\nfilters were incubated with 400μL of Buffer AL and 50μL of Proteinase K (both are double the volumes listed in the kit and are necessary to fully coat the filter in a 1.7mL snap cap tube)\n56oC incubations were performed overnight\n400μL of 100% ethanol was added to each after the 56oC incubation\nsamples were eluted in 50μL of Buffer AE\nall spins were performed at 20,000g\n\nSamples were quantified with the Roberts Lab Qubit 3.0 and the Qubit 1x dsDNA HS Assay Kit.\nUsed 5μL of each sample for measurement (see Results for update).\n\nResults:\nRaw data (Google Sheet): 20180426_qubit_metagenomics_filters\n\n\nSample Concentration(ng/μL) Initial_volume(μL) Yield(ng)\n\n\n\n\n\nFilter #10 pH 7.1 5/15/17\n\n\n0.296\n\n\n50\n\n\n14.65\n\n\n\n\nFilter #7 pH 8.2 5/15/17\n\n\n8.44\n\n\n50\n\n\n422\n\n\n\n\nFilter #7 pH 8.2 5/1917\n\n\n2.52\n\n\n50\n\n\n126\n\n\n\n\nFilter #10 pH 7.1 5/22/17\n\n\n2.0\n\n\n50\n\n\n100\n\n\n\n\nFilter #10 pH 7.1 5/26/17\n\n\n11.9\n\n\n50\n\n\n595\n\n\n\n\n\nSamples were stored Sam gDNA Box #2, positions G8 - H3. (FTR 213, #27 (small -20oC frezer))"
  },
  {
    "objectID": "posts/2018/2018-10-03-rna-isolation-ronits-c-gigas-diploidtriploid-dessicationheat-shock-ctenidia-tissues/index.html",
    "href": "posts/2018/2018-10-03-rna-isolation-ronits-c-gigas-diploidtriploid-dessicationheat-shock-ctenidia-tissues/index.html",
    "title": "RNA Isolation - Ronit’s C.gigas diploid/triploid dessication/heat shock ctenidia tissues",
    "section": "",
    "text": "Isolated RNA from a subset of Ronit’s Crassostrea gigas ctenidia samples (see Ronit’s notebook for experiment deets):\n\nD01 C\nD02 C\nD19 C\nD20 C\nT01 C\nT02 C\nT19 C\nT20 C\n\nRNA was isolated using RNAzol RT (Molecular Research Center) in the following way:\n\nUnweighed, frozen tissue transferred to 500uL of RNAzol RT and immediately homogenized with disposable pestle.\nAdded additional 500uL of RNAzol RT and vortexed to mix.\nAdded 400uL of 0.1% DEPC-treated H2O, vortexed and incubated 15mins at RT.\nCentrifuged 12,000g for 15mins at RT.\nTransferred 750uL of supernatant to clean tube (discarded remainder), added 1 volume (750uL) of isopropanol, vortexed, and incubated at RT for 10mins.\nCentrifuged 12,000g for 10mins at RT.\nDiscarded supernatant.\nWashed pellet with 75% ethanol (made with 0.1% DEPC-treated H2O).\nCentrifuged 4,000g for 2mins at RT.\nDiscarded supernatant and repeated wash steps.\n\nPellet was resuspended in 50uL of 0.1% DEPC-treated H2O and stored @ -80oC in Ronit’s temporary box."
  },
  {
    "objectID": "posts/2018/2018-01-16-samples-submitted-c-virginica-gdna-mbd-and-mspi-to-qiagen/index.html",
    "href": "posts/2018/2018-01-16-samples-submitted-c-virginica-gdna-mbd-and-mspi-to-qiagen/index.html",
    "title": "Samples Submitted - C. virginica gDNA, MBD, and MspI to Qiagen",
    "section": "",
    "text": "Sent Crassostrea virginica samples to Qiagen, as part of the collaboration we have with them for testing their new bisulfite conversion kit on various reduced representation DNA.\nSamples were sent on dry ice via FedEx International Priority: 771231112481\nHere are the samples I sent:\ngDNA C.virginica - Genomic DNA, 20uL, 58.4ng/uL MBD 1 virginica - Fragmented (~400bp average size), MBD-enriched, 25uL, 18.3ng/uL MBD 2 virginica - Fragmented (~400bp average size), MBD-enriched, 25uL, 19.6ng/uL MspI 1 virginica - gDNA digested with MspI, 25uL, 53.4ng/uL MspI 2 virginica - gDNA digested with MspI, 25uL, 31.0ng/uL\nGenomic DNA was isolated from mantle tissue using the E.Z.N.A. Mollusc DNA Kit (Omega). DNA was eluted with the Elution Buffer supplied with the kit.\nMBD enrichment was performed using the MethylMiner Methylated DNA Enrichment Kit (Invitrogen). DNA was resuspended in Buffer EB (Qiagen).\nMspI digestions were performed using MspI (NEB) and were subjected to a phenol:chloroform cleanup, post-digestion. DNA was resuspended in Buffer EB (Qiagen).\nNo tests have been performed on the samples to evaluate the presence/absence of non-oyster DNA.\nReference genome is available here: https://www.ncbi.nlm.nih.gov/assembly/GCF_002022765.2/\nNotebook entries:\n\ngDNA Isolation:\n\n\nMBD:\n\n\nMspI Digestion:"
  },
  {
    "objectID": "posts/2018/2018-10-17-qpcr-ronits-dnased-c-gigas-ploidydessication-rna-with-elongation-factor-primers/index.html",
    "href": "posts/2018/2018-10-17-qpcr-ronits-dnased-c-gigas-ploidydessication-rna-with-elongation-factor-primers/index.html",
    "title": "qPCR - Ronit’s DNAsed C.gigas Ploidy/Dessication RNA with elongation factor primers",
    "section": "",
    "text": "After I figured out the appropriate DNA and primers to use to detect gDNA in Crassostrea gigas samples, I checked Ronit’s [DNased ctenidia RNA (from 20181016)(2018-10-16-dnase-treatment-ronits-c-gigas-ploiyddessication-ctenidia-rna.html) for residual gDNA.\nElongation factor primers:\n\nEF1_qPCR_5’ (SRID 309)\nEF1_qPCR_3’ (SRID 310)\n\nBB16 from 20090519 was used as a positive control.\nSamples were run on Roberts Lab CFX Connect (BioRad). All samples were run in duplicate. See qPCR Report (Results section) for plate layout, cycling params, etc.\nqPCR master mix calcs (Google Sheet):\n\n20181017_qPCR_Cgigas_DNased_RNA\n\n\n\nResults\nqPCR Report (PDF):\n\nsam_2018-10-17 2007-21-05_BR006896.pdf\n\nqPCR File (PCRD):\n\nsam_2018-10-17 2007-21-05_BR006896.pcrd\n\nqPCR Data (CSV):\n\nsam_2018-10-17_07-21-05_BR006896_-__Quantification_Cq_Results.csv\n\nIn the plots below, green is the positive control, blue are the samples, and red is the no template control (NTC).\nEverything looks great! Nice, clean, gDNA-free RNA! Will proceed with reverse transcription.\n\n\nAmplification Plots\n\n\n\n\nMelt Curves"
  },
  {
    "objectID": "posts/2018/2018-03-20-dna-isolation-quantification-geoduck-larvae-metagenome-filter-rinses/index.html",
    "href": "posts/2018/2018-03-20-dna-isolation-quantification-geoduck-larvae-metagenome-filter-rinses/index.html",
    "title": "DNA Isolation & Quantification - Geoduck larvae metagenome filter rinses",
    "section": "",
    "text": "Isolated DNA from two of the geoduck hatchery metagenome samples Emma delivered on 20180313 to get an idea of what type of yields we might get from these.\n\nMG 5/15 #8\nMG 5/19 #6\n\nAs mentioned in my notebook entry upon receipt of these samples, I’m a bit skeptical will get any sort of recovery, based on sample preservation.\nIsolated DNA using [DNAzol (MRC, Inc.)(https://github.com/RobertsLab/resources/blob/master/protocols/Commercial_Protocols/MRC_DNAzol_GENOMIC_DNA_ISOLATION_REAGENT.pdf) in the following manner:\n\nAdded 1mL of DNAzol to each sample; mixed by pipetting.\nAdded 0.5mL of 100% ethanol; mixed by inversion.\nPelleted DNA 5,000g x 5mins @ RT.\nDiscarded supernatants.\nWash pellets (not visible) with 1mL 75% ethanol by dribbling down side of tubes.\nPelleted DNA 5,000g x 5mins @ RT.\nDiscarded supernatants and dried pellets for 5mins.\nResuspended DNA in 20uL of Buffer EB (Qiagen).\n\nSamples were quantified using the Roberts Lab Qubit 3.0 with the Qubit High Sensitivity dsDNA Kit (Invitrogen).\n5uL of each sample were used.\n\nResults:\nAs expected, both samples did not yield any detectable DNA.\nWill discuss with Steven on what should be done with the remaining samples."
  },
  {
    "objectID": "posts/2018/2018-04-30-assembly-stats-geoduck-genome-assembly-comparisons-wquast-sparseassembler-supernova-hi-c/index.html",
    "href": "posts/2018/2018-04-30-assembly-stats-geoduck-genome-assembly-comparisons-wquast-sparseassembler-supernova-hi-c/index.html",
    "title": "Assembly Stats - Geoduck Genome Assembly Comparisons w/Quast - SparseAssembler, SuperNova, Hi-C",
    "section": "",
    "text": "Steven requested a comparison of geoduck genome assemblies.\nRan the following Quast command:\n<code>/home/sam/software/quast-4.5/quast.py \\\n-t 24 \\\n--labels 20180405_sparse_kmer101,supernova_pseudohap_duck4-p,20180421_Hi-C \\\n/mnt/owl/Athaliana/20180405_sparseassembler_kmer101_geoduck/Contigs.txt \\\n/mnt/owl//halfshell/bu-mox/analyses/0305b/duck4-p.fasta.gz \\\n/mnt/owl/Athaliana/20180419_geoduck_hi-c/Results/geoduck_roberts\\ results\\ 2018-04-21\\ 18\\:09\\:04.514704/PGA_assembly.fasta</code>\n\nResults:\nQuast output folder: results_2018_04_30_08_00_42/\nQuast report (HTML): results_2018_04_30_08_00_42/report.html\n\nThe data’s pretty interesting and cool!\nSparseAssembler has over 2x the amount of data (in bas pairs), yet produces the worst assembly.\nSuperNova and Hi-C assemblies are very close in nearly all categories. This isn’t surprising, as the SuperNova assembly was used as a reference assembly for the Hi-C assembly.\nHowever, the Hi-C assembly is insanely better than the SuperNova assembly! For example:\n\nLargest contig is ~7x larger than the SuperNova assembly.\nThe N50 size is ~243x larger than the SuperNova assembly!!\nL50 is only 18, 46x smaller than the SuperNova assembly!\n\nThis is pretty amazing, honestly. Even more amazing is that this data was sent over to us as some “preliminary” data for us to take a peak at!"
  },
  {
    "objectID": "posts/2018/2018-03-28-trimgalorefastqcmultiqc-illumina-hiseq-genome-sequencing-data/index.html",
    "href": "posts/2018/2018-03-28-trimgalorefastqcmultiqc-illumina-hiseq-genome-sequencing-data/index.html",
    "title": "TrimGalore!/FastQC/MultiQC - Illumina HiSeq Genome Sequencing Data",
    "section": "",
    "text": "Previous FastQC/MultiQC analysis of the geoduck Illumina HiSeq data (NMP.fastq.gz files) revealed a high level of overrepresented sequences, high levels of Per Base N Content, failure of Per Sequence GC Content, and a few other bad things.\nRan these through TrimGalore! on our Mox HPC node.\nAdded an option in TrimGalore! to automatically run FastQC on the trimmed output files.\nTrimGalore! slurm script: 20180328_trim_galore_illumina_geoduck_hiseq_slurm.sh\n\nResults:\nSlurm output file: slurm-153098.out\nI received a job status email on 20180330:\nSLURM Job_id=153098 Name=20180328_trim_galore_geoduck_hiseq Failed, Run time 1-17:22:47, FAILED, ExitCode 141\nThe slurm output file didn’t indicate any errors, so I restarted the job and contacted UW IT to see if I could get more info.\n\nUPDATE\nHere’s their response:\n\n04/02/2018 9:13 AM PDT - Matt\nHi Sam,\nYour job died because of a networking hiccup that caused GPFS (/gscratch filesystem and such) to expel the node from the GPFS cluster. It’s a symptom of a known ongoing network issue that we’re actively working with Lenovo/Intel/IBM. Things like this aren’t happening super frequently, but enough that we recognized something was wrong and started investigating with vendors. Unfortunately, your job was unlucky and got bitten by it.\nSo, in short, you or your job didn’t do anything wrong. If you haven’t already (and if it is possible for your use case), we would highly recommend building in some sort of periodic state-preserving behavior (and a method to “resume”) into your longer-running jobs. Jobs can unexpectedly die for any number of reasons, and it is nice not to lose days of compute progress when that happens.\n-Matt\n\nWell, okay then."
  },
  {
    "objectID": "posts/2018/2018-03-08-assembly-geoduck-novaseq-using-sparseassembler-failed/index.html",
    "href": "posts/2018/2018-03-08-assembly-geoduck-novaseq-using-sparseassembler-failed/index.html",
    "title": "Assembly - Geoduck NovaSeq using SparseAssembler (failed)",
    "section": "",
    "text": "Steven came across a [2012 paper in BMC Bioinformatics (“Exploiting sparseness in de novo genome assembly”)(https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-13-S6-S1) that utilized an assembly program we hadn’t previously encountered: SparseAssembler\nThis software is intended to greatly reduce the required amount of RAM necessary to process very large assembly data sets. As I previously learned, RAM is a limiting factor for assembly programs, and the install (if you can even call it that) was simply upacking a zip file (program installations on Mox are not trivialso this seems like it has promise!\nThe job was run on our Mox node.\nHere’s the batch script to initiate the job:\n20180308_soap_novaseq_geoduck_slurm.sh\n[code lang=text] #!/bin/bash ## Job Name #SBATCH –job-name=20180308_sparse_assembler_geo_novaseq ## Allocation Definition #SBATCH –account=srlab #SBATCH –partition=srlab ## Resources ## Nodes (We only get 1, so this is fixed) #SBATCH –nodes=1\n## Walltime (days-hours:minutes:seconds format) #SBATCH –time=30-00:00:00 ## Memory per node #SBATCH –mem=500G ##turn on e-mail notification #SBATCH –mail-type=ALL #SBATCH –mail-user=samwhite@uw.edu ## Specify the working directory for this job #SBATCH –workdir=/gscratch/scrubbed/samwhite/20180308_SparseAssembler_novaseq_geoduck\n/gscratch/srlab/programs/SparseAssembler/SparseAssembler LD 0 NodeCovTh 1 EdgeCovTh 0 k 117 g 15 PathCovTh 100 GS 2200000000 i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/AD002_S9_L001_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/AD002_S9_L001_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/AD002_S9_L002_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/AD002_S9_L002_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR005_S4_L001_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR005_S4_L001_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR005_S4_L002_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR005_S4_L002_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR006_S3_L001_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR006_S3_L001_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR006_S3_L002_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR006_S3_L002_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR012_S1_L001_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR012_S1_L001_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR012_S1_L002_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR012_S1_L002_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR013_AD013_S2_L001_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR013_AD013_S2_L001_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR013_AD013_S2_L002_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR013_AD013_S2_L002_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR014_AD014_S5_L001_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR014_AD014_S5_L001_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR014_AD014_S5_L002_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR014_AD014_S5_L002_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR015_AD015_S6_L001_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR015_AD015_S6_L001_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR015_AD015_S6_L002_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR015_AD015_S6_L002_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR019_S7_L001_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR019_S7_L001_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR019_S7_L002_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR019_S7_L002_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR021_S8_L001_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR021_S8_L001_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR021_S8_L002_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR021_S8_L002_R2_001_val_2_val_2.fastq [/code]\n\nResults\nOutput folder: 20180308_SparseAssembler_novaseq_geoduck/\nWell, this failed, but not because of memory issues (which is a good start)!\nInstead, it failed because the kmer size was too large??!!\nSee the slurm output log file:\n\nslurm-142382.out\n\nKmergenie had indicated a kmer size of 117bp.\nWill reduce kmer size and try again. Fingers crossed…"
  },
  {
    "objectID": "posts/2018/2018-02-28-hardware-upgrades-usb-3-0-pci-card-and-1tb-ssd-in-woodpecker/index.html",
    "href": "posts/2018/2018-02-28-hardware-upgrades-usb-3-0-pci-card-and-1tb-ssd-in-woodpecker/index.html",
    "title": "Hardware Upgrades - USB 3.0 PCI Card and 1TB SSD in Woodpecker",
    "section": "",
    "text": "Installed an additional 1TB SSD and a USB 3.0 PCI card in woodpecker to make it usable for MinION sequencing. An SSD and USB 3.0 ports are just a couple of the hardware requirements for using the sequencer. Woodpecker already satisfied other hardware requirements (processor, RAM, hard drive space)."
  },
  {
    "objectID": "posts/2018/2018-08-09-rna-isolation-quantificaiton-tanner-crab-hemolymph/index.html",
    "href": "posts/2018/2018-08-09-rna-isolation-quantificaiton-tanner-crab-hemolymph/index.html",
    "title": "RNA Isolation & Quantificaiton - Tanner Crab Hemolymph",
    "section": "",
    "text": "Isolated RNA from 40 Tanner crab hemolymph samples selected by Grace with the RNeasy Plus Micro Kit (Qiagen) according to the manufacturer’s protocol, with the following modifications:\n\nAdded mercaptoethanol (2-ME) to Buffer RLT Plus.\nAll spins were at 21,130g\nDid not add RNA carrier\nUsed QIAshredder columns to aid in homogenization and removal of insoluble material\nEluted with 14uL\n\nRNA was quantified using the Qubit RNA HS (high sensitivity) Assay and run on the Roberts Lab Qubit 3.0.\nUsed 1uL of sample for quantification.\nRNA was returned to the -80C box from where original samples had been stored (Rack 2, Row 3, Column 4).\n\n\nRESULTS\nQubit quantification (Google Sheet):\n\n20180809_qubit_RNA_crab\n\nOverall, the results aren’t great. Only 15 samples (out of 40) had detectable amounts of RNA. Yields from those 15 samples ranged from 40ng - 300ng, with most landing between 50 - 100ng.\nWill pass info along to Grace. Will likely meet with her and Steven to discuss plan on how to move forward."
  },
  {
    "objectID": "posts/2018/2018-03-27-titrations-hollies-seawater-samples-4/index.html",
    "href": "posts/2018/2018-03-27-titrations-hollies-seawater-samples-4/index.html",
    "title": "Titrations - Hollie’s Seawater Samples",
    "section": "",
    "text": "All data is deposited in the following GitHub repo:\n\nRobertsLab/titrator\n\nSample sizes: ~50g\nLabX Method:\n\nTA_titration.pdf\n\nDaily pH calibration data file:\n\n2018-03-27T12_28_29_pH_calibration_7_4_10_T329.csv\n\nDaily pH log file:\n\ndaily_calibration_log.csv\n\nTitrant batch:\n\nA10\n\nCRM Batch:\n\n168\n\nDaily CRM data file:\n\n2018-03-27T12_58_53_CRM_TA_titration_T342.csv\n\nSample data file(s):\n\n2018-03-27T14_59_51_TA_titration_T343.csv\n\nSee metadata file for sample info (including links to master samples sheets):\n\nfile_metadata.csv"
  },
  {
    "objectID": "posts/2018/2018-04-24-total-alkalinity-calculations-yaaminis-ocean-chemistry-samples/index.html",
    "href": "posts/2018/2018-04-24-total-alkalinity-calculations-yaaminis-ocean-chemistry-samples/index.html",
    "title": "Total Alkalinity Calculations - Yaamini’s Ocean Chemistry Samples",
    "section": "",
    "text": "I ran a subset of Yaamini’s ocean chemistry samples on our T5 Excellence titrator (Mettler Toledo) at the beginning of April. The subset were samples taken from the beginning, middle, and end of the experiment. The rationale for this was to assess whether or not total alkalinity (TA) varied across the experiment. If there was little variation, then there’d likely be no need to run all of the samples. However, should there be temporal differences, then all samples should be processed.\nData analysis was performed in the following R Project:\n\n20180424_yaamini_TA\n\nThe R Project above was initially copied from the R Project for our titrator on GitHub:\n\nhttps://github.com/RobertsLab/titrator\n\nThree separate, data-file-specific versions of the TA_calculations.R script were created and run:\n\n20180402_TA_calculation-01.R\n20180402_TA_calculation-02.R\n20180403_TA_calculation.R\n\nSalinity values (PSU) were collected from the following spreadsheet (Google Sheet) and manually entered in each of the R scripts:\n\nManchester Water Chemistry Data\n\nSpecifically, the TA calculations were performed using the seacarb library, with the at() function.\n\nResults:\n\n\nsample_names TA_values (μmol/kg)\n\n\n\n\n\nH1 A 2/20/17\n\n\n2390.88423\n\n\n\n\nH2 A 2/20/17\n\n\n2393.39207\n\n\n\n\nT1 A 2/20/17\n\n\n2367.78791\n\n\n\n\nT2 A 2/20/17\n\n\n2319.39360\n\n\n\n\nT3 A 2/20/17\n\n\n2309.88602\n\n\n\n\nT4 A 2/20/17\n\n\n2287.72108\n\n\n\n\nT5 A 2/20/17\n\n\n2336.14773\n\n\n\n\nT6 A 2/20/17\n\n\n2298.36327\n\n\n\n\nH1 A 3/20/17\n\n\n2870.73309\n\n\n\n\nH2 A 3/20/17\n\n\n2760.49972\n\n\n\n\nT1 A 3/20/17\n\n\n2930.29308\n\n\n\n\nT2 A 3/20/17\n\n\n2925.95472\n\n\n\n\nT3 A 3/20/17\n\n\n2896.55123\n\n\n\n\nT4 A 3/20/17\n\n\n2769.72514\n\n\n\n\nT5 A 3/20/17\n\n\n2743.33934\n\n\n\n\nT6 A 3/20/17\n\n\n2727.94064\n\n\n\n\nH1 A 4/4/17\n\n\n2770.20971\n\n\n\n\nH2 A 4/4/17\n\n\n2656.27437\n\n\n\n\nT1 A 4/4/17\n\n\n2801.77913\n\n\n\n\nT2 A 4/4/17\n\n\n2822.51611\n\n\n\n\nT3 A 4/4/17\n\n\n2800.87387\n\n\n\n\nT4 A 4/4/17\n\n\n2584.60933\n\n\n\n\nT5 A 4/4/17\n\n\n2645.37017\n\n\n\n\nT6 A 4/4/17\n\n\n2604.22677\n\n\n\n\n\nWell, it certainly looks like there’s some variation across the experiment. It’s likely that all remaining samples will need to be processed. Will pass along data to Yaamini for her to evaluate."
  },
  {
    "objectID": "posts/2018/2018-02-05-novaseq-assembly-trimmed-geoduck-novaseq-with-meraculous/index.html",
    "href": "posts/2018/2018-02-05-novaseq-assembly-trimmed-geoduck-novaseq-with-meraculous/index.html",
    "title": "NovaSeq Assembly - Trimmed Geoduck NovaSeq with Meraculous",
    "section": "",
    "text": "Attempted to use Meraculous to assemble the trimmed geoduck NovaSeq data.\nHere’s the [Meraculous manual (PDF)(https://1ofdmq2n8tc36m6i46scovo2e.wpengine.netdna-cdn.com/wp-content/uploads/2014/12/Manual.pdf).\nAfter a bunch of various issues (running out of hard drive space - multiple times, config file issues, typos), I’ve finally given up on running meraculous. It failed, again, saying it couldn’t find a file in a directory that meraculous created! I’ve emailed the authors and if they have an easy fix, I’ll implement it and see what happens.\nAnyway, it’s all documented in the Jupyter Notebook below.\nOne good thing came out of all of it is that I had to run kmergenie to identify an appopriate kmer size to use for assembly, as well as estimated genome size (this info is needed for both meraculous and SOAPdeNovo (which I’ll be trying next)):\nkmergenie output folder: https://owl.fish.washington.edu/Athaliana/20180125_geoduck_novaseq/20180206_kmergenie/ kmergenie HTML report (doesn’t display histograms for some reason): 20180206_kmergenie/histograms_report.html kmer size: 117 Est. genome size: 2.17Gbp\nJupyter Notebook (GitHub): 20180205_roadrunner_meraculous_geoduck_novaseq.ipynb"
  },
  {
    "objectID": "posts/2018/2018-05-08-bs-seq-mapping-olympia-oyster-bisulfite-sequencing-trimgalore-fastqc-bismark/index.html",
    "href": "posts/2018/2018-05-08-bs-seq-mapping-olympia-oyster-bisulfite-sequencing-trimgalore-fastqc-bismark/index.html",
    "title": "BS-seq Mapping - Olympia oyster bisulfite sequencing: TrimGalore > FastQC > Bismark",
    "section": "",
    "text": "Steven asked me to evaluate our methylation sequencing data sets for Olympia oyster.\nAccording to our Olympia oyster genome wiki, we have the following two sets of BS-seq data:\n\nWhole genome BS-seq (2015)\nMBD BS-seq (2015)\n\nAll computing was conducted on our Apple Xserve: emu.\nAll steps were documented in this Jupyter Notebook (GitHub): 20180503_emu_oly_methylation_mapping.ipynb\nNOTE: The Jupyter Notebook linked above is very large in size. As such it will not render on GitHub. It will need to be downloaded to a computer that can run Jupyter Notebooks and viewed that way.\nHere’s a brief overview of what was done.\nSamples were trimmed with TrimGalore and then evaluated with FastQC. MultiQC was used to generate a nice visual summary report of all samples.\nThe Olympia oyster genome assembly, pbjelly_sjw_01, was used as the reference genome and was prepared for use in Bismark:\n\n/home/shared/Bismark-0.19.1/bismark_genome_preparation \\\n--path_to_bowtie /home/shared/bowtie2-2.3.4.1-linux-x86_64/ \\\n--verbose /home/sam/data/oly_methylseq/oly_genome/ \\\n2> 20180507_bismark_genome_prep.err\n\nBismark was run on trimmed samples with the following command:\n\n/home/shared/Bismark-0.19.1/bismark \\\n--path_to_bowtie /home/shared/bowtie2-2.3.4.1-linux-x86_64/ \\\n--genome /home/sam/data/oly_methylseq/oly_genome/ \\\n-u 1000000 \\\n-p 16 \\\n--non_directional \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/1_ATCACG_L001_R1_001_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/2_CGATGT_L001_R1_001_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/3_TTAGGC_L001_R1_001_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/4_TGACCA_L001_R1_001_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/5_ACAGTG_L001_R1_001_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/6_GCCAAT_L001_R1_001_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/7_CAGATC_L001_R1_001_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/8_ACTTGA_L001_R1_001_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/zr1394_10_s456_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/zr1394_11_s456_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/zr1394_12_s456_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/zr1394_13_s456_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/zr1394_14_s456_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/zr1394_15_s456_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/zr1394_16_s456_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/zr1394_17_s456_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/zr1394_18_s456_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/zr1394_1_s456_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/zr1394_2_s456_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/zr1394_3_s456_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/zr1394_4_s456_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/zr1394_5_s456_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/zr1394_6_s456_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/zr1394_7_s456_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/zr1394_8_s456_trimmed.fq.gz \\\n/home/sam/analyses/20180503_oly_methylseq_trimgalore/zr1394_9_s456_trimmed.fq.gz \\\n2> 20180507_bismark_02.err\n\n\nResults:\nTrimGalore output folder:\n\n20180503_oly_methylseq_trimgalore\n\nFastQC output folder:\n\n20180503_oly_methylseq_trimgalore/20180503_trim_fastqc/\n\nMultiQC output folder:\n\n20180503_oly_methylseq_trimgalore/20180503_trim_fastqc/multiqc_data/\n\nMultiQC Report (HTML):\n\n20180503_oly_methylseq_trimgalore/20180503_trim_fastqc/multiqc_data/multiqc_report.html\n\nBismark genome folder: 20180503_oly_genome_pbjelly_sjw_01_bismark/\nBismark output folder:\n\n20180507_oly_methylseq_bismark\n\n\n\n\nWhole genome BS-seq (2015)\n\nPrep overview\n\nLibrary prep: Roberts Lab\nSequencing: Genewiz\n\n\n\nBismark Report Mapping Percentage\n\n\n\n\n\n1_ATCACG_L001_R1_001_trimmed_bismark_bt2_SE_report.txt\n\n\n40.3%\n\n\n\n\n2_CGATGT_L001_R1_001_trimmed_bismark_bt2_SE_report.txt\n\n\n39.9%\n\n\n\n\n3_TTAGGC_L001_R1_001_trimmed_bismark_bt2_SE_report.txt\n\n\n40.2%\n\n\n\n\n4_TGACCA_L001_R1_001_trimmed_bismark_bt2_SE_report.txt\n\n\n40.4%\n\n\n\n\n5_ACAGTG_L001_R1_001_trimmed_bismark_bt2_SE_report.txt\n\n\n39.9%\n\n\n\n\n6_GCCAAT_L001_R1_001_trimmed_bismark_bt2_SE_report.txt\n\n\n39.6%\n\n\n\n\n7_CAGATC_L001_R1_001_trimmed_bismark_bt2_SE_report.txt\n\n\n39.9%\n\n\n\n\n8_ACTTGA_L001_R1_001_trimmed_bismark_bt2_SE_report.txt\n\n\n39.7%\n\n\n\n\n\n\n\n\n\nMBD BS-seq (2015)\n\nPrep overview\n\nMBD: Roberts Lab\nLibrary prep: ZymoResearch\nSequencing: ZymoResearch\n\n\n\nBismark Report Mapping Percentage\n\n\n\n\n\nzr1394_1_s456_trimmed_bismark_bt2_SE_report.txt\n\n\n33.0%\n\n\n\n\nzr1394_2_s456_trimmed_bismark_bt2_SE_report.txt\n\n\n34.1%\n\n\n\n\nzr1394_3_s456_trimmed_bismark_bt2_SE_report.txt\n\n\n32.5%\n\n\n\n\nzr1394_4_s456_trimmed_bismark_bt2_SE_report.txt\n\n\n32.8%\n\n\n\n\nzr1394_5_s456_trimmed_bismark_bt2_SE_report.txt\n\n\n35.2%\n\n\n\n\nzr1394_6_s456_trimmed_bismark_bt2_SE_report.txt\n\n\n35.5%\n\n\n\n\nzr1394_7_s456_trimmed_bismark_bt2_SE_report.txt\n\n\n32.8%\n\n\n\n\nzr1394_8_s456_trimmed_bismark_bt2_SE_report.txt\n\n\n33.0%\n\n\n\n\nzr1394_9_s456_trimmed_bismark_bt2_SE_report.txt\n\n\n34.7%\n\n\n\n\nzr1394_10_s456_trimmed_bismark_bt2_SE_report.txt\n\n\n34.9%\n\n\n\n\nzr1394_11_s456_trimmed_bismark_bt2_SE_report.txt\n\n\n30.5%\n\n\n\n\nzr1394_12_s456_trimmed_bismark_bt2_SE_report.txt\n\n\n35.8%\n\n\n\n\nzr1394_13_s456_trimmed_bismark_bt2_SE_report.txt\n\n\n32.5%\n\n\n\n\nzr1394_14_s456_trimmed_bismark_bt2_SE_report.txt\n\n\n30.8%\n\n\n\n\nzr1394_15_s456_trimmed_bismark_bt2_SE_report.txt\n\n\n31.3%\n\n\n\n\nzr1394_16_s456_trimmed_bismark_bt2_SE_report.txt\n\n\n30.7%\n\n\n\n\nzr1394_17_s456_trimmed_bismark_bt2_SE_report.txt\n\n\n32.4%\n\n\n\n\nzr1394_18_s456_trimmed_bismark_bt2_SE_report.txt\n\n\n34.9%"
  },
  {
    "objectID": "posts/2018/2018-10-17-samples-received-crassostrea-virginica-eastern-oyster-tissue-from-lotterhos-lab-northeastern-university/index.html",
    "href": "posts/2018/2018-10-17-samples-received-crassostrea-virginica-eastern-oyster-tissue-from-lotterhos-lab-northeastern-university/index.html",
    "title": "Samples Received - Crassostrea virginica (Eastern oyster) tissue from Lotterhos Lab (Northeastern University)",
    "section": "",
    "text": "Sample sheet (Google Sheet):\n\nRoberts_2017AdultExposureSampleInfo\n\nSamples were stored in -80oC:\n\nRack 9, Column 4, Row 2"
  },
  {
    "objectID": "posts/2018/2018-10-18-qpcrs-ronits-c-gigas-ploidydessicationheat-stress-cdna-15-dilution/index.html",
    "href": "posts/2018/2018-10-18-qpcrs-ronits-c-gigas-ploidydessicationheat-stress-cdna-15-dilution/index.html",
    "title": "qPCRs - Ronit’s C.gigas ploidy/dessication/heat stress cDNA (1:5 dilution)",
    "section": "",
    "text": "IMPORTANT: The cDNA used for the qPCRs described below was a 1:5 dilution of Ronit’s cDNA made 20181017 with the following primers! Diluted cDNA was stored in his -20oC box with his original cDNA.\nThe following primers were used:\n18s\n\nCg_18s_F (SR ID: 1408)\nCg_18s_R (SR ID: 1409)\n\nEF1 (elongation factor 1)\n\nEF1_qPCR_5′ (SR ID: 309)\nEF1_qPCR_3′ (SR ID: 308)\n\nHSC70 (heat shock cognate 70)\n\nCg_hsc70_F (SR ID: 1396)\nCg_hsc70_R2 (SR ID: 1416)\n\nHSP90 (heat shock protein 90)\n\nCg_Hsp90_F (SR ID: 1532)\nCg_Hsp90_R (SR ID: 1533)\n\nDNMT1 (DNA methyltransferase 1)\n\nCg_DNMT1_F (SR ID: 1511)\nCg_DNMT1_R (SR ID: 1510)\n\nPrx6 (peroxiredoxin 6)\n\nCg_Prx6_F (SR ID: 1381)\nCg_Prx6_R (SR ID: 1382)\n\nSamples were run on Roberts Lab CFX Connect (BioRad). All samples were run in duplicate. See qPCR Report (Results section) for plate layout, cycling params, etc.\nqPCR master mix calcs (Google Sheet):\n\n20181018_qPCR_Cgigas_ploidy_cDNA\n\n\n\nRESULTS\nNo analysis here. Will analyze data and post in different notebook entry. This entry just contains the qPCR setup, resulting data, and a glimpse of how each primer performed.\nNothing is broken down based on sample ploidy or experimental conditions.\n\n18s\nqPCR Report (PDF):\n\nsam_2018-10-18 2011-28-40_BR006896_18s.pdf\n\nqPCR File (PCRD):\n\nsam_2018-10-18 2011-28-40_BR006896_18s.pcrd\n\nqPCR Data (CSV):\n\nsam_2018-10-18_11-28-40_BR006896_-__Quantification_Cq_Results_18s.csv\n\n\n\nAmplication Plots\n\n\n\nMelt Curves\n\n\n\n\nDNMT1\nqPCR Report (PDF):\n\nsam_2018-10-18 2010-03-33_BR006896_DNMT1.pdf\n\nqPCR File (PCRD):\n\nsam_2018-10-18 2010-03-33_BR006896_DNMT1.pcrd\n\nqPCR Data (CSV):\n\nsam_2018-10-18 2010-03-33_BR006896_DNMT1.pcrd\n\n\n\nAmplication Plots\n\n\n\nMelt Curves\n\n\n\n\nEF1\nqPCR Report (PDF):\n\nsam_2018-10-18 2008-20-51_BR006896_EF1.pdf\n\nqPCR File (PCRD):\n\nsam_2018-10-18 2008-20-51_BR006896_EF1.pcrd\n\nqPCR Data (CSV):\n\nsam_2018-10-18_08-20-51_BR006896_-__Quantification_Cq_Results_EF1.csv\n\n\n\nAmplication Plots - Manual Threshold (Linear)\n\n\n\nAmplication Plots - Manual Threshold (Log)\n\n\n\nAmplication Plots - Automatic Threshold (Linear)\n\n\n\nAmplication Plots - Automatic Threshold (Log)\n\n\n\nMelt Curves\n\n\n\n\nHSC70\nqPCR Report (PDF):\n\nsam_2018-10-18 2011-28-40_BR006896_HSC70.pdf\n\nqPCR File (PCRD):\n\nsam_2018-10-18 2011-28-40_BR006896_HSC70.pcrd\n\nqPCR Data (CSV):\n\nsam_2018-10-18_11-28-40_BR006896_18s_-__Quantification_Cq_Results_HSC70.csv\n\n\n\nAmplication Plots\n\n\n\nMelt Curves\n\n\n\n\nHSP90\nqPCR Report (PDF):\n\ncfx_connect_data/sam_2018-10-18 2008-20-51_BR006896_HSP90.pdf\n\nqPCR File (PCRD):\n\ncfx_connect_data/sam_2018-10-18 2008-20-51_BR006896_HSP90.pcrd\n\nqPCR Data (CSV):\n\nsam_2018-10-18_08-20-51_BR006896_-__Quantification_Cq_Results_HSP90.csv\n\n\n\nAmplication Plots\n\n\n\nMelt Curves\n\n\n\n\nPrx6\nqPCR Report (PDF):\n\nsam_2018-10-18 2010-03-33_BR006896_Prx6.pcrd\n\nqPCR File (PCRD):\n\nsam_2018-10-18 2010-03-33_BR006896_Prx6.pcrd\n\nqPCR Data (CSV):\n\nsam_2018-10-18_10-03-33_BR006896_-__Quantification_Cq_Results_Prx6.csv\n\n\n\nAmplication Plots\n\n\n\nMelt Curves"
  },
  {
    "objectID": "posts/2018/2018-02-28-samples-received-triploid-crassostrea-gigas-from-nisbet-oyster-company/index.html",
    "href": "posts/2018/2018-02-28-samples-received-triploid-crassostrea-gigas-from-nisbet-oyster-company/index.html",
    "title": "Samples Received - Triploid Crassostrea gigas from Nisbet Oyster Company",
    "section": "",
    "text": "Received a bag of Pacific oysters from Nisbet Oyster Company.\nFour oysters were shucked and the following tissues were collected from each:\n\nctenidia\ngonad\nmantle\nmuscle\n\nUtensils were cleaned and sterilized in a 10% bleach solution between oysters.\nTissues were stored briefly on wet ice and then stored at -80C in Rack 2, Column 3, Row 1"
  },
  {
    "objectID": "posts/2018/2018-01-22-software-install-10x-genomics-supernova-on-mox-hyak/index.html",
    "href": "posts/2018/2018-01-22-software-install-10x-genomics-supernova-on-mox-hyak/index.html",
    "title": "Software Install - 10x Genomics Supernova on Mox (Hyak)",
    "section": "",
    "text": "Steven asked me to install Supernova (by 10x Genomics on our Mox node.\nFirst, need to install a dependency: bcl2fastq2.\nFollowed Illumina bcl2fastq2 manual (PDF)\nLogged into Mox and initiated a Build node:\nsrun -p build --time=1:00:00 --pty /bin/bash\n\nInstall bclsfastq2 dependency\nIllumina bcl2fastq2 manual (PDF)\ncd /gscratch/srlab/tmp\n\nwget ftp://webdata2:webdata2@ussd-ftp.illumina.com/downloads/software/bcl2fastq/bcl2fastq2-v2-20-0-tar.zip\n\nexport TMP=/gscratch/srlab/tmp/\n\nexport SOURCE=${TMP}/bcl2fastq\n\nexport BUILD=${TMP}/bcl2fastq2.20-build\n\nexport INSTALL_DIR=/gscratch/srlab/programs/bcl2fastq-v2.20\n\ncd ${TMP}\n\nunzip bcl2fastq2-v2-20-0-tar.zip\n\ntar -xvzf bcl2fastq2-v2.20.0.422-Source.tar.gz\n\ncd ${BUILD}\n\nchmod ugo+x ${SOURCE}/src/configure\n\nchmod ugo+x ${SOURCE}/src/cmake/bootstrap/installCmake.sh\n\n${SOURCE}/src/configure --prefix=${INSTALL_DIR}\n\ncd ${BUILD}\n\nmake\n\nmake install\n\n\nInstall Supernova 2.0.0\nSupernova install directions\ncd /gscratch/srlab/programs\n\nwget -O supernova-2.0.0.tar.gz \"https://cf.10xgenomics.com/releases/assembly/supernova-2.0.0.tar.gz?Expires=1516707075&Policy;=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cDovL2NmLjEweGdlbm9taWNzLmNvbS9yZWxlYXNlcy9hc3NlbWJseS9zdXBlcm5vdmEtMi4wLjAudGFyLmd6IiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNTE2NzA3MDc1fX19XX0_&Signature;=XJR7c9UlSkueydP304nKJrqomLXBH9~DWsenwlvBrplFMojbO-DPMghO09Sk6Wi5ApZSPwKB3sl1Wrnjy3qBLwr7dCoT~9oStyBpqlF~Xl2nBY6odnTzUaq3IpLyu8icIkt7DJM0GMXQTTp6rYu1PlLG31hMM5b5HZI3Tjzrhk8URbSrsG~7mm6m5-28afYHX00kT2Xfor7xr-ZSjjLe2jr99SEIARfzZjt6kUEnDMbl~3FXCHsSxXzKrkYXobGmfQhYBrey0iRyCAc9yNF7eSuBHAsqRGsP2yURVcYf3BB5nB1ZuEUo0qLgc5GlZJDQdsqDNC69HkyLCJamkJSnVg__&Key-Pair-Id;=APKAI7S6A5RYOXBWRPDA\"\n\ntar -xzvf supernova-2.0.0.tar.gz\n\nrm supernova-2.0.0.tar.gz\n\ncd supernova-2.0.0\n\nsupernova-cs/2.0.0/bin/supernova sitecheck > sitecheck.txt\n\nsupernova-cs/2.0.0/bin/supernova upload samwhite@uw.edu sitecheck.txt\n\nsrun -p srlab -A srlab --time=2:00:00 --pty /bin/bash\n\n/gscratch/srlab/programs/supernova-2.0.0/supernova testrun --id=tiny\n\nOK, looks like the test run finished successfully."
  },
  {
    "objectID": "posts/2018/2018-07-19-rna-cleanup-tanner-crab-rna-pools/index.html",
    "href": "posts/2018/2018-07-19-rna-cleanup-tanner-crab-rna-pools/index.html",
    "title": "RNA Cleanup - Tanner Crab RNA Pools",
    "section": "",
    "text": "Grace had previously pooled a set of crab RNA in preparation for RNAseq. Yesterday, we/she concentrated the samples and then quantified them. Unfortunately, Qubit results were not good (concentrations were far below the expected 20ng/uL) and the NanoDrop1000 results yielded awful looking curves.\nIn an attempt to figure out what was wrong, I decided to use the RNeasy Plus Mini Kit (Qiagen) on the three pools. I did this due to the poor spec curves seen in the NanoDrop1000 measurements. Additionally, all of the RNA pools had undissolved/insoluble bits floating around in them. My thinking was that excess contaminants/salts could be interfering with the Qubit assay. Removing these could/should enlighten us as to what the issue might be.\nFollowed the manufacturer’s protocol for RNeasy MiniElute Cleanup Kit (as the RNeasy Plus Mini Kit uses the same reagents/columns for RNA purification) for samples with <100uL.\nSamples were quantified on the RobertsLab NanoDrop1000 (ThermoFisher) and the Qubit 3.0 (ThermoFisher) using the RNA high sensitivity (HS) Kit. Used 1uL of each sample.\n\nResults:\nQubit (Google Sheet): 20180719_qubit_RNA_crab_pools\nNanoDrop:\n\nThe NanoDrop did not detect any RNA in the samples.\nThe Qubit did not detect any RNA in Crab Pool 1. The other two samples had similar concentrations (~7ng/uL). This would mean a total of ~84ng of RNA was present in each of those two samples.\nAll pools were expected to have well over 1000ng of RNA.\nWill have to think about what should be done, but I would lean towards attempting to run some “test” samples through the RNeasy Cleanup kit to see if that would help get us more accurate Qubit readings? I don’t know, though…"
  },
  {
    "objectID": "posts/2018/2018-03-27-assembly-geoduck-novaseq-using-sparseassembler-kmer-101/index.html",
    "href": "posts/2018/2018-03-27-assembly-geoduck-novaseq-using-sparseassembler-kmer-101/index.html",
    "title": "Assembly - Geoduck NovaSeq using SparseAssembler kmer = 101",
    "section": "",
    "text": "The prior run used a kmer size of 61, and the resulting assembly was rather poor (small N50).\nFor this run, I arbitrarily increased the kmer size to 101, in hopes that this will improve the assembly.\nThe job was run on our Mox node.\nHere’s the batch script to initiate the job:\n20180322_SparseAssembler_novaseq_geoduck_slurm.sh\n<code>\n#SBATCH --job-name=20180322_sparse_assembler_geo_novaseq\n## Allocation Definition \n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes (We only get 1, so this is fixed)\n#SBATCH --nodes=1   \n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=30-00:00:00\n## Memory per node\n#SBATCH --mem=500G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --workdir=/gscratch/scrubbed/samwhite/20180322_SparseAssembler_novaseq_geoduck\n\n/gscratch/srlab/programs/SparseAssembler/SparseAssembler \\\nLD 0 \\\nNodeCovTh 1 \\\nEdgeCovTh 0 \\\nk 101 \\\ng 15 \\\nPathCovTh 100 \\\nGS 2200000000 \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/AD002_S9_L001_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/AD002_S9_L001_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/AD002_S9_L002_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/AD002_S9_L002_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR005_S4_L001_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR005_S4_L001_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR005_S4_L002_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR005_S4_L002_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR006_S3_L001_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR006_S3_L001_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR006_S3_L002_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR006_S3_L002_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR012_S1_L001_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR012_S1_L001_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR012_S1_L002_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR012_S1_L002_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR013_AD013_S2_L001_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR013_AD013_S2_L001_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR013_AD013_S2_L002_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR013_AD013_S2_L002_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR014_AD014_S5_L001_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR014_AD014_S5_L001_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR014_AD014_S5_L002_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR014_AD014_S5_L002_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR015_AD015_S6_L001_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR015_AD015_S6_L001_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR015_AD015_S6_L002_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR015_AD015_S6_L002_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR019_S7_L001_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR019_S7_L001_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR019_S7_L002_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR019_S7_L002_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR021_S8_L001_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR021_S8_L001_R2_001_val_2_val_2.fastq \\\ni1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR021_S8_L002_R1_001_val_1_val_1.fastq \\\ni2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR021_S8_L002_R2_001_val_2_val_2.fastq\n</code>\n\nResults\nOutput folder: 20180322_SparseAssembler_novaseq_geoduck/\nThis completed much more quickly than the previous run (kmer = 61). The previous assembly took ~10 days, while this assembly completed in ~4 days!\nThe primary output file of interest is this FASTA file:\n\n[Contigs.txt (12GB)(https://owl.fish.washington.edu/Athaliana/20180322_SparseAssembler_novaseq_geoduck/Contigs.txt)\n\nIn order to get a rough idea of how this assembly looks, I ran it through Quast Version: 4.5, 15ca3b9:\npython software/quast-4.5/quast.py \\ -t 16  /mnt/owl/Athaliana/20180322_SparseAssembler_novaseq_geoduck/Contigs.txt\nQuast output folder: results_2018_03_27_08_25_52/\nHere’re the stats on the assembly:\nQuast output (text): results_2018_03_27_08_25_52/report.txt\nQuast output (HTML):results_2018_03_27_08_25_52/report.html\n\n\nThis is definitely a better assembly than the kmer = 61 assembly.\nN50 = 1149\nAlso, there’s a single, large contig of 56,361bp, and 54 contigs > 25,000bp. This is good.\nAdmittedly, I’m a little surprised (and, disappointed) the N50 is as small as it is. However, we have a pretty decent assembly on our hands!\nSince SparseAssembler seems to actually run (and, relatively quickly), I’m very tempted to just throw ALL of our geoduck data at it and see how it turns out…"
  },
  {
    "objectID": "posts/2018/2018-02-19-assembly-geoduck-illumina-novaseq-soapdenovo2-on-mox-fail/index.html",
    "href": "posts/2018/2018-02-19-assembly-geoduck-illumina-novaseq-soapdenovo2-on-mox-fail/index.html",
    "title": "Assembly - Geoduck Illumina NovaSeq SOAPdenovo2 on Mox (FAIL)",
    "section": "",
    "text": "Trying to get the NovaSeq data assembled using SOAPdenovo2 on the Mox HPC node we have and it will not work.\nTried a couple of times and it hasn’t run successfully. Here are links to the files used on Mox (including the batch script and slurm output files). I made slight changes to the formatting of the batch script because I thought there was something wrong. Specifically, the slurm output file in the 20180215 runs does not accurately reflect the command I issued (i.e. 1> ass.log is command, but slurm shows > ass.log).\n\n20180215_soapdenovo2_novaseq_geoduck: This failed for no obvious reason. The slurm output file simply indicates the job was killed and the SOAPdenov2 error log doesn’t contain any info regarding why the job failed.\n20180218_soapdenovo2_novaseq_geoduck/: This failed because there wasn’t enough memory(!!??) - see below for more info.\n\nNOTE: In the 20180218 run, I have excluded transferring the core dump file due to its crazy size:\n\nHere’s the error log generated by SOAPdenovo2 in the 20180218 run (the last line is all you really need to see, though):\n[code lang=text] Version 2.04: released on July 13th, 2012 Compile May 10 2017 12:50:52\n\nPregraph ********************\nParameters: pregraph -s /gscratch/scrubbed/samwhite/20180218_soapdenovo2_novaseq_geoduck/soap_config -K 117 -p 24 -o /gscratch/scrubbed/samwhite/20180218_soapdenovo2_novaseq_geoduck/\nIn /gscratch/scrubbed/samwhite/20180218_soapdenovo2_novaseq_geoduck/soap_config, 1 lib(s), maximum read length 150, maximum name length 256.\n24 thread(s) initialized. Import reads from file: /gscratch/scrubbed/samwhite/20180129_trimmed_again/AD002_S9_L001_R1_001_val_1_val_1.fq.gz Import reads from file: /gscratch/scrubbed/samwhite/20180129_trimmed_again/AD002_S9_L001_R2_001_val_2_val_2.fq.gz — 100000000th reads. — 200000000th reads. — 300000000th reads. Import reads from file: /gscratch/scrubbed/samwhite/20180129_trimmed_again/AD002_S9_L002_R1_001_val_1_val_1.fq.gz Import reads from file: /gscratch/scrubbed/samwhite/20180129_trimmed_again/AD002_S9_L002_R2_001_val_2_val_2.fq.gz — 400000000th reads. — 500000000th reads. — 600000000th reads. — 700000000th reads. Import reads from file: /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR005_S4_L001_R1_001_val_1_val_1.fq.gz Import reads from file: /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR005_S4_L001_R2_001_val_2_val_2.fq.gz Import reads from file: /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR005_S4_L002_R1_001_val_1_val_1.fq.gz Import reads from file: /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR005_S4_L002_R2_001_val_2_val_2.fq.gz Import reads from file: /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR006_S3_L001_R1_001_val_1_val_1.fq.gz Import reads from file: /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR006_S3_L001_R2_001_val_2_val_2.fq.gz Import reads from file: /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR006_S3_L002_R1_001_val_1_val_1.fq.gz Import reads from file: /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR006_S3_L002_R2_001_val_2_val_2.fq.gz Import reads from file: /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR012_S1_L001_R1_001_val_1_val_1.fq.gz Import reads from file: /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR012_S1_L001_R2_001_val_2_val_2.fq.gz Import reads from file: /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR012_S1_L002_R1_001_val_1_val_1.fq.gz Import reads from file: /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR012_S1_L002_R2_001_val_2_val_2.fq.gz Import reads from file: /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR013_AD013_S2_L001_R1_001_val_1_val_1.fq.gz Import reads from file: /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR013_AD013_S2_L001_R2_001_val_2_val_2.fq.gz — 800000000th reads. — 900000000th reads. – Out of memory –\n[/code]\nI guess I’ll explore some other options for assembling these? I’m having a difficult time accepting that 500GB of RAM is insufficient, but that seems to be the case. Ouch."
  },
  {
    "objectID": "posts/2018/2018-04-04-gunzip-trimmed-illumina-hiseq-genome-sequencing-data/index.html",
    "href": "posts/2018/2018-04-04-gunzip-trimmed-illumina-hiseq-genome-sequencing-data/index.html",
    "title": "Gunzip - Trimmed Illumina Geoduck HiSeq Genome Sequencing Data",
    "section": "",
    "text": "In preparation to run SpareAssembler, I needed to gunzip the trimmed gzipped FASTQ files from 20140401.\nRan the following slurm script on our Mox node:\n<code>\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=20180404_geoduck_gunzip\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes (We only get 1, so this is fixed)\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=30-00:00:00\n## Memory per node\n#SBATCH --mem=500G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --workdir=/gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck\n\nfor i in /gscratch/scrubbed/samwhite/illumina_geoduck_hiseq/20180328_trim_galore_illumina_hiseq_geoduck/*.gz; do\n    filename=\"${i##*/}\"\n    no_ext=\"${filename%%.*}\"\n    gunzip < \"$i\" > \"$no_ext\".fastq\ndone\n</code>\n\nResults:\nThis crashed shortly after initiating the run (~30mins later). Received following email notification:\n\nSLURM Job_id=155940 Name=20180404_geoduck_gunzip Failed, Run time 00:30:40, NODE_FAIL\n\nIt did not generate a slurm output file, nor any gunzipped files. Will contact UW IT…\n\n\nUPDATE 20140404\nWeird, about an hour after this crashed, I received the following email, indicating the job was submitted (I did no resubmit, btw):\n\nSLURM Job_id=155940 Name=20180404_geoduck_gunzip Began, Queued time 00:02:29\n\nCompleted about 3hrs later."
  },
  {
    "objectID": "posts/2018/2018-04-03-titrations-yaaminis-seawater-samples-2/index.html",
    "href": "posts/2018/2018-04-03-titrations-yaaminis-seawater-samples-2/index.html",
    "title": "Titrations - Yaamini’s Seawater Samples",
    "section": "",
    "text": "All data is deposited in the following GitHub repo:\n\nRobertsLab/titrator\n\nSample sizes: ~50g\nLabX Method:\n\npH_TA_titration.pdf\n\nDaily pH calibration data file:\n\n2018-04-03T07_17_55_pH_calibration_7_4_10_T350.csv\n\nDaily pH log file:\n\ndaily_calibration_log.csv\n\nTitrant batch:\n\nA10\n\nCRM Batch:\n\n168\n\nDaily CRM data file:\n\n2018-04-03T07_49_32_CRM_TA_titration_T351.csv\n\nSample data file(s):\n\n2018-04-03T09_12_45_pH_TA_titration_T363.csv\n\nSee metadata file for sample info (including links to master samples sheets):\n\nfile_metadata.csv"
  },
  {
    "objectID": "posts/2018/2018-03-29-data-recived-crassostrea-virginica-mbd-bs-seq-from-zymoresearch/index.html",
    "href": "posts/2018/2018-03-29-data-recived-crassostrea-virginica-mbd-bs-seq-from-zymoresearch/index.html",
    "title": "Data Received - Crassostrea virginica MBD BS-seq from ZymoResearch",
    "section": "",
    "text": "Received the sequencing data from ZymoResearch for the Crassostrea virginica gonad MBD DNA that was sent to them on 20180207 for bisulfite conversion, library construction, and sequencing.\nGzipped FASTQ files were:\n\ndownloaded to Owl/nightingales/C_virginica\nMD5 checksums verified\nMD5 checksums appended to the checksums.md5 file\nreadme.md file updated\nUpdated nightingales Google Sheet\n\nHere’s the list of files received:\n[code lang=text] zr2096_10_s1_R1.fastq.gz zr2096_10_s1_R2.fastq.gz zr2096_1_s1_R1.fastq.gz zr2096_1_s1_R2.fastq.gz zr2096_2_s1_R1.fastq.gz zr2096_2_s1_R2.fastq.gz zr2096_3_s1_R1.fastq.gz zr2096_3_s1_R2.fastq.gz zr2096_4_s1_R1.fastq.gz zr2096_4_s1_R2.fastq.gz zr2096_5_s1_R1.fastq.gz zr2096_5_s1_R2.fastq.gz zr2096_6_s1_R1.fastq.gz zr2096_6_s1_R2.fastq.gz zr2096_7_s1_R1.fastq.gz zr2096_7_s1_R2.fastq.gz zr2096_8_s1_R1.fastq.gz zr2096_8_s1_R2.fastq.gz zr2096_9_s1_R1.fastq.gz zr2096_9_s1_R2.fastq.gz [/code]\nHere’s the sample processing history:\n\nTissue received from K. Lotterhos\nDNA isolation\nYaamini MBD Day 1\nYaamini MBD Day 2\nYaamini MBD Day 3\nYaamini MBD Day 4\nEtOH precip, quantification, shipped"
  },
  {
    "objectID": "posts/2018/2018-07-03-transposable-element-mapping-olympia-oyster-genome-assembly-olurida_v081-using-repeatmasker-4-07/index.html",
    "href": "posts/2018/2018-07-03-transposable-element-mapping-olympia-oyster-genome-assembly-olurida_v081-using-repeatmasker-4-07/index.html",
    "title": "Transposable Element Mapping – Olympia Oyster Genome Assembly, Olurida_v081, using RepeatMasker 4.07",
    "section": "",
    "text": "I previously performed this analysis using a different version of our Ostrea lurida genome assembly. Steven asked that I repeat the analysis with a modified version of the genome assembly (Olurida_v081) - only has contigs >1000bp in length.\nGenome used: Olurida_v081\nI ran RepeatMasker (v4.07) with RepBase-20170127 and RMBlast 2.6.0 four times:\n\nDefault settings (i.e. no species select - will use human genome).\nSpecies = Crassostrea gigas (Pacific oyster)\nSpecies = Crassostrea virginica (Eastern oyster)\nSpecies = Ostrea lurida (Olympia oyster)\n\nThe idea was to get a sense of how the analyses would differ with species specifications. However, it’s likely that the only species setting that will make any difference will be Run #2 (Crassostrea gigas).\nThe reason I say this is that RepeatMasker has a built in tool to query which species are available in the RepBase database (e.g.):\n<code>RepeatMasker-4.0.7/util/queryRepeatDatabase.pl -species \"crassostrea virginica\" -stat</code>\nHere’s a very brief overview of what that yields:\n\nCrassotrea gigas: 792 specific repeats\nCrassostrea virginica: 4 Crassostrea virginica specific repeats\nOstrea lurida: 0 Ostrea lurida specific repeats\n\nAll runs were performed on roadrunner.\nAll commands were documented in a Jupyter Notebook (GitHub):\n\n20180702_roadrunner_oly_TEs_repeatmasker.ipynb\n\n_NOTE: RepeatMasker writes the desired output files (.out, .cat.gz, and *.gff) to the same directory that the genome is located in! If you conduct multiple runs with the same genome in the same directory, it will overwrite those files, as they are named using the genome assembly filename._\n\n\nRESULTS:\n\nRUN 1 (default settings - human genome)\nOutput folder:\n\n20180702_oly_repeatmasker_defaults\n\nSummary table (text):\n\nOlurida_v081.fa.tbl\n\nOutput table (GFF):\n\nOlurida_v081.fa.out.gff\n\n\n\n\nSUMMARY TABLE\n<code>\n==================================================\nfile name: Olurida_v081.fa          \nsequences:        159429\ntotal length: 1140787867 bp  (1077373535 bp excl N/X-runs)\nGC level:         36.58 %\nbases masked:   17954347 bp ( 1.67 %)\n==================================================\n               number of      length   percentage\n               elements*    occupied  of sequence\n--------------------------------------------------\nSINEs:            16599       978030 bp    0.09 %\n      ALUs            1          292 bp    0.00 %\n      MIRs          937        72873 bp    0.01 %\n\nLINEs:             3279       752631 bp    0.07 %\n      LINE1         172        10882 bp    0.00 %\n      LINE2         646        67827 bp    0.01 %\n      L3/CR1        659        60327 bp    0.01 %\n\nLTR elements:       569       127808 bp    0.01 %\n      ERVL           32         1949 bp    0.00 %\n      ERVL-MaLRs     10          490 bp    0.00 %\n      ERV_classI    165        17699 bp    0.00 %\n      ERV_classII    26         1590 bp    0.00 %\n\nDNA elements:      1911       161957 bp    0.02 %\n     hAT-Charlie     74         4216 bp    0.00 %\n     TcMar-Tigger   584        24985 bp    0.00 %\n\nUnclassified:        78         9834 bp    0.00 %\n\nTotal interspersed repeats:  2030260 bp    0.19 %\n\n\nSmall RNA:         5592       409456 bp    0.04 %\n\nSatellites:         117        21278 bp    0.00 %\nSimple repeats:  270784     12935570 bp    1.20 %\nLow complexity:   42130      2568284 bp    0.24 %\n==================================================\n\n* most repeats fragmented by insertions or deletions\n  have been counted as one element\n  Runs of >=20 X/Ns in query were excluded in % calcs\n\n\nThe query species was assumed to be homo sapiens  \nRepeatMasker Combined Database: Dfam_Consensus-20170127, RepBase-20170127\n        \nrun with rmblastn version 2.6.0+\n</code>\n\n\nRUN 2 (species - Crassostrea gigas)\nOutput folder:\n\n20180702_oly_repeatmasker_Cgigas\n\nSummary table (text):\n\nOlurida_v081.fa.tbl\n\nOutput table (GFF):\n\nOlurida_v081.fa.out.gff\n\n\n\n\nSUMMARY TABLE\n<code>\nfile name: Olurida_v081.fa          \nsequences:        159429\ntotal length: 1140787867 bp  (1077373535 bp excl N/X-runs)\nGC level:         36.58 %\nbases masked:  152816516 bp ( 14.18 %)\n==================================================\n               number of      length   percentage\n               elements*    occupied  of sequence\n--------------------------------------------------\nRetroelements       193250     67253771 bp    6.24 %\n   SINEs:             2087       284274 bp    0.03 %\n   Penelope         158576     56080082 bp    5.21 %\n   LINEs:           179430     61300904 bp    5.69 %\n    CRE/SLACS            0            0 bp    0.00 %\n     L2/CR1/Rex        675       348273 bp    0.03 %\n     R1/LOA/Jockey       0            0 bp    0.00 %\n     R2/R4/NeSL          7        10781 bp    0.00 %\n     RTE/Bov-B        7051      1827344 bp    0.17 %\n     L1/CIN4             0            0 bp    0.00 %\n   LTR elements:     11733      5668593 bp    0.53 %\n     BEL/Pao          1517       871288 bp    0.08 %\n     Ty1/Copia          78        72481 bp    0.01 %\n     Gypsy/DIRS1      9151      4445789 bp    0.41 %\n       Retroviral        0            0 bp    0.00 %\n\nDNA transposons     233691     33727339 bp    3.13 %\n   hobo-Activator    17578      1886743 bp    0.18 %\n   Tc1-IS630-Pogo    39184      6403235 bp    0.59 %\n   En-Spm                0            0 bp    0.00 %\n   MuDR-IS905            0            0 bp    0.00 %\n   PiggyBac           7261      1003937 bp    0.09 %\n   Tourist/Harbinger  8635       823434 bp    0.08 %\n   Other (Mirage,        0            0 bp    0.00 %\n    P-element, Transib)\n\nRolling-circles          0            0 bp    0.00 %\n\nUnclassified:       157855     36675484 bp    3.40 %\n\nTotal interspersed repeats:   137656594 bp   12.78 %\n\n\nSmall RNA:             222        72690 bp    0.01 %\n\nSatellites:           6260      1238331 bp    0.11 %\nSimple repeats:     241081     11662466 bp    1.08 %\nLow complexity:      38915      2347827 bp    0.22 %\n==================================================\n\n* most repeats fragmented by insertions or deletions\n  have been counted as one element\n  Runs of >=20 X/Ns in query were excluded in % calcs\n\n\nThe query species was assumed to be crassostrea gigas\nRepeatMasker Combined Database: Dfam_Consensus-20170127, RepBase-20170127\n        \nrun with rmblastn version 2.6.0+\n</code>\n\n\nRUN 3 (species - Crassostrea virginica)\nOutput folder:\n\n20180702_oly_repeatmasker_Cvirginica\n\nSummary table (text):\n\nOlurida_v081.fa.tbl\n\nOutput table (GFF):\n\nOlurida_v081.fa.out.gff\n\n\n\n\nSUMMARY TABLE\n<code>\nfile name: Olurida_v081.fa          \nsequences:        159429\ntotal length: 1140787867 bp  (1077373535 bp excl N/X-runs)\nGC level:         36.58 %\nbases masked:   36996910 bp ( 3.43 %)\n==================================================\n               number of      length   percentage\n               elements*    occupied  of sequence\n--------------------------------------------------\nRetroelements        59806      9886111 bp    0.92 %\n   SINEs:            59806      9886111 bp    0.92 %\n   Penelope              0            0 bp    0.00 %\n   LINEs:                0            0 bp    0.00 %\n    CRE/SLACS            0            0 bp    0.00 %\n     L2/CR1/Rex          0            0 bp    0.00 %\n     R1/LOA/Jockey       0            0 bp    0.00 %\n     R2/R4/NeSL          0            0 bp    0.00 %\n     RTE/Bov-B           0            0 bp    0.00 %\n     L1/CIN4             0            0 bp    0.00 %\n   LTR elements:         0            0 bp    0.00 %\n     BEL/Pao             0            0 bp    0.00 %\n     Ty1/Copia           0            0 bp    0.00 %\n     Gypsy/DIRS1         0            0 bp    0.00 %\n       Retroviral        0            0 bp    0.00 %\n\nDNA transposons       8720      2230426 bp    0.21 %\n   hobo-Activator        0            0 bp    0.00 %\n   Tc1-IS630-Pogo        0            0 bp    0.00 %\n   En-Spm                0            0 bp    0.00 %\n   MuDR-IS905            0            0 bp    0.00 %\n   PiggyBac              0            0 bp    0.00 %\n   Tourist/Harbinger     0            0 bp    0.00 %\n   Other (Mirage,        0            0 bp    0.00 %\n    P-element, Transib)\n\nRolling-circles          0            0 bp    0.00 %\n\nUnclassified:        47005      9434652 bp    0.88 %\n\nTotal interspersed repeats:    21551189 bp    2.00 %\n\n\nSmall RNA:           60030      9959172 bp    0.92 %\n\nSatellites:              8         5100 bp    0.00 %\nSimple repeats:     259134     12795379 bp    1.19 %\nLow complexity:      42184      2581162 bp    0.24 %\n==================================================\n\n* most repeats fragmented by insertions or deletions\n  have been counted as one element\n  Runs of >=20 X/Ns in query were excluded in % calcs\n\n\nThe query species was assumed to be crassostrea virginica\nRepeatMasker Combined Database: Dfam_Consensus-20170127, RepBase-20170127\n        \nrun with rmblastn version 2.6.0+\n</code>\n\n\nRUN 4 (species - Ostrea lurida)\nOutput folder:\n\n20180702_oly_repeatmasker_Olurida/\n\nSummary table (text):\n\nOlurida_v081.fa.tbl\n\nOutput table (GFF):\n\nOlurida_v081.fa.out.gff\n\n\n\n\nSUMMARY TABLE\n<code>\n==================================================\nfile name: Olurida_v081.fa          \nsequences:        159429\ntotal length: 1140787867 bp  (1077373535 bp excl N/X-runs)\nGC level:         36.58 %\nbases masked:   15918797 bp ( 1.48 %)\n==================================================\n               number of      length   percentage\n               elements*    occupied  of sequence\n--------------------------------------------------\nRetroelements            0            0 bp    0.00 %\n   SINEs:                0            0 bp    0.00 %\n   Penelope              0            0 bp    0.00 %\n   LINEs:                0            0 bp    0.00 %\n    CRE/SLACS            0            0 bp    0.00 %\n     L2/CR1/Rex          0            0 bp    0.00 %\n     R1/LOA/Jockey       0            0 bp    0.00 %\n     R2/R4/NeSL          0            0 bp    0.00 %\n     RTE/Bov-B           0            0 bp    0.00 %\n     L1/CIN4             0            0 bp    0.00 %\n   LTR elements:         0            0 bp    0.00 %\n     BEL/Pao             0            0 bp    0.00 %\n     Ty1/Copia           0            0 bp    0.00 %\n     Gypsy/DIRS1         0            0 bp    0.00 %\n       Retroviral        0            0 bp    0.00 %\n\nDNA transposons          0            0 bp    0.00 %\n   hobo-Activator        0            0 bp    0.00 %\n   Tc1-IS630-Pogo        0            0 bp    0.00 %\n   En-Spm                0            0 bp    0.00 %\n   MuDR-IS905            0            0 bp    0.00 %\n   PiggyBac              0            0 bp    0.00 %\n   Tourist/Harbinger     0            0 bp    0.00 %\n   Other (Mirage,        0            0 bp    0.00 %\n    P-element, Transib)\n\nRolling-circles          0            0 bp    0.00 %\n\nUnclassified:            3          189 bp    0.00 %\n\nTotal interspersed repeats:         189 bp    0.00 %\n\n\nSmall RNA:             224        73061 bp    0.01 %\n\nSatellites:              8         5100 bp    0.00 %\nSimple repeats:     273098     13256460 bp    1.23 %\nLow complexity:      42443      2592212 bp    0.24 %\n==================================================\n\n* most repeats fragmented by insertions or deletions\n  have been counted as one element\n  Runs of >=20 X/Ns in query were excluded in % calcs\n\n\nThe query species was assumed to be ostrea lurida \nRepeatMasker Combined Database: Dfam_Consensus-20170127, RepBase-20170127\n        \nrun with rmblastn version 2.6.0+\n\n\n</code>"
  },
  {
    "objectID": "posts/2018/2018-04-12-data-management-sra-submission-lsu-c-virginica-oil-spill-mbd-bs-seq-data/index.html",
    "href": "posts/2018/2018-04-12-data-management-sra-submission-lsu-c-virginica-oil-spill-mbd-bs-seq-data/index.html",
    "title": "Data Management - SRA Submission LSU C.virginica Oil Spill MBD BS-seq Data",
    "section": "",
    "text": "Submitted the Crassostrea virginica (Eastern oyster) MBD BS-seq data we received on 20150413 to NCBI Sequence Read Archive.\nData was uploaded via the web browser interface, as the FTP method was not functioning properly.\nSRA deets are below (assigned FASTQ files to new BioProject and created new BioSamples).\nSRA Study: SRP139854 BioProject: PRJNA449904\nBioSamples Table\n\n\nSample Treatment BioSample\n\n\n\n\n\nHB2\n\n\noil 25,000ppm\n\n\nSAMN08919868\n\n\n\n\nHB16\n\n\noil 25,000ppm\n\n\nSAMN08919921\n\n\n\n\nHB30\n\n\noil 25,000ppm\n\n\nSAMN08919953\n\n\n\n\nNB3\n\n\nunexposed\n\n\nSAMN08919461\n\n\n\n\nNB6\n\n\nunexposed\n\n\nSAMN08919577\n\n\n\n\nNB11\n\n\nunexposed\n\n\nSAMN08919772"
  },
  {
    "objectID": "posts/2018/2018-08-16-dna-methylation-analysis-bismark-pipeline-on-all-olympia-oyster-bsseq-datasets/index.html",
    "href": "posts/2018/2018-08-16-dna-methylation-analysis-bismark-pipeline-on-all-olympia-oyster-bsseq-datasets/index.html",
    "title": "DNA Methylation Analysis - Bismark Pipeline on All Olympia oyster BSseq Datasets",
    "section": "",
    "text": "Bismark analysis of all of our current Olympia oyster (Ostrea lurida) DNA methylation high-throughput sequencing data.\nAnalysis was run on Emu (Ubuntu 16.04LTS, Apple Xserve). The primary analysis took ~14 days to complete.\nAll operations are documented in a Jupyter notebook (GitHub):\n\n20180709_emu_oly_methylation_mapping.ipynb\n\nGenome used:\n\nOlurida_v080.fa ( run was initiated prior to creation of v081; see Genomic Resources wiki for more info)\n\n\nInput files ( see Olympia oyster Genomic GitHub wiki for more info ):\n\nWG BSseq of Fidalgo Bay offspring grown in Fidalgo Bay & Oyster Bay\n\n1_ATCACG_L001_R1_001.fastq.gz\n2_CGATGT_L001_R1_001.fastq.gz\n3_TTAGGC_L001_R1_001.fastq.gz\n4_TGACCA_L001_R1_001.fastq.gz\n5_ACAGTG_L001_R1_001.fastq.gz\n6_GCCAAT_L001_R1_001.fastq.gz\n7_CAGATC_L001_R1_001.fastq.gz\n8_ACTTGA_L001_R1_001.fastq.gz\n\n\n\nMBDseq of two populations (Hood Canal & Oyster Bay) grown in Clam Bay\n\nzr1394_10_s456.fastq.gz\nzr1394_11_s456.fastq.gz\nzr1394_12_s456.fastq.gz\nzr1394_13_s456.fastq.gz\nzr1394_14_s456.fastq.gz\nzr1394_15_s456.fastq.gz\nzr1394_16_s456.fastq.gz\nzr1394_17_s456.fastq.gz\nzr1394_18_s456.fastq.gz\nzr1394_1_s456.fastq.gz\nzr1394_2_s456.fastq.gz\nzr1394_3_s456.fastq.gz\nzr1394_4_s456.fastq.gz\nzr1394_5_s456.fastq.gz\nzr1394_6_s456.fastq.gz\nzr1394_7_s456.fastq.gz\nzr1394_8_s456.fastq.gz\nzr1394_9_s456.fastq.gz\n\n\n\n\nRESULTS:\nWith Bismark complete, these two sets of analyses can now be looked into further (and separately, as they are separate experiments) using things like MethylKit (R package) and the Integrative Genomics Viewer (IGV).\nOutput folder:\n\nowl/Athaliana/20180709_oly_methylseq\n\nBismark Summary Report:\n\n20180709_oly_methylseq/bismark_summary_report.html\n\nIndividual Sample Reports:\n\n1_ATCACG_L001_R1_001_trimmed_bismark_bt2_SE_report.html\n2_CGATGT_L001_R1_001_trimmed_bismark_bt2_SE_report.html\n3_TTAGGC_L001_R1_001_trimmed_bismark_bt2_SE_report.html\n4_TGACCA_L001_R1_001_trimmed_bismark_bt2_SE_report.html\n5_ACAGTG_L001_R1_001_trimmed_bismark_bt2_SE_report.html\n6_GCCAAT_L001_R1_001_trimmed_bismark_bt2_SE_report.html\n7_CAGATC_L001_R1_001_trimmed_bismark_bt2_SE_report.html\n8_ACTTGA_L001_R1_001_trimmed_bismark_bt2_SE_report.html\nzr1394_10_s456_trimmed_bismark_bt2_SE_report.html\nzr1394_11_s456_trimmed_bismark_bt2_SE_report.html\nzr1394_12_s456_trimmed_bismark_bt2_SE_report.html\nzr1394_13_s456_trimmed_bismark_bt2_SE_report.html\nzr1394_14_s456_trimmed_bismark_bt2_SE_report.html\nzr1394_15_s456_trimmed_bismark_bt2_SE_report.html\nzr1394_16_s456_trimmed_bismark_bt2_SE_report.html\nzr1394_17_s456_trimmed_bismark_bt2_SE_report.html\nzr1394_18_s456_trimmed_bismark_bt2_SE_report.html\nzr1394_1_s456_trimmed_bismark_bt2_SE_report.html\nzr1394_2_s456_trimmed_bismark_bt2_SE_report.html\nzr1394_3_s456_trimmed_bismark_bt2_SE_report.html\nzr1394_4_s456_trimmed_bismark_bt2_SE_report.html\nzr1394_5_s456_trimmed_bismark_bt2_SE_report.html\nzr1394_6_s456_trimmed_bismark_bt2_SE_report.html\nzr1394_7_s456_trimmed_bismark_bt2_SE_report.html\nzr1394_8_s456_trimmed_bismark_bt2_SE_report.html\nzr1394_9_s456_trimmed_bismark_bt2_SE_report.html"
  },
  {
    "objectID": "posts/2018/2018-08-30-fastqcmultiqctrimgaloremultiqcfastqcmultiqc-o-lurida-wgbsseq-for-methylation-analysis/index.html",
    "href": "posts/2018/2018-08-30-fastqcmultiqctrimgaloremultiqcfastqcmultiqc-o-lurida-wgbsseq-for-methylation-analysis/index.html",
    "title": "FastQC/MultiQC/TrimGalore/MultiQC/FastQC/MultiQC - O.lurida WGBSseq for Methylation Analysis",
    "section": "",
    "text": "I previously ran this data through the Bismark pipeline and followed up with MethylKit analysis. MethylKit analysis revealed an extremely low number of differentially methylated loci (DML), which seemed odd.\nSteven and I met to discuss and compare our different variations on the analysis and decided to try out different tweaks to evaluate how they affect analysis.\nI did the following tasks:\n\nLooked at original sequence data quality with FastQC.\nSummarized FastQC analysis with MultiQC.\nTrimmed data using TrimGalore!, trimming 10bp from 5’ end of reads (8bp is recommended by Bismark docs).\nSummarized trimming stats with MultiQC.\nLooked at trimmed sequence quality with FastQC.\nSummarized FastQC analysis with MultiQC.\n\nThis was run on the Univ. of Washington High Performance Computing (HPC) cluster, Mox.\nMox SBATCH submission script has all details on how the analyses were conducted:\n\n20180830_oly_WGBSseq_trimming.sh\n\n\n\nRESULTS\nOutput folder:\n\n20180830_oly_WGBSseq_trimming/\n\nRaw sequence FastQC output folder:\n\n20180830_oly_WGBSseq_trimming/20180830_fastqc/\n\nRaw sequence MultiQC report (HTML):\n\n20180830_oly_WGBSseq_trimming/20180830_fastqc/multiqc_report.html\n\nTrimGalore! output folder (trimmed FastQ files are here):\n\n20180830_oly_WGBSseq_trimming/20180830_trimgalore/\n\nTrimming MultiQC report (HTML):\n\n20180830_oly_WGBSseq_trimming/20180830_trimgalore/multiqc_report.html\n\nTrimmed FastQC output folder:\n\n20180830_oly_WGBSseq_trimming/20180830_trimmed_fastqc/\n\nTrimmed MultiQC report (HTML):\n\n20180830_oly_WGBSseq_trimming/20180830_trimmed_fastqc/multiqc_report.html"
  },
  {
    "objectID": "posts/2018/2018-04-02-titrations-yaaminis-seawater-samples/index.html",
    "href": "posts/2018/2018-04-02-titrations-yaaminis-seawater-samples/index.html",
    "title": "Titrations - Yaamini’s Seawater Samples",
    "section": "",
    "text": "All data is deposited in the following GitHub repo:\n\nRobertsLab/titrator\n\nSample sizes: ~50g\nLabX Methods:\n\nTA_titration.pdf\npH_TA_titration.pdf\n\nDaily pH calibration data file:\n\n2018-04-02T09_50_21_pH_calibration_7_4_10_T344.csv\n\nDaily pH log file:\n\ndaily_calibration_log.csv\n\nTitrant batch:\n\nA10\n\nCRM Batch:\n\n168\n\nDaily CRM data file:\n\n2018-04-02T10_26_11_CRM_TA_titration_T346.csv\n\nSample data file(s):\n\n2018-04-02T12_34_51_TA_titration_T347.csv - NOTE: This data set did not collect initial pH values prior to titration - used first LabX Method listed.\n2018-04-02T15_51_41_pH_TA_titration_T349.csv- NOTE: This data set did collect initial pH values prior to titration - used second LabX Method listed.\n\nSee metadata file for sample info (including links to master samples sheets):\n\nfile_metadata.csv"
  },
  {
    "objectID": "posts/2018/2018-08-23-assembly-stats-geoduck-hi-c-final-assembly-comparison/index.html",
    "href": "posts/2018/2018-08-23-assembly-stats-geoduck-hi-c-final-assembly-comparison/index.html",
    "title": "Assembly Stats – Geoduck Hi-C Final Assembly Comparison",
    "section": "",
    "text": "We received the final geoduck genome assembly data from Phase Genomics, in which they updated the assembly by performing some manual curation:\n\ngeoduck_manual_scaffolds.fasta\n\nThere are additional assembly files that provide some additional assembly data. See the following directory:\n\n20180822_phase_genomics_geoduck_Results/geoduck_manual/\n\nActual sequencing data and two previous assemblies were previously received on 20180421.\nAll assembly data (both old and new) from Phase Genomics was downloaded in full from the Google Drive link provided by them and stored here on Owl:\n\n20180822_phase_genomics_geoduck_Results/\n\nRan Quast to compare all three assemblies provided (command run on Swoose):\n<code>\n/home/sam/software/quast-4.5/quast.py \\\n-t 24 \\\n--labels 20180403_pga,20180421_pga,20180810_geo_manual \\\n/mnt/owl/Athaliana/20180421_geoduck_hi-c/Results/geoduck_roberts results 2018-04-03 11:05:41.596285/PGA_assembly.fasta \\ /mnt/owl/Athaliana/20180421_geoduck_hi-c/Results/geoduck_roberts results 2018-04-21 18:09:04.514704/PGA_assembly.fasta \\ /mnt/owl/Athaliana/20180822_phase_genomics_geoduck_Results/geoduck_manual/geoduck_manual_scaffolds.fasta\n</code>\n\n\nResults:\nQuast output folder: results_2018_08_23_07_38_28/\nQuast report (HTML): results_2018_08_23_07_38_28/report.html"
  },
  {
    "objectID": "posts/2018/2018-09-26-bedgraph-olympia-oyster-transcriptome-with-olurida_v081-genome-assembly/index.html",
    "href": "posts/2018/2018-09-26-bedgraph-olympia-oyster-transcriptome-with-olurida_v081-genome-assembly/index.html",
    "title": "Bedgraph – Olympia oyster transcriptome with Olurida_v081 genome assembly",
    "section": "",
    "text": "I took the sorted BAM file from yesterday’s corrected RNAseq genome alignment and converted it to a bedgraph using BEDTools genomeCoverageBed tool.\nAnalysis took place on our HPC Mox node.\nSBATCH script file:\n\n20180926_oly_RNAseq_bedgraphs.sh\n\n\n    #!/bin/bash\n    ## Job Name\n    #SBATCH --job-name=20180926_oly_bedgraphs\n    ## Allocation Definition\n    #SBATCH --account=srlab\n    #SBATCH --partition=srlab\n    ## Resources\n    ## Nodes\n    #SBATCH --nodes=1\n    ## Walltime (days-hours:minutes:seconds format)\n    #SBATCH --time=5-00:00:00\n    ## Memory per node\n    #SBATCH --mem=500G\n    ##turn on e-mail notification\n    #SBATCH --mail-type=ALL\n    #SBATCH --mail-user=samwhite@uw.edu\n    ## Specify the working directory for this job\n    #SBATCH --workdir=/gscratch/scrubbed/samwhite/20180926_oly_RNAseq_bedgraphs\n\n    # Load Python Mox module for Python module availability\n\n    module load intel-python3_2017\n\n    # Document programs in PATH (primarily for program version ID)\n\n    date >> system_path.log\n    echo \"\" >> system_path.log\n    echo \"System PATH for $SLURM_JOB_ID\" >> system_path.log\n    echo \"\" >> system_path.log\n    printf \"%0.s-\" {1..10} >> system_path.log\n    echo ${PATH} | tr : \\\\n >> system_path.log\n\n    # Set sorted transcriptome assembly bam file\n    oly_transcriptome_bam=/gscratch/scrubbed/samwhite/20180925_oly_RNAseq_genome_hisat2/20180925_Olurida_v081.sorted.bam\n\n\n    # Set program paths\n    bedtools=/gscratch/srlab/programs/bedtools-2.27.1/bin\n    samtools=/gscratch/srlab/programs/samtools-1.9/samtools\n\n\n    # Create bedgraph\n    ## Reports depth at each position (-bg in bedgraph format) and report regions with zero coverage (-a).\n    ## Screens for portions of reads coming from exons (-split).\n    ## Add genome browser track line to header of bedgraph file.\n    ${bedtools}/genomeCoverageBed \\\n    -ibam ${oly_transcriptome_bam} \\\n    -bga \\\n    -split \\\n    -trackline \\\n    > 20180926_oly_RNAseq.bedgraph\n\n\n\nRESULTS\nOutput folder:\n\n20180926_oly_RNAseq_bedgraphs/\n\nBedgraph file (1.2GB):\n\n20180926_oly_RNAseq_bedgraphs/20180926_oly_RNAseq.bedgraph\n\nLoaded in to IGV to verify things looked OK:\n\n\n\nScreencap of bedgraph in IGV"
  },
  {
    "objectID": "posts/2018/2018-05-16-fastqc-rrbs-geoduck-bs-seq-fastq-data/index.html",
    "href": "posts/2018/2018-05-16-fastqc-rrbs-geoduck-bs-seq-fastq-data/index.html",
    "title": "FastQC - RRBS Geoduck BS-seq FASTQ data",
    "section": "",
    "text": "Earlier today I finished trimming Hollie’s RRBS BS-seq FastQ data.\nHowever, the original files were never analyzed with FastQC, so I ran it on the original files.\nThese libraries were originally created by Hollie Putnam using the TruSeq DNA Methylation Kit (Illumina):\n\n[project_juvenile_geoduck_OA/Sample_Processing (GitHub)(https://github.com/hputnam/project_juvenile_geoduck_OA/tree/master/Sample_Processing)\n\nFastQC was run, followed by MultiQC. Analysis was run on Roadrunner.\nAll analysis is documented in a Jupyter Notebook; see link below.\n\nJupyter Notebook:\n\n20180516_roadrunner_geoduck_EPI_fastqc\n\n\n\n\nResults:\n\nFastQC output folder:\n\n20180516_geoduck_EPI_fastqc/\n\n\n\nMultiQC output folder:\n\n20180516_geoduck_EPI_fastqc/multiqc_data\n\n\n\nMultiQC report (HTML):\n\nmultiqc_report.html"
  },
  {
    "objectID": "posts/2018/2018-08-09-data-received-geoduck-metagenome-hiseqx-data/index.html",
    "href": "posts/2018/2018-08-09-data-received-geoduck-metagenome-hiseqx-data/index.html",
    "title": "Data Received - Geoduck Metagenome HiSeqX Data",
    "section": "",
    "text": "FastQ files are being transferred to owl/nightingales/P_generosa.\nThese aren’t geoduck sequences, but they are part of a geoduck project. Maybe I should establish a metagenomics directory under nightingales?\nWill verifiy md5 checksums and update readme file once the transfer is complete."
  },
  {
    "objectID": "posts/2018/2018-09-10-sequencing-data-analysis-c-virginica-oil-spill-mbdseq-concatenation-fastqc/index.html",
    "href": "posts/2018/2018-09-10-sequencing-data-analysis-c-virginica-oil-spill-mbdseq-concatenation-fastqc/index.html",
    "title": "Sequencing Data Analysis - C.virginica Oil Spill MBDseq Concatenation & FastQC",
    "section": "",
    "text": "Per Steven’s request, I concatenated our Crassostrea virginica LSU oil spill MBDseq sequencing data and ran FastQC on the concatenated files.\nHere’s the list of input files:\n2112_lane1_ACAGTG_L001_R1_001.fastq.gz 2112_lane1_ACAGTG_L001_R1_002.fastq.gz 2112_lane1_ATCACG_L001_R1_001.fastq.gz 2112_lane1_ATCACG_L001_R1_002.fastq.gz 2112_lane1_ATCACG_L001_R1_003.fastq.gz 2112_lane1_CAGATC_L001_R1_001.fastq.gz 2112_lane1_CAGATC_L001_R1_002.fastq.gz 2112_lane1_CAGATC_L001_R1_003.fastq.gz 2112_lane1_GCCAAT_L001_R1_001.fastq.gz 2112_lane1_GCCAAT_L001_R1_002.fastq.gz 2112_lane1_TGACCA_L001_R1_001.fastq.gz 2112_lane1_TTAGGC_L001_R1_001.fastq.gz 2112_lane1_TTAGGC_L001_R1_002.fastq.gz\nAll commands were run on roadrunner (Apple Xserve; Ubuntu 16.04). See Jupyter notebook below for details.\nJupyter notebook (GitHub):\n\n20180910_roadrunner_virginica_fastqc.ipynb\n\n\n\nRESULTS:\nThe concatenated gzip files and FastQC/MultiQC files are in the output folder linked below.\nOutput folder:\n\n20180910_Cvirginica_oil_fastqc/\n\nMultiQC report (HTML):\n\n20180910_Cvirginica_oil_fastqc/multiqc_report.html"
  },
  {
    "objectID": "posts/2018/2018-05-29-transposable-element-mapping-crassostrea-virginica-ncbi-genome-assembly-using-repeatmasker-4-07/index.html",
    "href": "posts/2018/2018-05-29-transposable-element-mapping-crassostrea-virginica-ncbi-genome-assembly-using-repeatmasker-4-07/index.html",
    "title": "Transposable Element Mapping – Crassostrea virginica NCBI Genome Assembly using RepeatMasker 4.07",
    "section": "",
    "text": "Genome used: NCBI GCA_002022765.4_C_virginica-3.0\nI ran RepeatMasker (v4.07) with RepBase-20170127 and RMBlast 2.6.0 with species set to Crassotrea virginica.\nAll commands were documented in a Jupyter Notebook (GitHub):\n\n20180529_roadrunner_virginica_TEs_repeatmasker.ipynb\n\n\n\nRESULTS:\nOutput folder:\n\n20180529_virginica_repeatmasker\n\nOutput table (GFF):\n\nGCF_002022765.2_C_virginica-3.0_genomic.fasta.out.gff\n\nSummary table (text):\n\nGCF_002022765.2_C_virginica-3.0_genomic.fasta.tbl\n==================================================\nfile name: GCF_002022765.2_C_virginica-3.0_genomic.fasta\nsequences:            11\ntotal length:  684741128 bp  (684675328 bp excl N/X-runs)\nGC level:         34.83 %\nbases masked:   46637065 bp ( 6.81 %)\n==================================================\n               number of      length   percentage\n               elements*    occupied  of sequence\n--------------------------------------------------\nRetroelements        43139      8952068 bp    1.31 %\n   SINEs:            43139      8952068 bp    1.31 %\n   Penelope              0            0 bp    0.00 %\n   LINEs:                0            0 bp    0.00 %\n    CRE/SLACS            0            0 bp    0.00 %\n     L2/CR1/Rex          0            0 bp    0.00 %\n     R1/LOA/Jockey       0            0 bp    0.00 %\n     R2/R4/NeSL          0            0 bp    0.00 %\n     RTE/Bov-B           0            0 bp    0.00 %\n     L1/CIN4             0            0 bp    0.00 %\n   LTR elements:         0            0 bp    0.00 %\n     BEL/Pao             0            0 bp    0.00 %\n     Ty1/Copia           0            0 bp    0.00 %\n     Gypsy/DIRS1         0            0 bp    0.00 %\n       Retroviral        0            0 bp    0.00 %\n\nDNA transposons       3538      1564942 bp    0.23 %\n   hobo-Activator        0            0 bp    0.00 %\n   Tc1-IS630-Pogo        0            0 bp    0.00 %\n   En-Spm                0            0 bp    0.00 %\n   MuDR-IS905            0            0 bp    0.00 %\n   PiggyBac              0            0 bp    0.00 %\n   Tourist/Harbinger     0            0 bp    0.00 %\n   Other (Mirage,        0            0 bp    0.00 %\n    P-element, Transib)\n\nRolling-circles          0            0 bp    0.00 %\n\nUnclassified:        65151     23982146 bp    3.50 %\n\nTotal interspersed repeats:    34499156 bp    5.04 %\n\n\nSmall RNA:           43353      8992879 bp    1.31 %\n\nSatellites:              1          222 bp    0.00 %\nSimple repeats:     232627     10544162 bp    1.54 %\nLow complexity:      29762      1561018 bp    0.23 %\n==================================================\n\n* most repeats fragmented by insertions or deletions\n  have been counted as one element\n  Runs of >=20 X/Ns in query were excluded in % calcs\n\n\nThe query species was assumed to be crassostrea virginica\nRepeatMasker Combined Database: Dfam_Consensus-20170127, RepBase-20170127\n\nrun with rmblastn version 2.6.0+"
  },
  {
    "objectID": "posts/2018/2018-04-11-trimgalorefastqcmultiqc-2bp-3-end-read-1s-trim-c-virginica-mbd-bs-seq-fastq-data/index.html",
    "href": "posts/2018/2018-04-11-trimgalorefastqcmultiqc-2bp-3-end-read-1s-trim-c-virginica-mbd-bs-seq-fastq-data/index.html",
    "title": "TrimGalore/FastQC/MultiQC - 2bp 3’ end Read 1s Trim C.virginica MBD BS-seq FASTQ data",
    "section": "",
    "text": "Earlier today, I ran TrimGalore/FastQC/MultiQC on the Crassostrea virginica MBD BS-seq data from ZymoResearch and hard trimmed the first 14bp from each read. Things looked better at the 5’ end, but the 3’ end of each of the READ1 seqs showed a wonky 2bp blip, so decided to trim that off.\nI ran TrimGalore (using the built-in FastQC option), with a hard trim of the last 2bp of each first read set that had previously had the 14bp hard trim and followed up with MultiQC for a summary of the FastQC reports.\nTrimGalore job script:\n\n20180410_trimgalore_trim14bp_Cvirginica_MDB.sh\n\nStandard error was redirected on the command line to this file:\n\n20180410_trimgalore_trim14bp5prim_2bp3prime_Cvirginica_MBD/stderr.log\n\nMD5 checksums were generated on the resulting trimmed FASTQ files:\n\n20180410_trimgalore_trim14bp5prim_2bp3prime_Cvirginica_MBD/checksums.md5\n\nAll data was copied to my folder on Owl.\nChecksums for FASTQ files were verified post-data transfer (data not shown).\n\nResults:\nOutput folder:\n\n20180410_trimgalore_trim14bp5prim_2bp3prime_Cvirginica_MBD/\n\nFastQC output folder:\n\n20180410_trimgalore_trim14bp5prim_2bp3prime_Cvirginica_MBD/20180410_fastqc_trimgalore_14bp5prime_2bp3prime_Cvirginica_MBD/\n\nMultiQC output folder:\n\n20180410_trimgalore_trim14bp5prim_2bp3prime_Cvirginica_MBD/20180410_fastqc_trimgalore_14bp5prime_2bp3prime_Cvirginica_MBD/multiqc_data/\n\nMultiQC HTML report:\n\n20180410_trimgalore_trim14bp5prim_2bp3prime_Cvirginica_MBD/20180410_fastqc_trimgalore_14bp5prime_2bp3prime_Cvirginica_MBD/multiqc_data/multiqc_report.html\n\nWell, this is a bit strange, but the 2bp trimming on the read 1s looks fine, but now the read 2s are weird in the same region!\nRegardless, while this was running, Steven found out that the Bismarck documentation (Bismarck is the bisulfite aligner we use in our BS-seq pipeline) suggests trimming 10bp from both the 5’ and 3’ ends. So, maybe this was all moot. I’ll go ahead and re-run this following the Bismark recommendations."
  },
  {
    "objectID": "posts/2018/2018-10-02-ubuntu-fix-no-video-signal-issue-on-emu/index.html",
    "href": "posts/2018/2018-10-02-ubuntu-fix-no-video-signal-issue-on-emu/index.html",
    "title": "Ubuntu – Fix “No Video Signal” Issue on Emu",
    "section": "",
    "text": "An issue with Emu cropped up a few weeks ago that was seemingly caused by upgrading from Ubuntu 16.04 to 18.04.\nHowever, the problems only seemed related to using Emu via the GUI; users could still use Emu as a headless computer via SSH.\nToday, I was upgrading some packages and noticed two things:\n\nWhen initially logging in to Emu.\n\n<code>\nsam@swoose:~$ ssh emu\nWelcome to Ubuntu 16.04.5 LTS (GNU/Linux 4.4.0-57-generic x86_64)\n\n* Documentation:  https://help.ubuntu.com\n* Management:     https://landscape.canonical.com\n* Support:        https://ubuntu.com/advantage\n\n0 packages can be updated.\n0 updates are security updates.\n\nNew release '18.04.1 LTS' available.\nRun 'do-release-upgrade' to upgrade to it.\n\nYou have mail.\nLast login: Tue Oct  2 07:30:32 2018 from 128.95.149.75\n</code>\nThis is showing that Emu is still running Ubuntu 16.04, not 18.04 as presumed!\n\nAn error in the GRUB config generation process when upgrading packages.\n\n<code>\nrun-parts: executing /etc/kernel/postrm.d/zz-update-grub 4.4.0-134-generic /boot/vmlinuz-4.4.0-134-generic\nGenerating grub configuration file ...\nFound linux image: /boot/vmlinuz-4.4.0-137-generic\nFound initrd image: /boot/initrd.img-4.4.0-137-generic\nFound linux image: /boot/vmlinuz-4.4.0-135-generic\nFound initrd image: /boot/initrd.img-4.4.0-135-generic\nFound linux image: /boot/vmlinuz-4.4.0-57-generic\nFound initrd image: /boot/initrd.img-4.4.0-57-generic\nFound linux image: /boot/vmlinuz-4.4.0-53-generic\nFound initrd image: /boot/initrd.img-4.4.0-53-generic\nerror: syntax error.\nerror: Incorrect command.\nerror: syntax error.\nSyntax error at line 98\nSyntax errors are detected in generated GRUB config file.\nEnsure that there are no errors in /etc/default/grub\nand /etc/grub.d/* files or please file a bug report with\n/boot/grub/grub.cfg.new file attached.\ndone\nProcessing triggers for libc-bin (2.23-0ubuntu10) ...\n</code>\nThese two bits of information led me to believe the problem wasn’t that the system upgrade to 18.04 was incompatible with these old Apple Xserve hardware (since the upgrade didn’t actually get implemented) and instead was that the upgrade might have been initiated, but aborted, which modified the GRUB configuration file(s), breaking the GUI; much like the problem I previously addressed earlier this summer.\nWhen I fixed the display/GUI issues with Emu and Roadrunner earlier this summer, I noted that the /etc/default/grub files on each of the computers were slightly different, despite the fact that these two computers should be identical. So, I replaced the /etc/default/grub file on Emu with the file from Roadrunner and rebooted Emu.\nContents of /etc/default/grub file on Emu/Roadrunner, for future reference:\n<code>\n# If you change this file, run 'update-grub' afterwards to update\n# /boot/grub/grub.cfg.\n# For full documentation of the options in this file, see:\n#   info -f grub -n 'Simple configuration'\n\nGRUB_DEFAULT=0\n#GRUB_HIDDEN_TIMEOUT=0\nGRUB_HIDDEN_TIMEOUT_QUIET=true\nGRUB_TIMEOUT=10\nGRUB_DISTRIBUTOR=`lsb_release -i -s 2> /dev/null || echo Debian`\nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash\"\nGRUB_CMDLINE_LINUX=\"\"\n\n# Uncomment to enable BadRAM filtering, modify to suit your needs\n# This works with Linux (no patch required) and with any kernel that obtains\n# the memory map information from GRUB (GNU Mach, kernel of FreeBSD ...)\n#GRUB_BADRAM=\"0x01234567,0xfefefefe,0x89abcdef,0xefefefef\"\n\n# Uncomment to disable graphical terminal (grub-pc only)\n#GRUB_TERMINAL=console\n\n# The resolution used on graphical terminal\n# note that you can use only modes which your graphic card supports via VBE\n# you can see them in real GRUB with the command `vbeinfo'\n#GRUB_GFXMODE=640x480\n\n# Uncomment if you don't want GRUB to pass \"root=UUID=xxx\" parameter to Linux\n#GRUB_DISABLE_LINUX_UUID=true\n\n# Uncomment to disable generation of recovery mode menu entries\n#GRUB_DISABLE_RECOVERY=\"true\"\n\n# Uncomment to get a beep at grub start\n#GRUB_INIT_TUNE=\"480 440 1\"\n</code>\nVoila! Emu now has a functional display/GUI again!"
  },
  {
    "objectID": "posts/2018/2018-10-16-qpcr-ronits-dnased-c-gigas-ploidydessication-rna-with-18s-primers/index.html",
    "href": "posts/2018/2018-10-16-qpcr-ronits-dnased-c-gigas-ploidydessication-rna-with-18s-primers/index.html",
    "title": "qPCR - Ronit’s DNAsed C.gigas Ploidy/Dessication RNA with 18s primers",
    "section": "",
    "text": "After DNasing Ronit’s RNA earlier today, I needed to check for any residual gDNA.\nIdentified some old, old C.gigas 18s primers that should amplify gDNA:\n\ngigas18s_fw (SRID 157)\ngigas18s_rv (SRID 156)\n\nUsed some old C.gigas gDNA (BB15 from 20090519) as a positive control.\nSamples were run on Roberts Lab CFX Connect (BioRad). All samples were run in duplicate. See qPCR Report (Results section) for plate layout, cycling params, etc.\nqPCR master mix calcs (Google Sheet):\n\n20181016_qPCR_Cgigas_DNased_RNA\n\n\n\nResults\nqPCR Report (PDF):\n\nsam_2018-10-16 2011-13-55_BR006896.pdf\n\nqPCR File (PCRD):\n\nsam_2018-10-16 2011-13-55_BR006896.pcrd\n\nqPCR Data (CSV):\n\nsam_2018-10-16_11-13-55_BR006896-Quantification_Cq_Results.csv\n\nWell, this primer set and/or the gDNA is not good. In the plots below, the positive control gNDA is in green, samples in blue, and no template controls (NTC) are in red.\nPoor performance is most easily noticed when looking at the melt curves. They have multiple peaks, suggesting non-specific amplification, even in the positive control.\nAdditionally, although less evident from just looking at the plots, is the replicates are highly inconsistent. Although it’s possible that might be due to poor technique, it’s very unlikely.\nWill have to identify different primers and/or positive control DNA.\n\n\nAmplification Plots\n\n\n\n\nMelt Curves"
  },
  {
    "objectID": "posts/2018/2018-10-02-installation-microsoft-machine-learning-server-microsoft-r-open-on-emuroadrunner-r-studio-server/index.html",
    "href": "posts/2018/2018-10-02-installation-microsoft-machine-learning-server-microsoft-r-open-on-emuroadrunner-r-studio-server/index.html",
    "title": "Installation - Microsoft Machine Learning Server (Microsoft R Open) on Emu/Roadrunner R Studio Server",
    "section": "",
    "text": "Steven recently saw an announcement that Microsoft R Open now handles multi-threaded processing (default R does not), so we were interested in trying it out. I installed MLR/MRO on Emu/Roadrunner (Apple Xserve; Ubuntu 16.04). Followed the Microsoft installation directions for Ubuntu. In retrospect, I think I could’ve just installed MRO, but this gets the job done as well and won’t hurt anything.\nI’ve set both Emu & Roadrunner R Studio Server to use this installation of R by changing the /etc/restudio/rserver.conf file to the following:\n<code>\n# Server Configuration File\n\n# Use Microsoft R Open instead of default R version.\n# Comment out and restart R Studio Server (sudo rstudio-server restart)\n# to restore default R version.\n\nrsession-which-r=/opt/microsoft/ropen/3.4.3/lib64/R/bin/R\n</code>\nI have confirmed that R Studio Server on both machines starts up and is using MRO instead of the default version of R."
  },
  {
    "objectID": "posts/2018/2018-09-19-transcriptome-assembly-olympia-oyster-rnaseq-data-with-trinity/index.html",
    "href": "posts/2018/2018-09-19-transcriptome-assembly-olympia-oyster-rnaseq-data-with-trinity/index.html",
    "title": "Transcriptome Assembly - Olympia oyster RNAseq Data with Trinity",
    "section": "",
    "text": "Used all of our current oly RNAseq data to assemble a transcriptome using Trinity.\nTrinity was run our our Mox HPC node.\nReads were trimmed using the built-in version of Trimmomatic with the default settings.\nSBATCH script:\n\n20180827_oly_trinity.sh\n\nDespite the naming conventions, this job was submitted to the Mox scheduler on 201800912 and finished on 20180913.\nAfter job completion, the entire folder was gzipped, using an interactive node (the following method of gzipping is SUPER fast, btw):\n<code>tar -c 20180827_trinity_oly_RNAseq | pigz > 20180827_trinity_oly_RNAseq.tar.gz</code>\n\n\nRESULTS:\nOutput folder:\n\n20180827_trinity_oly_RNAseq/\n\nTrinity assembly (FastA):\n\n20180827_trinity_oly_RNAseq/Trinity.fasta\n\nNext up, I’ll follow up on this GitHub issue and get some bedgraphs generated."
  },
  {
    "objectID": "posts/2018/2018-04-09-trimgalorefastqcmultiqc-auto-trim-c-virginica-mbd-bs-seq-fastq-data/index.html",
    "href": "posts/2018/2018-04-09-trimgalorefastqcmultiqc-auto-trim-c-virginica-mbd-bs-seq-fastq-data/index.html",
    "title": "TrimGalore/FastQC/MultiQC - Auto-trim C.virginica MBD BS-seq FASTQ data",
    "section": "",
    "text": "Yesterday, I ran FastQC/MultiQC on the Crassostrea virginica MBD BS-seq data from ZymoResearch. Steven wanted to trim it and see how things turned out.\nI ran TrimGalore (using the built-in FastQC option) and followed up with MultiQC for a summary of the FastQC reports.\nTrimGalore job script:\n\n20180409_trimgalore_autotrim_Cvirginica_MBD.sh\n\nStandard error was redirected on the command line to this file:\n\n20180409_trimgalore_autotrim_Cvirginica_MBD/stderr.log\n\nMD5 checksums were generated on the resulting trimmed FASTQ files:\n\n20180409_trimgalore_autotrim_Cvirginica_MBD/checksums.md5\n\nAll data was copied to my folder on Owl.\nChecksums for FASTQ files were verified post-data transfer.\n\nResults:\nOutput folder:\n\n20180409_trimgalore_autotrim_Cvirginica_MBD/\n\nFastQC output folder:\n\n20180409_trimgalore_autotrim_Cvirginica_MBD/20180409_fastqc_trimgalore_autotrim_Cvirginica_MBD/\n\nMultiQC output folder:\n\n20180409_trimgalore_autotrim_Cvirginica_MBD/20180409_fastqc_trimgalore_autotrim_Cvirginica_MBD/multiqc_data/\n\nMultiQC HTML report:\n\n20180409_trimgalore_autotrim_Cvirginica_MBD/20180409_fastqc_trimgalore_autotrim_Cvirginica_MBD/multiqc_data/multiqc_report.html\n\nOverall, the auto-trim didn’t alter things too much. Specifically, Steven is concerned about the variability in the first 15bp (seen in the Per Base Sequence Content section of the MultiQC output). It was reduced, but not greatly. Will perform an independent run of TrimGalore and employ a hard trim of the first 14bp of each read and see how that looks."
  },
  {
    "objectID": "posts/2018/2018-02-01-titrator-setup-functional-methods-data-exports/index.html",
    "href": "posts/2018/2018-02-01-titrator-setup-functional-methods-data-exports/index.html",
    "title": "Titrator Setup - Functional Methods & Data Exports",
    "section": "",
    "text": "I’ve been working on getting our T5 Excellence titrator (Mettler Toledo) with Rondolino sample changer (Mettler Toledo) set up and operational.\nA significant part of the setup process is utilizing the LabX Software (Mettler Toledo, v.8.0.0). The software is vastly overpowered (i.e. overly complicated) for the nature of our work. As such, it’s been quite the struggle to get the titrator to do what we need it to do.\nWe’ve received a great deal of help and insight from Dr. Hollie Putnam (Univ. of Rhode Island). She provided us with a LabX Method that was previously used by some of her colleagues. In addition, she provided us with an SOP from those colleagues that helps describe how to physically operate the titrator and a corresponding workflow for data collection. Of course, she’s also helped immensely with understanding the entire process of the chemistry to how to process samples to implementing various quality control checks to ensure we’ll get the most accurate data we can.\nAfter some significant struggles with getting the method to work properly, I contacted Mettler Toledo and the technician helped me modify the method that Hollie passed along to us to run properly.\n\n\nBasic Functionality Fixes\nThe updated method resolves the following issues we were having (see annotated screenshot below the lists for more detailed overview of method changes):\n\nMethod only ends titration at specified maximum volume instead of specified potential\nMethod exits with Sample State = “Not OK”\nMethod fails to calculate acid Consumption at end of titration\n\nI also modified the method to bring it up to spec with the Dickson Guide to Best Practices for Ocean CO2 Measurements- SOP3b:\n\nChanged method template to use Endpoint (EP) titration instead of Equivalence Point (EQP) titration\nImplemented initial titration step to pH=3.5 (200mV)\nAdded degassing step to match Dickson specs (increase stir speed and duration)\nImproved titration precision by changing titration rate to automatically adjust relative to set endpoint values\nSet correct voltages for pH=3.5 (200mV) & pH=3.0 (228.57mV); no need to adjust prior to running method\n\nI recommend opening the image below in a new tab in order to be able to read all of the annotations.\n\nSo, all of that stuff makes the method actually run according to the Dickson specs. It also fixes the Consumption calculation. Although this aspect of the method is totally unnecessary (the consumption calculation could easily be integrated in downstream analysis), it feels good to have fixed the issue and learn how that aspect of the LabX software functions.\n\n\n\nData Export Fixes\nWe recently acquired the necessary license to unlock the ability to export data.\n\nDigression:\nThis is a terrible practice implemented by Mettler Toledo, btw. I’m particularly annoyed because I specifically asked about data exports when I spoke with the sales rep when initiating the purchase. He neglected to mention that I’d need to purchase an additional license. I wasted a lot of time and hair pulling before I learned that this feature was locked by design and that I needed this additional license.\nAnyway, the struggles continued even after activating the license. I was not able to export any data - every attempt at specifying a directory in which to save data failed.\nMettler Toledo informed me that it has to do with Windows Services Permissions.\nTo change permissions to allow data export:\n\nSearch Windows for “Services”\nOpen “Services”\nRight-click on “LabXHostService”\nSelect “Properties”\nClick “Log On” tab.\nClick “Local System Account” radio button.\nCheck “Allow service to interact with desktop” box.\nRestart computer.\n\nNow, the data gets automatically exported to my desired directory as soon as a LabX task is finished!!\n\n\n\n\nData Management & Informational Resources\nAs we are very close to beginning to actually collect data with the titrator, I realized that all this data needs to go somewhere. Additionally, people need someplace to find out how to use all of this stuff (equipment, software, etc.).\nI created a new GitHub repo: RobertsLab/titrator\nPlease feel free to look through it and post any ideas to the Issues section of the repo.\nIn my mind, this will be a “master” data repository for all measurements conducted on the titrator. All daily pH calibration data should get pushed to this repo. Any sample titration data should also end up on this repo. Basically, all the raw data coming off the machine each time it is used should end up in this repo. I think this will reduce data fragmentation (e.g. I perform measurements on a subset of samples one day and put the data in my folder on Owl. Then Grace performs measurements on the remaining samples and uploads those data to her folder on Owl. Now, the complete data set for an experiment is split between two different locations, making it difficult to find.)\nAlthough this single data repository approach won’t eliminate fragmentation (it can’t be avoided since the Rondolino sample changer can only hold nine samples), I think it will be beneficial to know that all the data is in a single location.\nThis repo will also be a resource for SOPs and troubleshooting. A detailed SOP is currently in development (being modified from the SOP Hollie originally sent us) which will detail daily startup/shutdown procedures, running scripts to process data, and guides on how to evaluate quality control procedures at various points throughout the titration process.\nFinally, it will also contain the necessary scripts that we develop for data grooming and analysis.\n\n\n\nWhat’s Left?\n\nEquipment\nWe only need one final physical component to actually begin collecting data. After reviewing the Dickson SOP3b and speaking with Hollie, it turns out we need an aquarium pump and rotameter (acquired this week) to sparge our samples; this aids in degassing prior to the titration from pH=3.5 to pH=3.0. Just waiting on tubing and tubing adapters for the rotameter. Once we have this, I should be able to start powering through samples.\nInitial testing of the titrator (even without the full physical setup in place) shows highly consistent, reproducible measurements - both with pH calibration values and with total alkalinity (TA) determinations on Instant Ocean seawater. As such, I’m confident that I won’t have very much testing left to do once I can start bubbling air into the samples.\n\n\nSoftware\nAlthough these things are not necessary in order to start acquiring data, they will be necessary for performing TA calculations and, eventually be desired for analyzing and reporting TA calculations in near real-time (the end goal is to have this titrator setup in a wet lab where water TA calculations can be determined on the spot, as opposed to being stored and analyzed at a later time).\nA to-do list is outlined here: RobertsLab/titrator/issues/1"
  },
  {
    "objectID": "posts/2018/2018-04-05-gunzip-bgi-hiseq-geoduck-genome-sequencing-data/index.html",
    "href": "posts/2018/2018-04-05-gunzip-bgi-hiseq-geoduck-genome-sequencing-data/index.html",
    "title": "Gunzip - BGI HiSeq Geoduck Genome Sequencing Data",
    "section": "",
    "text": "In preparation to run SpareAssembler, I needed to gunzip the BGI gzipped FASTQ files from 20180327.\nRan the following slurm script on our Mox node:\n<code>\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=20180405_geoduck_bgi_gunzip\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes (We only get 1, so this is fixed)\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=30-00:00:00\n## Memory per node\n#SBATCH --mem=500G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --workdir=/gscratch/scrubbed/samwhite/bgi_geoduck\n\nfor i in /gscratch/scrubbed/samwhite/bgi_geoduck/*.gz; do\n    filename=\"${i##*/}\"\n    no_ext=\"${filename%%.*}\"\n    gunzip < \"$i\" > \"$no_ext\".fastq\ndone\n</code>\n\nResults:\nCompleted in ~45mins. Will proceed with massive geoduck genome assembly!"
  },
  {
    "objectID": "posts/2018/2018-02-07-ethanol-precipitation-dna-quantification-c-virginica-mbd-dna-from-yaamini/index.html",
    "href": "posts/2018/2018-02-07-ethanol-precipitation-dna-quantification-c-virginica-mbd-dna-from-yaamini/index.html",
    "title": "Ethanol Precipitation & DNA Quantification - C. virginica MBD DNA from Yaamini",
    "section": "",
    "text": "Finished the ethanol precipitation as described in the MethylMiner (Invitrogen) manual which Yaamini had previously initiated: https://yaaminiv.github.io/Virginica-MBDSeq-Day4/\nSamples were resuspended in 25μL of Buffer EB (Qiagen) and transferred to 0.5mL snap cap tubes. All tubes were labeled as: MBD CV #\nQuantified the Crassostrea virginica MBD-enriched DNA with the Qubit 3.0 (ThermoFisher) and the Qubit dsDNA High Sensitivity (HS) Kit (ThermoFisher).\nUsed 1uL of template DNA.\nResults:\nQuantification Spreadsheet (Google Sheet):20180207_qubit_DNA_HS_MBD_virginica\nOne sample (MBD CV 106) may not be usable due to low yield. However, the remainder should work fine.\nI’ve sent them all to ZymoResearch for bisulfite treatment, library construction, and Illumina sequencing.\nFedEx tracking: 771429590026"
  },
  {
    "objectID": "posts/2018/2018-05-31-bs-seq-mapping-olympia-oyster-bisulfite-sequencing-bismark-continued/index.html",
    "href": "posts/2018/2018-05-31-bs-seq-mapping-olympia-oyster-bisulfite-sequencing-bismark-continued/index.html",
    "title": "BS-seq Mapping – Olympia oyster bisulfite sequencing: Bismark Continued",
    "section": "",
    "text": "Previously took the analysis just through the mapping, but didn’t realize Steven wanted me to fully process the data.\nSo, as en exercise, I followed through with deduplication and sorting of the BAM files.\nThen, ran a quick analysis using MethylKit in R. The analysis simply copied what Steven had done with another data set and I haven’t examined it very thoroughly, so am not well-versed on what it’s doing and/or why.\nJupyter Notebook (GitHub):\n\n20180530_emu_oly_methylation_mapping_deduplication.ipynb\n\nR Studio Project (download the folder, load project in R Studio, and then run the script in the scripts subdirectory to run the analysis):\n\n20180531_oly_methylkit/\n\nWill take the full data sets through this whole pipeline."
  },
  {
    "objectID": "posts/2018/2018-01-10-dna-quantification-c-virginica-mbd-enriched-dna/index.html",
    "href": "posts/2018/2018-01-10-dna-quantification-c-virginica-mbd-enriched-dna/index.html",
    "title": "DNA Quantification - C.virginica MBD-enriched DNA",
    "section": "",
    "text": "Quantified Crassostrea virginica MBD-enriched DNA from earlier today for Qiagen project.\nUsed the Qubit 3.0 (ThermoFisher) and the Qubit dsDNA Broad Range (BR) Kit (ThermoFisher).\nUsed 1uL of template DNA.\nResults:\nQuantification Spreadsheet (Google Sheet): 20180110_qubit_dsDNA_BR_MBD_virginica\nBoth samples had decent yields and have usable quantities for Qiagen (they wanted ~300ng from each sample):\nvirginica_MBD_01 - 18.3ng/uL (457.5ng = 5.7% methylated DNA capture)\nvirginica_MBD_02 - 19.6ng/uL (490ng = 6.1% methylated DNA capture)\nWill store @ -20C until next week so that we’re not shipping so close to the weekend (shipping address is in Germany)."
  },
  {
    "objectID": "posts/2018/2018-03-22-assembly-geoduck-novaseq-using-sparseassembler-tldr-it-worked/index.html",
    "href": "posts/2018/2018-03-22-assembly-geoduck-novaseq-using-sparseassembler-tldr-it-worked/index.html",
    "title": "Assembly - Geoduck NovaSeq using SparseAssembler (TL;DR - it worked!)",
    "section": "",
    "text": "The prior attempt using SparseAssembler failed due to a kmer size that was deemed too large.\nFor this run, I arbitrarily reduced the kmer size by ~half (k 61) in hopes that this will just get through an assembly. We can potentially explore the effects of kmer size on assemblies if/when this runs and depending no how the assembly looks.\nThe job was run on our Mox node.\nHere’s the batch script to initiate the job:\n[code lang=text] #!/bin/bash ## Job Name #SBATCH –job-name=20180313_sparse_assembler_geo_novaseq ## Allocation Definition #SBATCH –account=srlab #SBATCH –partition=srlab ## Resources ## Nodes (We only get 1, so this is fixed) #SBATCH –nodes=1 ## Walltime (days-hours:minutes:seconds format) #SBATCH –time=30-00:00:00 ## Memory per node #SBATCH –mem=500G ##turn on e-mail notification #SBATCH –mail-type=ALL #SBATCH –mail-user=samwhite@uw.edu ## Specify the working directory for this job #SBATCH –workdir=/gscratch/scrubbed/samwhite/20180312_SparseAssembler_novaseq_geoduck\n/gscratch/srlab/programs/SparseAssembler/SparseAssembler LD 0 NodeCovTh 1 EdgeCovTh 0 k 61 g 15 PathCovTh 100 GS 2200000000 i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/AD002_S9_L001_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/AD002_S9_L001_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/AD002_S9_L002_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/AD002_S9_L002_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR005_S4_L001_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR005_S4_L001_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR005_S4_L002_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR005_S4_L002_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR006_S3_L001_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR006_S3_L001_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR006_S3_L002_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR006_S3_L002_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR012_S1_L001_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR012_S1_L001_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR012_S1_L002_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR012_S1_L002_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR013_AD013_S2_L001_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR013_AD013_S2_L001_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR013_AD013_S2_L002_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR013_AD013_S2_L002_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR014_AD014_S5_L001_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR014_AD014_S5_L001_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR014_AD014_S5_L002_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR014_AD014_S5_L002_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR015_AD015_S6_L001_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR015_AD015_S6_L001_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR015_AD015_S6_L002_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR015_AD015_S6_L002_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR019_S7_L001_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR019_S7_L001_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR019_S7_L002_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR019_S7_L002_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR021_S8_L001_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR021_S8_L001_R2_001_val_2_val_2.fastq i1 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR021_S8_L002_R1_001_val_1_val_1.fastq i2 /gscratch/scrubbed/samwhite/20180129_trimmed_again/NR021_S8_L002_R2_001_val_2_val_2.fastq [/code]\n\nResults\nOutput folder: 20180312_SparseAssembler_novaseq_geoduck\nIT WORKED!!! At last; we have an assembly of the geoduck NovaSeq data!! It took ~10days to complete.\nThe primary output file of interest is this FASTA file:\n\n[Contigs.txt (11GB)(https://owl.fish.washington.edu/Athaliana/20180312_SparseAssembler_novaseq_geoduck/Contigs.txt)\n\nIn order to get a rough idea of how this assembly looks, I ran it through Quast Version: 4.5, 15ca3b9:\npython software/quast-4.5/quast.py \\ -t 16  /mnt/owl/Athaliana/20180312_SparseAssembler_novaseq_geoduck/Contigs.txt\nQuast output folder: results_2018_03_22_08_12_12\nHere’re the stats on the assembly:\nQuast output (text): results_2018_03_22_08_12_12/report.txt\nQuast output (HTML):results_2018_03_22_08_12_12/report.html\n\n\nOverall, the assembly doesn’t look great. The N50 = 645 is really, really low. One would hope for a much large number for a quality assembly. As it stands, this assembly is comprised of many small contigs.\nLooks like we’ll have to fiddle with the kmer size used for SparseAssembler and see if we can improve upon this.\nDespite that, it’s an accomplishment to finally get any sort of assembler to run to completion for this data set!"
  },
  {
    "objectID": "posts/2018/2018-04-21-kmer-estimation-kmergenie-k-301-on-geoduck-sequence-data/index.html",
    "href": "posts/2018/2018-04-21-kmer-estimation-kmergenie-k-301-on-geoduck-sequence-data/index.html",
    "title": "Kmer Estimation – Kmergenie (k 301) on Geoduck Sequence Data",
    "section": "",
    "text": "Continuing the quest for the ideal kmer size to use for our geoduck assembly.\nThe previous two runs with kmergenie using the diploid setting were no good.\nSo, this time, I simply increased the maximum kmer size to 301 and left all other settings as default. I’m hoping this is large enough to produce a smooth curve, with a maximal value that can be determined from the output graph.\nThe job was run on our Mox HPC node.\n\nSlurm script: 20180421_kmergenie_k301_geoduck_slurm.sh\n\n\nResults:\nOutput folder:\n\n20180421_kmergenie_k301_geoduck/\n\nSlurm output file:\n\n20180421_kmergenie_k301_geoduck/slurm-163019.out\n\nKmer histogram (HTML) reports:\n\n20180421_kmergenie_k301_geoduck/histograms_report.html\n\n\nWell, the graph is closer to what we’d expect, in that it appears to reach a zenith, but after that plateau, we see a sharp dropoff, as opposed to a gradual dropoff that mirrors the left half. Not entirely sure what the implications for this are, but I’ll go ahead an run SparseAssembler using a kmer size of 131 and see how it goes."
  },
  {
    "objectID": "posts/2018/2018-01-16-assembly-comparisons-oly-assemblies-using-quast/index.html",
    "href": "posts/2018/2018-01-16-assembly-comparisons-oly-assemblies-using-quast/index.html",
    "title": "Assembly Comparisons – Oly Assemblies Using Quast",
    "section": "",
    "text": "I ran Quast to compare all of our current Olympia oyster genome assemblies.\nSee Jupyter Notebook in Results section for Quast execution.\n\nResults:\nOutput folder: https://owl.fish.washington.edu/Athaliana/quast_results/results_2018_01_16_10_08_35/\nHeatmapped table of results: https://owl.fish.washington.edu/Athaliana/quast_results/results_2018_01_16_10_08_35/report.html\nVery enlightening!\nAfter all the difficulties with PB Jelly, it has produced the most large contigs. However, it does also have the highest quantity and rate of N’s of all the assemblies produced to date.\n\nBEST OF:\n\n\n\ncontigs (>= 50000 bp): pbjelly_sjw_01 (894)\nLargest Contig: redundans_sjw_02 (322,397bp) Total Length: pbjelly_sjw_01 (1,180,563,613bp) Total Length (>=50,000bp): pbjelly_sjw_01 (57,741,906bp) N50: redundans_sjw_03 (17,679bp)\nJupyter Notebook (GitHub): 20180116_swoose_oly_assembly_comparisons_quast.ipynb"
  },
  {
    "objectID": "posts/2018/2018-07-05-ubuntu-fix-no-video-signal-issue-on-emuroadrunner/index.html",
    "href": "posts/2018/2018-07-05-ubuntu-fix-no-video-signal-issue-on-emuroadrunner/index.html",
    "title": "Ubuntu - Fix “No Video Signal” Issue on Emu/Roadrunner",
    "section": "",
    "text": "Both Apple Xserves (Emu/Roadrunner) running Ubuntu (16.04LTS) experienced the same issue - the monitor would indicate “No Video Signal”, would go dark, and wasn’t responsive to keyboard/mouse movements. However, you could ssh into both machines w/o issue.\nAlthough having these machines be “headless” (i.e. with no display) is usually fine, it’s not ideal for a couple of reasons:\n\nDifficult to use for other lab members who aren’t as familiar with SSH - specifically if they would want to use a Jupyter Notebook remotely (this would require setting up a tunnel to their own computer).\nCan’t use Remmina Remote Desktop until a user has physically logged in from the Ubuntu login screen at least once, in order to launch Remmina.\n\nThe second aspect was the major impetus in me finally being motivated to deal with this. Accessing these computers via remote desktop is much easier to manage long-running Jupyter Notebooks instead of relying on an SSH tunnel. The tunnel greatly limits my access to the Jupyter Notebook outside of the computer that has the tunnel set up.\nWell, this led me down a horrible rabbit hole of Linux stuff that I won’t get fully in to (particularly, since I didn’t understand most of it and can’t remember all the crazy stuff I read/tried).\nHowever, here’s the gist:\n\nNeeded to edit /etc/default/grub\nAfter editing, needed to update grub config file: sudo update-grub\n\nDespite the fact that both machines are (or, should be) identical, I did not get the same results. The edits I made to the /etc/default/grub file on Emu worked immediately. The edits were:\n\nAdd nomodeset to this (this is the edited line) line (this seemed to be the most common suggestion for fixing the “No Video Signal” issue):\n\nGRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash nomodeset\"\n\nComment out this line (this line was triggering an error/warning about writing the config file when running the update-grub command):\n\n#GRUB_HIDDEN_TIMEOUT=0\nFor some reason, Roadrunner did not take kindly to those changes and it took a long time to resolve, ending with changing permissions on ~/.Xauthority back to their original permissions (they got altered when I ran some command - sudo startx or something) to get out of a login loop.\nRegardless, both are fixed, both can be used when physically sitting at the computer, and both can be accessed remotely using Remmina!"
  },
  {
    "objectID": "posts/2018/2018-05-16-trimgalorefastqcmultiqc-trimgalore-rrbs-geoduck-bs-seq-fastq-data/index.html",
    "href": "posts/2018/2018-05-16-trimgalorefastqcmultiqc-trimgalore-rrbs-geoduck-bs-seq-fastq-data/index.html",
    "title": "TrimGalore/FastQC/MultiQC – TrimGalore! RRBS Geoduck BS-seq FASTQ data",
    "section": "",
    "text": "20180516 - UPDATE!!\n\nTHIS WAS RUN WITH THE INCORRECT SETTING IN TRIMGALORE! --non-directional\n\n\nWILL RE-RUN\n\nSteven requested that I trim the Geoduck RRBS libraries that we have, in preparation to run them through Bismark.\nThese libraries were originally created by Hollie Putnam using the TruSeq DNA Methylation Kit (Illumina):\n\nproject_juvenile_geoduck_OA/Sample_Processing (GitHub)\n\nAll analysis is documented in a Jupyter Notebook; see link below.\nOverview of process:\n\nCopy EPI* FastQ files from owl/P_generosa to roadrunner.\nConfirm data integrity via MD5 checksums.\nRun TrimGalore! with --paired, --rrbs, and --non-directional settings.\nRun FastQC and MultiQC on trimmed files.\nCopy all data to owl (see Results below for link).\nConfirm data integrity via MD5 checksums.\n\nJupyter Notebook:\n\n20180514_roadrunner_geoduck_RRBS_trimming.ipynb (GitHub)\n\n\n\nResults:\n\nTrimGalore! output folder:\n\n20180514_geoduck_trimgalore_rrbs\n\n\n\nFastQC output folder:\n\n20180514_geoduck_trimgalore_rrbs/20180514_geoduck_trimmed_fastqc/\n\n\n\nMultiQC output folder:\n\n20180514_geoduck_trimgalore_rrbs/20180514_geoduck_trimmed_fastqc/multiqc_data\n\n\n\nMultiQC report (HTML):\n\nmultiqc_report.html"
  },
  {
    "objectID": "posts/2018/2018-10-03-sra-submission-olymia-oyster-whole-genome-bs-seq-data/index.html",
    "href": "posts/2018/2018-10-03-sra-submission-olymia-oyster-whole-genome-bs-seq-data/index.html",
    "title": "SRA Submission - Olymia oyster Whole Genome BS-seq Data",
    "section": "",
    "text": "Submitted our whole genome bisulfite sequencing data to NCBI Sequence Read Archive (SRA).\nRelevant SRA info is below.\nHave updated nightingales Google Sheet with SRA info.\n\n\n\nSAMPLE\nSRA (study)\nBioProject\nBioSample\n\n\n\n\n1NF11\nSRP163248\nPRJNA494552\nSAMN10172233\n\n\n1NF15\nSRP163248\nPRJNA494552\nSAMN10172234\n\n\n1NF16\nSRP163248\nPRJNA494552\nSAMN10172235\n\n\n1NF17\nSRP163248\nPRJNA494552\nSAMN10172236\n\n\n2NF5\nSRP163248\nPRJNA494552\nSAMN10172237\n\n\n2NF6\nSRP163248\nPRJNA494552\nSAMN10172238\n\n\n2NF7\nSRP163248\nPRJNA494552\nSAMN10172239\n\n\n2NF8\nSRP163248\nPRJNA494552\nSAMN10172240"
  },
  {
    "objectID": "posts/2018/2018-09-12-dna-quantification-sea-lice-dna-from-20180523/index.html",
    "href": "posts/2018/2018-09-12-dna-quantification-sea-lice-dna-from-20180523/index.html",
    "title": "DNA Quantification - Sea Lice DNA from 20180523",
    "section": "",
    "text": "We previously received sea lice (Caligus tape) DNA from Cris Gallardo-Escarate at Universidad de Concepción.\nSteven asked that I quantify and assess the DNA quality.\nRan the samples on the Roberts Lab Qubit 3.0 using the dsDNA BR assay (Invitrogen) and 1uL of template DNA.\nRan the samples on the Roberts Lab NanoDrop1000 to get 260/280 values for quality assessment using 2uL of template DNA. NanoDrop1000 was blanked with water, but I don’t know what solvent the DNA is currently resuspended in.\n\n\nRESULTS\nQubit data (Google Sheet):\n\n20180912_qubit_DNA_sea_lice\n\n\n\nSAMPLE CONCENTRATION (ng/uL)\n\n\n\n\n\nFEMALE 1\n\n\n23.8\n\n\n\n\nFEMALE 2\n\n\n9.6\n\n\n\n\n\n\nNANODROP DATA\n\nTABLE\n\n\n\n\nABSORBANCE PLOTS\n\n\nDNA looks super clean. Not sure what this DNA is intended for so can’t speculate much on what the implications might be for the concentrations on downstream usage."
  },
  {
    "objectID": "posts/2018/2018-09-24-bedgraph-olympia-oyster-transcriptome-fail/index.html",
    "href": "posts/2018/2018-09-24-bedgraph-olympia-oyster-transcriptome-fail/index.html",
    "title": "Bedgraph - Olympia oyster transcriptome (FAIL)",
    "section": "",
    "text": "Progress on generating bedgraphs from our Olympia oyster transcriptome continues.\nTranscriptome assembly with Trinity completed 20180919.\nThen, aligned the assembled transcriptome to our genome using Bowtie2.\nFinally, I used BEDTools to convert the BAM to BED to bedgraph.\nThis required an initial indexing of our Olympia oyster genome FastA using samtools faidx tool.\nSBATCH script file:\n\n20180924_oly_RNAseq_bedgraphs.sh\n #!/bin/bash ## Job Name #SBATCH –job-name=20180924_oly_bedgraphs ## Allocation Definition #SBATCH –account=srlab #SBATCH –partition=srlab ## Resources ## Nodes #SBATCH –nodes=1 ## Walltime (days-hours:minutes:seconds format) #SBATCH –time=5-00:00:00 ## Memory per node #SBATCH –mem=500G ##turn on e-mail notification #SBATCH –mail-type=ALL #SBATCH –mail-user=samwhite@uw.edu ## Specify the working directory for this job #SBATCH –workdir=/gscratch/scrubbed/samwhite/20180924_oly_RNAseq_bedgraphs\nLoad Python Mox module for Python module availability\nmodule load intel-python3_2017\nDocument programs in PATH (primarily for program version ID)\ndate >> system_path.log echo “” >> system_path.log echo “System PATH for $SLURM_JOB_ID” >> system_path.log echo “” >> system_path.log printf “%0.s-” {1..10} >> system_path.log echo ${PATH} | tr : \\n >> system_path.log\nSet genome assembly FastA\noly_genome_fasta=/gscratch/srlab/sam/data/O_lurida/oly_genome_assemblies/Olurida_v081.fa\nSet indexed genome assembly file\noly_genome_indexed=/gscratch/srlab/sam/data/O_lurida/oly_genome_assemblies/Olurida_v081.fa.fai\nSet sorted transcriptome assembly bam file\noly_transcriptome=/gscratch/scrubbed/samwhite/20180919_oly_transcriptome_bowtie2/20180919_Olurida_v081.sorted.bam\nSet program paths\nbedtools=/gscratch/srlab/programs/bedtools-2.27.1/bin samtools=/gscratch/srlab/programs/samtools-1.9/samtools\nIndex genome FastA\n${samtools} faidx ${oly_genome_fasta}\nFormat indexed genome for bedtools\nRequires only two columns: namelength\nawk -v OFS=‘ {’print $1,$2’} ${oly_genome_indexed} > Olurida_v081.fa.fai.genome\nCreate bed file\n${bedtools}/bamToBed\n-i ${oly_transcriptome}\n> 20180924_oly_RNAseq.bam.bed\nCreate bedgraph\nReports depth at each position (-bg in bedgraph format) and report regions with zero coverage (-a).\nScreens for portions of reads coming from exons (-split).\nAdd genome browser track line to header of bedgraph file.\n${bedtools}/genomeCoverageBed\n-i ${PWD}/20180924_oly_RNAseq.bed\n-g Olurida_v081.fa.fai.genome\n-bga\n-split\n-trackline\n> 20180924_oly_RNAseq.bed \n\nAlignment was done using the following version of the Olympia oyster genome assembly:\n\nOlurida_v081.fa\n\n\n\nRESULTS:\nOutput folder:\n\n20180924_oly_RNAseq_bedgraphs/\n\nIndexed and formatted genome file:\n\nOlurida_v081.fa.fai.genome\n\nBedgraph file (for IGV):\n\n20180924_oly_RNAseq.bed\n\n\nThis doesn’t appear to have worked properly. Here’s a view of the bedgraph file:\n<code>\ntrack type=bedGraph\nContig0 0   116746  0\nContig1 0   87411   0\nContig2 0   139250  0\nContig3 0   141657  0\nContig4 0   95692   0\nContig5 0   130522  0\nContig6 0   94893   0\nContig7 0   109667  0\nContig8 0   95943   0\n</code>\nI’d expect multiple entries for each contig (ideally), indicating start/stop positions for where transcripts align within a given contig. However, this appears to simply be a list of all the genome contigs and their lengths (Start=0, Stop=n).\nI would expect to see something li\nI’ll look into this further and see where this pipeline goes wrong."
  },
  {
    "objectID": "posts/2018/2018-10-22-Repeat-Library-Construction---O.lurida-RepeatModeler-v1.0.11/index.html",
    "href": "posts/2018/2018-10-22-Repeat-Library-Construction---O.lurida-RepeatModeler-v1.0.11/index.html",
    "title": "Repeat Library Construction - O.lurida RepeatModeler v1.0.11",
    "section": "",
    "text": "In further attempts to improve our Ostrea lurida genome annotation, I decided to generate a species-specific repeat library for use with MAKER genome annotation using RepeatModeler.\nRan on both versions of our O.lurida genome assemblies. Details on assemblies can be found on our Genomic Resources wiki (GitHub).\n\nOlurida_v080.fa\nOlurida_v081.fa (only contigs >1000bp)\n\nTasks were run on Emu (Apple Xserve; Ubuntu 16.04). All operations were performed in the following Jupyter Notebook (GitHub):\n\n20181022_emu_oly_repeatmodeler.ipynb\n\n\n\nRESULTS\nEach run took ~1.5days to complete.\nOutput folders:\n\n20181022_Olurida_v080_repeatmodeler/\n20181022_Olurida_v081_repeatmodeler/\n\nRepeats FastAs:\n\nOstrea_lurida_v080-families.fa (1.3MB)\nOstrea_lurida_v081-families.fa (1.3MB)\n\nWill use these repeat libraries in subsequent MAKER genome annotations."
  },
  {
    "objectID": "posts/2018/2018-11-08-My-New-Notebook/index.html",
    "href": "posts/2018/2018-11-08-My-New-Notebook/index.html",
    "title": "My New Notebook",
    "section": "",
    "text": "Here we are - my new notebook!\nSo, I moved things over to here: GitHub Pages. Everyone else in the lab has been using these for quite some time.\nIt took me a bit of time to get everything configured, as I wanted to use a theme, instead of the default “jekyll-now” theme that everyone has has used. This theme (Basically Basic) had all of the features that I felt I needed:\n\nBuilt-in search\nTag organization\nProject (i.e. Categories) organization\nDisplay post date alongside the post excerpt\n\nGetting things up and running just to begin posting wasn’t terribly difficult. I set things up using the “remote themes guide” found in the Basically Basic documentation.\n\nI’ll have to manually transfer the content of those two posts.\nI wrote the following script to do that conversion:\nAlthough that script looks short and sweet, it took an inordinate amount of time to make it functional (I really got hung up on the regex in the grep command). I had to post to Stack Overflow to get it figured out."
  },
  {
    "objectID": "posts/2018/2018-11-14-Computing---Install-NCBI-nr-nt-BLAST-Database-on-Mox/index.html",
    "href": "posts/2018/2018-11-14-Computing---Install-NCBI-nr-nt-BLAST-Database-on-Mox/index.html",
    "title": "Computing - Install NCBI nr nt BLAST Database on Mox",
    "section": "",
    "text": "Per this issue on GitHub, I installed the pre-formatted NCBI non-redudant (nr) nucleotide (nt) database on Mox.\nDatabase was downloaded from here:\n\nftp://ftp.ncbi.nlm.nih.gov/blast/db\n\nDatabase is installed in the following location on Mox:\n\n/gscratch/srlab/blastdbs/ncbi-nr-nt-20181114\n\nHere’re the commands used to download and setup the database files:\n\nLogin Node\nCreate directories, download files (should’ve used the –no-directories option), move files to correct directory and remove unnecessary folders/files.\nmkdir /gscratch/srlab/blastdbs\nmkdir /gscratch/srlab/blastdbs/ncbi-nr-nt-20181114\ncd /gscratch/srlab/blastdbs/ncbi-nr-nt-20181114\nwget --recursive --no-parent --accept \"nt.*tar.gz\" ftp://ftp.ncbi.nlm.nih.gov/blast/db/\ncd ftp.ncbi.nlm.nih.gov/blast/db\nmv *.gz /gscratch/srlab/blastdbs/ncbi-nr-nt-20181114\ncd /gscratch/srlab/blastdbs/ncbi-nr-nt-20181114\nrm -rf ftp.ncbi.nlm.nih.gov\n\n\nBuild Node\nUnpack gzipped tarballs.\nfor i in *.gz; do tar -xzvf $i; done"
  },
  {
    "objectID": "posts/2018/2018-11-14-DNA-Isolation-and-Quantification---Lotterhos-C.virginica-Mantle-DNA/index.html",
    "href": "posts/2018/2018-11-14-DNA-Isolation-and-Quantification---Lotterhos-C.virginica-Mantle-DNA/index.html",
    "title": "DNA Isolation and Quantification - Lotterhos C.virginica Mantle DNA",
    "section": "",
    "text": "Isolated DNA from the Lotterhos Crassostrea virginica mantle samples received on 20181017 using the E.Z.N.A. Mollusc Kit, with the following modifications/notes:\n\nSamples were pulverized under liquid nitrogen.\nSamples were incubated O/N at 37oC in the MB1/Proteinase K buffer mixture.\n270uL of aqueous phase was recovered from each sample after chloroform:IAA step.\nSamples were eluted with 100uL of Elution Buffer.\n\nAll samples were quantified using the Roberts Lab Qubit 3.0 and the Qubit dsDNA BR Kit, using 1uL of template.\nAll samples were stored at -20oC, in Sam’s gDNA Box #3 in slots A1-C6.\n\n\nRESULTS\nYields were very good, ranging from ~2.8ug - 20ug.\nQubit data (Google Sheet):\n\n20181114_qubit_DNA_Cvirginica_mantle\n\nAll Qubit data has been added to the original sample sheet sent by the Lotterhos Lab:\n\nRoberts_2017AdultExposureSampleInfo"
  },
  {
    "objectID": "posts/2018/2018-11-15-DNase---Ronit's-C.gigas-Ctenidia-RNA/index.html",
    "href": "posts/2018/2018-11-15-DNase---Ronit's-C.gigas-Ctenidia-RNA/index.html",
    "title": "DNase - Ronit’s C.gigas Ctenidia RNA",
    "section": "",
    "text": "Ronit finished his RNA isolations for his ctenidia samples on 20181025 & 20181101, as well as quntification (he has no notebook entry for this, at this time). However, his Qubit data can be found in these two Google Sheets:\n\n20181108_qubit_RNA_ronit_ctenidia\n20181114_qubit_RNA_ronit_ctenidia_1-10_dilution\n\nIn preparation for reverse transcription, I DNased his samples using the Turbo DNA-free Kit (Ambion) according to the manufacturer’s standard protocol.\nUsed 500ng of each sample.\nNOTE: Sample T06 was very dilute, so performed a 60uL reaction instead of the standard 50uL reaction.\nCalculations are here (Google Sheet):\n\n20181115_DNase_ronit_RNA_calcs\n\nRonit’s master sheet (Google Sheet) is here:\n\nExposure 8/29-8/30 C.Gigas\n\nWill check these via qPCR to verify whether or not they have any detectable gDNA."
  },
  {
    "objectID": "posts/2018/2018-11-15-qPCR---Ronit's-DNased-C.gigas-RNA-with-Elongation-Factor-Primers/index.html",
    "href": "posts/2018/2018-11-15-qPCR---Ronit's-DNased-C.gigas-RNA-with-Elongation-Factor-Primers/index.html",
    "title": "qPCR - Ronit’s DNased C.gigas RNA with Elongation Factor Primers",
    "section": "",
    "text": "After DNasing Ronit’s RNA earlier today, I needed to verify the RNA was free of any contaminating gDNA.\nUsed elongation factor primers:\n\nEF1_qPCR_5’ (SRID 309)\nEF1_qPCR_3’ (SRID 310)\n\nBB16 from 20090519 was used as a positive control.\nSamples were run on Roberts Lab CFX Connect (BioRad). All samples were run in duplicate. See qPCR Report (Results section) for plate layout, cycling params, etc.\nqPCR master mix calcs (Google Sheet):\n\n20181115_qPCR_Ronit_Cgigas_DNased_RNA\n\n\nResults\nEverything looks great! Nice, clean, gDNA-free RNA! Will proceed with reverse transcription.\nqPCR Report (PDF):\n\nsam_2018-11-15 2013-17-42_BR006896.pdf\n\nqPCR File (PCRD):\n\nsam_2018-11-15 2013-17-42_BR006896.pcrd\n\nqPCR Data (CSV):\n\nsam_2018-11-15_13-17-42_BR006896_-__Quantification_Cq_Results.csv\n\nIn the plots below, green is the positive control, blue are the samples, and red is the no template control (NTC).\n\n\nAmplification Plots\n\n\n\n\nMelt Curves"
  },
  {
    "objectID": "posts/2018/2018-11-20-RNA-Quantification---Ronit's-C.gigas-DNased-RNA-from-20181115/index.html",
    "href": "posts/2018/2018-11-20-RNA-Quantification---Ronit's-C.gigas-DNased-RNA-from-20181115/index.html",
    "title": "RNA Quantification - Ronit’s C.gigas DNased RNA from 20181115",
    "section": "",
    "text": "After confirming Ronit’s DNased RNA was free of gDNA, I quantified the DNased RNA from 20181115 using the Roberts Lab Qubit 3.0 and the Qubit hsRNA Assay.\nUsed 1uL of each sample.\n\n\nRESULTS\nQubit data (Google Sheet):\n\n20181120_qubit_DNased_RNA_ronit_gigas_ctenidia\n\nWell, 14 samples were too concentrated and exceeded the assay’s range, so I created 1:10 dilutions of those samples (1ul of sample in 9uL of 0.1%DEPC-treated H2O) and remeasured; again using 1uL of sample.\nAdmittedly, I’m not terribly surprised that happened, since they were notably lower than Ronit’s first round of RNA isolations.\nI added the data to his master sheet (Google Sheet):\n\nExposure 8/29-8/30 C.Gigas\n\nI will proceed with making cDNA."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "quarto-testing",
    "section": "",
    "text": "Post With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nSep 19, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nSep 16, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Comparisons - C.bairdi Transcriptomes Evaluations with DETONATE rsem-eval on Mox\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nDec 29, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlignments - C.bairdi RNAseq Transcriptome Alignments Using Bowtie2 on Mox\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nDec 24, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSamples Received - Cockle Clam Gonad H and E Slides\n\n\n\n\n\n\n\nSamples Received\n\n\n\n\n\n\n\n\n\n\n\nDec 17, 2020\n\n\n\n\n\n\n  \n\n\n\n\nFastQC-MultiQC - M.magister MBD-BSseq Pool Test MiSeq Run on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 11, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Received - M.magister MBD-BSseq Pool Test MiSeq Run\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 11, 2020\n\n\n\n\n\n\n  \n\n\n\n\nAlignment - C.gigas RNAseq to GCF_000297895.1_oyster_v9 Genome Using STAR on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 8, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSRA Submission - Haws Lab C.gigas Ploidy pH WGBS\n\n\n\n\n\n\n\nSRA Submission\n\n\n\n\n\n\n\n\n\n\n\nDec 7, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTrimming - Haws Lab C.gigas Ploidy pH WGBS 10bp 5 and 3 Prime Ends Using fastp and MultiQC on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 6, 2020\n\n\n\n\n\n\n  \n\n\n\n\nFastQC-MultiQc - C.gigas Ploidy pH WGBS Raw Sequence Data from Haws Lab on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 6, 2020\n\n\n\n\n\n\n  \n\n\n\n\nData Received - C.gigas Diploid-Triploid pH Treatments Ctenidia WGBS from ZymoResearch\n\n\n\n\n\n\n\nData Received\n\n\n\n\n\n\n\n\n\n\n\nDec 5, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTrimming - Ronits C.gigas Ploidy WGBS 10bp 5 and 3 Prime Ends Using fastp and MultiQC on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 2, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission - M.magister MBD BSseq Libraries for MiSeq at NOAA\n\n\n\n\n\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nDec 2, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLibrary Quantification - M.magister MBD BSseq Libraries with Qubit\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 2, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSamples Submitted - Cockle Clam Gonad Histology Cassettes for H and E\n\n\n\n\n\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTrimming - Ronits C.gigas Ploidy WGBS Using fastp and MultiQC on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 30, 2020\n\n\n\n\n\n\n  \n\n\n\n\nBioanalyzer - M.magister MBD BSseq Libraries\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 25, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMBD BSseq Library Prep - M.magister MBD-selected DNA Using Pico Methyl-Seq Kit\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 24, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Isolation and Quantification - P.generosa Hemocytes from Shelly\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 19, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSRA Submission - Ronits C.gigas Ploidy WGBS\n\n\n\n\n\n\n\nSRA Submission\n\n\n\n\n\n\n\n\n\n\n\nNov 13, 2020\n\n\n\n\n\n\n  \n\n\n\n\nFastQC-MultiQc - C.gigas Ploidy WGBS Raw Sequence Data from Ronits Project on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 10, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Assessment - Crustacean Transcripome Completeness Evaluation Using BUSCO on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 10, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Received - C.gigas Ploidy WGBS from Ronits Project via ZymoResearch\n\n\n\n\n\n\n\nData received\n\n\n\n\n\n\n\n\n\n\n\nNov 10, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling - MultiQC on S.salar RNAseq from fastp and HISAT2 on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 6, 2020\n\n\n\n\n\n\n  \n\n\n\n\nHard Drive Upgrade - Gannet Synology Server\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2020\n\n\n\n\n\n\n  \n\n\n\n\nRNAseq Alignments - S.salar HISAT2 BAMs to GCF_000233375.1_ICSASG_v2_genomic.gtf Transcriptome Using StringTie on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 4, 2020\n\n\n\n\n\n\n  \n\n\n\n\nRNAseq Alignments - Trimmed S.salar RNAseq to GCF_000233375.1_ICSASG_v2_genomic.fa Using Hisat2 on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 3, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMBD Selection - M.magister Sheared Gill gDNA 16 of 24 Samples Set 3 of 3\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 3, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMBD Selection - M.magister Sheared Gill gDNA 8 of 24 Samples Set 2 of 3\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 2, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTrimming - Shelly S.salar RNAseq Using fastp and MultiQC on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 29, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMBD Selection - M.magister Sheared Gill gDNA 8 of 24 Samples Set 1 of 3\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 28, 2020\n\n\n\n\n\n\n  \n\n\n\n\nDNA Shearing - M.magister gDNA Additional Shearing CH05-01_21 CH07-11 and Bioanalyzer\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 27, 2020\n\n\n\n\n\n\n  \n\n\n\n\nDNA Shearing - M.magister gDNA Shearing All Samples and Bioanalyzer\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 26, 2020\n\n\n\n\n\n\n  \n\n\n\n\nDNA Shearing - M.magister CH05-21 gDNA Full Shearing Test and Bioanalyzer\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 22, 2020\n\n\n\n\n\n\n  \n\n\n\n\nDNA Shearing - M.magister gDNA Shear Testing and Bioanalyzer\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 21, 2020\n\n\n\n\n\n\n  \n\n\n\n\nRead Mapping - C.bairdi 201002558-2729-Q7 and 6129-403-26-Q7 Taxa-Specific NanoPore Reads to cbai_genome_v1.01.fasta Using Minimap2 on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 14, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling - C.bairdi NanoPore Reads Extractions With Seqtk on Mephisto\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 13, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNanoPore Reads Extractions - C.bairdi Taxonomic Reads Extractions with MEGAN6 on 201002558-2729-Q7 and 6129-403-26-Q7\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 7, 2020\n\n\n\n\n\n\n  \n\n\n\n\nComparison - C.bairdi 20102558-2729 vs. 6129-403-26 NanoPore Taxonomic Assignments Using MEGAN6\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 2, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTaxonomic Assignments - C.bairdi 6129-403-26-Q7 NanoPore Reads Using DIAMOND BLASTx on Mox and MEGAN6 daa2rma on emu\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 28, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTaxonomic Assignments - C.bairdi 20102558-2729-Q7 NanoPore Reads Using DIAMOND BLASTx on Mox and MEGAN6 daa2rma on emu\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 28, 2020\n\n\n\n\n\n\n  \n\n\n\n\nData Wrangling - C.bairdi NanoPore 6129-403-26 Quality Filtering Using NanoFilt on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 28, 2020\n\n\n\n\n\n\n  \n\n\n\n\nData Wrangling - C.bairdi NanoPore 20102558-2729 Quality Filtering Using NanoFilt on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 28, 2020\n\n\n\n\n\n\n  \n\n\n\n\nAssembly Assessment - BUSCO C.bairdi Genome v1.01 on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 24, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling - Subsetting cbai_genome_v1.0 Assembly with faidx\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 23, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSRA Submissions - NanoPore C.bairdi 20102558-2729 and 6129_403_26\n\n\n\n\n\n\n\nSRA Submission\n\n\n\n\n\n\n\n\n\n\n\nSep 21, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssembly Assessment - BUSCO C.bairdi Genome v1.0 on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 18, 2020\n\n\n\n\n\n\n  \n\n\n\n\nData Wrangling - C.bairdi NanoPore Quality Filtering Using NanoFilt on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 17, 2020\n\n\n\n\n\n\n  \n\n\n\n\nGenome Assembly - C.bairdi - cbai_v1.0 - Using All NanoPore Data With Flye on Mox\n\n\n\n\n\n\n\nGenome Assembly\n\n\n\n\n\n\n\n\n\n\n\nSep 17, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTaxonomic Assignments - C.bairdi NanoPore Reads Using DIAMOND BLASTx on Mox and MEGAN6 daa2rma on swoose\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 17, 2020\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Geoduck Normalizing Gene Primers 28s-v4 and EF1a-v1 Tests\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 16, 2020\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Geoduck Normalizing Gene Primer Checks\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 14, 2020\n\n\n\n\n\n\n  \n\n\n\n\nData Wrangling - Visualization of C.bairdi NanoPore Sequencing Using NanoPlot on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 14, 2020\n\n\n\n\n\n\n  \n\n\n\n\nData Wrangling - NanoPore Fast5 Conversion to FastQ of C.bairdi 6129_403_26 on Mox with GPU Node\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2020\n\n\n\n\n\n\n  \n\n\n\n\nData Wrangling - NanoPore Fast5 Conversion to FastQ of C.bairdi 20102558-2729 Run-02 on Mox with GPU Node\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2020\n\n\n\n\n\n\n  \n\n\n\n\nData Wrangling - NanoPore Fast5 Conversion to FastQ of C.bairdi 20102558-2729 Run-01 on Mox with GPU Node\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSamples Submission - Supplemental Ronits C.gigas Diploid-Triploid Ctendidia gDNA for WGBS by ZymoResearch\n\n\n\n\n\n\n\nSample Submission\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Quantification - Re-quant Ronits C.gigas Diploid-Triploid Ctenidia gDNA Submitted to ZymoResearch\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - Trinotate C.bairdi v2.1 on Mox\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nAug 31, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - Trinotate C.bairdi v3.1 on Mox\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nAug 28, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - Trinotate Hematodinium v3.1 on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 26, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - Trinotate Hematodinium v2.1 on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 26, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTransDecoder - C.bairdi Transcriptomes v2.1 and v3.1 on Mox\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nAug 26, 2020\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - P.generosa RPL5 and TIF3s6b v2 and v3 Normalizing Gene Assessment\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 25, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submitted - C.gigas Diploid-Triploid pH Treatments Ctenidia to ZymoResearch for WGBS\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 24, 2020\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - P.generosa RPL5-v2-v3 and TIF3s6b-v2-v3 Primer Tests\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 24, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Isolation and Quantification - C.gigas High-Low pH Triploid and Diploid Ctenidia\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 21, 2020\n\n\n\n\n\n\n  \n\n\n\n\nSamples Received - C.gigas High-Low pH Triploid Diploid from Maria Haws Lab\n\n\n\n\n\n\n\nSamples Received\n\n\n\n\n\n\n\n\n\n\n\nAug 20, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSamples Submitted - Ronits C.gigas Diploid and Triploid Ctenidia to ZymoResearch for WGBS\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 20, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssembly Stats - C.bairdi Transcriptomes v2.1 and v3.1 Trinity Stats on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 19, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTrimming-FastQC-MultiQC - Robertos C.gigas WGBS FastQ Data with fastp FastQC and MultiQC on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 18, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTransDecoder - Hematodinium Transcriptomes v1.6, v1.7, v2.1 and v3.1 on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 17, 2020\n\n\n\n\n\n\n  \n\n\n\n\nAssembly Stats - cbaiodinium Transcriptomes v2.1 and v3.1 Trinity Stats on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 17, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Assessment - BUSCO Metazoa on Hematodinium v1.6 v1.7 v2.1 and v3.1 on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 14, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - Hematodinium Transcriptomes v1.6 v1.7 v2.1 v3.1 with DIAMOND BLASTx on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 14, 2020\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - P.generosa APLP and TIF3s8-1 with cDNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 6, 2020\n\n\n\n\n\n\n  \n\n\n\n\nFastQ Read Alignment and Quantification - P.generosa Water Metagenomic Libraries to MetaGeneMark Assembly with Hisat2 on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 31, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrimer Design and In-Silico Testing - Geoduck Reproduction Primers\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 30, 2020\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Testing P.generosa Reproduction-related Primers\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 29, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSRA Submission - P.generosa Metagenomics Data\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 27, 2020\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Testing P.generosa Reproduction-related Primers\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 23, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Isolation and Quantification - C.gigas Diploid (Ronit) and Triploid (Nisbet)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 22, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSRA Submission - Geoduck Epigenetic Ocean Acidification RNAseq\n\n\n\n\n\n\n\nSRA Submission\n\n\n\n\n\n\n\n\n\n\n\nJul 9, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nENA Submission - Ostrea lurida draft genome Olurida_v081.fa\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJul 8, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetagenomics - Data Extractions Using MEGAN6\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 18, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - C.bairdi Transcriptomes v2.1 and v3.1 Using DIAMOND BLASTx on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 8, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Assessment - BUSCO Metazoa on C.bairdi Transcriptome v3.1\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 5, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Assessment - BUSCO Metazoa on C.bairdi Transcriptome v2.1\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 5, 2020\n\n\n\n\n\n\n  \n\n\n\n\nSequence Extractions - C.bairdi Transcriptomes v2.0 and v3.0 Excluding Alveolata with MEGAN6 on Swoose\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 5, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - C.bairdi Transcriptomes v2.0 and v3.0 with DIAMOND BLASTx on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 4, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Comparison - C.bairdi Transcriptomes Evaluations with DETONATE on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 1, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Comparison - C.bairdi Transcriptomes Compared with DETONATE on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 29, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - Trinotate C.bairdi Transcriptome-v1.7 on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 29, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Comparisons - C.bairdi BUSCO Scores\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 28, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTransDecoder - C.bairdi Transcriptome v1.7 on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 27, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - C.bairdi Transcriptome v1.7 Using DIAMOND BLASTx on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 27, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Assessment - BUSCO Metazoa on C.bairdi Transcriptome v1.7\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 27, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Assembly - C.bairdi All Pooled Arthropoda-only RNAseq Data with Trinity on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 27, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - Trinotate C.bairdi Transcriptome-v3.0 on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Assembly - P.trituberculatus (Japanese blue crab) NCBI SRA BioProject PRJNA597187 Data with Trinity on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2020\n\n\n\n\n\n\n  \n\n\n\n\nSRA Library Assessment - Determine RNAseq Library Strandedness from P.trituberculatus SRA BioProject PRJNA597187\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 21, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTutorial - SRA Toolkit for Data Retrieval and Conversion to FastQ\n\n\n\n\n\n\n\nTutorials\n\n\n\n\n\n\n\n\n\n\n\nMay 21, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - Trinotate C.bairdi Transcriptome-v1.6 on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 20, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTransDecoder - C.bairdi Transcriptome v1.6 on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 19, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTransDecoder - C.bairdi Transcriptome v3.0 from 20200518 on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 19, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - C.bairdi Transcriptome v1.6 Using DIAMOND BLASTx on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 19, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Assessment - BUSCO Metazoa on C.bairdi Transcriptome v1.6\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 19, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - C.bairdi Transcriptome v3.0 Using DIAMOND BLASTx on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 19, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Assessment - BUSCO Metazoa on C.bairdi Transcriptome v3.0\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 19, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Assembly - C.bairdi All Arthropoda-specific RNAseq Data with Trinity on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 18, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling - Arthropoda and Alveolata D26 Pool RNAseq FastQ Extractions\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 18, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Assembly - C.bairdi All Pooled RNAseq Data Without Taxonomic Filters with Trinity on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 18, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - Trinotate C.bairdi Transcriptome v2.0 from 20200502 on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 13, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTransDecoder - C.bairdi Transcriptome v2.0 from 20200502 on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 8, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - C.bairdi Transcriptome v2.0 Using DIAMOND BLASTx on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 8, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Assessment - BUSCO Metazoa on C.bairdi v2.0 Transcriptome\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 8, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Assembly - C.bairdi All RNAseq Data Without Taxonomic Filters with Trinity on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 2, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscript Abundance - C.bairdi Alignment-free with Salmon Using 2020-GW Data on Mox\n\n\n\n\n\n\n\nMiscellneous\n\n\n\n\n\n\n\n\n\n\n\nApr 29, 2020\n\n\n\n\n\n\n  \n\n\n\n\nGO to GOslim - C.bairdi Enriched GO Terms from 20200422 DEGs\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 27, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFastQC-MultiQC - Laura Spencer’s QuantSeq Data\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 26, 2020\n\n\n\n\n\n\n  \n\n\n\n\nGene Expression - C.bairdi Pairwise DEG Comparisons with 2019 RNAseq using Trinity-Salmon-EdgeR on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 22, 2020\n\n\n\n\n\n\n  \n\n\n\n\nRNAseq Reads Extractions - C.bairdi Taxonomic Reads Extractions with MEGAN6 on swoose\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 19, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscript Abundance - C.bairdi Alignment-free with Salmon on Mox for Grace\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 15, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSRA Submission - C.bairdi RNAseq Data\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 15, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTrimmingFastQCMultiQC—C.bairdi-RNAseq-FastQ-with-fastp-on-Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 14, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTaxonomic Assignments - C.bairdi RNAseq Using DIAMOND BLASTx on Mox and MEGAN6 Meganizer on swoose\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 14, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFastQC-MultiQC - C.bairdi Raw RNAseq from NWGSC\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 14, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling - Arthropoda and Alveolata Day and Treatment Taxonomic RNAseq FastQ Extractions\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 13, 2020\n\n\n\n\n\n\n  \n\n\n\n\nData Received - C.bairdi RNAseq from NWGSC\n\n\n\n\n\n\n\nData Received\n\n\n\n\n\n\n\n\n\n\n\nApr 13, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - Trinotate C.bairdi MEGAN6 Taxonomic-specific Trinity Assembly on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 9, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - C.bairdi MEGAN Trinity Assembly Using DIAMOND BLASTx on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 8, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - Trinotate Hematodinium MEGAN6 Taxonomic-specific Trinity Assembly on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 8, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTransdecoder - Hematodinium MEGAN6 Taxonomic-Specific Reads Assembly from 20200330\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 7, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTransdecoder - C.bairdi MEGAN6 Taxonomic-Specific Reads Assembly from 20200330\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 7, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Assessment - BUSCO Metazoa on C.bairdi MEGAN Transcriptome\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 7, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - Hematodinium MEGAN Trinity Assembly Using DIAMOND BLASTx on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 31, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Assessment - BUSCO Metazoa on Hematodinium MEGAN Transcriptome\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 31, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Assembly - Hematodinium with MEGAN6 Taxonomy-specific Reads with Trinity on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 30, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Assembly - C.bairdi with MEGAN6 Taxonomy-specific Reads with Trinity on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 30, 2020\n\n\n\n\n\n\n  \n\n\n\n\nRNAseq Reads Extractions - C.bairdi Taxonomic Reads Extractions with MEGAN6 on swoose\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 30, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Annotation - C.bairdi Using DIAMOND BLASTx on Mox and MEGAN6 Meganizer on swoose\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nMar 18, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTrimming/FastQC/MultiQC - C.bairdi RNAseq FastQ with fastp on Mox\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nMar 18, 2020\n\n\n\n\n\n\n  \n\n\n\n\nData Received - C.bairdi RNAseq Data from Genewiz\n\n\n\n\n\n\n\nData Received\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nMar 18, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Isolation and Quantification - C.bairdi Hemocyte Pellets in RNAlater\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 11, 2020\n\n\n\n\n\n\n  \n\n\n\n\nNanoPore Sequencing - C.bairdi gDNA 6129_403_26\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 11, 2020\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - C.bairdi RNA Check for Residual gDNA\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nMar 10, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTrimming/MultiQC - Methcompare Bisulfite FastQs with fastp on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 6, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Isolation and Quantification - C.bairdi RNA from Hemolymph Pellets in RNAlater\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nMar 6, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling - Create Canonical Olurida_v081 Genes FastA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 28, 2020\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - C.bairdi RNA Check for Residual gDNA\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2020\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - C.bairdi Primer Tests on gDNA\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nFeb 25, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrimer Design - C.bairdi Primers for Checking RNA for Residual gDNA\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nFeb 20, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Isolation & Quantification - C.bairdi RNA from Samples 6212_132_9 6212_334_12 6212_485_26\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nFeb 11, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Isolation & Quantification - C.bairdi RNA from Samples 6212_132_9 6212_334_12 6212_485_26\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nFeb 11, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Isolation & Quantification - C.bairdi RNA from Sample 6129_403_26\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nFeb 10, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Isolation & Quantification - Additional C.bairdi gDNA from Sample 6129_403_26\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 10, 2020\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation, Quantification, and Gel - C.bairdi gDNA Sample 6129_403_26\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 10, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Assessment - BUSCO Metazoa on Hematodinium MEGAN Transcriptome\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nFeb 7, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Assessment - BUSCO Metazoa on C.bairdi MEGAN Transcriptome\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nFeb 7, 2020\n\n\n\n\n\n\n  \n\n\n\n\nGene Expression - Hematodinium MEGAN6 with Trinity and EdgeR\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 7, 2020\n\n\n\n\n\n\n  \n\n\n\n\nGene Expression - C.bairdi MEGAN6 with Trinity and EdgeR\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nFeb 7, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling - Arthropoda and Alveolata Day and Treatment Taxonomic RNAseq FastQ Extractions\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nJan 31, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Isolation and Quantification - C.bairdi Hemocyte Pellets in RNAlater\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 28, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Annotation - Trinotate Hematodinium MEGAN6 Taxonomic-specific Trinity Assembly on Mox\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nJan 26, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - Trinotate C.bairdi MEGAN6 Taxonomic-specific Trinity Assembly on Mox\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nJan 26, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Isolation and Quantification - C.bairdi Hemocyte Pellets in RNAlater\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nJan 26, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Isolation and Quantification - C.bairdi Hemocyte Pellets in RNAlater\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nJan 24, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTransdecoder - Hematodinium MEGAN6 Taxonomic-Specific Reads Assembly from 20200122\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 23, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTransdecoder - C.bairdi MEGAN6 Taxonomic-Specific Reads Assembly from 20200122\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nJan 23, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - Hematodinium MEGAN Trinity Assembly Using DIAMOND BLASTx on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 23, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - C.bairdi MEGAN Trinity Assembly Using DIAMOND BLASTx on Mox\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nJan 23, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Isolation and Quantification - C.bairdi Hemocyte Pellets in RNAlater Troubleshooting\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nJan 23, 2020\n\n\n\n\n\n\n  \n\n\n\n\nDNA Quality Assessment - Agarose Gel for C.bairdi 20102558-2729 gDNA from 20200122\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 22, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling - Arthropoda and Alveolata Taxonomic RNAseq FastQ Extractions\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nJan 22, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Isolation - C.bairdi 20102558-2729 EtOH-preserved Tissue via Three Variations Using Quick DNA-RNA MicroPrep Kit\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 22, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Assembly - Hematodinium with MEGAN6 Taxonomy-specific Reads with Trinity on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 22, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Assembly - C.bairdi with MEGAN6 Taxonomy-specific Reads with Trinity on Mox\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nJan 22, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Isolation and Quantification - C.bairdi Hemolymph Pellets in RNAlater\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 17, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Isolation and Quantification - C.bairdi Hemolymph Pellets in RNAlater\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nJan 17, 2020\n\n\n\n\n\n\n  \n\n\n\n\nRNAseq Reads Extractions - C.bairdi Taxonomic Reads Extractions with MEGAN6 on swoose\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nJan 14, 2020\n\n\n\n\n\n\n  \n\n\n\n\nLab Maintenance - Cluster UPS Battery Replacement\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 10, 2020\n\n\n\n\n\n\n  \n\n\n\n\nNanoPore Sequencing - C.bairdi gDNA Sample 20102558-2729\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 9, 2020\n\n\n\n\n\n\n  \n\n\n\n\nDNA Quality Assessment - Agarose Gel and NanoDrop on C.bairdi gDNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 9, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Isolation and Quantification - C.bairdi gDNA from EtOH Preserved Tissue\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 8, 2020\n\n\n\n\n\n\n  \n\n\n\n\nNanoPore Sequencing - Initial NanoPore MinION Lambda Sequencing Test\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 7, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - C.bairdi Using DIAMOND BLASTx on Mox and MEGAN6 Meganizer\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nJan 3, 2020\n\n\n\n\n\n\n  \n\n\n\n\nReagent Prep - RNA Pico Ladder Aliquoting and Testing\n\n\n\n\n\n\n\nReagent Prep\n\n\n\n\n\n\n\n\n\n\n\nJan 2, 2020\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - C.bairdi Trinity Assembly Trinotate on Mox\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nDec 25, 2019\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - C.bairdi Trinity Assembly BLASTx on Mox\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nDec 24, 2019\n\n\n\n\n\n\n  \n\n\n\n\nTransdecoder - C.bairdi De Novo Transcriptome from 20191218 on Mox\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nDec 20, 2019\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Assembly - C.bairdi Trimmed RNAseq Using Trinity on Mox\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nDec 18, 2019\n\n\n\n\n\n\n  \n\n\n\n\nTrimming/FastQC/MultiQC - C.bairdi RNAseq FastQ with fastp on Mox\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nDec 18, 2019\n\n\n\n\n\n\n  \n\n\n\n\nData Wrangling - Olurida_v081 UTR GFFs and Intergenic, Intron BED files\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 14, 2019\n\n\n\n\n\n\n  \n\n\n\n\nSamples Received - Pacific Oyster Tissues from Hawaii (Maria Haws) from High and Low pCO2\n\n\n\n\n\n\n\nSamples Received\n\n\n\n\n\n\n\n\n\n\n\nDec 10, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling - Renaming, Splitting, and Feature Counts of Updated Pgenerosa_v074 GenSAS Merged GFF\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nDec 3, 2019\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Crassostrea gigas and sikamea Mantle gDNA from Marinelli Shellfish Company\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 3, 2019\n\n\n\n\n\n\n  \n\n\n\n\nSamples Received - C.bairdi Hemolymph and Tissue in Ethanol from Pam Jensen\n\n\n\n\n\n\n\nSamples Received\n\n\n\n\n\n\n\n\n\n\n\nNov 27, 2019\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Geoduck hemolymph and hemocyte cDNA with vitellogenin primers\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 27, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReverse Transcription - P.generosa DNased Hemolypmh and Hemocyte RNA from 20191125\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 26, 2019\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation and Quantification - Geoduck hemolymph and hemocyte samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 25, 2019\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Crassostrea gigas and sikamea Mantle gDNA from Marinellie Shellfish Company - No Multiplex\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 21, 2019\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Crassostrea gigas and sikamea Mantle gDNA from Marinelli Shellfish Company\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 21, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling - Rename Pgenerosa_v074 Bismark Coverage Files Scaffold Names\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nNov 20, 2019\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Crassostrea gigas and sikamea Mantle gDNA from Marinelli Shellfish Company\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 19, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Isolation and Quantification - Crassostrea gigas and Crassostrea sikamea Mantle Tissue from Marinelli Shellfish Company\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 19, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling - Additional Features Stats for Panopea-generosa-v1.0\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nNov 6, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling - Rename Pgenerosa_v074 Files and Scaffolds\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling - Splitting BAM by Size for Upload to OSF\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nOct 31, 2019\n\n\n\n\n\n\n  \n\n\n\n\nSamples Received - Marinelli Shellfish Company C.gigas and C.sikamea Oysters\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 30, 2019\n\n\n\n\n\n\n  \n\n\n\n\nData Wrangling - Create Panopea-generosa-vv0.74.a4 Intron and Intergenic BED Files\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nOct 30, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenome Feature Counts - Panopea-generosa-vv0.74.a4\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nOct 29, 2019\n\n\n\n\n\n\n  \n\n\n\n\nFastQC-MultiQC - C.bairdi RNAseq Day 12 26 Infected Uninfected\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nOct 24, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Received - C.bairdi RNAseq Day9-12-26 Infected-Uninfected\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\nData Received\n\n\n\n\n\n\n\n\n\n\n\nOct 24, 2019\n\n\n\n\n\n\n  \n\n\n\n\nLab Maintenance - Cluster UPS Battery Replacement\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 22, 2019\n\n\n\n\n\n\n  \n\n\n\n\nMetagenomics Annotation - P.generosa Water Samples with MEGAN6\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 14, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Received - C.bairdi RNAseq Day9-12-26 Infected-Uninfected\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Annotation - Pgenerosa_v074 a4 Using GenSAS\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nSep 28, 2019\n\n\n\n\n\n\n  \n\n\n\n\nMetagenomics Annotation - P.generosa Water Samples Using DIAMOND BLASTx on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 25, 2019\n\n\n\n\n\n\n  \n\n\n\n\nTrimming/FastQC/MultiQC - P.generosa EPI FastQs with FASTP on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 23, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSRA Submission - Hollie’s Juvenile OA BS-seq Data\n\n\n\n\n\n\n\nSRA Submissions\n\n\n\n\n\n\n\n\n\n\n\nSep 18, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling - Pgenerosa_v074.a3 Annotation Genome Repeats Compostion\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nSep 5, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling - Pgenerosa_v074.a3 Annotation Genome Feature Sequence Lengths\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling - Panopea generosa Genome Feature Sequence Lengths\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nAug 26, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling - Create a CpG GFF from Pgenerosa_v074 using EMBOSS fuzznuc on Swoose\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nAug 21, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Annotation - Pgenerosa_v074 MAKER on Mox with Stringtie Transcripts GFF\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nAug 19, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Comparison - Pgenerosa_v074 vs Pgenerosa_v070 with MUMmer Promer on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 13, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Comparison - Pgenerosa_v074 vs S.glomerata NCBI with MUMmer Promer on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 13, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Comparison - Pgenerosa_v074 vs M.yessoensis NCBI with MUMmer Promer on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 13, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Comparison - Pgenerosa_v074 vs H.sapiens NCBI with MUMmer Promer on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 13, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Comparison - Pgenerosa_v074 vs C.virginica NCBI with MUMmer Promer on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 13, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Comparison - Pgenerosa_v074 vs C.gigas NCBI with MUMmer Promer on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 13, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Comparison - Pgenerosa_v074 vs Pgenerosa_v070 with MUMmer on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 7, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Comparison - Pgenerosa_v074 vs Pgenerosa_v074 with MUMmer on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 7, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Comparison - Pgenerosa_v074 vs S.glomerata NCBI with MUMmer on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 7, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Comparison - Pgenerosa_v074 vs M.yessoensis NCBI with MUMmer on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 7, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Comparison - Pgenerosa_v074 vs C.gigas NCBI with MUMmer on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 7, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Comparison - Pgenerosa_v074 vs H.sapiens NCBI with MUMmer on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 7, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Comparison - Pgenerosa_v074 vs C.virginica NCBI with MUMmer on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 6, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRepeatMasker - Pgenerosa_v070 for Transposable Element ID on Roadrunner\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nAug 6, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling - FastA Splitting With faSplit\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 31, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Summary - P.generosa Transcriptome Assemblies Stats\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 29, 2019\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Compression - P.generosa Transcriptome Assemblies Using CD-Hit-est on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 29, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Annotation - Pgenerosa_v074 Transcript Isoform ID with Stringtie on Mox\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJul 23, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Annotation - Pgenerosa_v070 Transcript Isoform ID with Stringtie on Mox\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJul 23, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Annotation - Pgenerosa_v074 Hisat2 Transcript Isoform Index\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJul 23, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Annotation - Pgenerosa_v070 Hisat2 Transcript Isoform Index\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJul 23, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenome Annotation - Pgenerosa_v070 and v074 Top 18 Scaffolds Feature Count Comparisons\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJul 22, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Annotation - O.lurida 20190709-v081 Transcript Isoform ID with Stringtie on Mox\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJul 16, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Annotation - O.lurida 20190709-v081 Hisat2 Transcript Isoform Index\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJul 16, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Assessment - BUSCO Metazoa on Pgenerosa_v074 on Mox\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJul 10, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Assessment - BUSCO Metazoa on Pgenerosa_v70 on Mox\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJul 10, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Annotation - Pgenerosa_v071 Using GenSAS\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJul 10, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Annotation - Pgenerosa_v074 Using GenSAS\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJul 10, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Annotation - Olurida_v081 with MAKER and Tissue-specific Transcriptomes on Mox\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJul 9, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Annotation - Pgenerosa_v074 MAKER on Mox\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJul 1, 2019\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - Geoduck Juvenile Ambient OA EPI123 with Transdecoder on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 27, 2019\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - Geoduck Juvenile Super Low OA EPI115 with Transdecoder on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 27, 2019\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - Geoduck Larvae Day5 EPI99 with Transdecoder on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 27, 2019\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - Geoduck Gonad with Transdecoder on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 27, 2019\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - Geoduck Juvenile Ambient OA EPI124 with Transdecoder on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 27, 2019\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - Geoduck Ctenidia with Transdecoder on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 27, 2019\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Annotation - Geoduck Super Low OA EPI116 with Transdecoder on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 27, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRepeatModeler - Pgenerosa_v074 for MAKER Annotation on Emu\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 26, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRepeatMasker - Pgenerosa_v074 for Transposable Element ID on Roadrunner\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 26, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Received - C.virginica Mantle MBD-BSseq from ZymoResearch\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 26, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling - FastA Subsetting of Pgenerosa_v070.fa Using samtools faidx\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 25, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Annotation - O.lurida (v081) Transcript Isoform ID with Stringtie on Mox\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJun 25, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenome Annotation - O.lurida (v081) Hisat2 Transcript Isoforms Index\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJun 25, 2019\n\n\n\n\n\n\n  \n\n\n\n\nMetagenomics - Refining Anvio Binning\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 19, 2019\n\n\n\n\n\n\n  \n\n\n\n\nMetagenomics - Taxonomic Diversity and Sequencing Coverage with MEGAHIT BLASTx and Krona Plots\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 12, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling - Create Pgenerosa_v070 GFFs\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission - Tanner Crab Infected vs Uninfected RNAseq\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nMay 21, 2019\n\n\n\n\n\n\n  \n\n\n\n\nMetagenomics - BLASTx of Individual Water Sample MEGAHIT Assemblies on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 16, 2019\n\n\n\n\n\n\n  \n\n\n\n\nLibrary Decisions - C.bairdi RNAs for Library Pools\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nMay 14, 2019\n\n\n\n\n\n\n  \n\n\n\n\nFastQC-MultiQC - Additional C.gigas WGBS Sequencing Data from Genewiz Received 20190501\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 1, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Received - Additional C.gigas Whole Genome Bisulfite Sequencing Data from Genewiz\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 1, 2019\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation and Quantification - C.bairdi Hemolymph Pellet in RNAlater\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 30, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSRA Submission - P.generosa 10x Genomics Sequencing Data\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nApr 24, 2019\n\n\n\n\n\n\n  \n\n\n\n\nData Analysis - C.virginica MBD Sequencing Coverage\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 18, 2019\n\n\n\n\n\n\n  \n\n\n\n\nMetagenomics Annotation - P.generosa Water Samples Using BLASTn on Mox and KronaTools Visualization to Compare pH Treatments\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 16, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetagenomics Gene Prediction - P.generosa Water Samples Using MetaGeneMark on Mox to Compare pH Treatments\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 16, 2019\n\n\n\n\n\n\n  \n\n\n\n\nFastQC - WGBS Sequencing Data from Genewiz Received 20190408\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 15, 2019\n\n\n\n\n\n\n  \n\n\n\n\nMetagenome Assemblies - P.generosa Water Samples Trimmed HiSeqX Data Using Megahit on Mox to Compare pH Treatments\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 15, 2019\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation and Quantification - Crab Hemolypmh Using Quick-DNA-RNA Microprep Plus Kit\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nApr 11, 2019\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Assembly - Geoduck Tissue-specific Assembly Larvae Day5 EPI99 with HiSeq and NovaSeq Data on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 9, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Assembly - Geoduck Tissue-specific Assembly Gonad HiSeq and NovaSeq Data on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 9, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Assembly - Geoduck Tissue-specific Assembly Juvenile Ambient OA EPI124 with HiSeq and NovaSeq Data on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 9, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Assembly - Geoduck Tissue-specific Assembly Juvenile Ambient OA EPI123 with HiSeq Data on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 9, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Assembly - Geoduck Tissue-specific Assembly Juvenile Super Low OA EPI116 with HiSeq and NovaSeq Data on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 9, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Assembly - Geoduck Tissue-specific Assembly Juvenile Super Low OA EPI115 with HiSeq Data on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 9, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Assembly - Geoduck Tissue-specific Assembly Ctenidia with HiSeq and NovaSeq Data on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 9, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management - Whole Genome Bisulfite Sequencing Data from Genewiz Received\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 8, 2019\n\n\n\n\n\n\n  \n\n\n\n\nMetagenomics - P.generosa Water Sample Assembly Comparisons with Quast\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 8, 2019\n\n\n\n\n\n\n  \n\n\n\n\nMetagenomics - Geoduck Water Sample Assembly Comparisons with MetaQuast\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 3, 2019\n\n\n\n\n\n\n  \n\n\n\n\nMetagenomics - Taxonomic Diversity Comparisons from Geoduck Water with Anvio on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 1, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetagenome Assemblies - P.generosa Water Samples Trimmed HiSeqX Data Using Megahit on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 27, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTransposable Element Mapping - Crassostrea gigas Genome v9 Using RepeatMasker 4.07 on Roadrunner\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 27, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission - Lotterhos C.virginica Mantle MBD DNA to ZymoResearch for BSseq\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 26, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management - SRA Submission Panopea generosa Day 5 Larvae RNAseq\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 26, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetagenomics - Taxonomic Diversity from Geoduck Water with BLASTn and Krona Plots\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 25, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMetagenomics - Taxonomic Diversity from Geoduck Water with BLASTp and Krona plots\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 25, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMBD Enrichment - DNA Quantification of C.virginica MBD Samples from 20190312\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 19, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Annotation - Geoduck Juvenile Day 5 with Trinotate on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 18, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Annotation - Geoduck Heart with Trinotate on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 18, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Annotation - Geoduck Ctenidia with Trinotate on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 18, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Annotation - Geoduck Gonad with Trinotate on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 18, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Annotation - Geoduck Heart with BLASTx on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 18, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Annotation - Geoduck Gonad with BLASTx on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 18, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Annotation - Geoduck Ctenidia with BLASTx on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 18, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Annotation - Geoduck Juvenile Day 5 with BLASTx on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 18, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Annotation - Geoduck Juvenile Day 5 with Transdecoder on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 18, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Annotation - Geoduck Heart with Transdecoder on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 18, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Annotation - Geoduck Gonad with Transdecoder on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 18, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Annotation - Geoduck Ctenidia with Transdecoder on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 18, 2019\n\n\n\n\n\n\n  \n\n\n\n\nMethylation Analysis - C.virginica Gonad MBD with Varying Read Subsets with Bismark on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 13, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management - Create C.virginica Bisulfite Genome with Bismark on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 12, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMBD Enrichment - Ethanol Precipitation of C.virginica MBD samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 12, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMBD Enrichment - C.virginica Sheared Mantle DNA from 20190306\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 11, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMBD Enrichment - C.virginica Sheared Mantle DNA from 20190306\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 7, 2019\n\n\n\n\n\n\n  \n\n\n\n\nDNA Shearing & Bioanalyzer - Lotterhos C.virginica Mantle gDNA from 2018114\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 6, 2019\n\n\n\n\n\n\n  \n\n\n\n\nAgarose Gel - Lotterhos C.virginica Mantle DNA from 20181114\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 5, 2019\n\n\n\n\n\n\n  \n\n\n\n\nData Management - Data Migration and Drive Expansion on Gannet\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 4, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenome Assessment - BUSCO Metazoa on P.generosa v071 on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 2, 2019\n\n\n\n\n\n\n  \n\n\n\n\nGenome Annotation - Pgenerosa_v070 MAKER on Mox\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nFeb 28, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Wrangling - CpG OE Calculations on C.virginica Genes\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMethylation Analysis - O.lurida Bismark on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 22, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMethylation Analysis - P.generosa Bismark on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 22, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMethylation Analysis - C.virginica\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 22, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMethylation Analysis - C.gigas Bismark on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 22, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management - Create C.virginica Bisulfite Genome wit Bismark on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 21, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management - Create C.gigas Bisulfite Genome with Bismark on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 21, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management - Create Geoduck Bisulfite Genomes with Bismark on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 21, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Assembly - Geoduck Tissue-specific Assembly Juvenile Day 5\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Assembly - Geoduck Tissue-specific Assembly Heart\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Assembly - Geoduck Tissue-specific Assembly Gonad\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Assembly - Geoduck Tissue-specific Assembly Ctenidia\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenome Annotation - Pgenerosa_v71 with MAKER on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 13, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSequence Subsetting - Pgenerosa_v70 Genome Assembly with faidx\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 11, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSamples Submitted - Robertos C.gigas DNA for Whole Genome Bisulfite Sequencing (Genewiz)\n\n\n\n\n\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nFeb 7, 2019\n\n\n\n\n\n\n  \n\n\n\n\nSamples Received - C.virginica DNA and Tissues from Lotterhos Lab\n\n\n\n\n\n\n\nSamples Received\n\n\n\n\n\n\n\n\n\n\n\nJan 29, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Isolation and Quantification - Ronit’s C.gigas Ploidy Ctenidia\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 23, 2019\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - C.gigas Ploidy Experiment Ctenidia\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 17, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnnotation - Olurida_v081 MAKER BUSCO Metazoa Augustus Training on Mox\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJan 15, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnnotation - Geoduck Genome with MAKER Submitted to Mox\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJan 15, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnnotation - Olurida_v081 MAKER BUSCO (eukaryota_odb9) Augustus Training Submitted to Mox\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJan 14, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnnotation - Olurida_v081 MAKER Functional Annotations on Mox\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJan 9, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnnotation - Olurida_v081 MAKER Proteins BLASTp on Mox\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJan 8, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnnotation - Olurida_v081 MAKER Proteins InterProScan5 on Mox\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJan 8, 2019\n\n\n\n\n\n\n  \n\n\n\n\nAnnotation - Olurida_v081 MAKER ID Mapping\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJan 8, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGene Prediction - HiSeqX Metagenomics from Geoduck Water Using MetaGeneMark on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 3, 2019\n\n\n\n\n\n\n  \n\n\n\n\nMetagenome Assembly - P.generosa Water Sample Trimmed HiSeqX Data Using Megahit on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 2, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVCF Splitting - C.virginica VCF Using BCFtools\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 2, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Isolation - C.gigas Ploidy Experiment Ctenidia\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 20, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRepeat Library Construction - P.generosa RepeatModeler v1.0.11\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nDec 19, 2018\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Relative mitochondrial abundance in C.gigas diploids and triploids subjected to acute heat stress via COX1\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 17, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBLASTx - Clupea pallasii (Pacific herring) liver and testes transcriptomes on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 12, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFastQC and Trimming - Metagenomics (Geoduck) HiSeqX Reads from 20180809\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 11, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrimer Design - Gigas COX1 using Primer3\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 11, 2018\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Geoduck gonad cDNA with vitellogenin primers\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 6, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReverse Transcription - Geoduck gonad RNA pool\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 6, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrimer Design - Geoduck Vitellogenin using Primer3\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 29, 2018\n\n\n\n\n\n\n  \n\n\n\n\nAnnotation - Olurida_v081 MAKER on Mox\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nNov 27, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnnotation - Geoduck Transcritpome with TransDecoder\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 21, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Quantification - Ronit’s C.gigas DNased RNA from 20181115\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 20, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReverse Transcription - Ronit’s C.gigas DNased RNA from 20181115\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 20, 2018\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Ronit’s DNased C.gigas RNA with Elongation Factor Primers\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 15, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNase - Ronit’s C.gigas Ctenidia RNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 15, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Isolation and Quantification - Lotterhos C.virginica Mantle DNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 14, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComputing - Install NCBI nr nt BLAST Database on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 14, 2018\n\n\n\n\n\n\n  \n\n\n\n\nMy New Notebook\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNov 8, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRepeat Library Construction - O.lurida RepeatModeler v1.0.11\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nOct 22, 2018\n\n\n\n\n\n\n  \n\n\n\n\nqPCRs - Ronit’s C.gigas ploidy/dessication/heat stress cDNA (1:5 dilution)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 18, 2018\n\n\n\n\n\n\n  \n\n\n\n\nSamples Received - Crassostrea virginica (Eastern oyster) tissue from Lotterhos Lab (Northeastern University)\n\n\n\n\n\n\n\nSamples Received\n\n\n\n\n\n\n\n\n\n\n\nOct 17, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReverse Transcription - Ronit’s C.gigas DNased ctenidia RNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 17, 2018\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Ronit’s DNAsed C.gigas Ploidy/Dessication RNA with elongation factor primers\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 17, 2018\n\n\n\n\n\n\n  \n\n\n\n\nqPCR – C.gigas primer and gDNA tests with 18s and EF1 primers\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 16, 2018\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Ronit’s DNAsed C.gigas Ploidy/Dessication RNA with 18s primers\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 16, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNase Treatment - Ronit’s C.gigas Ploiyd/Dessication Ctenidia RNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 16, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Quantification - Ronit’s C.gigas Ploidy/Dessication RNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 16, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Received - Chionoecetes bairdi RNAseq & FastQC Analysis\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 15, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVCF Splitting with bcftools\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 15, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Isolation - Tanner Crab Hemolymph Pellet in RNAlater using TriReagent\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 9, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Isolation - Ronit’s C.gigas diploid/triploid dessication/heat shock ctenidia tissues\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSRA Submission - Olymia oyster Whole Genome BS-seq Data\n\n\n\n\n\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstallation - Microsoft Machine Learning Server (Microsoft R Open) on Emu/Roadrunner R Studio Server\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 2, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUbuntu – Fix “No Video Signal” Issue on Emu\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nOct 2, 2018\n\n\n\n\n\n\n  \n\n\n\n\nTranscriptome Alignment & Bedgraph – Olympia oyster transcriptome with Olurida_v080 genome assembly\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 26, 2018\n\n\n\n\n\n\n  \n\n\n\n\nBedgraph – Olympia oyster transcriptome with Olurida_v081 genome assembly\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 26, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Alignment – Olympia oyster RNAseq reads aligned to genome with HISAT2\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 25, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBedgraph - Olympia oyster transcriptome (FAIL)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 24, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Alignment - Olympia oyster Trinity transcriptome aligned to genome with Bowtie2\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 19, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Assembly - Olympia oyster RNAseq Data with Trinity\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 19, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Methylation Analysis – Olympia Oyster Whole Genome BSseq Bismark Pipeline MethylKit Comparison\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 18, 2018\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Lyophilized Tanner Crab Hemolymph in RNAlater\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 17, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Methylation Analysis - Olympia Oyster Whole Genome BSseq Bismark Pipeline Comparison\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 13, 2018\n\n\n\n\n\n\n  \n\n\n\n\nDNA Quantification - Sea Lice DNA from 20180523\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 12, 2018\n\n\n\n\n\n\n  \n\n\n\n\nTrimGalore/FastQC/MultiQC - C.virginica Oil Spill MBDseq Concatenated Sequences\n\n\n\n\n\n\n\nLSU C.virginica Oil Spill MBD BS Sequencing\n\n\n\n\n\n\n\n\n\n\n\nSep 11, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSequencing Data Analysis - C.virginica Oil Spill MBDseq Concatenation & FastQC\n\n\n\n\n\n\n\nLSU C.virginica Oil Spill MBD BS Sequencing\n\n\n\n\n\n\n\n\n\n\n\nSep 10, 2018\n\n\n\n\n\n\n  \n\n\n\n\nDNA Methylation Analysis - Olympia oyster BSseq MethylKit Analysis\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTranscriptome Assembly - Geoduck RNAseq data\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFastQC/MultiQC/TrimGalore/MultiQC/FastQC/MultiQC - O.lurida WGBSseq for Methylation Analysis\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 30, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTransposable Element Mapping – Crassostrea virginica Genome, Cvirginica_v300, using RepeatMasker 4.07\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 28, 2018\n\n\n\n\n\n\n  \n\n\n\n\nAssembly Stats – Geoduck Hi-C Final Assembly Comparison\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nAug 23, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Methylation Analysis - Bismark Pipeline on All Olympia oyster BSseq Datasets\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 16, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Received - Geoduck Metagenome HiSeqX Data\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 9, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Isolation & Quantificaiton - Tanner Crab Hemolymph\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 9, 2018\n\n\n\n\n\n\n  \n\n\n\n\nGenome Annotation – Olympia oyster genome annotation results #02\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nAug 8, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenome Annotation - Olympia oyster genome annotation results #01\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nAug 8, 2018\n\n\n\n\n\n\n  \n\n\n\n\nGenome Annotation – Olympia oyster genome complete - brief note\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nAug 7, 2018\n\n\n\n\n\n\n  \n\n\n\n\nGenome Annotation - Olympia oyster genome using WQ-MAKER Instance on Jetstream\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nAug 7, 2018\n\n\n\n\n\n\n  \n\n\n\n\nBioanalyzer - Tanner Crab RNA Isolated with RNeasy Plus Mini Kit\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 1, 2018\n\n\n\n\n\n\n  \n\n\n\n\nRNA Cleanup - Tanner Crab RNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 31, 2018\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Tanner Crab Hemolymph Using RNeasy Plus Mini Kit\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 31, 2018\n\n\n\n\n\n\n  \n\n\n\n\nMox – Over quota: Olympia oyster genome annotation progress (using Maker 2.31.10)\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJul 30, 2018\n\n\n\n\n\n\n  \n\n\n\n\nRNA Cleanup - Tanner Crab RNA Pools\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nJul 19, 2018\n\n\n\n\n\n\n  \n\n\n\n\nMox - Olympia oyster genome annotation progress (using Maker 2.31.10)\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJul 11, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMox - Password-less SSH!\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 11, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUbuntu - Fix “No Video Signal” Issue on Emu/Roadrunner\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nJul 5, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTransposable Element Mapping – Olympia Oyster Genome Assembly, Olurida_v081, using RepeatMasker 4.07\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 3, 2018\n\n\n\n\n\n\n  \n\n\n\n\nLibrary Construction - Geoduck Water Filter Metagenome with Nextera DNA Flex Kit (Illumina)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 6, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBS-seq Mapping – Olympia oyster bisulfite sequencing: Bismark Continued\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 31, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTransposable Element Mapping – Crassostrea virginica NCBI Genome Assembly using RepeatMasker 4.07\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 29, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRead Mapping – Olympia oyster 2bRAD Data with Bowtie2 (on Mox)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTransposable Element Mapping - Olympia Oyster Genome Assembly using RepeatMasker 4.07\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2018\n\n\n\n\n\n\n  \n\n\n\n\nDNA Received - Sea lice DNA from Cris Gallardo-Escarate at Universidad de Concepción\n\n\n\n\n\n\n\nSamples Received\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2018\n\n\n\n\n\n\n  \n\n\n\n\nSoftware Installation – RepeatMasker v4.0.7 on Emu/Roadrunner Continued\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2018\n\n\n\n\n\n\n  \n\n\n\n\nSoftware Installation - RepeatMasker v4.0.7 on Emu/Roadrunner\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 22, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrimGalore/FastQC/MultiQC – TrimGalore! RRBS Geoduck BS-seq FASTQ data (directional)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 16, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFastQC - RRBS Geoduck BS-seq FASTQ data\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 16, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrimGalore/FastQC/MultiQC – TrimGalore! RRBS Geoduck BS-seq FASTQ data\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 16, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management - Illumina NovaSeq Geoduck Genome Sequencing\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nMay 16, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssembly - Geoduck Hi-C Assembly Subsetting\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nMay 12, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRead Mapping - Mapping Illumina Data to Geoduck Genome Assemblies with Bowtie2\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nMay 9, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBS-seq Mapping - Olympia oyster bisulfite sequencing: TrimGalore > FastQC > Bismark\n\n\n\n\n\n\n\nBS-seq Libraries for Sequencing at Genewiz\n\n\nMBD Enrichment for Sequencing at ZymoResearch\n\n\n\n\n\n\n\n\n\n\n\nMay 8, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssembly & Stats - SparseAssembler (k95) on Geoduck Sequence Data > Quast for Stats\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nMay 1, 2018\n\n\n\n\n\n\n  \n\n\n\n\nAssembly Stats - Geoduck Genome Assembly Comparisons w/Quast - SparseAssembler, SuperNova, Hi-C\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nApr 30, 2018\n\n\n\n\n\n\n  \n\n\n\n\nAssembly Stats - Geoduck Hi-C Assembly Comparison\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nApr 30, 2018\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation & Quantification - Metagenomics Water Filters\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 26, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTotal Alkalinity Calculations - Yaamini’s Ocean Chemistry Samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 24, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssembly – SparseAssembler (k 111) on Geoduck Sequence Data\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nApr 23, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssembly – SparseAssembler (k 131) on Geoduck Sequence Data\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nApr 22, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management - Geoduck Phase Genomics Hi-C Data\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\nSamples Received\n\n\n\n\n\n\n\n\n\n\n\nApr 21, 2018\n\n\n\n\n\n\n  \n\n\n\n\nKmer Estimation – Kmergenie (k 301) on Geoduck Sequence Data\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nApr 21, 2018\n\n\n\n\n\n\n  \n\n\n\n\nKmer Estimation – Kmergenie Tweaks on Geoduck Sequence Data\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nApr 19, 2018\n\n\n\n\n\n\n  \n\n\n\n\nKmer Estimation - Kmergenie on Geoduck Sequence Data (default settings)\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nApr 19, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssembly Stats - Quast Stats for Geoduck SparseAssembler Job from 20180405\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nApr 15, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management - SRA Submission LSU C.virginica Oil Spill MBD BS-seq Data\n\n\n\n\n\n\n\nLSU C.virginica Oil Spill MBD BS Sequencing\n\n\n\n\n\n\n\n\n\n\n\nApr 12, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrimGalore/FastQC/MultiQC - Trim 10bp 5’/3’ ends C.virginica MBD BS-seq FASTQ data\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 11, 2018\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation & Quantification - Metagenomics Water Filters\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 11, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrimGalore/FastQC/MultiQC - 2bp 3’ end Read 1s Trim C.virginica MBD BS-seq FASTQ data\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 10, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrimGalore/FastQC/MultiQC - 14bp Trim C.virginica MBD BS-seq FASTQ data\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 10, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrimGalore/FastQC/MultiQC - Auto-trim C.virginica MBD BS-seq FASTQ data\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 9, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFastQC/MultiQC - C. virginica MBD BS-seq Data\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 9, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenome Assembly - SparseAssembler Geoduck Genomic Data, kmer=101\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nApr 5, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGunzip - BGI HiSeq Geoduck Genome Sequencing Data\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nApr 5, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGunzip - Trimmed Illumina Geoduck HiSeq Genome Sequencing Data\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nApr 4, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Isolation & Quantification – Geoduck larvae metagenome filter rinses\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 3, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitrations - Yaamini’s Seawater Samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 3, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitrations - Yaamini’s Seawater Samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 2, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrimGalore!/FastQC/MultiQC - Illumina HiSeq Genome Sequencing Data Continued\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nApr 1, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Received - Crassostrea virginica MBD BS-seq from ZymoResearch\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 29, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFastQC/MultiQC – Illumina HiSeq Genome Sequencing Data\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nMar 28, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrimGalore!/FastQC/MultiQC - Illumina HiSeq Genome Sequencing Data\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nMar 28, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFastQC/MultiQC - BGI Geoduck Genome Sequencing Data\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nMar 27, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitrations - Hollie’s Seawater Samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 27, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssembly - Geoduck NovaSeq using SparseAssembler kmer = 101\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nMar 27, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssembly - Geoduck NovaSeq using SparseAssembler (TL;DR - it worked!)\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nMar 22, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitrations - Hollie’s Seawater Samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 20, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Isolation & Quantification - Geoduck larvae metagenome filter rinses\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 20, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitrations - Hollie’s Seawater Samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 19, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTitrations - Hollie’s Seawater Samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 16, 2018\n\n\n\n\n\n\n  \n\n\n\n\nSamples Received - Geoduck larvae metagenome filter rinses\n\n\n\n\n\n\n\nSamples Received\n\n\n\n\n\n\n\n\n\n\n\nMar 13, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssembly - Geoduck NovaSeq using SparseAssembler (failed)\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nMar 8, 2018\n\n\n\n\n\n\n  \n\n\n\n\nProgress Report - Titrator\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 6, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUbuntu Installation - Convert Apple Xserve “bigfish” to Ubuntu\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nFeb 28, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHardware Upgrades - USB 3.0 PCI Card and 1TB SSD in Woodpecker\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nFeb 28, 2018\n\n\n\n\n\n\n  \n\n\n\n\nSamples Received - Triploid Crassostrea gigas from Nisbet Oyster Company\n\n\n\n\n\n\n\nSamples Received\n\n\n\n\n\n\n\n\n\n\n\nFeb 28, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNovaSeq Assembly - The Struggle is Real - Real Annoying!\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nFeb 21, 2018\n\n\n\n\n\n\n  \n\n\n\n\nAssembly - Geoduck Illumina NovaSeq SOAPdenovo2 on Mox (FAIL)\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nFeb 19, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEthanol Precipitation & DNA Quantification - C. virginica MBD DNA from Yaamini\n\n\n\n\n\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nFeb 7, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNovaSeq Assembly - Trimmed Geoduck NovaSeq with Meraculous\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nFeb 5, 2018\n\n\n\n\n\n\n  \n\n\n\n\nTitrator Setup - Functional Methods & Data Exports\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 1, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdapter Trimming and FASTQC - Illumina Geoduck Novaseq Data\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJan 25, 2018\n\n\n\n\n\n\n  \n\n\n\n\nSoftware Install - 10x Genomics Supernova on Mox (Hyak)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 22, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSamples Submitted - C. virginica gDNA, MBD, and MspI to Qiagen\n\n\n\n\n\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nJan 16, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssembly Comparisons – Oly Assemblies Using Quast\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJan 16, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Quantification - MspI-digested Crassostrea virginica gDNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 11, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhenol:Chloroform Extractions and EtOH Precipitations - MspI Digestions of C.virginica DNA from Earlier Today\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 11, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRestriction Digestion - MspI on Crassotrea virginica gDNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 11, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Quantification - C.virginica MBD-enriched DNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 10, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMBD Enrichment – Crassostrea virginica Sheared DNA Day 3\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 10, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMBD Enrichment – Crassostrea virginica Sheared DNA Day 2\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 9, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMBD Enrichment - Crassostrea virginica Sheared DNA Day 1\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 8, 2018\n\n\n\n\n\n\n  \n\n\n\n\nTissue Sampling - Crassostrea virginica Tissues for Archiving\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 13, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSoftware Install - MSMTP For Email Notices of Bash Job Completion on Emu (Ubuntu)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 13, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSamples Submitted - Pulverized Geoduck Tissues to Illumina for More 10x Genomics Sequencing\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nDec 12, 2017\n\n\n\n\n\n\n  \n\n\n\n\nDNA Sonication & Bioanalzyer - C. virginica gDNA for MeDIP\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 11, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Isolation & Quantification - Crassostrea virginica Mantle gDNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 11, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenome Assembly – Olympia Oyster Illumina & PacBio Using PB Jelly w/BGI Scaffold Assembly\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nNov 30, 2017\n\n\n\n\n\n\n  \n\n\n\n\nTroubleshooting – PB Jelly Install on Emu Continued\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 30, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSamples Submitted - Geoduck Tissues to Illumina for More 10x Genomics Sequencing\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nNov 20, 2017\n\n\n\n\n\n\n  \n\n\n\n\nTroubleshooting - PB Jelly Install on Emu\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 20, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Isolation & Quantification - C. virginica Gonad gDNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 14, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssembly Comparison - Oly Assemblies Using Quast\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nNov 14, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenome Assembly - Olympia Oyster Illumina & PacBio Using PB Jelly w/BGI Scaffold Assembly\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nNov 14, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenome Assembly - Olympia Oyster Illumina & PacBio Using PB Jelly w/Platanus Assembly\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nNov 13, 2017\n\n\n\n\n\n\n  \n\n\n\n\nSamples Received - Tanner Crab Hemolymph in RNA Later from Pam Jensen\n\n\n\n\n\n\n\nSamples Received\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nNov 13, 2017\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation & Quantification - Tanner crab hemolymph\n\n\n\n\n\n\n\nTanner Crab RNAseq\n\n\n\n\n\n\n\n\n\n\n\nNov 7, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSoftware Installation - ALPACA on Roadrunner\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 31, 2017\n\n\n\n\n\n\n  \n\n\n\n\nSoftware Crash - Olympia oyster genome assembly with Masurca on Mox\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 31, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSoftware Installation - PB Jelly Suite and Blasr on Emu\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 30, 2017\n\n\n\n\n\n\n  \n\n\n\n\nGenome Assembly - Olympia oyster Illumina & PacBio Reads Using Redundans\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nOct 24, 2017\n\n\n\n\n\n\n  \n\n\n\n\nAssembly Comparison - Oly PacBio Canu: Sam vs. Sean with Quast\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 23, 2017\n\n\n\n\n\n\n  \n\n\n\n\nFAIL - Missing Data on Owl!\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 23, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenome Assembly - Olympia oyster Illumina & PacBio reads using MaSuRCA\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nOct 19, 2017\n\n\n\n\n\n\n  \n\n\n\n\nSoftware Installation - MaSuRCA v3.2.3 Assembler on Mox (Hyak)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 19, 2017\n\n\n\n\n\n\n  \n\n\n\n\nFail - Directory Contents Deleted!\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 18, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenome Assembly - Olympia oyster PacBio Canu v1.6\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nOct 18, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management - Convert Oly PacBio H5 to FASTQ\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nOct 9, 2017\n\n\n\n\n\n\n  \n\n\n\n\nGenome Assembly - Olympia oyster Redundans/Canu vs. Redundans/Racon\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nOct 6, 2017\n\n\n\n\n\n\n  \n\n\n\n\nGenome Assembly - Olympia Oyster Redundans with Illumina + PacBio\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenome Assembly - minimap/miniasm/racon Overview\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nOct 4, 2017\n\n\n\n\n\n\n  \n\n\n\n\nAssembly Comparisons - Olympia oyster genome assemblies\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSamples Received - C.virginica gonad tissue from Katie Lotterhos\n\n\n\n\n\n\n\nSamples Received\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2017\n\n\n\n\n\n\n  \n\n\n\n\nGoals - October 2017\n\n\n\n\n\n\n\nGoals\n\n\n\n\n\n\n\n\n\n\n\nOct 2, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenome Assembly - Olympia oyster PacBio minimap/miniasm/racon\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 18, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenome Assembly - Olympia oyster PacBio minimap/miniasm/racon\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nSep 18, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenome Assembly - Olympia oyster PacBio minimap/miniasm/racon\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nSep 7, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSamples Submitted - Geoduck Ctenidia to Illumina for 10x Genomics Sequencing\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nAug 28, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProject Progress - Olympia Oyster Genome Assemblies by Sean Bennett\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nAug 28, 2017\n\n\n\n\n\n\n  \n\n\n\n\nData Management - Illumina Geoduck HiSeq & MiSeq Data\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nAug 8, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoals - August 2017\n\n\n\n\n\n\n\nGoals\n\n\n\n\n\n\n\n\n\n\n\nAug 3, 2017\n\n\n\n\n\n\n  \n\n\n\n\nData Received - Geoduck Genome Sequencing by Illumina\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJul 31, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission - Olympia oyster gonad RNA to Katherine Silliman @ Univ. of Chicago\n\n\n\n\n\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nJul 20, 2017\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Olympia oyster gonad tissue in paraffin histology blocks\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 19, 2017\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Olympia oyster gonad tissue in paraffin histology blocks\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 10, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management - SRA Submission Olympia Oyster UW PacBio Data from 20170323\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJul 6, 2017\n\n\n\n\n\n\n  \n\n\n\n\nData Management – Tarball of Olympia oyster UW PacBio Data from 20170323\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJul 6, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management - OLYMPIA OYSTER UW PACBIO DATA (FROM 20170323) TO NIGHTINGALES\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJul 5, 2017\n\n\n\n\n\n\n  \n\n\n\n\nSample Annotation - Olympia oyster histology blocks (from Laura Spencer)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 5, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nManuscript Re-submission - Oly Stress Response to PeerJ for Review\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 3, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management - Olympia oyster UW PacBio Data from 20170323\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJul 3, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub Curation\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 22, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoals - June 2017\n\n\n\n\n\n\n\nGoals\n\n\n\n\n\n\n\n\n\n\n\nJun 1, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Methylation Quantification - Acropora cervicornis (Staghorn coral) DNA from Javier Casariego (FIU)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 11, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Quantification - Acropora cervicornis (Staghorn coral) DNA from Javier Casariego (FIU)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 11, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Concentration - Acropora cervicornis (Staghorn coral) DNA from Javier Casariego (FIU)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 10, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Quantification - Acropora cervicornis (Staghorn coral) DNA from Javier Casariego (FIU)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 10, 2017\n\n\n\n\n\n\n  \n\n\n\n\nSamples Received - Olympia oyster Histology Blocks and Slides (for Laura Spencer)\n\n\n\n\n\n\n\nSamples Received\n\n\n\n\n\n\n\n\n\n\n\nMay 9, 2017\n\n\n\n\n\n\n  \n\n\n\n\nSamples Received - Acropora cervicornis (Staghorn coral) DNA from Javier Casariego (FIU)\n\n\n\n\n\n\n\nSamples Received\n\n\n\n\n\n\n\n\n\n\n\nMay 9, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoals - May 2017\n\n\n\n\n\n\n\nGoals\n\n\n\n\n\n\n\n\n\n\n\nMay 2, 2017\n\n\n\n\n\n\n  \n\n\n\n\nManuscript Writing - Submitted!\n\n\n\n\n\n\n\nGenotype-by-sequencing at BGI\n\n\n\n\n\n\n\n\n\n\n\nApr 19, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nManuscript - Oly GBS 14 Day Plan\n\n\n\n\n\n\n\nGenotype-by-sequencing at BGI\n\n\n\n\n\n\n\n\n\n\n\nApr 18, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Received - Olympia oyster PacBio Data\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nMar 23, 2017\n\n\n\n\n\n\n  \n\n\n\n\nData Management – SRA Submission Oly GBS Batch Submission\n\n\n\n\n\n\n\nGenotype-by-sequencing at BGI\n\n\n\n\n\n\n\n\n\n\n\nMar 21, 2017\n\n\n\n\n\n\n  \n\n\n\n\nComputing - Owl Partially Restored\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nMar 21, 2017\n\n\n\n\n\n\n  \n\n\n\n\nData Management - SRA Submission Oly GBS Batch Submission Fail\n\n\n\n\n\n\n\nGenotype-by-sequencing at BGI\n\n\n\n\n\n\n\n\n\n\n\nMar 20, 2017\n\n\n\n\n\n\n  \n\n\n\n\nTroubleshooting - Synology NAS (Owl) Down After Update\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nMar 18, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComputing – Oly BGI GBS Reproducibility; fail?\n\n\n\n\n\n\n\nGenotype-by-sequencing at BGI\n\n\n\n\n\n\n\n\n\n\n\nMar 17, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComputing – Oly BGI GBS Reproducibility Fail (but, less so than last time)…\n\n\n\n\n\n\n\nBS-seq Libraries for Sequencing at Genewiz\n\n\n\n\n\n\n\n\n\n\n\nMar 14, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComputing - Oly BGI GBS Reproducibility Fail\n\n\n\n\n\n\n\nGenotype-by-sequencing at BGI\n\n\n\n\n\n\n\n\n\n\n\nMar 7, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFASTQC - Oly BGI GBS Raw Illumina Data Demultiplexed\n\n\n\n\n\n\n\nGenotype-by-sequencing at BGI\n\n\n\n\n\n\n\n\n\n\n\nMar 7, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFASTQC - Oly BGI GBS Raw Illumina Data\n\n\n\n\n\n\n\nGenotype-by-sequencing at BGI\n\n\n\n\n\n\n\n\n\n\n\nMar 2, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoals - March 2017\n\n\n\n\n\n\n\nGoals\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nManuscript Writing - More “Nuances” Using Authorea\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 28, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Received - Jay’s Coral RADseq and Hollie’s Geoduck Epi-RADseq\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 27, 2017\n\n\n\n\n\n\n  \n\n\n\n\nData Management - SRA Submission of Ostrea lurida GBS FASTQ Files\n\n\n\n\n\n\n\nGenotype-by-sequencing at BGI\n\n\nSRA Submissions\n\n\n\n\n\n\n\n\n\n\n\nFeb 8, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoals - February 2017\n\n\n\n\n\n\n\nGoals\n\n\n\n\n\n\n\n\n\n\n\nFeb 2, 2017\n\n\n\n\n\n\n  \n\n\n\n\nManuscript Writing - The “Nuances” of Using Authorea\n\n\n\n\n\n\n\nGenotype-by-sequencing at BGI\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 23, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission – Geoduck gDNA for Illumina Pilot Sequencing Project\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nJan 5, 2017\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - Geoduck gDNA for Illumina-initiated Sequencing Project\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJan 5, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management - Replacement of Corrupt BGI Oly Genome FASTQ Files\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJan 4, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoals - January 2017\n\n\n\n\n\n\n\nGoals\n\n\n\n\n\n\n\n\n\n\n\nJan 3, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management - Geoduck RRBS Data Integrity Verification\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 30, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Received - Geoduck RRBS Sequencing Data\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 29, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission - Geoduck Tissue & gDNA for Illumina Pilot Sequencing Project\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nDec 21, 2016\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - Geoduck gDNA for Potential Illumina-initiated Sequencing Project\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nDec 21, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission - Geoduck Reduced Representation Bisulfite Pooled Libraries\n\n\n\n\n\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nDec 20, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission - Ostrea lurida gDNA for PacBio Sequencing\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nDec 19, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management - Integrity Check of Final BGI Olympia Oyster & Geoduck Data\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nDec 15, 2016\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - Ostrea lurida DNA for PacBio Sequencing\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nDec 14, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Managment - Trim Output Cells from Jupyter Notebook\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 14, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management - Download Final BGI Genome & Assembly Files\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nDec 14, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoals - December 2016\n\n\n\n\n\n\n\nGoals\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Analysis - Continued O.lurida Fst Analysis from GBS Data\n\n\n\n\n\n\n\nGenotype-by-sequencing at BGI\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComputing - An Excercise in Futility\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 30, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Analysis - Initial O.lurida Fst Determination from GBS Data\n\n\n\n\n\n\n\nGenotype-by-sequencing at BGI\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nNov 17, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management - Tracking O.lurida FASTQ File Corruption\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nNov 17, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComputer Management - Additional Configurations for Reformatted Xserves\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nNov 16, 2016\n\n\n\n\n\n\n  \n\n\n\n\nData Management - Modify Eagle/Owl Cloud Sync Account\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nNov 7, 2016\n\n\n\n\n\n\n  \n\n\n\n\nComputing - Retrieve data from Amazon EC2 Instance\n\n\n\n\n\n\n\nGenotype-by-sequencing at BGI\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nNov 4, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoals - November 2016\n\n\n\n\n\n\n\nGoals\n\n\n\n\n\n\n\n\n\n\n\nNov 2, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management – Geoduck Small Insert Library Genome Assembly from BGI\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nOct 25, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoals - October 2016\n\n\n\n\n\n\n\nGoals\n\n\n\n\n\n\n\n\n\n\n\nOct 3, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Received – Jay’s Coral epiRADseq - Not Demultiplexed\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 19, 2016\n\n\n\n\n\n\n  \n\n\n\n\nOyster Sampling - Olympia Oyster OA Populations at Manchester\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 12, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Received - Jay’s Coral epiRADseq\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 8, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoals - September 2016\n\n\n\n\n\n\n\nGoals\n\n\n\n\n\n\n\n\n\n\n\nSep 6, 2016\n\n\n\n\n\n\n  \n\n\n\n\nData Management - Synology Cloud Sync to UW Google Drive\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nAug 29, 2016\n\n\n\n\n\n\n  \n\n\n\n\nServer HDD Failure – Owl\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nAug 22, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nManuscript Submission - Oly Stress Response to PeerJ for Review\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 18, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Analysis - fastStructure Population Analysis of Oly GBS PyRAD Output\n\n\n\n\n\n\n\nGenotype-by-sequencing at BGI\n\n\n\n\n\n\n\n\n\n\n\nAug 16, 2016\n\n\n\n\n\n\n  \n\n\n\n\nComputing - Amazon EC2 Cost “Analysis”\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 1, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoals - August 2016\n\n\n\n\n\n\n\nGoals\n\n\n\n\n\n\n\n\n\n\n\nAug 1, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Analysis - PyRad Analysis of Olympia Oyster GBS Data\n\n\n\n\n\n\n\nGenotype-by-sequencing at BGI\n\n\n\n\n\n\n\n\n\n\n\nJul 27, 2016\n\n\n\n\n\n\n  \n\n\n\n\nComputing - Not Enough Power!\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 18, 2016\n\n\n\n\n\n\n  \n\n\n\n\nComputing - Amazon EC2 Instance Out of Space?\n\n\n\n\n\n\n\nGenotype-by-sequencing at BGI\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nJul 17, 2016\n\n\n\n\n\n\n  \n\n\n\n\nComputing - A Very Quick “Guide” to Amazon EC2 Continued\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 14, 2016\n\n\n\n\n\n\n  \n\n\n\n\nDissection - Frozen Geoduck & Pacific Oyster\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 14, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFilter Replacement - Xserve Server Rack Enclosure\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nJul 14, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComputing - The Very Quick “Guide” to Amazon Web Services Cloud Computing Instances (EC2)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 13, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Methylation Quantification - Coral DNA from Jose M. Eirin-Lopez (Florida International University)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 7, 2016\n\n\n\n\n\n\n  \n\n\n\n\nGoals - July 2016\n\n\n\n\n\n\n\nGoals\n\n\n\n\n\n\n\n\n\n\n\nJul 1, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Quantification - Coral DNA from Jose M. Eirin-Lopez (Florida International University)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 30, 2016\n\n\n\n\n\n\n  \n\n\n\n\nSamples Received - Coral DNA from Jose M. Eirin-Lopez (Florida International University)\n\n\n\n\n\n\n\nSamples Received\n\n\n\n\n\n\n\n\n\n\n\nJun 15, 2016\n\n\n\n\n\n\n  \n\n\n\n\nDocker - VirtualBox Defaults on OS X\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nJun 14, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDocker - One liner to create Docker container\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 9, 2016\n\n\n\n\n\n\n  \n\n\n\n\nRAM Upgrade - Roadrunner (Apple Xserve) to 48GB RAM\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nJun 9, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoals - June 2016\n\n\n\n\n\n\n\nGoals\n\n\n\n\n\n\n\n\n\n\n\nJun 6, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDocker - Improving Roberts Lab Reproducibility\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nJun 1, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComputer Setup - Cluster Node003 Conversion\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nMay 31, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Analysis - Oly GBS Data Using Stacks 1.37\n\n\n\n\n\n\n\nGenotype-by-sequencing at BGI\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management - Olympia Oyster Small Insert Library Genome Assembly from BGI\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nMay 16, 2016\n\n\n\n\n\n\n  \n\n\n\n\nGBS Frustrations\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 3, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoals - May 2016\n\n\n\n\n\n\n\nGoals\n\n\n\n\n\n\n\n\n\n\n\nMay 2, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSRA Release - Transcriptomic Profiles of Adult Female & Male Gonads in Panopea generosa (Pacific geoduck)\n\n\n\n\n\n\n\nProtein expression profiles during sexual maturation in Geoduck\n\n\nSRA Submissions\n\n\n\n\n\n\n\n\n\n\n\nApr 28, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management - O.lurida Raw BGI GBS FASTQ Data\n\n\n\n\n\n\n\nGenotype-by-sequencing at BGI\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nApr 27, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComputing - Speed Benchmark Comparisons Between Local, External, & Server Files\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 27, 2016\n\n\n\n\n\n\n  \n\n\n\n\nData Analysis - Subset Olympia Oyster GBS Data from BGI as Single Population Using PyRAD\n\n\n\n\n\n\n\nGenotype-by-sequencing at BGI\n\n\n\n\n\n\n\n\n\n\n\nApr 18, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management - Concatenate FASTQ files from Oly MBDseq Project\n\n\n\n\n\n\n\nMBD Enrichment for Sequencing at ZymoResearch\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nApr 11, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Analysis - Oly GBS Data from BGI Using Stacks\n\n\n\n\n\n\n\nGenotype-by-sequencing at BGI\n\n\n\n\n\n\n\n\n\n\n\nApr 6, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSoftware Install - samtools-0.1.19 and stacks-1.37\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nApr 6, 2016\n\n\n\n\n\n\n  \n\n\n\n\nSRA Submission – Genome sequencing of the Olympia oyster (Ostrea lurida)\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\nSRA Submissions\n\n\n\n\n\n\n\n\n\n\n\nMar 28, 2016\n\n\n\n\n\n\n  \n\n\n\n\nSRA Submission – Genome sequencing of the Pacific geoduck (Panopea generosa)\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\nSRA Submissions\n\n\n\n\n\n\n\n\n\n\n\nMar 28, 2016\n\n\n\n\n\n\n  \n\n\n\n\nSRA Submission - Transcriptomic Profiles of Adult Female & Male Gonads in Panopea generosa (Pacific geoduck).\n\n\n\n\n\n\n\nProtein expression profiles during sexual maturation in Geoduck\n\n\n\n\n\n\n\n\n\n\n\nMar 24, 2016\n\n\n\n\n\n\n  \n\n\n\n\nSRA Submission - Individual Transcriptomic Profiles of C.gigas Before & After Heat Shock\n\n\n\n\n\n\n\nSRA Submissions\n\n\n\n\n\n\n\n\n\n\n\nMar 23, 2016\n\n\n\n\n\n\n  \n\n\n\n\nData Management - SRA Submission Overview\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 23, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management - O. lurida genotype-by-sequencing (GBS) data from BGI\n\n\n\n\n\n\n\nGenotype-by-sequencing at BGI\n\n\n\n\n\n\n\n\n\n\n\nMar 14, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Received - Initial Geoduck Genome Assembly from BGI\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nMar 14, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Received - Initial Olympia oyster Genome Assembly from BGI\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nMar 14, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management - O.lurida 2bRAD Dec2015 Undetermined FASTQ files\n\n\n\n\n\n\n\n2bRAD Library Tests for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nMar 8, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Management - High-throughput Sequencing Data\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 4, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Received - Ostrea lurida MBD-enriched BS-seq\n\n\n\n\n\n\n\nMBD Enrichment for Sequencing at ZymoResearch\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nFeb 3, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Received - Ostrea lurida genome sequencing files from BGI\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJan 27, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Received - Panopea generosa genome sequencing files from BGI\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJan 27, 2016\n\n\n\n\n\n\n  \n\n\n\n\nData Analysis - Identification of duplicate files on Eagle\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nJan 14, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Received - Bisulfite-treated Illumina Sequencing from Genewiz\n\n\n\n\n\n\n\nBS-seq Libraries for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nJan 8, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData Received - Oly 2bRAD Illumina Sequencing from Genewiz\n\n\n\n\n\n\n\n2bRAD Library Tests for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nDec 31, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission - BS-seq Library Pool to Genewiz\n\n\n\n\n\n\n\nBS-seq Libraries for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nDec 22, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIllumina Methylation Library Quantification - BS-seq Oly/C.gigas Libraries\n\n\n\n\n\n\n\nBS-seq Libraries for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nDec 22, 2015\n\n\n\n\n\n\n  \n\n\n\n\nIllumina Methylation Library Construction - Oly/C.gigas Bisulfite-treated DNA\n\n\n\n\n\n\n\nBS-seq Libraries for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nDec 21, 2015\n\n\n\n\n\n\n  \n\n\n\n\nBioanalyzer - Bisulfite-treated Oly/C.gigas DNA\n\n\n\n\n\n\n\nBS-seq Libraries for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nDec 18, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReagent Prep - RNA Pico 6000 Ladder\n\n\n\n\n\n\n\nReagent Prep\n\n\n\n\n\n\n\n\n\n\n\nDec 18, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBisulfite Treatment - Oly Reciprocal Transplant DNA & C.gigas Lotterhos DNA for BS-seq\n\n\n\n\n\n\n\nBS-seq Libraries for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nDec 18, 2015\n\n\n\n\n\n\n  \n\n\n\n\nAgarose Gel - Oly gDNA for BS-seq Libraries, Take Two\n\n\n\n\n\n\n\nBS-seq Libraries for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nDec 17, 2015\n\n\n\n\n\n\n  \n\n\n\n\nAgarose Gel - Oly gDNA for BS-seq Libraries\n\n\n\n\n\n\n\nBS-seq Libraries for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nDec 17, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Isolation - Oly gDNA for BS-seq\n\n\n\n\n\n\n\nBS-seq Libraries for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nDec 16, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission - 2bRAD Libraries for Genewiz\n\n\n\n\n\n\n\n2bRAD Library Tests for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nDec 10, 2015\n\n\n\n\n\n\n  \n\n\n\n\nSamples Received - C.gigas Tissue & DNA from Katie Lotterhos\n\n\n\n\n\n\n\nSamples Received\n\n\n\n\n\n\n\n\n\n\n\nDec 10, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission - Olympia oyster MBD-enriched DNA to ZymoResearch\n\n\n\n\n\n\n\nMBD Enrichment for Sequencing at ZymoResearch\n\n\nOlympia oyster reciprocal transplant\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nDec 8, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission - Additional Olympia Oyster gDNA for Genome Sequencing @ BGI\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission - Additional Geoduck gDNA for Genome Sequencing @ BGI\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2015\n\n\n\n\n\n\n  \n\n\n\n\nData Storage - Synology DX513\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nNov 30, 2015\n\n\n\n\n\n\n  \n\n\n\n\nSample Submission - Oly Oyster Bay Tissues for GBS\n\n\n\n\n\n\n\nGenotype-by-sequencing at BGI\n\n\nOlympia oyster reciprocal transplant\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nNov 30, 2015\n\n\n\n\n\n\n  \n\n\n\n\nSamples Received - Oly Tissue & DNA from Katherine Silliman\n\n\n\n\n\n\n\nOlympia oyster reciprocal transplant\n\n\nSamples Received\n\n\n\n\n\n\n\n\n\n\n\nNov 25, 2015\n\n\n\n\n\n\n  \n\n\n\n\nDNA Quality Assessment - Geoduck & Olympia Oyster gDNA\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nNov 25, 2015\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - Olympia Oyster Outer Mantle gDNA\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nNov 25, 2015\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - Geoduck Ctenidia gDNA\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nNov 25, 2015\n\n\n\n\n\n\n  \n\n\n\n\nPhenol-Chloroform DNA Cleanup - Geoduck gDNA\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nNov 24, 2015\n\n\n\n\n\n\n  \n\n\n\n\nPhenol-Chloroform DNA Cleanup - Olympia Oyster gDNA\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nNov 24, 2015\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - Geoduck Adductor Muscle gDNA\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nNov 24, 2015\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - Olympia Oyster Outer Mantle gDNA\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nNov 24, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Quantification - MBD-enriched Olympia oyster DNA\n\n\n\n\n\n\n\nMBD Enrichment for Sequencing at ZymoResearch\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nNov 23, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEthanol Precipitation - Olympia oyster MBD\n\n\n\n\n\n\n\nMBD Enrichment for Sequencing at ZymoResearch\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nNov 22, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMBD Enrichment - Sonicated Olympia Oyster gDNA\n\n\n\n\n\n\n\nMBD Enrichment for Sequencing at ZymoResearch\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nNov 21, 2015\n\n\n\n\n\n\n  \n\n\n\n\nDNA Sonication - Oly gDNA for MBD\n\n\n\n\n\n\n\nMBD Enrichment for Sequencing at ZymoResearch\n\n\n\n\n\n\n\n\n\n\n\nNov 19, 2015\n\n\n\n\n\n\n  \n\n\n\n\nqPCR – Oly RAD-Seq Library Quantification\n\n\n\n\n\n\n\n2bRAD Library Tests for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nNov 17, 2015\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Oly RAD-Seq Library Quantification\n\n\n\n\n\n\n\n2bRAD Library Tests for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nNov 16, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGel Extraction - Oly RAD-Seq Prep Scale PCR\n\n\n\n\n\n\n\n2bRAD Library Tests for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nNov 16, 2015\n\n\n\n\n\n\n  \n\n\n\n\nDNA Quality Assessment - Geoduck, Oly & Oly 2SN\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\nOlympia Oyster Genome Sequencing\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nNov 13, 2015\n\n\n\n\n\n\n  \n\n\n\n\nPCR – Oly RAD-seq Prep Scale PCR\n\n\n\n\n\n\n\n2bRAD Library Tests for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nNov 13, 2015\n\n\n\n\n\n\n  \n\n\n\n\nPCR – Oly RAD-seq Test-scale PCR\n\n\n\n\n\n\n\n2bRAD Library Tests for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nNov 12, 2015\n\n\n\n\n\n\n  \n\n\n\n\nDNA Quantification & Quality Assessment - Oly 2SN gDNA\n\n\n\n\n\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nNov 4, 2015\n\n\n\n\n\n\n  \n\n\n\n\nDNA Quantification & Quality Assessment - Geoduck & Oly gDNA\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nNov 4, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Isolations – Oly Fidalgo 2SN Ctenidia\n\n\n\n\n\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nNov 3, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOyster Sampling - Oly Fidalgo 2SN, 2HL, 2NF Reciprocal Transplants Final Samplings\n\n\n\n\n\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nOct 30, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Isolation – Geoduck & Olympia Oyster\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nOct 29, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdaptor Ligation – Oly AlfI-Digested gDNA for RAD-seq\n\n\n\n\n\n\n\n2bRAD Library Tests for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nOct 29, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRestriction Digest – Oly gDNA for RAD-seq w/AlfI\n\n\n\n\n\n\n\n2bRAD Library Tests for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nOct 28, 2015\n\n\n\n\n\n\n  \n\n\n\n\nTroubleshooting - Oly RAD-seq\n\n\n\n\n\n\n\n2bRAD Library Tests for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nOct 23, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Isolations - Fidalgo 2SN Reciprocal Transplants Final Samplings\n\n\n\n\n\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nOct 21, 2015\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Oly RAD-seq Prep Scale PCR\n\n\n\n\n\n\n\n2bRAD Library Tests for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nOct 13, 2015\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Oly RAD-seq Test-scale PCR\n\n\n\n\n\n\n\n2bRAD Library Tests for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nOct 12, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdaptor Ligation – Oly AlfI-Digested gDNA for RAD-seq\n\n\n\n\n\n\n\n2bRAD Library Tests for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nOct 9, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRestriction Digest – Oly gDNA for RAD-seq w/AlfI\n\n\n\n\n\n\n\n2bRAD Library Tests for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nOct 9, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission - Additional Geoduck gDNA for Genome Sequencing @ BGI\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nOct 6, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission - Additional Olympia Oyster gDNA for Genome Sequencing @ BGI\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nOct 6, 2015\n\n\n\n\n\n\n  \n\n\n\n\nAgarose Gel - Geoduck & Olympia Oyster gDNA\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\nOlympia Oyster Genome Sequencing\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2015\n\n\n\n\n\n\n  \n\n\n\n\nDNA Quantification - Pooled geoduck gDNA\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2015\n\n\n\n\n\n\n  \n\n\n\n\ngDNA Isolation - Geoduck Adductor Muscle\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2015\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - Geoduck & Olympia Oyster\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\nOlympia Oyster Genome Sequencing\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nOct 2, 2015\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Oly RAD-seq Test-scale PCR\n\n\n\n\n\n\n\n2bRAD Library Tests for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nOct 2, 2015\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Oly RAD-seq Test-scale PCR\n\n\n\n\n\n\n\n2bRAD Library Tests for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\nReagent Prep\n\n\n\n\n\n\n\n\n\n\n\nOct 1, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdaptor Ligation - Oly AlfI-Digested gDNA for RAD-seq\n\n\n\n\n\n\n\n2bRAD Library Tests for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\nReagent Prep\n\n\n\n\n\n\n\n\n\n\n\nOct 1, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoals - October 2015\n\n\n\n\n\n\n\nGoals\n\n\n\n\n\n\n\n\n\n\n\nOct 1, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRestriction Digest - Oly gDNA for RAD-seq w/AlfI\n\n\n\n\n\n\n\n2bRAD Library Tests for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\nReagent Prep\n\n\n\n\n\n\n\n\n\n\n\nSep 30, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission - Olympia Oyster gDNA for Genome Sequencing @ BGI\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nSep 21, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission - Geoduck gDNA for Genome Sequencing @ BGI\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nSep 21, 2015\n\n\n\n\n\n\n  \n\n\n\n\nUninterruptible Power Supplies (UPS)\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nSep 18, 2015\n\n\n\n\n\n\n  \n\n\n\n\nAgarose Gel - Geoduck & Olympia oyster gDNA Integrity Check\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nSep 17, 2015\n\n\n\n\n\n\n  \n\n\n\n\nEthanol Precipitation - Geoduck & Olympia oyster gDNA\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nSep 17, 2015\n\n\n\n\n\n\n  \n\n\n\n\nAgarose Gel - Olympia oyster Whole Body gDNA Integrity Check\n\n\n\n\n\n\n\n2bRAD Library Tests for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nSep 17, 2015\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - Olympia oyster whole body\n\n\n\n\n\n\n\n2bRAD Library Tests for Sequencing at Genewiz\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nSep 16, 2015\n\n\n\n\n\n\n  \n\n\n\n\nAgarose Gel – Geoduck gDNA Integrity Check\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nSep 16, 2015\n\n\n\n\n\n\n  \n\n\n\n\nGenomic DNA Isolation – Geoduck Adductor Muscle & Foot\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nSep 16, 2015\n\n\n\n\n\n\n  \n\n\n\n\nAgarose Gel - Geoduck & Olympia Oyster gDNA Integrity Check\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nSep 15, 2015\n\n\n\n\n\n\n  \n\n\n\n\nGenomic DNA Isolation – Olympia oyster adductor musle & mantle\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nSep 15, 2015\n\n\n\n\n\n\n  \n\n\n\n\nGenomic DNA Isolation – Geoduck Adductor Muscle & Foot\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nSep 15, 2015\n\n\n\n\n\n\n  \n\n\n\n\nAgarose Gel - Geoduck & Olympia Oyster gDNA Integrity Check\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nSep 15, 2015\n\n\n\n\n\n\n  \n\n\n\n\nGenomic DNA Isolation - Olympia oyster adductor musle & mantle\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nSep 14, 2015\n\n\n\n\n\n\n  \n\n\n\n\nGenomic DNA Isolation - Geoduck Adductor Muscle & Foot\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nSep 14, 2015\n\n\n\n\n\n\n  \n\n\n\n\nAgarose Gel - Geoduck & Olympia Oyster gDNA Integrity Check\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2015\n\n\n\n\n\n\n  \n\n\n\n\nGenomic DNA Isolation - Olympia oyster adductor musle & mantle\n\n\n\n\n\n\n\nOlympia Oyster Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nServer Email Notifications Fix - Eagle\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2015\n\n\n\n\n\n\n  \n\n\n\n\nGenomic DNA Isolation - Geoduck Adductor Muscle & Foot\n\n\n\n\n\n\n\nGeoduck Genome Sequencing\n\n\n\n\n\n\n\n\n\n\n\nAug 28, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRAD-Seq Library Prep Reagents\n\n\n\n\n\n\n\n2bRAD Library Tests for Sequencing at Genewiz\n\n\nReagent Prep\n\n\n\n\n\n\n\n\n\n\n\nAug 19, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSsoFast EvaGreen Supermix Aliquots\n\n\n\n\n\n\n\nReagent Prep\n\n\n\n\n\n\n\n\n\n\n\nAug 11, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReverse Transcription – O.lurida DNased RNA 1hr post-mechanical stress\n\n\n\n\n\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nAug 6, 2015\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Jake’s O.lurida ctenidia 1hr post-mechanical stress DNased RNA\n\n\n\n\n\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nAug 6, 2015\n\n\n\n\n\n\n  \n\n\n\n\nRNA Quantification - O.lurida 1hr post-mechanical heat stress DNased RNA\n\n\n\n\n\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nAug 6, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoals - August 2015\n\n\n\n\n\n\n\nGoals\n\n\n\n\n\n\n\n\n\n\n\nAug 3, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission – Olympia oyster PCRs Sanger Sequencing\n\n\n\n\n\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nJul 31, 2015\n\n\n\n\n\n\n  \n\n\n\n\nServer HDD Failure - Owl\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nJul 31, 2015\n\n\n\n\n\n\n  \n\n\n\n\nDNase Treatment - O.lurida Ctenidia 1hr Post-Mechanical Stress RNA\n\n\n\n\n\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nJul 27, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Isolation – O.lurida Ctenidia 1hr Post-Mechanical Stress\n\n\n\n\n\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nJul 15, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Isolation - O.lurida Ctenidia 1hr Post-Mechanical Stress\n\n\n\n\n\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nJul 10, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSsoFast EvaGreen Supermix Aliquots\n\n\n\n\n\n\n\nReagent Prep\n\n\n\n\n\n\n\n\n\n\n\nJul 10, 2015\n\n\n\n\n\n\n  \n\n\n\n\nAutomatic Notebook Backups - wget Script & Synology Task Scheduler\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nJul 2, 2015\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Sea Pen luciferase\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 2, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGOALS - July 2015\n\n\n\n\n\n\n\nGoals\n\n\n\n\n\n\n\n\n\n\n\nJul 2, 2015\n\n\n\n\n\n\n  \n\n\n\n\nOpticon2 Calibration\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 30, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNAseq Data Receipt - Geoduck Gonad RNA 100bp PE Illumina\n\n\n\n\n\n\n\nProtein expression profiles during sexual maturation in Geoduck\n\n\n\n\n\n\n\n\n\n\n\nJun 30, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission – Olympia oyster PCRs Sanger Sequencing\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 25, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReverse Transcription - O.lurida DNased RNA Controls and 1hr Heat Shock\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 17, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission – Olympia oyster & Sea Pen PCRs Sanger Sequencing\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 16, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGel Purification - Olympia Oyster and Sea Pen PCRs\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 15, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission - Olympia oyster PCRs Sanger Sequencing\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 12, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission - Geoduck Gonad for RNA-seq\n\n\n\n\n\n\n\nProtein expression profiles during sexual maturation in Geoduck\n\n\n\n\n\n\n\n\n\n\n\nJun 1, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoals - June 2015\n\n\n\n\n\n\n\nGoals\n\n\n\n\n\n\n\n\n\n\n\nJun 1, 2015\n\n\n\n\n\n\n  \n\n\n\n\nBioanalyzer - Geoduck Gonad RNA Quality Assessment\n\n\n\n\n\n\n\nProtein expression profiles during sexual maturation in Geoduck\n\n\n\n\n\n\n\n\n\n\n\nMay 27, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReverse Transcription - Subset of Jake’s O.lurida DNased RNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 22, 2015\n\n\n\n\n\n\n  \n\n\n\n\nBioinformatics – Trimmomatic/FASTQC on C.gigas Larvae OA NGS Data\n\n\n\n\n\n\n\nCrassostrea gigas larvae OA (2011) bisulfite sequencing\n\n\n\n\n\n\n\n\n\n\n\nMay 22, 2015\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Re-run Jake’s O.lurida DNased RNA Samples NC1, SC1, SC2, SC4 from 20150514\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 21, 2015\n\n\n\n\n\n\n  \n\n\n\n\nqPCR – Jake’s O.lurida ctenidia DNased RNA (1hr Heat Shock Samples)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 14, 2015\n\n\n\n\n\n\n  \n\n\n\n\nqPCR – Jake’s O.lurida ctenidia DNased RNA (Control Samples)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 14, 2015\n\n\n\n\n\n\n  \n\n\n\n\nDNase Treatment - Jake’s O.lurida Ctenidia RNA (1hr Heat Shock) from 20150506\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 14, 2015\n\n\n\n\n\n\n  \n\n\n\n\nDNase Treatment - Jake’s O.lurida Ctenidia RNA (Controls) from 20150507\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 14, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nISO Creation - OpticonMonitor3 Disc Cloning\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nMay 14, 2015\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Jake O.lurida ctenidia RNA (Heat Shock Samples) from 20150506\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 12, 2015\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Jake O.lurida ctenidia RNA (Control Samples) From 20150507\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 12, 2015\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation – Geoduck Gonad in Paraffin Histology Blocks\n\n\n\n\n\n\n\nProtein expression profiles during sexual maturation in Geoduck\n\n\n\n\n\n\n\n\n\n\n\nMay 7, 2015\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation – Jake’s O. lurida Ctenidia Control from 20150422\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 7, 2015\n\n\n\n\n\n\n  \n\n\n\n\nBioinformatics - Trimmomatic/FASTQC on C.gigas Larvae OA NGS Data\n\n\n\n\n\n\n\nCrassostrea gigas larvae OA (2011) bisulfite sequencing\n\n\n\n\n\n\n\n\n\n\n\nMay 6, 2015\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Jake’s O. lurida Ctenidia 1hr Heat Stress from 20150422\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 6, 2015\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation – Geoduck Gonad in Paraffin Histology Blocks\n\n\n\n\n\n\n\nProtein expression profiles during sexual maturation in Geoduck\n\n\n\n\n\n\n\n\n\n\n\nMay 5, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBLAST - C.gigas Larvae OA Illumina Data Against GenBank nt DB\n\n\n\n\n\n\n\nCrassostrea gigas larvae OA (2011) bisulfite sequencing\n\n\n\n\n\n\n\n\n\n\n\nMay 4, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoals - May 2015\n\n\n\n\n\n\n\nCrassostrea gigas larvae OA (2011) bisulfite sequencing\n\n\nGoals\n\n\nLineage-specific DNA methylation patterns in developing oysters\n\n\nLSU C.virginica Oil Spill MBD BS Sequencing\n\n\nProtein expression profiles during sexual maturation in Geoduck\n\n\n\n\n\n\n\n\n\n\n\nMay 1, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBLASTN - C.gigas OA Larvae to C.gigas Ensembl 1.24 BLAST DB\n\n\n\n\n\n\n\nCrassostrea gigas larvae OA (2011) bisulfite sequencing\n\n\n\n\n\n\n\n\n\n\n\nApr 29, 2015\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation – Geoduck Gonad in Paraffin Histology Blocks\n\n\n\n\n\n\n\nProtein expression profiles during sexual maturation in Geoduck\n\n\n\n\n\n\n\n\n\n\n\nApr 26, 2015\n\n\n\n\n\n\n  \n\n\n\n\nBioanalyzer Data - Geoduck RNA from Histology Blocks\n\n\n\n\n\n\n\nProtein expression profiles during sexual maturation in Geoduck\n\n\n\n\n\n\n\n\n\n\n\nApr 24, 2015\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation – Geoduck Gonad in Paraffin Histology Blocks\n\n\n\n\n\n\n\nProtein expression profiles during sexual maturation in Geoduck\n\n\n\n\n\n\n\n\n\n\n\nApr 23, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBioanalyzer Submission - Geoduck Gonad RNA from Histology Blocks\n\n\n\n\n\n\n\nProtein expression profiles during sexual maturation in Geoduck\n\n\n\n\n\n\n\n\n\n\n\nApr 22, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuality Trimming - C.gigas Larvae OA BS-Seq Data\n\n\n\n\n\n\n\nCrassostrea gigas larvae OA (2011) bisulfite sequencing\n\n\n\n\n\n\n\n\n\n\n\nApr 15, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuality Trimming - LSU C.virginica Oil Spill MBD BS-Seq Data\n\n\n\n\n\n\n\nLSU C.virginica Oil Spill MBD BS Sequencing\n\n\n\n\n\n\n\n\n\n\n\nApr 15, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSequence Data Analysis - LSU C.virginica Oil Spill MBD BS-Seq Data\n\n\n\n\n\n\n\nLSU C.virginica Oil Spill MBD BS Sequencing\n\n\n\n\n\n\n\n\n\n\n\nApr 13, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSequence Data Analysis - C.gigas Larvae OA BS-Seq Data\n\n\n\n\n\n\n\nCrassostrea gigas larvae OA (2011) bisulfite sequencing\n\n\n\n\n\n\n\n\n\n\n\nApr 13, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSequence Data - C.gigas OA Larvae BS-Seq Demultiplexed\n\n\n\n\n\n\n\nCrassostrea gigas larvae OA (2011) bisulfite sequencing\n\n\n\n\n\n\n\n\n\n\n\nApr 13, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSequence Data - LSU C.virginica Oil Spill MBD BS-Seq Demultiplexed\n\n\n\n\n\n\n\nLSU C.virginica Oil Spill MBD BS Sequencing\n\n\n\n\n\n\n\n\n\n\n\nApr 13, 2015\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Geoduck Gonad in Paraffin Histology Blocks\n\n\n\n\n\n\n\nProtein expression profiles during sexual maturation in Geoduck\n\n\n\n\n\n\n\n\n\n\n\nApr 8, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSequencing Data - C.gigas Larvae OA\n\n\n\n\n\n\n\nCrassostrea gigas larvae OA (2011) bisulfite sequencing\n\n\n\n\n\n\n\n\n\n\n\nMar 19, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEpinext Adaptor 1 Counts - LSU C.virginica Oil Spill Samples\n\n\n\n\n\n\n\nLSU C.virginica Oil Spill MBD BS Sequencing\n\n\n\n\n\n\n\n\n\n\n\nMar 17, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTruSeq Adaptor Counts – LSU C.virginica Oil Spill Sequences\n\n\n\n\n\n\n\nLSU C.virginica Oil Spill MBD BS Sequencing\n\n\n\n\n\n\n\n\n\n\n\nMar 16, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTruSeq Adaptor Identification Method Comparison - LSU C.virginica Oil Spill Sequences\n\n\n\n\n\n\n\nLSU C.virginica Oil Spill MBD BS Sequencing\n\n\n\n\n\n\n\n\n\n\n\nMar 14, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Quantification - Claire’s C.gigas Sheared DNA\n\n\n\n\n\n\n\nLineage-specific DNA methylation patterns in developing oysters\n\n\n\n\n\n\n\n\n\n\n\nMar 3, 2015\n\n\n\n\n\n\n  \n\n\n\n\nLibrary Quality Assessment - C.gigas OA larvae Illumina libraries\n\n\n\n\n\n\n\nCrassostrea gigas larvae OA (2011) bisulfite sequencing\n\n\n\n\n\n\n\n\n\n\n\nMar 2, 2015\n\n\n\n\n\n\n  \n\n\n\n\nBS-seq Library Prep - C.gigas Larvae OA 1000ppm\n\n\n\n\n\n\n\nCrassostrea gigas larvae OA (2011) bisulfite sequencing\n\n\n\n\n\n\n\n\n\n\n\nFeb 27, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Quantification - C.gigas Larvae 1000ppm\n\n\n\n\n\n\n\nCrassostrea gigas larvae OA (2011) bisulfite sequencing\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2015\n\n\n\n\n\n\n  \n\n\n\n\nDNA Quantification - Claire’s Sheared C.gigas Mantle Heat Shock Samples\n\n\n\n\n\n\n\nLineage-specific DNA methylation patterns in developing oysters\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2015\n\n\n\n\n\n\n  \n\n\n\n\nBioanalyzer - C.gigas Sheared DNA from 20140108\n\n\n\n\n\n\n\nLineage-specific DNA methylation patterns in developing oysters\n\n\n\n\n\n\n\n\n\n\n\nFeb 20, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLibrary Prep - Quantification of C.gigas larvae OA 1000ppm library\n\n\n\n\n\n\n\nCrassostrea gigas larvae OA (2011) bisulfite sequencing\n\n\n\n\n\n\n\n\n\n\n\nFeb 9, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSequencing Data - LSU C.virginica MBD BS-Seq\n\n\n\n\n\n\n\nLSU C.virginica Oil Spill MBD BS Sequencing\n\n\n\n\n\n\n\n\n\n\n\nFeb 9, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBisulfite NGS Library Prep - Bisulfite Conversion & Illumina Library Construction of C.gigas larvae DNA\n\n\n\n\n\n\n\nCrassostrea gigas larvae OA (2011) bisulfite sequencing\n\n\n\n\n\n\n\n\n\n\n\nFeb 6, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBisuflite NGS Library Prep – C.gigas larvae OA bisulfite library quantification\n\n\n\n\n\n\n\nCrassostrea gigas larvae OA (2011) bisulfite sequencing\n\n\n\n\n\n\n\n\n\n\n\nJan 28, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBisuflite NGS Library Prep - C.gigas larvae OA bisulfite DNA (continued from yesterday)\n\n\n\n\n\n\n\nCrassostrea gigas larvae OA (2011) bisulfite sequencing\n\n\n\n\n\n\n\n\n\n\n\nJan 27, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBisuflite NGS Library Prep - C.gigas larvae OA bisulfite DNA\n\n\n\n\n\n\n\nCrassostrea gigas larvae OA (2011) bisulfite sequencing\n\n\n\n\n\n\n\n\n\n\n\nJan 26, 2015\n\n\n\n\n\n\n  \n\n\n\n\nLibrary Cleanup - LSU C.virginica MBD BS Library\n\n\n\n\n\n\n\nLSU C.virginica Oil Spill MBD BS Sequencing\n\n\n\n\n\n\n\n\n\n\n\nJan 22, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Bisulfite Conversion - C.gigas larvae OA Sheared DNA\n\n\n\n\n\n\n\nCrassostrea gigas larvae OA (2011) bisulfite sequencing\n\n\n\n\n\n\n\n\n\n\n\nJan 14, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpeedVac - C.gigas larvae OA DNA\n\n\n\n\n\n\n\nCrassostrea gigas larvae OA (2011) bisulfite sequencing\n\n\n\n\n\n\n\n\n\n\n\nJan 12, 2015\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - C.gigas larvae from 2011 NOAA OA Experiment\n\n\n\n\n\n\n\nCrassostrea gigas larvae OA (2011) bisulfite sequencing\n\n\n\n\n\n\n\n\n\n\n\nJan 9, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBisulfite NGS Library - LSU C.virginica Oil Spill MBD Bisulfite DNA Sequencing Submission\n\n\n\n\n\n\n\nLSU C.virginica Oil Spill MBD BS Sequencing\n\n\n\n\n\n\n\n\n\n\n\nDec 22, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBisulfite NGS Library Prep - LSU C.virginica Oil Spill MBD Bisulfite DNA and Emma’s C.gigas Larvae OA Bisulfite DNA (continued from yesterday)\n\n\n\n\n\n\n\nCrassostrea gigas larvae OA (2011) bisulfite sequencing\n\n\nLSU C.virginica Oil Spill MBD BS Sequencing\n\n\n\n\n\n\n\n\n\n\n\nDec 18, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBisulfite NGS Library Prep - LSU C.virginica Oil Spill Bisulfite DNA and Emma’s C.gigas Larvae OA Bisulfite DNA\n\n\n\n\n\n\n\nCrassostrea gigas larvae OA (2011) bisulfite sequencing\n\n\nLSU C.virginica Oil Spill MBD BS Sequencing\n\n\n\n\n\n\n\n\n\n\n\nDec 17, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBisulfite Conversion - LSU C.virginica Oil Spill MBD DNA and Emma’s C.gigas Larvae OA DNA\n\n\n\n\n\n\n\nCrassostrea gigas larvae OA (2011) bisulfite sequencing\n\n\nLSU C.virginica Oil Spill MBD BS Sequencing\n\n\n\n\n\n\n\n\n\n\n\nDec 16, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Isolation - Claire’s C.gigas Female Gonad for Illumina Bisulfite Sequencing\n\n\n\n\n\n\n\nLineage-specific DNA methylation patterns in developing oysters\n\n\n\n\n\n\n\n\n\n\n\nDec 11, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEtOH Precipitation - LSU C.virginica Oil Spill MBD Continued (from 20141126)\n\n\n\n\n\n\n\nLSU C.virginica Oil Spill MBD BS Sequencing\n\n\n\n\n\n\n\n\n\n\n\nDec 2, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMethylated DNA Enrichment (MBD) - LSU C.virginica Oil Spill gDNA\n\n\n\n\n\n\n\nLSU C.virginica Oil Spill MBD BS Sequencing\n\n\n\n\n\n\n\n\n\n\n\nNov 26, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Shearing - LSU C.virginica Oil Spill gDNA\n\n\n\n\n\n\n\nLSU C.virginica Oil Spill MBD BS Sequencing\n\n\n\n\n\n\n\n\n\n\n\nNov 25, 2014\n\n\n\n\n\n\n  \n\n\n\n\nGel - Sheared gDNA\n\n\n\n\n\n\n\nLSU C.virginica Oil Spill MBD BS Sequencing\n\n\n\n\n\n\n\n\n\n\n\nNov 25, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Seq - C.gigas Total RNA from Claire’s Pre/Post Heat Shock\n\n\n\n\n\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nNov 24, 2014\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - C.gigas Larvae from Emma OA Experiments\n\n\n\n\n\n\n\nCrassostrea gigas larvae OA (2011) bisulfite sequencing\n\n\n\n\n\n\n\n\n\n\n\nNov 21, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRAD Sequencing - Oly Oyster gDNA-01 RAD Library (from 20141110)\n\n\n\n\n\n\n\nOlympia oyster reciprocal transplant\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nNov 17, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Quantification - Oly Oyster gDNA-01 RAD Library\n\n\n\n\n\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nNov 10, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLibrary Prep - Oly Oyster gDNA-01 RAD\n\n\n\n\n\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nNov 7, 2014\n\n\n\n\n\n\n  \n\n\n\n\nDNA Shearing & Size Selection - Oly Oyster gDNA RAD P1 Adapters (from 20141105)\n\n\n\n\n\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nNov 6, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLigation - Illumina P1 Adapters for Oly Oyster gDNA-01 RAD Sequencing (from 20141031)\n\n\n\n\n\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2014\n\n\n\n\n\n\n  \n\n\n\n\nRestriction Digest - Oly Oyster gDNA-01 for RAD Sequencing (from 20141029)\n\n\n\n\n\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nOct 31, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Allocation - Oly Oyster gDNA-01 for RAD Sequencing (from 20141022)\n\n\n\n\n\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nOct 29, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Quantification - Oly Oyster gDNA-01 for RAD Sequencing (from 20141014)\n\n\n\n\n\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nOct 22, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Isolation - Olympia Oyster Populations for RAD Sequencing\n\n\n\n\n\n\n\nOlympia oyster reciprocal transplant\n\n\n\n\n\n\n\n\n\n\n\nOct 14, 2014\n\n\n\n\n\n\n  \n\n\n\n\nPackage - Received Package from Jerome LaPeyre from LSU\n\n\n\n\n\n\n\nLSU C.virginica Oil Spill MBD BS Sequencing\n\n\n\n\n\n\n\n\n\n\n\nSep 26, 2014\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - C.gigas Larvae from Katie Latterhos\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 23, 2014\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - C.gigas Larvae from Katie Latterhos and Emma\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 22, 2014\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Mac’s Bisulfite-Treated DNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 3, 2014\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Mac’s Bisulfite-Treated DNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 28, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA-Seq - Sea Star Data Download\n\n\n\n\n\n\n\nSea star RNA-seq\n\n\n\n\n\n\n\n\n\n\n\nMay 28, 2014\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Jessica’s Geoduck Larval Stages\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 27, 2014\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - Mackenzie’s C.gigas EE2 Gonad Samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 16, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission - Colleen Sea Star (Pycnopodia) Coelomycete RNA for Illumina Sequencing\n\n\n\n\n\n\n\nSamples Submitted\n\n\nSea star RNA-seq\n\n\n\n\n\n\n\n\n\n\n\nMay 14, 2014\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Colleen Sea Star (Pycnopodia) Coelomycete Sample\n\n\n\n\n\n\n\nSea star RNA-seq\n\n\n\n\n\n\n\n\n\n\n\nMay 8, 2014\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Colleen Sea Star (Pycnopodia) Coelomycete Samples\n\n\n\n\n\n\n\nSea star RNA-seq\n\n\n\n\n\n\n\n\n\n\n\nApr 28, 2014\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - Claire’s C.gigas Female Gonad\n\n\n\n\n\n\n\nLineage-specific DNA methylation patterns in developing oysters\n\n\n\n\n\n\n\n\n\n\n\nApr 25, 2014\n\n\n\n\n\n\n  \n\n\n\n\nEthanol Precipitation - Colleen’s Sea Star Coelomycete RNA from Yesterday\n\n\n\n\n\n\n\nSea star RNA-seq\n\n\n\n\n\n\n\n\n\n\n\nApr 25, 2014\n\n\n\n\n\n\n  \n\n\n\n\nRNA Clean Up - Colleen’s Sea Star Coelomycete RNA from 20140416\n\n\n\n\n\n\n\nSea star RNA-seq\n\n\n\n\n\n\n\n\n\n\n\nApr 24, 2014\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Colleens’ Sea Star Coelomycetes Samples\n\n\n\n\n\n\n\nSea star RNA-seq\n\n\n\n\n\n\n\n\n\n\n\nApr 16, 2014\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - Test Sample\n\n\n\n\n\n\n\nLineage-specific DNA methylation patterns in developing oysters\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 16, 2014\n\n\n\n\n\n\n  \n\n\n\n\nPhenol-Chloroform DNA Clean Up - Mac and Claire’s Samples (from 20140410)\n\n\n\n\n\n\n\nLineage-specific DNA methylation patterns in developing oysters\n\n\n\n\n\n\n\n\n\n\n\nApr 14, 2014\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Sea Star Coelomocytes (from Colleen)\n\n\n\n\n\n\n\nSea star RNA-seq\n\n\n\n\n\n\n\n\n\n\n\nApr 10, 2014\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - Claire’s C.gigas Female Gonad and Mac’s C.gigas Gonad\n\n\n\n\n\n\n\nLineage-specific DNA methylation patterns in developing oysters\n\n\n\n\n\n\n\n\n\n\n\nApr 10, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCloned Hard Drive - Windows XP Opticon Computer (Aquacul8)\n\n\n\n\n\n\n\nComputer Servicing\n\n\n\n\n\n\n\n\n\n\n\nApr 4, 2014\n\n\n\n\n\n\n  \n\n\n\n\nDNA gel - Claire’s C.gigas Female Gonad and Mac’s C.gigas Gonad\n\n\n\n\n\n\n\nLineage-specific DNA methylation patterns in developing oysters\n\n\n\n\n\n\n\n\n\n\n\nApr 4, 2014\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Sea Star Coelomocytes (provided by Colleen Burge)\n\n\n\n\n\n\n\nSea star RNA-seq\n\n\n\n\n\n\n\n\n\n\n\nApr 2, 2014\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Sea Star Coelomocytes (provided by Colleen Burge)\n\n\n\n\n\n\n\nSea star RNA-seq\n\n\n\n\n\n\n\n\n\n\n\nApr 1, 2014\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - Mackenzie’s C.gigas Gonad Sample\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 1, 2014\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - C.gigas Female Gonads (from frozen)\n\n\n\n\n\n\n\nLineage-specific DNA methylation patterns in developing oysters\n\n\n\n\n\n\n\n\n\n\n\nMar 28, 2014\n\n\n\n\n\n\n  \n\n\n\n\nDNA Quality Check - Yanouk’s Oyster gDNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 14, 2014\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - Geoduck\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 19, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Precipitation - Geoduck DNA from 20140213\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 18, 2014\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - Geoduck\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 13, 2014\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - Geoduck\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 12, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGylcogen Assay - Emma’s C.gigas Whole Body Samples (continued from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 7, 2013\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGylcogen Assay - Emma’s C.gigas Whole Body Samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 6, 2013\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGylcogen & Carboyhydrate Assays - Emma’s C.gigas Whole Body Samples (continued from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 26, 2013\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGylcogen and Carboyhydrate Assays - Emma’s C.gigas Whole Body Samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 25, 2013\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPCR - Lake Trout C1q\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 28, 2013\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPCR - Lake Trout C1q\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 10, 2013\n\n\n\n\n\n\n  \n\n\n\n\nDNA Quantification - Yanouk’s DNA Samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 4, 2013\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Lake Trout C1q\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 19, 2013\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Hexokinase Partial CDS\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 9, 2013\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Hexokinase and Partial Exon #1\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 8, 2013\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPCR - Hexokinase Promoter and CDS (repeat from 20130227)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 14, 2013\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Hexokinase Promoter and CDS\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 27, 2013\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReverse Transcription - Herring RNA from 20091026\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 13, 2013\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Halley cDNA Check\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 28, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReverse Transcription - FISH441 RNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 21, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Manila Clam Larvae cDNA (from August 2012 - Dave’s Notebook)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 8, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Manila Clam Larvae cDNA (from August 2012 - Dave’s Notebook)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 8, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Manila Clam Larvae cDNA (from August 2012 - Dave’s Notebook)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 8, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - DNased Manila Clam Larvae RNA (from August 2012 - Dave’s Notebook)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 26, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReceived oysters from Taylor Shellfish.\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 16, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Opticon Test\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 10, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMinipreps - Emma’s Illumina Library Cloning\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 23, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIllumina RNAseq Library Construction - 32 C.gigas Individuals\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 11, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOligo Reconstitution - Illumina RNAseq Library Oligos and Barcodes\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 11, 2012\n\n\n\n\n\n\n  \n\n\n\n\nChloroform Clean Up - Lexie’s QPX RNA from 20110504\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 10, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission - QPX RNA and DNA for Illumina 36bp single-end RNA/DNAseq\n\n\n\n\n\n\n\nMiscellaneous\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nJul 9, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQPX Sample Pooling for Illumina Sequencing\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 6, 2012\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Detection of V.tubiashii Presence and Expression Using VtpA Primers in DNA/cDNA from yesterday\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 1, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReverse Transcription - DNased C.gigas Larval RNA from 20120427\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 30, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Check DNased RNA from Earlier Today for Residual gDNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 27, 2012\n\n\n\n\n\n\n  \n\n\n\n\nDNase Treatment - C.gigas Larvae RNA from yesterday\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 27, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngDNA Isolation - C.gigas Larvae from Taylor Summer 2011\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 26, 2012\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - C.gigas Larvae from Taylor Summer 2011\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 26, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Taylor Water Filter DNA Extracts from 20120322 - Sam White\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 26, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Repeat of qPCR from Earlier Today\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 23, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Taylor Water Filter DNA Extracts from Yesterday\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 23, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Extraction - Taylor Water Filter Samples from 2011\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 22, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReverse Transcription - Dave’s Manila Clam (Venerupis philippinarum) DNased RNA from 20120307 and 20120302\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 12, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Dave’s Manila Calm (Venerupis philippinarum) DNased RNA from yesterday and 20120302\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 8, 2012\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Dave’s Manila Clam (Venerupis philippinarum) Gill Samples (#25-48)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 7, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNase - Dave’s Manila Clam (Venerupis philippinarum) Gill RNA from Yesterday\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 2, 2012\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Dave’s Manila Clam (Venerupis philippinarum) Gill Samples (#1-24)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - cDNA from 20120208\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 9, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - cDNA from earlier today\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 8, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReverse Transcription - C.gigas larvae DNased RNA (from 20120125)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 8, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - DNased RNA from earlier today\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 25, 2012\n\n\n\n\n\n\n  \n\n\n\n\nDNAse - C.gigas RNA from 20120124\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 25, 2012\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - C.gigas Larvae from 20110412 & 20110705 (Continued from 20120112)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 24, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Isolation - C.gigas Larvae from 20110412 & 20110705\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 12, 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSequencing - COX/PGS Clones from yesterday/today\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 14, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMini-preps - COX/PGS Cloning Colonies from today\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 13, 2011\n\n\n\n\n\n\n  \n\n\n\n\nPCR - COX/PGS Cloning Colony Screens from yesterday\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 13, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCloning - Purified COX/PGS “qPCR Fragment” from 20111006\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 12, 2011\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Purified COX/PGS 1/2 DNA from earlier today\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 6, 2011\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Region Outside of COX/PGS qPCR Primers\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 6, 2011\n\n\n\n\n\n\n  \n\n\n\n\nEthanol Precipitation - Full-length PGS1 cDNA (from 20110921)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 29, 2011\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Full-length PGS1 cDNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 21, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEthanol Precipitation - Purified PGS1 PCR from yesterday\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 21, 2011\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Full-length PGS1 cDNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 20, 2011\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Full-length PGS2 cDNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 14, 2011\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Full-length PGS1 & PGS2 cDNAs\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 25, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - C.gigas V.vulnificus Exposure cDNA (from 20110311)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 11, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSequencing - C.gigas COX2/PGS2 Clone #4 from 20110728\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 4, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlasmid Isolation & Sequencing - C.gigas COX2/PGS2 Clones (from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 28, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBacterial Cultures - C.gigas COX2/PGS2 Clones (from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 27, 2011\n\n\n\n\n\n\n  \n\n\n\n\nColony PCRs - C.gigas COX2/PGS2 Clones (from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 26, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCloning - C.gigas COX2/PGS2 5’/3’ RACE Products (from earlier today)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 25, 2011\n\n\n\n\n\n\n  \n\n\n\n\n5’/3’ RACE - C.gigas COX2/PGS2 Nested RACE PCR\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 25, 2011\n\n\n\n\n\n\n  \n\n\n\n\n5’/3’ RACE - C.gigas COX2/PGS2 RACE PCR\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 22, 2011\n\n\n\n\n\n\n  \n\n\n\n\nSequencing - PGS Hi 4 (PGS2/COX2)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 15, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlasmid Isolation - Miniprep on PGS Hi 4 Colony from yesterday\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 12, 2011\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Colony PCR on Restreaked PGS2 Clones from 20110707\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 11, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBacterial Cultures - Liquid Cultures of PGS2/COX2 Colonies from 20110707\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 11, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClone Restreaking - PGS2 Hi/Lo Clones (from 20110421)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 7, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - C.gigas GAPDH second rep on V.vulnificus exposure cDNA (from 20110311) and standard curves for COX1, COX2, GAPDH\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 3, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - C.gigas actin and GAPDH on V.vulnificus exposure cDNA (from 20110311)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 2, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - C.gigas 18s and EF1a on V.vulnificus exposure cDNA (from 20110311)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 2, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - C.gigas COX2 on V.vulnificus exposure cDNA (from 20110311)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 1, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - C.gigas COX1 on V.vulnificus exposure cDNA (from 20110311)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 1, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Hard Clam NGS Primer Checks\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Lexie’s QPX Temp & Tissue Experiment (see Lexies Notebook 4/26/2011)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 20, 2011\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Emma’s New 3KDSqPCR Primers\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 20, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReverse Transcription - Hard Clam Gill DNased RNA (from 20110509)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 11, 2011\n\n\n\n\n\n\n  \n\n\n\n\nDNase - Hard Clam Gill RNA (from earlier today)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 9, 2011\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Hard Clam Gill Tissue from Vibrio Experiment (see Dave’s Notebook 5/2/2011)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 9, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrimer Design - Hard Clam NGS Primers\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 8, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Isolation - Hard Clam Gill Tissue from Vibrio Experiment (see Dave’s Notebook 5/2/2011)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 6, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReceived - Live Hard Clams From Scott Lindell\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 28, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBacterial Cultures - Colonies Selected from Yesterday’s Colony PCRs\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 26, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMini Preps - Liquid Cultures from yesterday\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 26, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBacterial Cultures - Colonies Selected by Steven from Steven’s Re-Streaked Plate\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 25, 2011\n\n\n\n\n\n\n  \n\n\n\n\nColony PCR - Colonies from COX1 Genomic Cloning (from 20110411)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 25, 2011\n\n\n\n\n\n\n  \n\n\n\n\nColony PCR - 5’RACE Colony: COX2 (repeat of yesterday’s PCR)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 22, 2011\n\n\n\n\n\n\n  \n\n\n\n\nColony PCR - 5’ RACE Colony: COX2\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 21, 2011\n\n\n\n\n\n\n  \n\n\n\n\nColony PCR - 5’ RACE Colonies\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 14, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLigations - COX1/COX2 PCR Products\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 11, 2011\n\n\n\n\n\n\n  \n\n\n\n\n5’/3’ RACE PCRs - Nested PCRs for COX2 Sequence\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 7, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5’/3’ RACE PCRs - COX2 Sequence on 5’ & 3’ RACE Libraries (from 20080619)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 6, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - C.gigas BB/DH cDNA for PROPS (TIMP3(BB) primers)\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nMar 21, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - C.gigas BB/DH cDNA for PROPS (HMGP primers)\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nMar 21, 2011\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - C.gigas COX1/COX2 Tissue Distribution\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 15, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - C.gigas BB/DH cDNA for PROPS\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nMar 14, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReverse Transcription - C.gigas BB/DH DNased RNA (from 20090507) for PROPS\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nMar 11, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReverse Transcription - C.gigas DNased RNA (from 20110131) from V.vulnificus Exposure & Tissues (from 20110111)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 11, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSOLiD Sequencing Submission\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 10, 2011\n\n\n\n\n\n\n  \n\n\n\n\nmRNA Isolation - Pooled Black Abalone Dg RNA (from Abalone Dg Exp 1)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 7, 2011\n\n\n\n\n\n\n  \n\n\n\n\n3’RACE - C.gigas 3’RACE for COX2\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 4, 2011\n\n\n\n\n\n\n  \n\n\n\n\nNanoDrop1000 Comparison - Roberts vs. Young Lab\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Check DNased RNA BB01 for Residual gDNA (from earlier today)\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2011\n\n\n\n\n\n\n  \n\n\n\n\nDNase - C.gigas BB01 (PROPS) RNA (from 20090507)\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Check DNased RNA BB01 for Residual gDNA (from earlier today)\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nFeb 28, 2011\n\n\n\n\n\n\n  \n\n\n\n\nDNase - C.gigas BB01 from 20110225\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nFeb 28, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEthanol Precpitation - DNased RNA BB01 (from earlier today)\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nFeb 25, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Check DNased RNA BB01 for Residual gDNA (from earlier today)\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nFeb 25, 2011\n\n\n\n\n\n\n  \n\n\n\n\nDNase - C.gigas BB01 from 20110216\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nFeb 25, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEthanol Precipitation - DNased RNA BB01 (from earlier today)\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nFeb 16, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Check DNased RNA BB01 & 09 (from earlier today)\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nFeb 16, 2011\n\n\n\n\n\n\n  \n\n\n\n\nDNase - C.gigas BB/DH (PROPS) RNA (from 20090507)\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nFeb 16, 2011\n\n\n\n\n\n\n  \n\n\n\n\nData Analysis - Young Lab ABI 7300 Calibration Checks\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 9, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Test Young Lab qPCR Calibration\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 9, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNanoDrop1000 Comparison - Roberts vs. Young Lab\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 9, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Test Young Lab qPCR Calibration (Repeat)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 8, 2011\n\n\n\n\n\n\n  \n\n\n\n\nPCR - New C. gigas COX Primers for Sequencing of Isoforms\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 8, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Test Young Lab qPCR Calibration (Repeat)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 8, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Test Young Lab qPCR Calibration (Repeat)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 4, 2011\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Test Young Lab qPCR Calibration\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 4, 2011\n\n\n\n\n\n\n  \n\n\n\n\nGenomic PCR - Repeat of C.gigas COX genomic PCR from 20110118\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 31, 2011\n\n\n\n\n\n\n  \n\n\n\n\nDNase - DNase C.gigas RNA from 20110120, 20110121 and 20110124\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 28, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Isolation - Various C.gigas Tissue from 20110111\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 24, 2011\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Various C.gigas Tissue from 20110111\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 21, 2011\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Various C.gigas Tissue from 20110111\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 20, 2011\n\n\n\n\n\n\n  \n\n\n\n\nGenomic PCR - C.gigas cyclooxygenase (COX) genomic sequence\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 18, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBacterial Dilutions - Determination of Colony Forming Units from Gigas Bacterial challenge (from earlier today)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 11, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGigas Bacterial Challenge - 1hr & 3hr Challenges with Vibrio vulnificus\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 11, 2011\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSOLiD - Retrieved SOLiD Library Samples from CEG from 20101213\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 23, 2010\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - COX qPCR Vibrio Exposure Response Check\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 13, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - COX qPCR Primer Test and Tissue Distribution\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 10, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRestriction Digestions/Ligations - MS-AFLP\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 30, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRestriction Digestions - HpaII and MspI on Mac’s C.gigas Samples: Round 1\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 29, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEtOH Precipitations - HpaII and MspI 2nd Round Digests from 20101124\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 29, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRestriction Digestions - HpaII and MspI on Mac’s C.gigas Samples: Round 2\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 24, 2010\n\n\n\n\n\n\n  \n\n\n\n\nPhenol:Chloroform Extractions and EtOH Precipitations - HapII and MspI digests from yesterday\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 23, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRestriction Digestions - HpaII and MspI on Mac’s C.gigas gDNA Samples: Round 1\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 22, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQPX Washes\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 26, 2010\n\n\n\n\n\n\n  \n\n\n\n\ngDNA Isolation\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 26, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEtOH Precipitation - Whale gDNA from 20101022\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 25, 2010\n\n\n\n\n\n\n  \n\n\n\n\ngDNA Isolation\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 22, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReceived Hard Clam Samples and Live Clams from MBL\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 19, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReceived Hard Clam Samples from Rutgers\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 15, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Test Plate for Opticon 2\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 12, 2010\n\n\n\n\n\n\n  \n\n\n\n\nOpticon Calibration\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 17, 2010\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Hard Clam Primers on cDNA from yesterday\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 9, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReverse Transcription - DNased Hard Clam RNA from earlier today\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 8, 2010\n\n\n\n\n\n\n  \n\n\n\n\nDNase - DNasing Hard Clam RNA from yesterday\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 8, 2010\n\n\n\n\n\n\n  \n\n\n\n\nEtOH Precipitation - Hard Clam RNA from earlier today\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 7, 2010\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Hard Clam Tissues Rec’d from Rutgers on 20100820\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 7, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPackage - Hard Clam Samples from MBL\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 2, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPackage - Hard Clam Samples from Rutgers\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 20, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - HpaII/MspI Digests from earlier today\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 9, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRestriction Digests - Various gigas gDNA from earlier today\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 9, 2010\n\n\n\n\n\n\n  \n\n\n\n\ngDNA Isolation - Various gigas samples (continued from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 9, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngDNA Isolation - Various gigas samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 8, 2010\n\n\n\n\n\n\n  \n\n\n\n\nMeDIP - SB/WB Fragmented gDNA EtOH precipitation (continued from 20100702)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 8, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMeDIP - SB/WB Fragmented gDNA (continued from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 2, 2010\n\n\n\n\n\n\n  \n\n\n\n\nRestriction Digests - Various gigas gDNAs of Mac’s\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 2, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMeDIP - SB/WB Fragmented gDNA (continued from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 1, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMeDIP - SB/WB Fragmented gDNA (from 20100625)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 30, 2010\n\n\n\n\n\n\n  \n\n\n\n\nBioanalyzer - Fragmented SB/WB gDNA (from 20100625)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 30, 2010\n\n\n\n\n\n\n  \n\n\n\n\ngDNA Sonication - SB/WB gDNA pools (prep for MeDIP) from 20100618\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 25, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSamples Received - Hard Clam samples from Rutgers and MBL\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 24, 2010\n\n\n\n\n\n\n  \n\n\n\n\ngDNA Sonication - SB/WB gDNA pools (prep for MeDIP) from earlier today\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 18, 2010\n\n\n\n\n\n\n  \n\n\n\n\ngDNA Precipitation - SB/WB gDNA pools (prep for MeDIP)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 18, 2010\n\n\n\n\n\n\n  \n\n\n\n\ngDNA Isolation - Mac gigas larvae samples: control larvae 6.7.10 and 5-aza tr larvae 6.7.10\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 8, 2010\n\n\n\n\n\n\n  \n\n\n\n\ngDNA Isolation - Mac gigas gill samples (continued from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 5, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngDNA Isolation - Mac gigas gill samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 4, 2010\n\n\n\n\n\n\n  \n\n\n\n\ngDNA Isolation - Mac gigas gill samples (continued from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 28, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPackage Rec’d - From NOAA in Connecticut\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 27, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngDNA Isolation - Mac gigas gill samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 27, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSOLiD ePCR/Templated Bead Prep - Lake Trout Lean library\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSOLiD Templated Bead Prep - Yellow perch CT, WB and lake trout Lean libraries (continued from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 13, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSOLiD ePCRs - Yellow perch CT, WB and lake trout Lean libraries\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 12, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPackage - Hard Clam gill tissue/hemolymph in RNA later\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 5, 2010\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - Qiagen Kit Comparison\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 5, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - V.tubiashii primers test (Vpt A and Vt IGS)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 3, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTemplated Bead Prep SOLiD Libraries - Yellow perch WB, lake trout Lean and Sisco, and herring G/O HWS09 libraries\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 16, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nePCR SOLiD Libraries - Lake Trout Sisco and Herring G/O HPWS09 libraries (from 20100408)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 15, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTemplated Bead Prep SOLiD Libraries - Abalone CC, CE pools and yellow perch CT, PQ libraries\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 14, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nePCR SOLiD Libraries - Yellow perch PQ, WB and Lake Trout Lean libraries (from 20100408)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 13, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nePCR SOLiD Libraries - Abalone CC, CE pools and yellow perch CT SOLiD libraries (from 20100408)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 12, 2010\n\n\n\n\n\n\n  \n\n\n\n\ncDNA clean up & Bioanalyzer for SOLiD Libraries - Abalone, Yellow Perch, Lake Trout, Herring\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 8, 2010\n\n\n\n\n\n\n  \n\n\n\n\nGel Purification & PCR cDNA SOLiD Libraries - Abalone, Yellow Perch, Lake Trout, Herring\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 7, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReverse Transcription SOLiD Libraries - Abalone, Yellow Perch, Lake Trout, Herring\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 6, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHibridizaton/Ligation SOLiD Libraries - Abalone, Yellow Perch, Lake Trout, Herring\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 5, 2010\n\n\n\n\n\n\n  \n\n\n\n\nBioanalyzer Total, mRNA and post-fragmentation SOLiD Libraries - Abalone pools\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 2, 2010\n\n\n\n\n\n\n  \n\n\n\n\nRNA Precipitation and Fragmentation for SOLiD Libraries - Pooled abalone mRNA (from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 1, 2010\n\n\n\n\n\n\n  \n\n\n\n\nRNA Precipitation & mRNA Isolation for SOLiD Libraries - Pooled abalone total RNA: Carmel control, Carmel exposed\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 31, 2010\n\n\n\n\n\n\n  \n\n\n\n\nBioanalyzer for SOLiD Libraries - Fragmented mRNA from Perch, Lake Trout & Herring RNA samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 29, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSOLiD Library Prep - mRNA (perch, lake trout, herring from 20100318) Fragmentation\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 25, 2010\n\n\n\n\n\n\n  \n\n\n\n\nBioanalyzer for SOLiD libraries - Total and mRNA from Perch, Lake Trout & Herring RNA samples (CONTINUED from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 18, 2010\n\n\n\n\n\n\n  \n\n\n\n\nmRNA Precipitation for SOLiD - Perch, Lake Trout, & Herring mRNA (CONTINUED from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 17, 2010\n\n\n\n\n\n\n  \n\n\n\n\nmRNA Isolation for SOLiD - Perch, Lake Trout, and Herring total RNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 16, 2010\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Test Lexie’s Mercenaria 18s contamination issue\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 10, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Mac’s BB/DH cDNA from 20091223\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nJan 15, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSOLiD Bead Titration - Herring fragmented cDNA libraries: 2LHKOD09, 4LHTOG09, 6LHPWS09\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 14, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSOLiD ePCRs - Herring cDNA libraries\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 13, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSOLiD ePCR - Herring fragmented cDNA library: 2LHKOD09\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 11, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCRs - Mac’s BB/DH cDNA from 20091223\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nJan 11, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSOLiD Bead Titration - Herring fragmented cDNA library 3LHSITK09 (CONTINUED from ePCR yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 8, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSOLiD ePCR - Herring fragmented cDNA library: 3LHSITK09\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 7, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSOLiD Bead Titration - Herring fragmented cDNA library 3LHSITK09(CONTINUED from ePCR yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 7, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCRs - Tim’s Adult Gigas gill cDNA (from 20091009)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 6, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSOLiD ePCR - Herring fragmented cDNA library: 3LHSITK09 (from 20091209)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 6, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCRs - Tim’s Adult Gigas gill cDNA (from 20091009)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 5, 2010\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - BB & DH cDNA (from 20091223)\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nDec 31, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCRs - BB & DH cDNA (from 20091223)\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nDec 30, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - BB & DH cDNA (from 20091223)\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nDec 29, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlaska sockeye salmon sampling (with Seebs): Family #13\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 29, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - BB & DH cDNA (from 20091223) and Emma primer sets for testing\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nDec 29, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCRs - BB & DH cDNA (from 20091223)\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nDec 28, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCRs - BB & DH cDNA (from yesterday)\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nDec 24, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSequencing - Mac methylation samples, Sam rhodopsin samples, Lisa samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 23, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - BB & DH cDNA (from earlier today)\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nDec 23, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReverse Transcription - BB & DH DNased RNA (from 20090514)\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nDec 23, 2009\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Sepia cDNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 17, 2009\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Sepia cDNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 16, 2009\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Sepia cDNA and DNased RNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 16, 2009\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Sepia cDNA (from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 15, 2009\n\n\n\n\n\n\n  \n\n\n\n\nReverse Transcription - Abalone 07:12 DNased RNA (from 20090623)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 15, 2009\n\n\n\n\n\n\n  \n\n\n\n\nReverse Transcription - Sepia DNased RNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 14, 2009\n\n\n\n\n\n\n  \n\n\n\n\nBioanalyzer - Herring Liver cDNA for SOLiD Libraries\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 11, 2009\n\n\n\n\n\n\n  \n\n\n\n\nEmulsion PCR - Herring Liver cDNA for SOLiD Libraries\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 9, 2009\n\n\n\n\n\n\n  \n\n\n\n\nReverse Transcription - Herring Liver mRNA for SOLiD Libraries\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 9, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Adapter Hybridization and Ligation - Herring Liver mRNA for SOLiD Libraries\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 8, 2009\n\n\n\n\n\n\n  \n\n\n\n\nRNA Fragmentation - Herring Liver mRNA for SOLiD Libraries\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 7, 2009\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Sepia samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 4, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSequencing - Dungan Isolates, Lake Trout HRM and Emma DD cloning\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 3, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmRNA Precipitation - Herring Liver mRNA for SOLiD Libraries (continued from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 3, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHard Clam Challenge - QPX Strain S-1 (continued from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 2, 2009\n\n\n\n\n\n\n  \n\n\n\n\nRNA Precipitation - Herring Liver RNA for SOLiD Libraries (continued from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 2, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Precipitation - Herring Liver RNA for SOLiD Libraries\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHard Clam Challenge - QPX Strain S-1\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMBL Shipment - Hard Clam gill tissue in RNA Later\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMBL Shipment - Sepia tissue samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 25, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMBL Shipment - Hard Clams\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 24, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHerring 454 Data\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 19, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMBL Shipment - MV oysters/cod\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 19, 2009\n\n\n\n\n\n\n  \n\n\n\n\nPCR - “Unknown” Dungans/Lyons\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 18, 2009\n\n\n\n\n\n\n  \n\n\n\n\nPCR - “Unkown” Dungans/Lyons\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 17, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHard Clams - Shipment from Rutgers\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 13, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSequencing - Lake Trout HRM\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 10, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOyster CO2/Mechanical Stress - Water quality\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 5, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submissions to MoGene for 454 Analysis - Herring Liver and Testes mRNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\nSamples Submitted\n\n\n\n\n\n\n\n\n\n\n\nOct 27, 2009\n\n\n\n\n\n\n  \n\n\n\n\nmRNA Isolation - Herring gonad/ovary RNA (from 20091023)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 27, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Precipitation - Herring gonad/ovary RNA (from 20091023)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 26, 2009\n\n\n\n\n\n\n  \n\n\n\n\nmRNA Isolation - Herring Liver RNA (from 20091021)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 26, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Precipitation - Herring Liver Samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 23, 2009\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Herring Gonad/Ovary Samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 23, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Isolation - Herring Gonad/Ovary Samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 22, 2009\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Herring Liver Samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 21, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Isolation - Herring Liver Samples (LHPWS09 1-6)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 20, 2009\n\n\n\n\n\n\n  \n\n\n\n\nqPCRs - Tim’s adult gigas challenge cDNA (from 20091009)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 13, 2009\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Tim’s adult gigas challenge cDNA (from 20091009)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 12, 2009\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Tim’s adult gigas challenge cDNA (from today)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 9, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReverse Transcription - Tim’s adult gigas challenge DNased RNA (from 20091008)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 9, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Tim’s adults gigas challenge re-DNased RNA (from today)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 9, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNase Treatment - Re-DNase of Tim’s adult gigas challenge RNA (from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 9, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Tim’s adults gigas challenge DNased RNA (from today)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 8, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Tim’s adults gigas challenge DNased RNA (from today)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 8, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNase Treatment - Tim’s adult gigas challenge RNA (from 20090930)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 8, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBioanalyzer Submission - Trout RBC, Colleen’s gigas GE sample, Mac’s DH/BB PCR for SOLiD WTK\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 7, 2009\n\n\n\n\n\n\n  \n\n\n\n\nReverse Transcription/cDNA purification/Emulsion PCR - Ligation rxns of trout fragmented RNA for SOLiD WTK (from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 6, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdapter Ligation - Rick’s trout fragmented control/poly I:C samples for SOLiD WTK\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Tim’s adults gigas challenge DNased RNA (from 20091002)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNase Treatment - Tim’s adult gigas challenge RNA (from 20090930)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 2, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCRs - Check gDNA contamination with EF1 & 18s primers in gigas gill RNA (from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nOct 1, 2009\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Tim’s adult gigas challenge samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 30, 2009\n\n\n\n\n\n\n  \n\n\n\n\nBioanalyzer Submission - Rick’s trout RBC samples (various dates)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 29, 2009\n\n\n\n\n\n\n  \n\n\n\n\nRNA Fragmentation - Rick’s trout RBC samples prepped earlier today\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 29, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEtOH Precipitation - Rick’s trout Ribosomoal-depleted RNA for SOLiD WTK (from today)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 28, 2009\n\n\n\n\n\n\n  \n\n\n\n\nRibosomal-depleted RNA - Rick’s trout RBC samples for the SOLiD WTK\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 28, 2009\n\n\n\n\n\n\n  \n\n\n\n\nRNA Fragmentation - Rick’s trout RBC samples prepped earlier today (see below)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 23, 2009\n\n\n\n\n\n\n  \n\n\n\n\nmRNA Isolation - Rick’s trout RBC samples previously treated with Ribominus Kit (by Mac)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 23, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmRNA Isolation - Gigas BB and DH samples previously treated with Ribominus Kit (by Mac)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 18, 2009\n\n\n\n\n\n\n  \n\n\n\n\nmRNA Isolation - Gigas BB and DH samples previously treated with Ribominus Kit (by Mac)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 16, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHRMs - Lake Trout SNPs (HRM_white-05 & HRM_white_06)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 15, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHRMs - Lake Trout SNPs (HRM_white-03 & HRM_white-04)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 10, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHRM - Lake Trout SNPs (HRM_white-02)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 9, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHRM - Lake Trout SNPs (HRM-white-01)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 3, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - HRM Lake Trout SNP primer test\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrimers - Lake Trout Primers for HRM\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 27, 2009\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Gigas gDNA test of recalibrated Opticon 2\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 27, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Recalibration of Opticon 2\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 26, 2009\n\n\n\n\n\n\n  \n\n\n\n\nDNA Precipitation - C.pugetti DNA for JGI submission (continued from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 26, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Precipitation - C.pugetti DNA for JGI submission\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 25, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Additional Calibration test of Opticon 2\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 24, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Carita Primer Test for High Resolution Melt (HRM) Curve Analysis\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 17, 2009\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Calibration test of Opticon 2\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 13, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Calibration test of Opticon 2\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nAug 6, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBacteria - C.pugetti culture (from 20090713)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 23, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Gigas DNA for Opticon testing\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 22, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRT Rxns - H.crach DNased RNA (from 20090623)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 22, 2009\n\n\n\n\n\n\n  \n\n\n\n\nNanoDrop - H.crach DNased RNA (from 20090623)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 21, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Abalone cDNA (07:12 set from 3/3/2009 by Lisa) and DNased RNA (from 20090623)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 20, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Abalone gDNA (H.crach 06:7-1)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 17, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Abalone cDNA (07:12 set from 3/3/2009 by Lisa) and DNased RNA (from 20090623)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 16, 2009\n\n\n\n\n\n\n  \n\n\n\n\nqPCR - Abalone cDNA (07:12 set from 3/3/2009 by Lisa) and DNased RNA (from 20090623)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 16, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Abalone gDNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 15, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Abalone RNA/DNased RNA & “dirty” and “clean” cDNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 14, 2009\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Dungan isolate (MIE-14v) gDNA from 20090708\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 13, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBacteria - C.pugetti large culture\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 13, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Abalone gDNA/cDNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 11, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - DNased Abalone Dg RNA from 20090625\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 10, 2009\n\n\n\n\n\n\n  \n\n\n\n\nDNA Precipitation CONTINUED - Dungan MIE-14v gDNA from yesterday\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 9, 2009\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Bay/Sea Scallop DNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 9, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - DNased Abalone Dg RNA from 20090625\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 8, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNA Precipitation - Dungan MIE-14v gDNA from earlier today\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 7, 2009\n\n\n\n\n\n\n  \n\n\n\n\ngDNA Isolation - Dungan isolate MIE-14v\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 7, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - MV hemocyte cDNA from 20090614\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 7, 2009\n\n\n\n\n\n\n  \n\n\n\n\nSpec Reading - C.pugetti gDNA from 20090526\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 6, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - MV hemocyte cDNA from 20090614\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 6, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBacteria - C. pugetti liquid cultures\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 6, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - MV hemocyte cDNA from 20090614\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 2, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - MV hemocyte cDNA from 20090614\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 1, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - MV hemocyte cDNA from 20090614\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 1, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - MV hemocyte cDNA from 20090614\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJul 1, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCRs - MV hemocyte cDNA from 20090614\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 30, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCRs - MV hemocyte cDNA from 20090614\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 29, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - MV hemocyte cDNA from 20090614\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 26, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Abalone Dg DNased RNA from yesterday and earlier today\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 25, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNase Treatment - Abalone Dg RNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 25, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCRs - MV hemocyte cDNA from 20090614\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 24, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNase Treatment - Abalone Dg RNA (07:12 set)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 24, 2009\n\n\n\n\n\n\n  \n\n\n\n\nEtOH Precipitation - DNased Abalone Dg RNA from yesterday AND the 07:12 set (DNased by Lisa 20090306)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 23, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - MV hemocyte cDNA from 20090614\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 22, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - DNased Abalone Dg RNA from earlier today AND the 07:12 set (DNased by Lisa 20090306)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 22, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNase Treatment - Abalone Dg DNased RNA 20090610\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 22, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - MV hemocyte cDNA from 20090614\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 18, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - MV hemocyte cDNA from 20090614\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 17, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - MV hemocyte cDNA: Test Immomix (SYTO13) vs. Strategene SYBR\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 15, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - MV hemocyte cDNA from yesterday\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 15, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReverse Transcription - MV hemocyte DNased RNA from 20090612\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 14, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - DNased MV hemocyte RNA from earlier today AND Turbo kit test\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 12, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNase Treatment - MV hemocyte RNA from yesterday\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 12, 2009\n\n\n\n\n\n\n  \n\n\n\n\nDNase Treatment - MV hemocyte RNA from earlier today\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 11, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Isolation - Martha’s Vineyard (MV) hemocytes\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 11, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Re-DNased abalone Dg RNA from earlier today\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 10, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Re-DNased abalone Dg RNA from earlier today\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 10, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNase Treatment - Abalone Dg DNased RNA from 20090605\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 10, 2009\n\n\n\n\n\n\n  \n\n\n\n\nPCR - C.pugetti gDNA from 20090526\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 9, 2009\n\n\n\n\n\n\n  \n\n\n\n\nPCR - C.pugetti gDNA from 20090513 & 20090526\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 8, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Re-DNased abalone Dg RNA from earlier today\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 8, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNase Treatment - Abalone Dg DNased RNA from 20090605\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 8, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBacteria - C.pugetti culture (1x 1L)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 5, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - DNased abalone Dg RNA from earlier today\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 5, 2009\n\n\n\n\n\n\n  \n\n\n\n\nDNase Treatment - Abalone Dg RNA isolated yesterday and from 20090518\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 5, 2009\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Abalone Dg Project Samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 4, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNase Treatment - Abalone Dg RNA isolated yesterday\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 3, 2009\n\n\n\n\n\n\n  \n\n\n\n\nPCR - C.pugetti DNA from 20090513 & 20090526\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 2, 2009\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Abalone Dg Project\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 2, 2009\n\n\n\n\n\n\n  \n\n\n\n\nPCR - C.pugetti DNA from 20090513 & 20090526\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 1, 2009\n\n\n\n\n\n\n  \n\n\n\n\nDNA Gel - JGI QC check of C. pugetti DNA from 20090526\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJun 1, 2009\n\n\n\n\n\n\n  \n\n\n\n\ngDNA Isolation - C. pugetti (from 20090518)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2009\n\n\n\n\n\n\n  \n\n\n\n\nDNA Methylation Test - Gigas site gDNA (BB & DH) from 20090515\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 19, 2009\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Abalone Dg Project samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 18, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC.pugetti - Liquid Cultures\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 18, 2009\n\n\n\n\n\n\n  \n\n\n\n\ngDNA Isolation - Gigas Dermo Samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 15, 2009\n\n\n\n\n\n\n  \n\n\n\n\ngDNA Isolation - Mac’s BB and DH site samples\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nMay 15, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReverse Transcription - Mac’s gigas DNased RNA from 20090512\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nMay 14, 2009\n\n\n\n\n\n\n  \n\n\n\n\ngDNA Isolation - C.pugetti\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 13, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Mac’s gigas DNased RNA from earlier today\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nMay 12, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNase Treatment (Rigorous!) - Mac’s gigas RNA/Re-DNased RNA from 20090507 & 20090508, respectively\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nMay 12, 2009\n\n\n\n\n\n\n  \n\n\n\n\nDNA Isolation - Mac’s gigas samples from 20090505 & 20090506\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nMay 11, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Re-DNased oyster RNA from today\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nMay 8, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDNase Treatment - Oyster RNA from yesterday\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nMay 8, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - DNased oyster RNA from earlier today\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nMay 7, 2009\n\n\n\n\n\n\n  \n\n\n\n\nDNase Treatment - Oyster RNA from today\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nMay 7, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Isolation - Mac’s oyster tissues (BB and DH) (CONTINUED from yesterday)\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nMay 7, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Isolation - Mac’s oyster tissues (BB and DH) (CONTINUED from yesterday)\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nMay 6, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBacteria - C. pugetti liquid cultures\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 5, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA Isolation - Mac’s oyster tissues (BB and DH)\n\n\n\n\n\n\n\nPROPS\n\n\n\n\n\n\n\n\n\n\n\nMay 5, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBacteria - C. pugetti liquid cultures\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMay 1, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBacteria - C. pugetti plate (from 20090424)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 30, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBacteria - C. pugetti plate (from 20090424)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 29, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBacteria - C. pugetti liquid culture\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 27, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBacteria - C. pugetti plate\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 24, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReverse Transcription - cDNA from DNased Abalone RNA from 20090420\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 22, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Abalone DNased RNA from yesterday\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 21, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBacteria - C. pugettii culture CONTINUED (from 20090419)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 21, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngDNA Removal - Abalone RNA from 20090402 and 20090331\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 20, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBacteria - C. pugettii culture\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 19, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSequencing - Dungan isolates\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 17, 2009\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Two new Dungan isolates\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 16, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Rab7_SYBR primers on abalone RNA and DNased RNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 15, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPCR - Two new Dungan isolates from earlier today\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 15, 2009\n\n\n\n\n\n\n  \n\n\n\n\ngDNA Isolation - Two new Dungan isolates\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 15, 2009\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Test QT Kit with No RT Abalone rxns from 20090408\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 14, 2009\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Bay/Sea scallop gDNAs\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 14, 2009\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Bay/Sea scallop gDNA isolated earlier today\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 13, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngDNA Isolation - Bay/Sea Scallop and hybrid samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 13, 2009\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Abalone gDNA/RNA/cDNA w/new TOLLIP primer\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 10, 2009\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Old Dungan isolates #1-35 w/EukA/B primers\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 10, 2009\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Bay/Sea scallop hybrids\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 10, 2009\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Dungan isolates from 20090402 with Euk primers\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 9, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Check DNased abalone RNA (by Lisa) for gDNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 9, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Repeat (modified) of yesterday’s abalone cDNA check\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 9, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Abalone cDNA (QT) from earlier today\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 8, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncDNA - Abalone RNA from 20090331 & 20090402\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 8, 2009\n\n\n\n\n\n\n  \n\n\n\n\nPCR - New Dungan isolates\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 6, 2009\n\n\n\n\n\n\n  \n\n\n\n\nPCR - New Dungan isolates\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 3, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Abalone RNA, check for gDNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 3, 2009\n\n\n\n\n\n\n  \n\n\n\n\ngDNA Isolation - New Dungan isolates\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 2, 2009\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Abalone digestive gland samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nApr 2, 2009\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Abalone digestive gland samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 31, 2009\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Abalone digestive gland samples\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 27, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Virginica cDNA (see workup sheet below for more info regarding cDNA)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 24, 2009\n\n\n\n\n\n\n  \n\n\n\n\nmRNA Sample Submission Hard clam gill #1 mRNA from 20090313\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 16, 2009\n\n\n\n\n\n\n  \n\n\n\n\nmRNA Isolation - hard clam gill #1 continued from yesterday\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 13, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmRNA Isolation - hard clam gill #1 DNased RNA from today\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 12, 2009\n\n\n\n\n\n\n  \n\n\n\n\nRNA Precipitation - Hard clam gill #1 RNA from 20080819\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 12, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Repeat of qPCR from earlier today with fresh primer working stocks\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 2, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Repeat of 20090227 qPCR with clean water\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nMar 2, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - New 16s primers for V.tubiashii Control vs. Autoclaved gigas samples (see 20090224)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 27, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - Replicate of V.tubiashii Control vs. Autoclaved gigas samples (see yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 25, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nqPCR - V.tubiashii Control vs. Autoclaved gigas samples (see below)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 24, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReverse Transcription - V.tubiashii DNAsed RNA (from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 24, 2009\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - V.tubiashii samples from autoclaved gigas exposure (from 20081218)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEpigenetics Experiment - Gigas treatment\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 20, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSample Submission - V.tubiashii Mass Spec\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 18, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrypsin digestion - Vibrio 2D spots CONTINUED (from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 12, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrypsin digestion - Vibrio 2D spots from 20081217\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 11, 2009\n\n\n\n\n\n\n  \n\n\n\n\nmRNA - Submission for Agilent Bioanalyzer\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nFeb 6, 2009\n\n\n\n\n\n\n  \n\n\n\n\nmRNA - Precipitation continued from yesterday\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 23, 2009\n\n\n\n\n\n\n  \n\n\n\n\nmRNA Isolation - Hard Clam gill and hemo RNA\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 22, 2009\n\n\n\n\n\n\n  \n\n\n\n\nRNA - Hard clam hemo RNA (from 20090121)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 22, 2009\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Hard clam hemo (from 20090121)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 21, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBleeding/Tissue Collection - Hard Clams\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 20, 2009\n\n\n\n\n\n\n  \n\n\n\n\nRNA - Precipitation of Hard Clam Hemo RNA from 20090116\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 20, 2009\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Hard clam gill, hemos\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 16, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBleeding - Hard Clams\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 14, 2009\n\n\n\n\n\n\n  \n\n\n\n\nRNA - Precipitation continued from yesterday\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 14, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRNA - Reprecipitation of hard clam RNA from yesterday\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 13, 2009\n\n\n\n\n\n\n  \n\n\n\n\nBleeding - Hard Clams\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 12, 2009\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - Hard Clam hemolymph from 20090108, 20090109\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 12, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBleeding - Hard Clams\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 9, 2009\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBleeding - Hard Clams\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 8, 2009\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Dungan Isolates\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 7, 2009\n\n\n\n\n\n\n  \n\n\n\n\nPCR - Dungan Isolates\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 6, 2009\n\n\n\n\n\n\n  \n\n\n\n\nSDS/PAGE, Western Blot - Test of HSP70 Ab on heat stressed shellfish for FISH441\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nJan 2, 2009\n\n\n\n\n\n\n  \n\n\n\n\nSDS/PAGE, Western Blot - Test of new Western Breeze Kit & HSP70 Ab for FISH441\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 31, 2008\n\n\n\n\n\n\n  \n\n\n\n\nRNA Gel - V. tubiashii mRNA samples (from 20081224)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 29, 2008\n\n\n\n\n\n\n  \n\n\n\n\nrRNA Removal - V. tubiashii total RNA from yesterday\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 24, 2008\n\n\n\n\n\n\n  \n\n\n\n\nRNA Isolation - V. tubiashii from challenge (see 20081216)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 22, 2008\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVibrio challenge CONTINUED (from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 19, 2008\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVibrio challenge CONTINUED (from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 18, 2008\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVibrio challenge CONTINUED (from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 17, 2008\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVibrio challenge\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 16, 2008\n\n\n\n\n\n\n  \n\n\n\n\nSDS/PAGE/Western - anti-HSP70 Ab Re-test\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 16, 2008\n\n\n\n\n\n\n  \n\n\n\n\nSDS/PAGE/Western - Attempt to fix/identify problem(s) with Westerns\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 12, 2008\n\n\n\n\n\n\n  \n\n\n\n\nSDS/PAGE/Western - anti-HSP70 Ab test CONTINUED (from yesterday)\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 10, 2008\n\n\n\n\n\n\n  \n\n\n\n\nSDS/PAGE/Western - anti-HSP70 Ab test\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nDec 9, 2008\n\n\n\n\n\n\n  \n\n\n\n\nSDS/PAGE/Western - Purified (His column) FST samples from 20081112\n\n\n\n\n\n\n\nMiscellaneous\n\n\n\n\n\n\n\n\n\n\n\nNov 17, 2008\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSequencing - Y2H colony PCRs from 20081112\n\n\n\n\n\n\n\nMyostatin Interacting Proteins\n\n\n\n\n\n\n\n\n\n\n\nNov 14, 2008\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMass Spec - Band #1 from 20081106\n\n\n\n\n\n\n\nMyostatin Interacting Proteins\n\n\n\n\n\n\n\n\n\n\n\nNov 14, 2008\n\n\n\n\n\n\n  \n\n\n\n\nWestern Blot - Purified (His column) decorin, FST, LAP & telethonin\n\n\n\n\n\n\n\nMyostatin Interacting Proteins\n\n\n\n\n\n\n\n\n\n\n\nNov 13, 2008\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2018/2018-11-20-Reverse-Transcription---Ronits-C.gigas-DNased-RNA-from-20181115/index.html",
    "href": "posts/2018/2018-11-20-Reverse-Transcription---Ronits-C.gigas-DNased-RNA-from-20181115/index.html",
    "title": "Reverse Transcription - Ronit’s C.gigas DNased RNA from 20181115",
    "section": "",
    "text": "Quantified Ronit’s DNased RNA earlier today and proceeded with reverse transcription using 100ng of DNased RNA with oligo dT primers (Promega) and M-MLV reverse transcriptase (Promega) according to the manufacturer’s protocol.\nRNA and oligo dTs were incubated at 70oC for 10mins in a PTC-200 thermal cycler (MJ Research) without a heated lid and immediately placed on ice.\nA master mix of buffer, dNTPs, and M-MLV was distributed to each sample (10uL to each sample), mixed, and incubated at 42oC for 1hr, 3min at 95oC, and then held overnight at 4oC in the PTC-200 thermal cycler.\nA 1:5 working dilution of each cDNA (5uL cDNA + 20uL PCR H2O was made and will be used for all subsequent qPCRs.\nAll samples were stored in Ronit’s -20oC box.\nReverse transcription calcs (Google Sheet):\n\n201811120_Cgigas_ploidy_cDNA_calcs\n\nInfo was added to Ronit’s master sheet (Google Sheet):\n\nExposure 8/29-8/30 C.Gigas"
  },
  {
    "objectID": "posts/2018/2018-11-15-qPCR---Ronits-DNased-C.gigas-RNA-with-Elongation-Factor-Primers/index.html",
    "href": "posts/2018/2018-11-15-qPCR---Ronits-DNased-C.gigas-RNA-with-Elongation-Factor-Primers/index.html",
    "title": "qPCR - Ronit’s DNased C.gigas RNA with Elongation Factor Primers",
    "section": "",
    "text": "After DNasing Ronit’s RNA earlier today, I needed to verify the RNA was free of any contaminating gDNA.\nUsed elongation factor primers:\n\nEF1_qPCR_5’ (SRID 309)\nEF1_qPCR_3’ (SRID 310)\n\nBB16 from 20090519 was used as a positive control.\nSamples were run on Roberts Lab CFX Connect (BioRad). All samples were run in duplicate. See qPCR Report (Results section) for plate layout, cycling params, etc.\nqPCR master mix calcs (Google Sheet):\n\n20181115_qPCR_Ronit_Cgigas_DNased_RNA\n\n\nResults\nEverything looks great! Nice, clean, gDNA-free RNA! Will proceed with reverse transcription.\nqPCR Report (PDF):\n\nsam_2018-11-15 2013-17-42_BR006896.pdf\n\nqPCR File (PCRD):\n\nsam_2018-11-15 2013-17-42_BR006896.pcrd\n\nqPCR Data (CSV):\n\nsam_2018-11-15_13-17-42_BR006896_-__Quantification_Cq_Results.csv\n\nIn the plots below, green is the positive control, blue are the samples, and red is the no template control (NTC).\n\n\nAmplification Plots\n\n\n\n\nMelt Curves"
  },
  {
    "objectID": "posts/2018/2018-11-20-RNA-Quantification---Ronits-C.gigas-DNased-RNA-from-20181115/index.html",
    "href": "posts/2018/2018-11-20-RNA-Quantification---Ronits-C.gigas-DNased-RNA-from-20181115/index.html",
    "title": "RNA Quantification - Ronit’s C.gigas DNased RNA from 20181115",
    "section": "",
    "text": "After confirming Ronit’s DNased RNA was free of gDNA, I quantified the DNased RNA from 20181115 using the Roberts Lab Qubit 3.0 and the Qubit hsRNA Assay.\nUsed 1uL of each sample.\n\n\nRESULTS\nQubit data (Google Sheet):\n\n20181120_qubit_DNased_RNA_ronit_gigas_ctenidia\n\nWell, 14 samples were too concentrated and exceeded the assay’s range, so I created 1:10 dilutions of those samples (1ul of sample in 9uL of 0.1%DEPC-treated H2O) and remeasured; again using 1uL of sample.\nAdmittedly, I’m not terribly surprised that happened, since they were notably lower than Ronit’s first round of RNA isolations.\nI added the data to his master sheet (Google Sheet):\n\nExposure 8/29-8/30 C.Gigas\n\nI will proceed with making cDNA."
  },
  {
    "objectID": "posts/2018/2018-11-15-DNase---Ronits-C.gigas-Ctenidia-RNA/index.html",
    "href": "posts/2018/2018-11-15-DNase---Ronits-C.gigas-Ctenidia-RNA/index.html",
    "title": "DNase - Ronit’s C.gigas Ctenidia RNA",
    "section": "",
    "text": "Ronit finished his RNA isolations for his ctenidia samples on 20181025 & 20181101, as well as quntification (he has no notebook entry for this, at this time). However, his Qubit data can be found in these two Google Sheets:\n\n20181108_qubit_RNA_ronit_ctenidia\n20181114_qubit_RNA_ronit_ctenidia_1-10_dilution\n\nIn preparation for reverse transcription, I DNased his samples using the Turbo DNA-free Kit (Ambion) according to the manufacturer’s standard protocol.\nUsed 500ng of each sample.\nNOTE: Sample T06 was very dilute, so performed a 60uL reaction instead of the standard 50uL reaction.\nCalculations are here (Google Sheet):\n\n20181115_DNase_ronit_RNA_calcs\n\nRonit’s master sheet (Google Sheet) is here:\n\nExposure 8/29-8/30 C.Gigas\n\nWill check these via qPCR to verify whether or not they have any detectable gDNA."
  },
  {
    "objectID": "posts/2018/2018-11-21-Annotation---Geoduck-Transcritpome-with-TransDecoder/index.html",
    "href": "posts/2018/2018-11-21-Annotation---Geoduck-Transcritpome-with-TransDecoder/index.html",
    "title": "Annotation - Geoduck Transcritpome with TransDecoder",
    "section": "",
    "text": "I was tasked with generating some qPCR primers to analyze vitellogenin expression in geoduck. In order to do so, I needed to annotate a geoduck transcriptome in order to identify potential vitellogenin genes. I had previously assembled a geoduck transcriptome. For annotation, I used TransDecoder (v5.5.0). The annotation was run on our Mox HPC node.\nMox SBATCH script:\n\n20181121_geo_transdecoder.sh\n\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=transcoder\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=30-00:00:00\n## Memory per node\n#SBATCH --mem=500G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --workdir=/gscratch/scrubbed/samwhite/20181121_geo_transdecoder\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\ndate >> system_path.log\necho \"\" >> system_path.log\necho \"System PATH for $SLURM_JOB_ID\" >> system_path.log\necho \"\" >> system_path.log\nprintf \"%0.s-\" {1..10} >> system_path.log\necho ${PATH} | tr : \\\\n >> system_path.log\n\n\n# Make blast database available to blast\nexport BLASTDB=/gscratch/srlab/blastdbs/UniProtKB_20181008/\n\n## Establish variables for more readable code\n### Transdecoder programs\ntd_longorfs=\"/gscratch/srlab/programs/TransDecoder-v5.5.0/TransDecoder.LongOrfs\"\n\ntd_predict=\"/gscratch/srlab/programs/TransDecoder-v5.5.0/TransDecoder.Predict\"\n\n### BLASTp\nblastp=\"/gscratch/srlab/programs/ncbi-blast-2.6.0+/bin/blastp\"\n\n### HMMscan\nhmmscan=\"/gscratch/srlab/programs/hmmer-3.2.1/src/hmmscan\"\n### Transcriptome\ngeo_trinity_loc=\"/gscratch/srlab/sam/data/P_generosa/generosa_transcriptomes/20180827_trinity_geoduck.fasta\"\n\ngeo_trinity=\"20180827_trinity_geoduck.fasta\"\n\n### UniProt database\nuniprot=\"/gscratch/srlab/blastdbs/UniProtKB_20181008/20181008_uniprot_sprot.fasta\"\n\n### Pfam databases\npfam=\"/gscratch/srlab/sam/data/databases/pfam_db/Pfam31.0/Pfam-A.hmm\"\n\n####################\n# Run transdecoder longorfs\n${td_longorfs} -t ${geo_trinity_loc}\n\n# Run blastp on UniProt database\n${blastp} \\\n-query ${geo_trinity}.transdecoder_dir/longest_orfs.pep \\\n-db ${uniprot} \\\n-max_target_seqs 1 \\\n-outfmt 6 \\\n-evalue 1e-5 \\\n-num_threads 28 \\\n> blastp.outfmt6 \\\n2> blastp.err\n\n# Run HMMscan on Pfam databases\n${hmmscan} \\\n--cpu 28 \\\n--domtblout pfam.domtblout \\\n${pfam} \\\n${geo_trinity}.transdecoder_dir/longest_orfs.pep \\\n2> hmmscan.err\n\n# Run transdecoder predict, using info from blatp and hmmscan\n${td_predict} \\\n-t ${geo_trinity_loc} \\\n--retain_pfam_hits pfam.domtblout \\\n--retain_blastp_hits blastp.outfmt6\n\nList of input files and databases used:\n\n20180827_trinity_geoduck.fasta (FastA 972MB)\n20181008_uniprot_sprot.fasta: Downloaded 20181008.\nPfam31.0/Pfam-A.hmm\n\nHere’s a quick rundown of the TransDecoder process:\n\nIdentify longest open reading frames (ORFs)\nBLASTp ORFs against UniProt database to identify protein matches.\nHMMscan (Hidden Markov Model) against Pfam database to identify protein families.\nTransDecoder predicts final coding sequences (CDS) using BLASTp and HMMscan info to provide additional support functional CDS identification.\n\n\n\nRESULTS\nData was copied to Gannet via rsync\nOutput directory:\n\n20181121_geo_transdecoder/\n\nCDS FastA (271MB):\n\n20181121_geo_transdecoder/20180827_trinity_geoduck.fasta.transdecoder.cds\n\nBED file (81MB): - 20181121_geo_transdecoder/20180827_trinity_geoduck.fasta.transdecoder.bed\nGFF3 file (277MB):\n\n20181121_geo_transdecoder/20180827_trinity_geoduck.fasta.transdecoder.gff3\n\nAlrighty, now we have an annotated transcriptome that I can use for finding vitellogenin transcripts and designing some primers!"
  },
  {
    "objectID": "posts/2018/2018-11-27-Annotation---Olurida_v081-MAKER-on-Mox/index.html",
    "href": "posts/2018/2018-11-27-Annotation---Olurida_v081-MAKER-on-Mox/index.html",
    "title": "Annotation - Olurida_v081 MAKER on Mox",
    "section": "",
    "text": "Remarkably, I managed to burn through our Xsede computing resources and don’t have terribly much to show for it. Ooof! This is a major bummer, as it “only” takes ~8hrs for a WQ-MAKER job to run there, as opposed to months the last time I tried running it on Mox. Although we have used up our Xsede allocation, all is not lost! The experience of setting up/running WQ-MAKER has enlightened me on how it all works and how to run it on Mox so it will (hopefully) take far, far less time than the last Mox attempt. With that said, here we go…\nFirstly, I re-installed MAKER (v2.31.10) and configured for OpenMPI support. This is computing jargon that basically allows MAKER to work on a computer cluster efficiently. Now that we have two Mox nodes, I think this will help accelerate the process.\nWith that out of the way, here’s a very brief overview of the entire MAKER annotation process. Be aware, despite it’s “brevity”, this is still a lengthy read:\n\nCreate custom repeat library for your organism (did this with RepeatModeler on 20181022)\nProvide RNAseq data (transcriptome v3)\nProvide species-specific and/or related proteomic data (used publicly available proteomes from NCBI for C.gigas (GCA_000297895.1_oyster_v9) and C.virginica (GCF_002022765.2_C_virginica-3.0)\nRun MAKER to produce initial gene models.\nMerge all the hundred thousands (seriously) of individual GFFs and FastAs in to a singular file of each file type. MAKER has built-in scripts to do this.\nGenerate ab initio gene prediction using SNAP. This is integrated in to MAKER.\nRun MAKER again, using the SNAP gene models.\nMerge the new set of GFFs.\nRun SNAP a second time.\nRun MAKER a third time using the second set of SNAP gene models.\nMerge the final set of GFFs.\nDone???\n\nSo, that’s how it’s done! Easy!\nWith each round of MAKER, a “control” file needs to be generated and modified appropriately. Modifications consist of telling MAKER locations of files and whether or not to use certain types of files when producing a new model (e.g. RNAseq data, SNAP HMM file, etc.). Here are the three control files that were used to run MAKER. The links are simply text files, despite their extension, so they can be downloaded and viewed in any text editor, if desired, but I’ve pasted their contents below for easier review:\n\nROUND 1 (Initial MAKER run)\n\n20181127_oly_maker_genome_annotation/maker_opts.ctl\n\n\n#-----Genome (these are always required)\ngenome=/gscratch/srlab/sam/data/O_lurida/oly_genome_assemblies/Olurida_v081/Olurida_v081.fa #genome sequence (fasta file or fasta embeded in GFF3 file)\norganism_type=eukaryotic #eukaryotic or prokaryotic. Default is eukaryotic\n\n#-----Re-annotation Using MAKER Derived GFF3\nmaker_gff= #MAKER derived GFF3 file\nest_pass=0 #use ESTs in maker_gff: 1 = yes, 0 = no\naltest_pass=0 #use alternate organism ESTs in maker_gff: 1 = yes, 0 = no\nprotein_pass=0 #use protein alignments in maker_gff: 1 = yes, 0 = no\nrm_pass=0 #use repeats in maker_gff: 1 = yes, 0 = no\nmodel_pass=0 #use gene models in maker_gff: 1 = yes, 0 = no\npred_pass=0 #use ab-initio predictions in maker_gff: 1 = yes, 0 = no\nother_pass=0 #passthrough anyything else in maker_gff: 1 = yes, 0 = no\n\n#-----EST Evidence (for best results provide a file for at least one)\nest=/gscratch/srlab/sam/data/O_lurida/oly_transcriptome_assemblies/Olurida_transcriptome_v3.fasta #set of ESTs or assembled mRNA-seq in fasta format\naltest= #EST/cDNA sequence file in fasta format from an alternate organism\nest_gff= #aligned ESTs or mRNA-seq from an external GFF3 file\naltest_gff= #aligned ESTs from a closly relate species in GFF3 format\n\n#-----Protein Homology Evidence (for best results provide a file for at least one)\nprotein=/gscratch/scrubbed/samwhite/outputs/20181127_oly_maker_genome_annotation/gigas_virginica_ncbi_proteomes.fasta  #protein sequence file in fasta format (i.e. from mutiple oransisms)\nprotein_gff=  #aligned protein homology evidence from an external GFF3 file\n\n#-----Repeat Masking (leave values blank to skip repeat masking)\nmodel_org=all #select a model organism for RepBase masking in RepeatMasker\nrmlib=/gscratch/srlab/sam/data/O_lurida/Ostrea_lurida_v081-families.fa #provide an organism specific repeat library in fasta format for RepeatMasker\nrepeat_protein=/gscratch/srlab/programs/maker-2.31.10/data/te_proteins.fasta #provide a fasta file of transposable element proteins for RepeatRunner\nrm_gff= #pre-identified repeat elements from an external GFF3 file\nprok_rm=0 #forces MAKER to repeatmask prokaryotes (no reason to change this), 1 = yes, 0 = no\nsoftmask=1 #use soft-masking rather than hard-masking in BLAST (i.e. seg and dust filtering)\n\n#-----Gene Prediction\nsnaphmm= #SNAP HMM file\ngmhmm= #GeneMark HMM file\naugustus_species= #Augustus gene prediction species model\nfgenesh_par_file= #FGENESH parameter file\npred_gff= #ab-initio predictions from an external GFF3 file\nmodel_gff= #annotated gene models from an external GFF3 file (annotation pass-through)\nest2genome=1 #infer gene predictions directly from ESTs, 1 = yes, 0 = no\nprotein2genome=1 #infer predictions from protein homology, 1 = yes, 0 = no\ntrna=0 #find tRNAs with tRNAscan, 1 = yes, 0 = no\nsnoscan_rrna= #rRNA file to have Snoscan find snoRNAs\nunmask=0 #also run ab-initio prediction programs on unmasked sequence, 1 = yes, 0 = no\n\n#-----Other Annotation Feature Types (features MAKER doesn't recognize)\nother_gff= #extra features to pass-through to final MAKER generated GFF3 file\n\n#-----External Application Behavior Options\nalt_peptide=C #amino acid used to replace non-standard amino acids in BLAST databases\ncpus=1 #max number of cpus to use in BLAST and RepeatMasker (not for MPI, leave 1 when using MPI)\n\n#-----MAKER Behavior Options\nmax_dna_len=100000 #length for dividing up contigs into chunks (increases/decreases memory usage)\nmin_contig=1 #skip genome contigs below this length (under 10kb are often useless)\n\npred_flank=200 #flank for extending evidence clusters sent to gene predictors\npred_stats=0 #report AED and QI statistics for all predictions as well as models\nAED_threshold=1 #Maximum Annotation Edit Distance allowed (bound by 0 and 1)\nmin_protein=0 #require at least this many amino acids in predicted proteins\nalt_splice=0 #Take extra steps to try and find alternative splicing, 1 = yes, 0 = no\nalways_complete=0 #extra steps to force start and stop codons, 1 = yes, 0 = no\nmap_forward=0 #map names and attributes forward from old GFF3 genes, 1 = yes, 0 = no\nkeep_preds=0 #Concordance threshold to add unsupported gene prediction (bound by 0 and 1)\n\nsplit_hit=10000 #length for the splitting of hits (expected max intron size for evidence alignments)\nsingle_exon=0 #consider single exon EST evidence when generating annotations, 1 = yes, 0 = no\nsingle_length=250 #min length required for single exon ESTs if 'single_exon is enabled'\ncorrect_est_fusion=0 #limits use of ESTs in annotation to avoid fusion genes\n\ntries=2 #number of times to try a contig if there is a failure for some reason\nclean_try=0 #remove all data from previous run before retrying, 1 = yes, 0 = no\nclean_up=0 #removes theVoid directory with individual analysis files, 1 = yes, 0 = no\nTMP= #specify a directory other than the system default temporary directory for temporary files\n\n\n\nROUND 2 (After initial SNAP run)\n\n20181127_oly_maker_genome_annotation/snap01/maker_opts.ctl\n\n\n#-----Genome (these are always required)\ngenome=/gscratch/srlab/sam/data/O_lurida/oly_genome_assemblies/Olurida_v081/Olurida_v081.fa #genome sequence (fasta file or fasta embeded in GFF3 file)\norganism_type=eukaryotic #eukaryotic or prokaryotic. Default is eukaryotic\n\n#-----Re-annotation Using MAKER Derived GFF3\nmaker_gff= #MAKER derived GFF3 file\nest_pass=0 #use ESTs in maker_gff: 1 = yes, 0 = no\naltest_pass=0 #use alternate organism ESTs in maker_gff: 1 = yes, 0 = no\nprotein_pass=0 #use protein alignments in maker_gff: 1 = yes, 0 = no\nrm_pass=0 #use repeats in maker_gff: 1 = yes, 0 = no\nmodel_pass=0 #use gene models in maker_gff: 1 = yes, 0 = no\npred_pass=0 #use ab-initio predictions in maker_gff: 1 = yes, 0 = no\nother_pass=0 #passthrough anyything else in maker_gff: 1 = yes, 0 = no\n\n#-----EST Evidence (for best results provide a file for at least one)\nest=/gscratch/srlab/sam/data/O_lurida/oly_transcriptome_assemblies/Olurida_transcriptome_v3.fasta #set of ESTs or assembled mRNA-seq in fasta format\naltest= #EST/cDNA sequence file in fasta format from an alternate organism\nest_gff= #aligned ESTs or mRNA-seq from an external GFF3 file\naltest_gff= #aligned ESTs from a closly relate species in GFF3 format\n\n#-----Protein Homology Evidence (for best results provide a file for at least one)\nprotein=/gscratch/scrubbed/samwhite/outputs/20181127_oly_maker_genome_annotation/gigas_virginica_ncbi_proteomes.fasta  #protein sequence file in fasta format (i.e. from mutiple oransisms)\nprotein_gff=  #aligned protein homology evidence from an external GFF3 file\n\n#-----Repeat Masking (leave values blank to skip repeat masking)\nmodel_org=all #select a model organism for RepBase masking in RepeatMasker\nrmlib=/gscratch/srlab/sam/data/O_lurida/Ostrea_lurida_v081-families.fa #provide an organism specific repeat library in fasta format for RepeatMasker\nrepeat_protein=/gscratch/srlab/programs/maker-2.31.10/data/te_proteins.fasta #provide a fasta file of transposable element proteins for RepeatRunner\nrm_gff= #pre-identified repeat elements from an external GFF3 file\nprok_rm=0 #forces MAKER to repeatmask prokaryotes (no reason to change this), 1 = yes, 0 = no\nsoftmask=1 #use soft-masking rather than hard-masking in BLAST (i.e. seg and dust filtering)\n\n#-----Gene Prediction\nsnaphmm=20181127__oly_snap01.hmm #SNAP HMM file\ngmhmm= #GeneMark HMM file\naugustus_species= #Augustus gene prediction species model\nfgenesh_par_file= #FGENESH parameter file\npred_gff= #ab-initio predictions from an external GFF3 file\nmodel_gff= #annotated gene models from an external GFF3 file (annotation pass-through)\nest2genome=0 #infer gene predictions directly from ESTs, 1 = yes, 0 = no\nprotein2genome=0 #infer predictions from protein homology, 1 = yes, 0 = no\ntrna=0 #find tRNAs with tRNAscan, 1 = yes, 0 = no\nsnoscan_rrna= #rRNA file to have Snoscan find snoRNAs\nunmask=0 #also run ab-initio prediction programs on unmasked sequence, 1 = yes, 0 = no\n\n#-----Other Annotation Feature Types (features MAKER doesn't recognize)\nother_gff= #extra features to pass-through to final MAKER generated GFF3 file\n\n#-----External Application Behavior Options\nalt_peptide=C #amino acid used to replace non-standard amino acids in BLAST databases\ncpus=1 #max number of cpus to use in BLAST and RepeatMasker (not for MPI, leave 1 when using MPI)\n\n#-----MAKER Behavior Options\nmax_dna_len=100000 #length for dividing up contigs into chunks (increases/decreases memory usage)\nmin_contig=1 #skip genome contigs below this length (under 10kb are often useless)\n\npred_flank=200 #flank for extending evidence clusters sent to gene predictors\npred_stats=0 #report AED and QI statistics for all predictions as well as models\nAED_threshold=1 #Maximum Annotation Edit Distance allowed (bound by 0 and 1)\nmin_protein=0 #require at least this many amino acids in predicted proteins\nalt_splice=0 #Take extra steps to try and find alternative splicing, 1 = yes, 0 = no\nalways_complete=0 #extra steps to force start and stop codons, 1 = yes, 0 = no\nmap_forward=0 #map names and attributes forward from old GFF3 genes, 1 = yes, 0 = no\nkeep_preds=0 #Concordance threshold to add unsupported gene prediction (bound by 0 and 1)\n\nsplit_hit=10000 #length for the splitting of hits (expected max intron size for evidence alignments)\nsingle_exon=0 #consider single exon EST evidence when generating annotations, 1 = yes, 0 = no\nsingle_length=250 #min length required for single exon ESTs if 'single_exon is enabled'\ncorrect_est_fusion=0 #limits use of ESTs in annotation to avoid fusion genes\n\ntries=2 #number of times to try a contig if there is a failure for some reason\nclean_try=0 #remove all data from previous run before retrying, 1 = yes, 0 = no\nclean_up=0 #removes theVoid directory with individual analysis files, 1 = yes, 0 = no\nTMP= #specify a directory other than the system default temporary directory for temporary files\n\n\n\nROUND 3 (After second SNAP run)\n\n20181127_oly_maker_genome_annotation/snap02/maker_opts.ctl\n\n\n#-----Genome (these are always required)\ngenome=/gscratch/srlab/sam/data/O_lurida/oly_genome_assemblies/Olurida_v081/Olurida_v081.fa #genome sequence (fasta file or fasta embeded in GFF3 file)\norganism_type=eukaryotic #eukaryotic or prokaryotic. Default is eukaryotic\n\n#-----Re-annotation Using MAKER Derived GFF3\nmaker_gff= #MAKER derived GFF3 file\nest_pass=0 #use ESTs in maker_gff: 1 = yes, 0 = no\naltest_pass=0 #use alternate organism ESTs in maker_gff: 1 = yes, 0 = no\nprotein_pass=0 #use protein alignments in maker_gff: 1 = yes, 0 = no\nrm_pass=0 #use repeats in maker_gff: 1 = yes, 0 = no\nmodel_pass=0 #use gene models in maker_gff: 1 = yes, 0 = no\npred_pass=0 #use ab-initio predictions in maker_gff: 1 = yes, 0 = no\nother_pass=0 #passthrough anyything else in maker_gff: 1 = yes, 0 = no\n\n#-----EST Evidence (for best results provide a file for at least one)\nest=/gscratch/srlab/sam/data/O_lurida/oly_transcriptome_assemblies/Olurida_transcriptome_v3.fasta #set of ESTs or assembled mRNA-seq in fasta format\naltest= #EST/cDNA sequence file in fasta format from an alternate organism\nest_gff= #aligned ESTs or mRNA-seq from an external GFF3 file\naltest_gff= #aligned ESTs from a closly relate species in GFF3 format\n\n#-----Protein Homology Evidence (for best results provide a file for at least one)\nprotein=/gscratch/scrubbed/samwhite/outputs/20181127_oly_maker_genome_annotation/gigas_virginica_ncbi_proteomes.fasta  #protein sequence file in fasta format (i.e. from mutiple oransisms)\nprotein_gff=  #aligned protein homology evidence from an external GFF3 file\n\n#-----Repeat Masking (leave values blank to skip repeat masking)\nmodel_org=all #select a model organism for RepBase masking in RepeatMasker\nrmlib=/gscratch/srlab/sam/data/O_lurida/Ostrea_lurida_v081-families.fa #provide an organism specific repeat library in fasta format for RepeatMasker\nrepeat_protein=/gscratch/srlab/programs/maker-2.31.10/data/te_proteins.fasta #provide a fasta file of transposable element proteins for RepeatRunner\nrm_gff= #pre-identified repeat elements from an external GFF3 file\nprok_rm=0 #forces MAKER to repeatmask prokaryotes (no reason to change this), 1 = yes, 0 = no\nsoftmask=1 #use soft-masking rather than hard-masking in BLAST (i.e. seg and dust filtering)\n\n#-----Gene Prediction\nsnaphmm=20181127__oly_snap01.hmm #SNAP HMM file\ngmhmm= #GeneMark HMM file\naugustus_species= #Augustus gene prediction species model\nfgenesh_par_file= #FGENESH parameter file\npred_gff= #ab-initio predictions from an external GFF3 file\nmodel_gff= #annotated gene models from an external GFF3 file (annotation pass-through)\nest2genome=0 #infer gene predictions directly from ESTs, 1 = yes, 0 = no\nprotein2genome=0 #infer predictions from protein homology, 1 = yes, 0 = no\ntrna=0 #find tRNAs with tRNAscan, 1 = yes, 0 = no\nsnoscan_rrna= #rRNA file to have Snoscan find snoRNAs\nunmask=0 #also run ab-initio prediction programs on unmasked sequence, 1 = yes, 0 = no\n\n#-----Other Annotation Feature Types (features MAKER doesn't recognize)\nother_gff= #extra features to pass-through to final MAKER generated GFF3 file\n\n#-----External Application Behavior Options\nalt_peptide=C #amino acid used to replace non-standard amino acids in BLAST databases\ncpus=1 #max number of cpus to use in BLAST and RepeatMasker (not for MPI, leave 1 when using MPI)\n\n#-----MAKER Behavior Options\nmax_dna_len=100000 #length for dividing up contigs into chunks (increases/decreases memory usage)\nmin_contig=1 #skip genome contigs below this length (under 10kb are often useless)\n\npred_flank=200 #flank for extending evidence clusters sent to gene predictors\npred_stats=0 #report AED and QI statistics for all predictions as well as models\nAED_threshold=1 #Maximum Annotation Edit Distance allowed (bound by 0 and 1)\nmin_protein=0 #require at least this many amino acids in predicted proteins\nalt_splice=0 #Take extra steps to try and find alternative splicing, 1 = yes, 0 = no\nalways_complete=0 #extra steps to force start and stop codons, 1 = yes, 0 = no\nmap_forward=0 #map names and attributes forward from old GFF3 genes, 1 = yes, 0 = no\nkeep_preds=0 #Concordance threshold to add unsupported gene prediction (bound by 0 and 1)\n\nsplit_hit=10000 #length for the splitting of hits (expected max intron size for evidence alignments)\nsingle_exon=0 #consider single exon EST evidence when generating annotations, 1 = yes, 0 = no\nsingle_length=250 #min length required for single exon ESTs if 'single_exon is enabled'\ncorrect_est_fusion=0 #limits use of ESTs in annotation to avoid fusion genes\n\ntries=2 #number of times to try a contig if there is a failure for some reason\nclean_try=0 #remove all data from previous run before retrying, 1 = yes, 0 = no\nclean_up=0 #removes theVoid directory with individual analysis files, 1 = yes, 0 = no\nTMP= #specify a directory other than the system default temporary directory for temporary files\n[samwhite@mox1 snap01]$ cd ../snap02\n[samwhite@mox1 snap02]$ cat maker_opts.ctl\n#-----Genome (these are always required)\ngenome=/gscratch/srlab/sam/data/O_lurida/oly_genome_assemblies/Olurida_v081/Olurida_v081.fa #genome sequence (fasta file or fasta embeded in GFF3 file)\norganism_type=eukaryotic #eukaryotic or prokaryotic. Default is eukaryotic\n\n#-----Re-annotation Using MAKER Derived GFF3\nmaker_gff= #MAKER derived GFF3 file\nest_pass=0 #use ESTs in maker_gff: 1 = yes, 0 = no\naltest_pass=0 #use alternate organism ESTs in maker_gff: 1 = yes, 0 = no\nprotein_pass=0 #use protein alignments in maker_gff: 1 = yes, 0 = no\nrm_pass=0 #use repeats in maker_gff: 1 = yes, 0 = no\nmodel_pass=0 #use gene models in maker_gff: 1 = yes, 0 = no\npred_pass=0 #use ab-initio predictions in maker_gff: 1 = yes, 0 = no\nother_pass=0 #passthrough anyything else in maker_gff: 1 = yes, 0 = no\n\n#-----EST Evidence (for best results provide a file for at least one)\nest=/gscratch/srlab/sam/data/O_lurida/oly_transcriptome_assemblies/Olurida_transcriptome_v3.fasta #set of ESTs or assembled mRNA-seq in fasta format\naltest= #EST/cDNA sequence file in fasta format from an alternate organism\nest_gff= #aligned ESTs or mRNA-seq from an external GFF3 file\naltest_gff= #aligned ESTs from a closly relate species in GFF3 format\n\n#-----Protein Homology Evidence (for best results provide a file for at least one)\nprotein=/gscratch/scrubbed/samwhite/outputs/20181127_oly_maker_genome_annotation/gigas_virginica_ncbi_proteomes.fasta  #protein sequence file in fasta format (i.e. from mutiple oransisms)\nprotein_gff=  #aligned protein homology evidence from an external GFF3 file\n\n#-----Repeat Masking (leave values blank to skip repeat masking)\nmodel_org=all #select a model organism for RepBase masking in RepeatMasker\nrmlib=/gscratch/srlab/sam/data/O_lurida/Ostrea_lurida_v081-families.fa #provide an organism specific repeat library in fasta format for RepeatMasker\nrepeat_protein=/gscratch/srlab/programs/maker-2.31.10/data/te_proteins.fasta #provide a fasta file of transposable element proteins for RepeatRunner\nrm_gff= #pre-identified repeat elements from an external GFF3 file\nprok_rm=0 #forces MAKER to repeatmask prokaryotes (no reason to change this), 1 = yes, 0 = no\nsoftmask=1 #use soft-masking rather than hard-masking in BLAST (i.e. seg and dust filtering)\n\n#-----Gene Prediction\nsnaphmm=20181127__oly_snap02.hmm #SNAP HMM file\ngmhmm= #GeneMark HMM file\naugustus_species= #Augustus gene prediction species model\nfgenesh_par_file= #FGENESH parameter file\npred_gff= #ab-initio predictions from an external GFF3 file\nmodel_gff= #annotated gene models from an external GFF3 file (annotation pass-through)\nest2genome=0 #infer gene predictions directly from ESTs, 1 = yes, 0 = no\nprotein2genome=0 #infer predictions from protein homology, 1 = yes, 0 = no\ntrna=0 #find tRNAs with tRNAscan, 1 = yes, 0 = no\nsnoscan_rrna= #rRNA file to have Snoscan find snoRNAs\nunmask=0 #also run ab-initio prediction programs on unmasked sequence, 1 = yes, 0 = no\n\n#-----Other Annotation Feature Types (features MAKER doesn't recognize)\nother_gff= #extra features to pass-through to final MAKER generated GFF3 file\n\n#-----External Application Behavior Options\nalt_peptide=C #amino acid used to replace non-standard amino acids in BLAST databases\ncpus=1 #max number of cpus to use in BLAST and RepeatMasker (not for MPI, leave 1 when using MPI)\n\n#-----MAKER Behavior Options\nmax_dna_len=100000 #length for dividing up contigs into chunks (increases/decreases memory usage)\nmin_contig=1 #skip genome contigs below this length (under 10kb are often useless)\n\npred_flank=200 #flank for extending evidence clusters sent to gene predictors\npred_stats=0 #report AED and QI statistics for all predictions as well as models\nAED_threshold=1 #Maximum Annotation Edit Distance allowed (bound by 0 and 1)\nmin_protein=0 #require at least this many amino acids in predicted proteins\nalt_splice=0 #Take extra steps to try and find alternative splicing, 1 = yes, 0 = no\nalways_complete=0 #extra steps to force start and stop codons, 1 = yes, 0 = no\nmap_forward=0 #map names and attributes forward from old GFF3 genes, 1 = yes, 0 = no\nkeep_preds=0 #Concordance threshold to add unsupported gene prediction (bound by 0 and 1)\n\nsplit_hit=10000 #length for the splitting of hits (expected max intron size for evidence alignments)\nsingle_exon=0 #consider single exon EST evidence when generating annotations, 1 = yes, 0 = no\nsingle_length=250 #min length required for single exon ESTs if 'single_exon is enabled'\ncorrect_est_fusion=0 #limits use of ESTs in annotation to avoid fusion genes\n\ntries=2 #number of times to try a contig if there is a failure for some reason\nclean_try=0 #remove all data from previous run before retrying, 1 = yes, 0 = no\nclean_up=0 #removes theVoid directory with individual analysis files, 1 = yes, 0 = no\nTMP= #specify a directory other than the system default temporary directory for temporary files\n\nHere’s the SBATCH script (plain text file) used to actually run this job:\n\n20181127_oly_maker_genome_annotation/20181127_oly_maker_genome_annotation.sh\n\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=20181127_oly_maker_genome_annotation\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=2\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=15-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --workdir=/gscratch/scrubbed/samwhite/outputs/20181127_oly_maker_genome_annotation\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Load Open MPI module for parallel, multi-node processing\n\nmodule load icc_19-ompi_3.1.2\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\n\ndate >> system_path.log\necho \"\" >> system_path.log\necho \"System PATH for $SLURM_JOB_ID\" >> system_path.log\necho \"\" >> system_path.log\nprintf \"%0.s-\" {1..10} >> system_path.log\necho ${PATH} | tr : \\\\n >> system_path.log\n\n## Establish variables for more readable code\n\n### Paths to Maker binaries\nmaker=/gscratch/srlab/programs/maker-2.31.10/bin/maker\ngff3_merge=/gscratch/srlab/programs/maker-2.31.10/bin/gff3_merge\nfasta_merge=/gscratch/srlab/programs/maker-2.31.10/bin/fasta_merge\nmaker2zff=/gscratch/srlab/programs/maker-2.31.10/bin/maker2zff\nfathom=/gscratch/srlab/programs/maker-2.31.10/exe/snap/fathom\nforge=/gscratch/srlab/programs/maker-2.31.10/exe/snap/forge\nhmmassembler=/gscratch/srlab/programs/maker-2.31.10/exe/snap/hmm-assembler.pl\n\n### Path to Olympia oyster genome FastA file\noly_genome=/gscratch/srlab/sam/data/O_lurida/oly_genome_assemblies/Olurida_v081/Olurida_v081.fa\n\n### Path to Olympia oyster transcriptome FastA file\noly_transcriptome=/gscratch/srlab/sam/data/O_lurida/oly_transcriptome_assemblies/Olurida_transcriptome_v3.fasta\n\n### Path to Crassotrea gigas NCBI protein FastA\ngigas_proteome=/gscratch/srlab/sam/data/C_gigas/gigas_ncbi_protein/GCA_000297895.1_oyster_v9_protein.faa\n\n### Path to Crassostrea virginica NCBI protein FastA\nvirginica_proteome=/gscratch/srlab/sam/data/C_virginica/virginica_ncbi_protein/GCF_002022765.2_C_virginica-3.0_protein.faa\n\n### Path to concatenated NCBI prteins FastA\ngigas_virginica_ncbi_proteomes=/gscratch/scrubbed/samwhite/outputs/20181127_oly_maker_genome_annotation/gigas_virginica_ncbi_proteomes.fasta\n\n### Path to O.lurida-specific repeat library\noly_repeat_library=/gscratch/srlab/sam/data/O_lurida/Ostrea_lurida_v081-families.fa\n\n## Create Maker control files needed for running Maker\n$maker -CTL\n\n## Store path to options control file\nmaker_opts_file=./maker_opts.ctl\n\n## Create combined proteome FastA file, only if it doesn't already exist.\nif [ ! -e gigas_virginica_ncbi_proteomes.fasta ]; then\n    touch gigas_virginica_ncbi_proteomes.fasta\n    cat \"$gigas_proteome\" >> gigas_virginica_ncbi_proteomes.fasta\n    cat \"$virginica_proteome\" >> gigas_virginica_ncbi_proteomes.fasta\nfi\n\n## Edit options file\n\n### Set paths to O.lurida genome and transcriptome.\n### Set path to combined C. gigas and C.virginica proteomes.\n## The use of the % symbol sets the delimiter sed uses for arguments.\n## Normally, the delimiter that most examples use is a slash \"/\".\n## But, we need to expand the variables into a full path with slashes, which screws up sed.\n## Thus, the use of % symbol instead (it could be any character that is NOT present in the expanded variable; doesn't have to be \"%\").\nsed -i \"/^genome=/ s% %$oly_genome %\" \"$maker_opts_file\"\nsed -i \"/^est=/ s% %$oly_transcriptome %\" \"$maker_opts_file\"\nsed -i \"/^protein=/ s% %$gigas_virginica_ncbi_proteomes %\" \"$maker_opts_file\"\nsed -i \"/^rmlib=/ s% %$oly_repeat_library %\" \"$maker_opts_file\"\nsed -i \"/^est2genome=0/ s/est2genome=0/est2genome=1/\" \"$maker_opts_file\"\nsed -i \"/^protein2genome=0/ s/protein2genome=0/protein2genome=1/\" \"$maker_opts_file\"\n\n## Run Maker\n### Specify number of nodes to use.\nmpiexec -n 56 $maker\n\n## Merge gffs\n${gff3_merge} -d Olurida_v081.maker.output/Olurida_v081_master_datastore_index.log\n\n## GFF with no FastA in footer\n${gff3_merge} -n -s -d Olurida_v081.maker.output/Olurida_v081_master_datastore_index.log > Olurida_v081.maker.all.noseqs.gff\n\n## Merge all FastAs\n${fasta_merge} -d Olurida_v081.maker.output/Olurida_v081_master_datastore_index.log\n\n## Run SNAP training, round 1\nmkdir snap01 && cd snap01\n${maker2zff} ../Olurida_v081.all.gff\n${fathom} -categorize 1000 genome.ann genome.dna\n${fathom} -export 1000 -plus uni.ann uni.dna\n${forge} export.ann export.dna\n${hmmassembler} test_snap1 . > 20181127__oly_snap01.hmm\n\n## Initiate second Maker run.\n### Copy initial maker control files and\n### - change gene prediction settings to 0 (i.e. don't generate Maker gene predictions)\n### - set location of snaphmm file to use for gene prediction\ncp ../maker_* .\nsed -i \"/^est2genome=1/ s/est2genome=1/est2genome=0/\" maker_opts.ctl\nsed -i \"/^protein2genome=1/ s/protein2genome=1/protein2genome=0/\" maker_opts.ctl\nsed -i \"/^snaphmm=/ s% %20181127__oly_snap01.hmm %\" maker_opts.ctl\n\n## Run Maker\n### Set basename of files and specify number of CPUs to use\nmpiexec -n 56 $maker \\\n-base 20181127_oly_genome_snap01\n\n## Merge gffs\n${gff3_merge} -d 20181127_oly_genome_snap01.maker.output/20181127_oly_genome_snap01_master_datastore_index.log\n\n### GFF with no FastA in footer\n${gff3_merge} -n -s -d 20181127_oly_genome_snap01.maker.output/20181127_oly_genome_snap01_master_datastore_index.log > 20181127_oly_genome_snap01.all.noseqs.gff\n\n### Merge all FastAs\n${fasta_merge} -d 20181127_oly_genome_snap01.maker.output/20181127_oly_genome_snap01_master_datastore_index.log\n\n## Run SNAP training, round 2\ncd ..\nmkdir snap02 && cd snap02\n${maker2zff} ../snap01/20181127_oly_genome_snap01.all.gff\n${fathom} -categorize 1000 genome.ann genome.dna\n${fathom} -export 1000 -plus uni.ann uni.dna\n${forge} export.ann export.dna\n${hmmassembler} test_snap1 . > 20181127__oly_snap02.hmm\n\n## Initiate third and final Maker run.\n### Copy initial maker control files and:\n### - change gene prediction settings to 0 (i.e. don't generate Maker gene predictions)\n### - set location of snaphmm file to use for gene prediction\ncp ../maker_* .\nsed -i \"/^est2genome=1/ s/est2genome=1/est2genome=0/\" maker_opts.ctl\nsed -i \"/^protein2genome=1/ s/protein2genome=1/protein2genome=0/\" maker_opts.ctl\nsed -i \"/^snaphmm=/ s% %20181127__oly_snap02.hmm %\" maker_opts.ctl\n\n## Run Maker\n### Set basename of files and specify number of CPUs to use\nmpiexec -n 56 $maker \\\n-base 20181127_oly_genome_snap02\n\n## Merge gffs\n${gff3_merge} \\\n-d 20181127_oly_genome_snap02.maker.output/20181127_oly_genome_snap02_master_datastore_index.log\n\n### GFF with no FastA in footer\n{gff3_merge} -n -s -d 20181127_oly_genome_snap02.maker.output/20181127_oly_genome_snap02_master_datastore_index.log > 20181127_oly_genome_snap02.all.noseqs.gff\n\n### Merge all FastAs\n${fasta_merge} -d 20181127_oly_genome_snap02.maker.output/20181127_oly_genome_snap02_master_datastore_index.log\n\nWe’ll see how this goes…\n\n\n\nRESULTS\nThis actually completed, and in a reasonable (relatively) amount of time (2 weeks)!\n\nAll files were rsync’d to my folder on Gannet.\nOutput directory:\n\n20181127_oly_maker_genome_annotation/\n\nHere are some of the key output files:\n\nMAKER Protein FastA\n\n20181127_oly_maker_genome_annotation/Olurida_v081.all.maker.proteins.fasta(9.3MB)\n\n\n\nMAKER Transcripts FastAs\n\n20181127_oly_maker_genome_annotation/Olurida_v081.all.maker.transcripts.fasta (28MB)\n\n\n\nInitial MAKER Run GFF3\n\n20181127_oly_maker_genome_annotation/Olurida_v081.maker.all.noseqs.gff (1.1GB)\n\n\n\n2nd MAKER Run GFF (after 1st SNAP)\n\n20181127_oly_maker_genome_annotation/snap01/20181127_oly_genome_snap01.all.noseqs.gff (1.2GB)\n\n\n\n3rd MAKER Run GFF (after 2nd SNAP)\n\n20181127_oly_maker_genome_annotation/snap02/20181127_oly_genome_snap02.all.noseqs.gff\n\nSo, what to do with all of this?\nFirstly, I’ve learned a lot about how all of this should work and recently discovered this remarkably informative GitHub Gist that walks through the process of annotating a snake genome:\n\nIn-depth description of running MAKER for genome annotation.\n\nThe post above provides details on how to speed the process up (hint: use GFFs for subsequent MAKER rounds to avoid repeated BLAST-ing. BLAST-ing is one of the slowest parts of the process.) and provides some explanations of how to evaluate the process, as well as how to run BUSCO/Augustus.\nThe 3rd MAKER Run GFF should contain the most refined gene models. This GFF has individual genes, coding sequences (CDS), mRNAs, and proteins. However, it’s a good idea to load all three GFFs in a genome browser and see how they compare.\nA run through BUSCO/Augustus gene prediction should refine these models even further and seems to be the standard practice when annotating genomes.\nAdditionally, the protein FastA file needs to be subject to BLASTp, as well as run through InterProScan to actually assign functions to the genome.\nFinally, MAKER can put all this together and create better sequence ID info in the FastA files and the GFFs (will create NCBI-standardized sequence IDs)."
  },
  {
    "objectID": "posts/2018/2018-11-29-Primer-Design---Geoduck-Vitellogenin-using-Primer3/index.html",
    "href": "posts/2018/2018-11-29-Primer-Design---Geoduck-Vitellogenin-using-Primer3/index.html",
    "title": "Primer Design - Geoduck Vitellogenin using Primer3",
    "section": "",
    "text": "In preparation for designing primers for developing a geoduck vitellogenin qPCR assay, I annotated a de novo geoduck transcriptome assembly last week. Next up, identify vitellogenin genes, design primers, confirm their specificity, and order them!\nAll of this was done in a Jupyter Notebook on my computer (Swoose).\nJupyter notebook (GitHub):\n\n20181128_swoose_geoduck_vitellogenin_analysis.ipynb\n\nAnnoated transcriptome FastA (271MB):\n\n20181121_geo_transdecoder/20180827_trinity_geoduck.fasta.transdecoder.cds\n\nAlthough everything is explained pretty well in the Jupyter Notebook, here’s the brief rundown of the process:\n\nDownload FastA file.\nSplit into individual FastA files for each sequence (used pyfaidx v0.5.5.2)\nIdentify sequences (in original FastA file, not individual files) annotated as vitellogenin.\nDesign primers on best vitellogenin match (based on TransDecoder score and BLASTp e-values) using Primer3.\nConfirm primer specificity using EMBOSS(v6.6.0) primersearch tool to check all individual sequence files for possible matches.\n\n\n\nRESULTS\nAll files were transferred to Gannet using rsync.\nOutput direoctory:\n\n20181129_geoduck_vtg_primers/\n\nPrimer3 human-readable output: - 20181129_primer3_primers.txt\nHere’s the info on the Primer3 top primer pair (scroll to the right to see primer sequences):\n\nPRIMER PICKING RESULTS FOR TRINITY_DN51983_c0_g1_i8.p1.cds\n\nNo mispriming library specified\nUsing 0-based sequence positions\nOLIGO            start  len      tm     gc%  any_th  3'_th hairpin seq\nLEFT PRIMER       1347   18   59.89   55.56    9.11   0.13   42.06 TTACGCCACGGCAACTGT\nRIGHT PRIMER      1471   18   60.05   61.11   10.11   0.00    0.00 CGCAGTGCCAACAAGCTG\nSEQUENCE SIZE: 14484\nINCLUDED REGION SIZE: 14484\n\nPRODUCT SIZE: 125, PAIR ANY_TH COMPL: 10.66, PAIR 3'_TH COMPL: 0.00\n\nPrimer3 Primer Design Parameters:\n\n20181129_geoduck_vtg_primers/20181129_primer3_params.txt\n\nThe EMBOSS primersearch tool produced only two matches:\n\ntrinity_dn51983_c0_g1_i4.primersearch\ntrinity_dn51983_c0_g1_i8.primersearch\n\nThe second file is the original FastA file from which the primers were generated, so that’s expected.\nThe first file is the a different isoform of the same gene.\nIn any case, I’ll go ahead and order this primer set."
  },
  {
    "objectID": "posts/2018/2018-12-11-FastQC-and-Trimming---Metagenomics-Geoduck-HiSeqX-Reads-from-20180809/index.html",
    "href": "posts/2018/2018-12-11-FastQC-and-Trimming---Metagenomics-Geoduck-HiSeqX-Reads-from-20180809/index.html",
    "title": "FastQC and Trimming - Metagenomics (Geoduck) HiSeqX Reads from 20180809",
    "section": "",
    "text": "Steven tasked me with assembling our geoduck metagenomics HiSeqX data. The first part of the process is examining the quality of the sequencing reads, performing quality trimming, and then checking the quality of the trimmed reads. It’s also possible (likely) that I’ll need to run another round of trimming. The process is documented in the Jupyter Notebook linked below. After these reads are cleaned up, I’ll transfer them over to our HPC nodes (Mox) and try assembling them.\nJupyter Notebook (GitHub):\n\n20181212_emu_geo_metagenomics_fastqc_trimgalore.ipynb\n\n\n\nRESULTS\nSamples required three rounds of trimming:\n\nInitial quality/adapter trimming.\nRemove funky 5’ 10bp from each read.\nRemove funky 5’ 10bp from each read (again? maybe I misread the number of bases needing to be trimmed from the previous trimming?)\n\nNow that the reads are cleaned, will transfer triply-trimmed data to Mox for assembly.\n\nOutput folder:\n\n20181211_metagenomics_fastqc_trimgalore/\n\n\nInitial FastQC folder:\n\n20181211_metagenomics_fastqc_trimgalore/20181211_metagenomics_fastqc/\n\nMultiQC Report (HTML):\n\n20181211_metagenomics_fastqc_trimgalore/20181211_metagenomics_fastqc/multiqc_report.html\n\n\nTrimGalore! folder (initial qualitry trim):\n\n20181211_metagenomics_fastqc_trimgalore/20181211_metagenomics_trimgalore_01/\n\nPost-trimming FastQC folder (first round):\n\n20181211_metagenomics_fastqc_trimgalore/20181211_metagenomics_trimgalore_01/20181211_metagenomics_trimmed_fastqc/\n\nMultiQC Report (HTML):\n\n20181211_metagenomics_fastqc_trimgalore/20181211_metagenomics_trimgalore_01/20181211_metagenomics_trimmed_fastqc/multiqc_report.html\n\n\nTrimGalore! folder (second round, 10bp trim):\n\n20181211_metagenomics_fastqc_trimgalore/20181211_metagenomics_trimgalore_02\n\nPost-trimming FastQC folder (second round, 10bp trim):\n\n20181211_metagenomics_fastqc_trimgalore/20181211_metagenomics_trimgalore_02/20181211_metagenomics_trimmed_fastqc/\n\nMultiQC Report (HTML):\n\n20181211_metagenomics_fastqc_trimgalore/20181211_metagenomics_trimgalore_02/20181211_metagenomics_trimmed_fastqc/multiqc_report.html\n\n\nTrimGalore! folder (third round, 10bp trim):\n\n20181211_metagenomics_fastqc_trimgalore/20181211_metagenomics_trimgalore_03\n\nPost-trimming FastQC folder (second round, 10bp trim):\n\n20181211_metagenomics_fastqc_trimgalore/20181211_metagenomics_trimgalore_03/20181211_metagenomics_trimmed_fastqc/\n\nMultiQC Report (HTML):\n\n20181211_metagenomics_fastqc_trimgalore/20181211_metagenomics_trimgalore_03/20181211_metagenomics_trimmed_fastqc/multiqc_report.html"
  },
  {
    "objectID": "posts/2018/2018-12-11-Primer-Design---Gigas-COX1-using-Primer3/index.html",
    "href": "posts/2018/2018-12-11-Primer-Design---Gigas-COX1-using-Primer3/index.html",
    "title": "Primer Design - Gigas COX1 using Primer3",
    "section": "",
    "text": "We’re attempting a quick & dirty comparison of relative mitochondria counts between diploid and triploid C.gigas, so needed a single-copy mitochondrial gene target for qPCR. Selected cytochrome c oxidase subunit 1 (COX1), based on a quick glance at the NCBI mt genome browser for C.gigas NC_001276.\nAlthough everything is explained pretty well in the Jupyter Notebook linked below, here’s the brief rundown of the process:\n\nDownload FastA files for C.gigas genome, C.gigas mt genome, C.gigas mt coding sequences (only way I could figure out how to get individual gene nucleotides).\nSplit into individual FastA files for each sequence (used pyfaidx v0.5.5.2)\nDesign primers on AF177226 (COX1) using Primer3.\nConfirm primer specificity using EMBOSS(v6.6.0) primersearch tool to check all individual sequence files for possible matches.\n\nJupyter Notebook (GitHub):\n\n20181211_swoose_gigas_mt_primer_design.ipynb\n\n\n\nRESULTS\nAll files were transferred to Gannet using rsync.\nOutput directory:\n\n20181211_gigas_cox1_primers/\n\nPrimer3 human-readable output (TXT):\n\n20181211_gigas_cox1_primers/20181211_primer3_primers.txt\n\nHere’s the info on the Primer3 top primer pair (scroll to the right to see primer sequences):\n\nPRIMER PICKING RESULTS FOR AF177226.1_cds_AAF20053.1_12\n\nNo mispriming library specified\nUsing 0-based sequence positions\nOLIGO            start  len      tm     gc%  any_th  3'_th hairpin seq\nLEFT PRIMER        205   19   59.54   57.89    0.00   0.00   34.59 GGGGGTTTGGTAACTGGCT\nRIGHT PRIMER       352   18   59.88   61.11    0.00   0.00    0.00 CCTGCCCCAACTCCGTTT\nSEQUENCE SIZE: 1518\nINCLUDED REGION SIZE: 1518\n\nPRODUCT SIZE: 148, PAIR ANY_TH COMPL: 0.00, PAIR 3'_TH COMPL: 0.00\n\n\nPrimer3 Primer Design Parameters (TXT):\n\n20181211_gigas_cox1_primers/20181211_primer3_params.txt\n\nThe EMBOSS primersearch tool produced two matches (TXT):\n\n20181211_gigas_cox1_primers/nc_001276.primersearch\n20181211_gigas_cox1_primers/nw_011935054.primersearch\n\nThe first match (nc_001276.primersearch) is a match in the full mt genome, which corresponds to the COX1 coding sequence location.\nThe second match (nw_011935054.primersearch) is within a scaffold of the full C.gigas genome. This result suggests that the full genome includes mitochondrial sequences, as we would not expect mtDNA sequences to be found in the nuclear DNA.\nThese results confirm that this primer set is specific for COX1.\nWill order this primer set."
  },
  {
    "objectID": "posts/2018/2018-12-19-Repeat-Library-Construction---P.generosa-RepeatModeler-v1.0.11/index.html",
    "href": "posts/2018/2018-12-19-Repeat-Library-Construction---P.generosa-RepeatModeler-v1.0.11/index.html",
    "title": "Repeat Library Construction - P.generosa RepeatModeler v1.0.11",
    "section": "",
    "text": "Needed to generate a generate a species-specific repeat library for use with MAKER genome annotation using RepeatModeler and the Pgenerosa_v070.fa (see our Genomic Resources wiki for more info) version of the genome.\nThis was run in a Jupyter Notebook on Emu (Apple Xserve running Ubuntu 16.04LTS).\nJupyter Notebook (GitHub):\n\n20181219_emu_geoduck_repeatmodeler.ipynb\n\n\n\nRESULTS\nThis took ~34hrs to complete, but now I have a geoduck repeat library to use with MAKER!\nOutput folder:\n\n20181219_Pgenerosa_repeatmodeler/\n\nRepeatModeler FastA (1.4MB):\n\n20181219_Pgenerosa_repeatmodeler/Pgenerosa_v070-families.fa"
  },
  {
    "objectID": "posts/2018/2018-12-20-DNA-Isolation---C.gigas-Ploidy-Experiment-Ctenidia/index.html",
    "href": "posts/2018/2018-12-20-DNA-Isolation---C.gigas-Ploidy-Experiment-Ctenidia/index.html",
    "title": "DNA Isolation - C.gigas Ploidy Experiment Ctenidia",
    "section": "",
    "text": "Yesterday, Ronit initiated DNA isolation from ctenidia samples from his experiment (Google Sheet) from the following four samples:\n\nD11\nD12\nD13\nD14\n\nFrozen tissue was excised from frozen tissue block via razor blade (weight not recorded) and pulverized under liquid nitrogen. Samples were incubated O/N @ 37oC (heating block) in 350uL of MB1 Buffer + 25uL Proteinase K, per the E.Z.N.A. Mollusc DNA Kit (Omega) instructions.\nAfter the O/N incubation, I processed the samples according to the E.Z.N.A. Mollusc DNA Kit (Omega) with the following notes:\nSamples were eluted in 100uL of Elution Buffer and quantified with the Roberts Lab Qubit 3.0 and the Qubit dsDNA BR Assay (Invitrogen), using 2uL of each sample.\nSamples were stored in “Ronit’s gDNA Box #1 (positions B2 - B5)” in the FTR213 -20oC freezer.\n\n\nRESULTS\nQubit data (Google Sheet):\n\n20181220_qubit_gDNA_gigas_ploidy\n\n\n\n\nsample_ID\nConcentration(ng/uL)\n\n\n\n\nD11-C\n181\n\n\nD12-C\n192\n\n\nD13-C\n288\n\n\nD14-C\n452"
  },
  {
    "objectID": "posts/2018/2018-12-12-BLASTx---Clupea-pallasii-Pacific-herring-liver-and-testes-transcriptomes/index.html",
    "href": "posts/2018/2018-12-12-BLASTx---Clupea-pallasii-Pacific-herring-liver-and-testes-transcriptomes/index.html",
    "title": "BLASTx - Clupea pallasii (Pacific herring) liver and testes transcriptomes on Mox",
    "section": "",
    "text": "Apparently we’ve had some interest in the Pacific herring transcriptomes (liver and testes) we produced many years ago. As such, Steven asked that I do a quick BLASTx to help annotate these two transcriptomes.\nTwo FastA files were downloaded from FigShare to Mox with the following commands:\nLiver transcriptome:\nwget https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/88394/HerringHepaticTranscriptome34300contigs.fa\nTestes transcriptome:\nwget https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/88395/HerringTesticularTranscriptome31545contigs.fa\nUsed the UniProtKB database that I downloaded on 20181008 as the blast database.\nHere are the SBATCH script files used to run these jobs:\nLiver job: - 20181212_blastx_herring_transcriptomes/20181212_herring_liver_blastx.sh\nTestes job: - 20181212_blastx_herring_transcriptomes/20181212_herring_testes_blastx.sh\nSince the two scripts are fairly short in length, I’ll put the full contents below.\nLiver job:\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=herring_blast\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=2\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=02-0:00:10\n## Memory per node\n#SBATCH --mem=120\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --workdir=/gscratch/srlab/sam/outputs/20181212_blastx_herring_liver\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\ndate >> system_path.log\necho \"\" >> system_path.log\necho \"System PATH for $SLURM_JOB_ID\" >> system_path.log\necho \"\" >> system_path.log\nprintf \"%0.s-\" {1..10} >> system_path.log\necho ${PATH} | tr : \\\\n >> system_path.log\n\n# Copy SBATCH script to working directory\ncp /gscratch/srlab/sam/sbatch_scripts/20181212_herring_liver_blastx.sh .\n\n# Make blast database available to blast\nexport BLASTDB=/gscratch/srlab/blastdbs/UniProtKB_20181008/\n\n# Set variables\n## BLASTx\nblastx=\"/gscratch/srlab/programs/ncbi-blast-2.6.0+/bin/blastx\"\n\n## UniProt database\nuniprot=\"/gscratch/srlab/blastdbs/UniProtKB_20181008/20181008_uniprot_sprot.fasta\"\n\nliver_fasta=\"/gscratch/srlab/sam/data/C_pallasii/transcriptomes/HerringHepaticTranscriptome34300contigs.fa\"\n\n# Run blastp on UniProt database\n${blastx} \\\n-query ${liver_fasta} \\\n-db ${uniprot} \\\n-max_target_seqs 1 \\\n-outfmt 6 \\\n-num_threads 56 \\\n> 20181212.herring.liver.blastx.outfmt6 \\\n2> 20181212.herring.liver.blastx.err\n\nTestes job:\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=herring_blast\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=2\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=02-0:00:10\n## Memory per node\n#SBATCH --mem=120\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --workdir=/gscratch/srlab/sam/outputs/20181212_blastx_herring_liver\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\ndate >> system_path.log\necho \"\" >> system_path.log\necho \"System PATH for $SLURM_JOB_ID\" >> system_path.log\necho \"\" >> system_path.log\nprintf \"%0.s-\" {1..10} >> system_path.log\necho ${PATH} | tr : \\\\n >> system_path.log\n\n# Copy SBATCH script to working directory\ncp /gscratch/srlab/sam/sbatch_scripts/20181212_herring_testes_blastx.sh .\n\n# Make blast database available to blast\nexport BLASTDB=/gscratch/srlab/blastdbs/UniProtKB_20181008/\n\n# Set variables\n## BLASTx\nblastx=\"/gscratch/srlab/programs/ncbi-blast-2.6.0+/bin/blastx\"\n\n## UniProt database\nuniprot=\"/gscratch/srlab/blastdbs/UniProtKB_20181008/20181008_uniprot_sprot.fasta\"\n\ntestes_fasta=\"/gscratch/srlab/sam/data/C_pallasii/transcriptomes/HerringTesticularTranscriptome31545contigs.fa\"\n\n# Run blastp on UniProt database\n${blastx} \\\n-query ${testes_fasta} \\\n-db ${uniprot} \\\n-max_target_seqs 1 \\\n-outfmt 6 \\\n-num_threads 56 \\\n> 20181212.herring.testes.blastx.outfmt6 \\\n2> 20181212.herring.testes.blastx.err\n\n\n\nRESULTS\nOutput folder:\n\n20181212_blastx_herring_transcriptomes/\n\nLiver BLASTx output file:\n\n20181212_blastx_herring_transcriptomes/20181212.herring.liver.blastx.outfmt6\n\nTestes BLASTx output file:\n\n20181212_blastx_herring_transcriptomes/20181212.herring.testes.blastx.outfmt6"
  },
  {
    "objectID": "posts/2018/2018-12-06-qPCR---Geoduck-gonad-cDNA-with-vitellogenin-primers/index.html",
    "href": "posts/2018/2018-12-06-qPCR---Geoduck-gonad-cDNA-with-vitellogenin-primers/index.html",
    "title": "qPCR - Geoduck gonad cDNA with vitellogenin primers",
    "section": "",
    "text": "Earlier today I made some cDNA from geoduck gonad RNA for use in this qPCR to test out the vitellogenin primers I designed on 20181129\nI also used geoduck gDNA (162ng/uL; from 20170105) as a potential positive control, or as confirmation that these primers will not amplify gDNA.\nPrimers:\nSR IDs:\n\n1712\n1711\n\nAll qPCR reactions were run in duplicate. See qPCR Report (Results section below) for plate layout, cycling params, etc.\nqPCR Master Mix calcs (Google Sheet):\n\n20181206_qPCR_geoduck_vtg_primer_test\n\n\n\nResults\nqPCR Report (PDF):\n\nsam_2018-12-06 2013-24-33_BR006896.pdf\n\nCFX Data File (PCRD):\n\nsam_2018-12-06 2013-24-33_BR006896.pcrd\n\nPrimers worked perfectly (although, expression comes up a bit later than I’d like)! Good amplification, single peak in melt curve, and no amplification in gDNA.\nThis also means I can use this cDNA as a positive control for future geoduck VTG qPCRs.\n\nKey for plots below:\n\nGreen = cDNA\nBlue = gDNA\nRed = No Template Controls (NTC)\n\n\nAMPLIFCATION PLOT\n\n\n\n\nMELT CURVE"
  },
  {
    "objectID": "posts/2018/2018-12-17-qPCR---Relative-mitochondrial-abundance-in-C.gigas-diploids-and-triploids-subjected-to-acute-heat-stress-via-COX1/index.html",
    "href": "posts/2018/2018-12-17-qPCR---Relative-mitochondrial-abundance-in-C.gigas-diploids-and-triploids-subjected-to-acute-heat-stress-via-COX1/index.html",
    "title": "qPCR - Relative mitochondrial abundance in C.gigas diploids and triploids subjected to acute heat stress via COX1",
    "section": "",
    "text": "Using the C.gigas cytochrome c oxidase (COX1) primers (SR IDs: 1713, 1714)I designed the other day, I ran a qPCR on a subset of Ronit’s diploid/triploid control/heat shocked oyster DNA that Shelly had previously isolated and performed global DNA methylation assay. The goal is to get a rough assessment of whether or not there appear to be differences in relative mitochondrial abundances between these samples.\nI used 50ng (2uL) of DNA in each qPCR reaction. The DNA had been previously diluted to 25ng/uL by Shelly when performing her DNA methylation assay (Google Sheet), however I did need to prepare a dilution for sample T02 (control, triploid), as there wasn’t an existing 25ng/uL dilution in her box:\n\n5.54uL stock DNA (27ng/uL )\n0.46uL H2O\n\nqPCR master mix calcs (Google Sheet):\n\n20181217_qPCR_gigas_COX1_ploidy\n\nAll samples were run in duplicate using 2x SsoFast EVAGreen Master Mix (BioRad) on the Roberts Lab CFX Connect. Plate layout, cycling params, etc can be seen in the qPCR Report (see Results below).\nRonit’s master spreadsheet that describes all samples is here (Google Sheet):\n\nExposure 8/29-8/30 C.Gigas\n\nSamples used for this qPCR (samples starting with “D” are diploid and starting with “T” are triploid):\n\nD01 (control)\nD02 (control)\nD19 (heat stressed)\nD20 (heat stressed)\nT01 (control)\nT02 (control)\nT19 (heat stressed)\nT20 (heat stressed)\n\n\n\nRESULTS\nqPCR Report (PDF):\n\nsam_2018-12-17%2011-03-40_BR006896.pdf\n\nqPCR Data File (PCRD - Requires CFX Maestro):\n\nsam_2018-12-17%2011-03-40_BR006896.pcrd\n\nqPCR Data (CSV):\n\nsam_2018-12-17_11-03-40_BR006896_-__Quantification_Cq_Results.csv\n\nFirstly, as this is the first time these primers are being used, their performance looks good, based on the melt curves (see below); nice, tight single peak.\nOverall, the qPCRs don’t look that great. Technical reps are remarkably bad, which is surprising and disappointing.\nThe data, via a quick visual assessment of differences between the various sample groups (see table below), suggests that there could be a difference between heat stressed diploid and triploid COX1 (i.e. mitochondrial abundance) numbers, however, there is a remarkably wide spread between biological replicates, as well as technical replicates. No statistical analysis was performed to compare these groups.\nDue to potential differences between the aformentioned groups, the large differences in biological replicates, and poor performance of technical replicates, this certainly warrants further work; likely isolation of additional DNA (Shelly’s T02 stock sample was essentially depleted to make working dilutions for these qPCRs) and repeat of the qPCR to improve technical replicates.\n\n\nTABLE\nSummary table of means of replicate Cq values. Values have been grouped on various categories (table headers). A mean Cq value for each category is provided at the bottom of the respective column.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nControls\nHS\nDiploid\nTriploid\nControl Diploid\nControl Triploid\nHS diploid\nHS triploid\n\n\n\n\n\n21.54\n25.98\n21.54\n23.36\n21.54\n23.36\n25.98\n22.05\n\n\n\n23.94\n17.62\n23.94\n22.73\n23.94\n22.73\n17.62\n27.64\n\n\n\n23.36\n22.05\n25.98\n22.05\n\n\n\n\n\n\n\n22.73\n27.64\n17.62\n27.64\n\n\n\n\n\n\nMEAN Cqs\n22.89\n23.32\n22.27\n23.95\n22.74\n23.04\n21.80\n24.85\n\n\n\n\n\n\nAMPLIFICATION PLOTS\nBlue: heat stressed\nPurple: controls\nRed: no template controls (NTC)\nCircles: diploids\nSquares: triploids\n\n\n\n\nMELT CURVES"
  },
  {
    "objectID": "posts/2018/2018-12-06-Reverse-Transcription---Geoduck-gonad-RNA-pool/index.html",
    "href": "posts/2018/2018-12-06-Reverse-Transcription---Geoduck-gonad-RNA-pool/index.html",
    "title": "Reverse Transcription - Geoduck gonad RNA pool",
    "section": "",
    "text": "To be able to actually test the vitellegenin primers I made, I needed some geoduck cDNA.\nI pooled 1uL of each of the following 12 geoduck gonad RNA (isolated previously from histology blocks):\n\n02\n04\n07\n09\n38\n41\n46\n51\n65\n67\n68\n\nThe concentration of the pooled sample was 95ng/uL.\nUsed 950ng of the pooled RNA in the following reverse transcription reaction:\n\n10uL RNA\n1uL oligo dT primers (Promega)\n4uL H2O\nIncubate 10mins @ 70oC in MJ PTC-200 (no heated lid); immediately on ice after incubation.\n1.25uL of 10mM dNTPs (Promega)\n5uL 5x MMLV Buffer (Promega)\n1uL M-MLV reverse transcriptase (Promega)\n3.75uL HH2O\nFinal volume = 25uL\nIncubate 42oC in MJ PTC-200 (heated lid); 5mins @ 95oC\n\nWill run qPCR and then stored in Sam’s cDNA Box 2 in -20oC."
  },
  {
    "objectID": "posts/2019/2019-11-19-PCR---Crassostrea-gigas-and-sikamea-Mantle-gDNA-from-Marinelli-Shellfish-Company/index.html",
    "href": "posts/2019/2019-11-19-PCR---Crassostrea-gigas-and-sikamea-Mantle-gDNA-from-Marinelli-Shellfish-Company/index.html",
    "title": "PCR - Crassostrea gigas and sikamea Mantle gDNA from Marinelli Shellfish Company",
    "section": "",
    "text": "UPDATE 20191125\nSince the results I obtained on my final attempt to get this to work failed, I decided to double-check the primer sequences.\nWell, I ordered/used the wrong sequences! The two general Crassostrea spp. primers ordered were the 28s primers listed in that paper, instead of the cytochrome oxidase primers! I’ve ordered the correct universal CO primers [which are actually listed in this paper: (Folmer, O., M. Black, W. Hoeh, R. Lutz & R. Vrijenhoek. 1994. DNA primers for amplification of mitochondrial cytochrome C oxidase subunit I from diverse metazoan invertebrate. Mol. Mar. Biol. Biotechnol. 3:294–299.) and will re-run this.\nI’m leaving the original post below for posterity:\nAfter isolating DNA earlier today, I ran PCRs on all the samples.\nPrimers and cycling parameters were taken from this publication:\n\nHaiyan Wang and Ximing Guo “Identification of Crassostrea ariakensis and Related Oysters by Multiplex Species-Specific PCR,” Journal of Shellfish Research 27(3), 481-487, (1 May 2008).\n\n\n\n\nSR ID\nPrimer Name\nSequence\n\n\n\n\n1727\nCOreverse\nCAGGGGGCCGTTCGCGGTCAACGCT\n\n\n1726\nCOCsi546r\nAAGTAACCTTAATAGATCAGGGAACC\n\n\n1725\nCOCgi269r\nTCGAGGAAATTGCATGTCTGCTACAA\n\n\n1724\nCOforward\nGGGACTACCCCCTGAATTTAAGCAT\n\n\n\nThis is a multiplex PCR, where the COforward/reverse primers should amplify any Crassostrea spp. DNA (i.e. a positive control - 697bp) and the other two primers will amplify either C.gigas (Cgi269r - 269bp) or C.sikamea (Csi546r - 546bp).\nI ended up running this PCR two times, due to:\n\nRan the gel too far and ran most of the target products off the gel!\nMany non-specific bands produced.\n\nFirst PCR info:\n\n\n\n\n\n\n\n\n\nComponent\nSingle Rxn Vol. (uL)\nNum. Rxns\nTotal Volumes (uL)\n\n\n\n\nDNA\n4\nNA\nNA\n\n\n2x Apex Red Master Mix\n12.5\n18\n225\n\n\nP1 Mix\n1.5\n18\n27\n\n\nP2 Mix\n1.5\n18\n27\n\n\nH2O\n5.5\n18\n99\n\n\n\n25\n\nAdd 21uL to each PCR tube\n\n\n\nCycling params:\n95oC for 10mins\n30 cycles of:\n\n95oC 1min\n51oC 1min\n72oC 1min\n\n72oC 10mins\nRun on 0.8% agarose gel.\nSince the first PCR didn’t work, I made some changes:\n\nLonger gel (1.5% agarose) to improve ability to resolve lower molecular weight bands.\nIncrease annealing temp and reduce extension time to try to increasae specificity.\nAdd primers individually instead of primer mixes. Used 100uM stocks.\n\n\n\n\n\n\n\n\n\n\nComponent\nSingle Rxn Vol. (uL)\nNum. Rxns\nTotal Volumes (uL)\n\n\n\n\nDNA\n4\nNA\nNA\n\n\n2x Apex Red Master Mix\n12.5\n18\n225\n\n\nCOforward\n0.15\n18\n2.7\n\n\nCoreverse\n0.15\n18\n2.7\n\n\nCOCgi269r\n0.1\n18\n1.8\n\n\nCOCsi546r\n0.1\n18\n1.8\n\n\nH2O\n8\n18\n144\n\n\n\n25\n\nAdd 21uL to each PCR tube\n\n\n\nCycling params:\n95oC for 10mins\n30 cycles of:\n\n95oC 1min\n55oC 1min\n72oC 45secs\n\n72oC 10mins\nUsed the GeneRuler DNA Ladder Mix (ThermoFisher) for all gels:\n\n\n\nGeneRuler DNA Ladder Mix\n\n\n\n\nRESULTS\nGel #1\n\n\n\nGel image from first PCR with too many bands; also ran target bands off gel\n\n\nOverall, this gel is a mess, so I’m haven’t bothered taking the time to label anything. The ladders should be obvious. The no template control (NTC) is in the lane on the furthest right side of the gel and is blank, as it should be.\nAll other lanes show many bands, most of them larger than the expected largest band size (697bp).\nIn addition to that, I ended up running the gel too long (in an attempt to get better resolution of the lower molecular weight PCR products), so I lost any bands <500bp.\nGel #2\n\n\n\nGel image from 2nd PCR with anneal temp of 55C, showing no bands\n\n\nAlthough this gel is cleaner and has the full range of the ladder and encompasses all potential band sizes, there’s no amplification in any lane; just primer dimers. That suggests that the changes I made to the cycling parameters were no good.\nGuess I’ll repeat the PCR using the original cycling parameters and I’ll be sure to run the products on a large gel to get a better idea of what’s happening here."
  },
  {
    "objectID": "posts/2019/2019-04-11-RNA-Isolation-and-Quantification---Crab-Hemolypmh-Using-Quick-DNA-RNA-Microprep-Plus-Kit/index.html",
    "href": "posts/2019/2019-04-11-RNA-Isolation-and-Quantification---Crab-Hemolypmh-Using-Quick-DNA-RNA-Microprep-Plus-Kit/index.html",
    "title": "RNA Isolation and Quantification - Crab Hemolypmh Using Quick-DNA-RNA Microprep Plus Kit",
    "section": "",
    "text": "In the continuing struggle to isolate RNA from the Chionoecetes bairdi hemolymph preserved in RNAlater, Pam managed to find the Quick-DNA-RNA Microprep Plus Kit (ZymoResearch) as a potential option. We received a free sample of the kit and so I gave it a shot. Grace pulled 10 samples she’d previously used to isolate RNA (and was unable to get anything out of virtually all of them using the RNeasy Plus Micro Kit (Qiagen)) for me to try out this new kit:\n\n31\n142\n285\n291\n317\n326\n419\n455\n503\n506\n\nI’ve included an image of the sample tubes, due to the fact that they are colored, and I can’t remember the significance (insignificance?) of this. Want to make sure that is documented in case it’s important.\n\n\n\n10 samples used for RNA isolation in ice bucket\n\n\nUsed the same starting volume of hemolymph/RNAlater “slurry” as Grace: 15uL\nThen followed the Zymo protocol for “Samples in RNAlater” (used H2O as intial sample diluent).\n\nI did not perform the DNase step. This should be performed for all future preparations, though.\n\nEluted with 15uL.\nQuantified RNA using the Roberts Lab Qubit 3.0 and the RNA High Sensitivity Assay (Invitrogen).\nUsed 5uL of each sample.\nThe news is most excellent! There are detectable levels of RNA in all samples!\n\n\nRESULTS\nQubit data (Google Sheet):\n\n20190411_qubit_RNA_crab_zymokit\n\n\n\n\nSampleID\nConcentration (ng/uL)\n\n\n\n\n31\n6.24\n\n\n142\n9.2\n\n\n285\n9.92\n\n\n291\n3.49\n\n\n317\n10.1\n\n\n326\n11.6\n\n\n419\n8.28\n\n\n455\n7.2\n\n\n503\n7.64\n\n\n506\n15.6"
  },
  {
    "objectID": "posts/2019/2019-11-06-Data-Wrangling---Additional-Features-Stats-for-Panopea-generosa-v1.0/index.html",
    "href": "posts/2019/2019-11-06-Data-Wrangling---Additional-Features-Stats-for-Panopea-generosa-v1.0/index.html",
    "title": "Data Wrangling - Additional Features Stats for Panopea-generosa-v1.0",
    "section": "",
    "text": "Although I’d previously generated some feature stats for this genome annotation (see 20191029), we decided we wanted to get some additional info, similar to that of Table 1 in M.Aranda et al 2016. Scientific Reports.\nI’d previously created intron and intergenic features, but didn’t do any sort of analysis on them. In order to try to mirror some of what is in the table linked above, we need some stats from the introns file.\nSo, I generated some relevant stats with the introns file, as well as some other basic stats. Check out the deets in the Jupyter Notebook linked below.\nJupyter Notebook (GitHub):\n\n20191106_swoose_pgen_feature_stats.ipynb"
  },
  {
    "objectID": "posts/2019/2019-03-06-DNA-Shearing-and-Bioanalyzer--Lotterhos-C.virginica-Mantle-gDNA-from-2018114/index.html",
    "href": "posts/2019/2019-03-06-DNA-Shearing-and-Bioanalyzer--Lotterhos-C.virginica-Mantle-gDNA-from-2018114/index.html",
    "title": "DNA Shearing & Bioanalyzer - Lotterhos C.virginica Mantle gDNA from 2018114",
    "section": "",
    "text": "Crassostrea virginica mantle gDNA that had previously been isolated on 20181114 was evaluated for integrity via agaroase gel yesterday (20190305). Everything looked pretty good, so proceeded with shearing in preparation for MBD enrichment.\nAliquoted 2500ng of DNA in a final volume of 100uL of each sample in 0.5mL snap cap (polypropylene) tubes for shearing in the Seeb Lab sonicator (Diagenode Bioruptor 300) with the following settings:\n\n30 cycles\n30 seconds on\n30 seconds off\n\n\n\n\nCycle settings on Diagenode Bioruptor for DNA shearing\n\n\nCalculations for DNA dilutions are here (Google Sheet):\n\nRoberts_2017AdultExposureSampleInfo\n\nIdeally, this will shear DNA to a target size around 300bp.\nAfter shearing, ran all samples on the Bionalyzer 2100 (Agilent) using a DNA 12000 chip according to manufacturer’s protocol.\n\n\nRESULTS\nDate files (XAD - requires Windows and 2100 Expert software):\n\n2100 expert_DNA 2012000_DE72902486_2019-03-06_09-33-02.xad\n2100 expert_DNA 12000_DE72902486_2019-03-06_10-12-36.xad\n\nElectropherograms:\n\n\n\nBioanalyzer DNA12000 electopherograms of sheard DNA 1 of 2\n\n\n\n\n\nBioanalyzer DNA12000 electopherograms of sheard DNA 2 of 2\n\n\nOverall, shearing was decent, albeit, the majority of the resulting fragementation is a tad bit on the larger side (e.g. ~500bp). However, all of these samples will be subjected to bisulfite conversion which should fragment the DNA further, so things should be fine."
  },
  {
    "objectID": "posts/2019/2019-06-27-Transcriptome-Annotation---Geoduck-Juvenile-Ambient-OA-EPI124-with-Transdecoder-on-Mox/index.html",
    "href": "posts/2019/2019-06-27-Transcriptome-Annotation---Geoduck-Juvenile-Ambient-OA-EPI124-with-Transdecoder-on-Mox/index.html",
    "title": "Transcriptome Annotation - Geoduck Juvenile Ambient OA EPI124 with Transdecoder on Mox",
    "section": "",
    "text": "Used Transdecoder to identify open reading frames (ORFs) for use in annotating Pgenerosa_v074 genome assembly. Relies on BLASTp, Pfam, and HMM scanning to ID ORFs.\nTrinity notebook:\n\n20190409_trinity_geoduck_EPI124_RNAseq\n\nSBATCH script (GitHub):\n\n20190627_transdecoder_geoduck_EPI124_RNAseq.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=transdecoder\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=25-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --workdir=/gscratch/scrubbed/samwhite/outputs/20190627_transdecoder_geoduck_EPI124_RNAseq\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\ndate >> system_path.log\necho \"\" >> system_path.log\necho \"System PATH for $SLURM_JOB_ID\" >> system_path.log\necho \"\" >> system_path.log\nprintf \"%0.s-\" {1..10} >> system_path.log\necho \"${PATH}\" | tr : \\\\n >> system_path.log\n\n\nwd=\"$(pwd)\"\n\n\n# Paths to input/output files\nblastp_out_dir=\"${wd}/blastp_out\"\ntransdecoder_out_dir=\"${wd}/Trinity.fasta.transdecoder_dir\"\npfam_out_dir=\"${wd}/pfam_out\"\nblastp_out=\"${blastp_out_dir}/blastp.outfmt6\"\n\npfam_out=\"${pfam_out_dir}/pfam.domtblout\"\nlORFs_pep=\"${transdecoder_out_dir}/longest_orfs.pep\"\npfam_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/Pfam-A.hmm\"\nsp_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/uniprot_sprot.pep\"\n\n# From 20190409 Trinity assembly\ntrinity_fasta=\"/gscratch/srlab/sam/data/P_generosa/transcriptomes/juvenile/EPI124/Trinity.fasta\"\n\n# Paths to programs\nblast_dir=\"/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin\"\nblastp=\"${blast_dir}/blastp\"\nhmmer_dir=\"/gscratch/srlab/programs/hmmer-3.2.1/src\"\nhmmscan=\"${hmmer_dir}/hmmscan\"\ntransdecoder_dir=\"/gscratch/srlab/programs/TransDecoder-v5.5.0\"\ntransdecoder_lORFs=\"${transdecoder_dir}/TransDecoder.LongOrfs\"\ntransdecoder_predict=\"${transdecoder_dir}/TransDecoder.Predict\"\n\n# Make output directories\nmkdir \"${blastp_out_dir}\"\nmkdir \"${pfam_out_dir}\"\n\n# Record FastA checksum for verification, if needed.\nmd5sum ${trinity_fasta} > fasta.md5\n\n# Extract long open reading frames\n${transdecoder_lORFs} \\\n-t ${trinity_fasta}\n\n# Run blastp on long ORFs\n${blastp} \\\n-query \"${lORFs_pep}\" \\\n-db ${sp_db} \\\n-max_target_seqs 1 \\\n-outfmt 6 \\\n-evalue 1e-5 \\\n-num_threads 28 \\\n> \"${blastp_out}\"\n\n# Run pfam search\n${hmmscan} \\\n--cpu 28 \\\n--domtblout \"${pfam_out}\" \\\n${pfam_db} \\\n\"${lORFs_pep}\"\n\n# Run Transdecoder with blastp and Pfam results\n${transdecoder_predict} \\\n-t ${trinity_fasta} \\\n--retain_pfam_hits \"${pfam_out}\" \\\n--retain_blastp_hits \"${blastp_out}\"\n\n\nRESULTS\nRun time:\n\n\n\nScreencap of Mox Transdecoder run time\n\n\nOutput folder:\n\n20190627_transdecoder_geoduck_EPI124_RNAseq/\n\nCDS FastA:\n\n20190627_transdecoder_geoduck_EPI124_RNAseq/Trinity.fasta.transdecoder.cds\n\nPeptide FastA:\n\n20190627_transdecoder_geoduck_EPI124_RNAseq/Trinity.fasta.transdecoder.pep\n\nBED file:\n\n20190627_transdecoder_geoduck_EPI124_RNAseq/Trinity.fasta.transdecoder.bed\n\nGFF file:\n\n20190627_transdecoder_geoduck_EPI124_RNAseq/Trinity.fasta.transdecoder.gff3"
  },
  {
    "objectID": "posts/2019/2019-03-27-Transposable-Element-Mapping---Crassostrea-gigas-Genome-v9-Using-RepeatMasker-4.07-on-Roadrunner/index.html",
    "href": "posts/2019/2019-03-27-Transposable-Element-Mapping---Crassostrea-gigas-Genome-v9-Using-RepeatMasker-4.07-on-Roadrunner/index.html",
    "title": "Transposable Element Mapping - Crassostrea gigas Genome v9 Using RepeatMasker 4.07 on Roadrunner",
    "section": "",
    "text": "Per this GitHub issue, I’m IDing transposable elements (TEs) in the Crassostrea gigas genome. Even though the C.gigas genome should be fully annotated, Steven wants a comparable set of analyses to compare to the Crassostrea virginica TE mapping we previously performed.\nI used the Crassostrea gigas genome we have linked on our GitHub Genomic Resources wiki:\n\nCrassostrea_gigas.oyster_v9.dna_sm.toplevel.fa\n\nAnalysis was performed in the following Jupyter Notebok (GitHub):\n\n20190327_roadrunner_cgig_TEs_repeatmasker.ipynb\n\n\n\nRESULTS\nThis took ~24hrs to complete.\nOutput folder:\n\n20190327_cgig_repeatmasker_all/\n\nGenome used (from our Genomic Resources wiki):\n\nCrassostrea_gigas.oyster_v9.dna_sm.toplevel.fa\n\nGFF file:\n\n20190327_cgig_repeatmasker_all/Crassostrea_gigas.oyster_v9.dna_sm.toplevel.fa.out.gff\n\nSummary table (text):\n\n20190327_cgig_repeatmasker_all/Crassostrea_gigas.oyster_v9.dna_sm.toplevel.fa.tbl\n\n\n\n==================================================\nfile name: Crassostrea_gigas.oyster_v9.dna_sm.toplevel.fa\nsequences:          7658\ntotal length:  557717710 bp  (491860439 bp excl N/X-runs)\nGC level:         33.42 %\nbases masked:  160369613 bp ( 32.60 %)\n==================================================\n               number of      length   percentage\n               elements*    occupied  of sequence\n--------------------------------------------------\nRetroelements        48481     19773596 bp    4.02 %\n   SINEs:             2498       317084 bp    0.06 %\n   Penelope           5749      1808270 bp    0.37 %\n   LINEs:            26463     10472676 bp    2.13 %\n    CRE/SLACS           15         1289 bp    0.00 %\n     L2/CR1/Rex       1712       307207 bp    0.06 %\n     R1/LOA/Jockey     299        21470 bp    0.00 %\n     R2/R4/NeSL        218        69735 bp    0.01 %\n     RTE/Bov-B        8417      3631379 bp    0.74 %\n     L1/CIN4           983        64189 bp    0.01 %\n   LTR elements:     19520      8983836 bp    1.83 %\n     BEL/Pao          2050      1349545 bp    0.27 %\n     Ty1/Copia        2139       189535 bp    0.04 %\n     Gypsy/DIRS1     11971      6501545 bp    1.32 %\n       Retroviral     1263        69288 bp    0.01 %\n\nDNA transposons     299050     85782505 bp   17.44 %\n   hobo-Activator     9348      2278556 bp    0.46 %\n   Tc1-IS630-Pogo    32515      8695261 bp    1.77 %\n   En-Spm                0            0 bp    0.00 %\n   MuDR-IS905            0            0 bp    0.00 %\n   PiggyBac           4136       747000 bp    0.15 %\n   Tourist/Harbinger 11590      2828277 bp    0.58 %\n   Other (Mirage,      232        14514 bp    0.00 %\n    P-element, Transib)\n\nRolling-circles          0            0 bp    0.00 %\n\nUnclassified:       109149     49075277 bp    9.98 %\n\nTotal interspersed repeats:   154631378 bp   31.44 %\n\n\nSmall RNA:             830        93282 bp    0.02 %\n\nSatellites:           2087       401812 bp    0.08 %\nSimple repeats:     110847      4687373 bp    0.95 %\nLow complexity:      16716       787611 bp    0.16 %\n==================================================\n\n* most repeats fragmented by insertions or deletions\n  have been counted as one element\n  Runs of >=20 X/Ns in query were excluded in % calcs\n\n\nThe query species was assumed to be root          \nRepeatMasker Combined Database: Dfam_Consensus-20170127, RepBase-20170127\n\nrun with rmblastn version 2.6.0+\n\n\nI’ve put together the TE comparison requested in the GitHub Issue mentioned above in a Google Sheet:\n\n20190327_te_comparison_cgig_cvir"
  },
  {
    "objectID": "posts/2019/2019-07-10-Genome-Assessment---BUSCO-Metazoa-on-Pgenerosa_v074-on-Mox/index.html",
    "href": "posts/2019/2019-07-10-Genome-Assessment---BUSCO-Metazoa-on-Pgenerosa_v074-on-Mox/index.html",
    "title": "Genome Assessment - BUSCO Metazoa on Pgenerosa_v074 on Mox",
    "section": "",
    "text": "Ran BUSCO on Mox for our Pgenerosa_v74 genome assembly to assess “completeness”. This is the assembly that only has the longest 18 scaffolds (the scaffolds hand-curated by Phase Genomics).\nSBATCH script (GitHub):\n\n20190710_busco_pgen_v074_unannotated.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=busco_pgen74\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=15-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --workdir=/gscratch/scrubbed/samwhite/outputs/20190710_busco_pgen_v074_unannotated\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Load Open MPI module for parallel, multi-node processing\nmodule load icc_19-ompi_3.1.2\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\ndate >> system_path.log\necho \"\" >> system_path.log\necho \"System PATH for $SLURM_JOB_ID\" >> system_path.log\necho \"\" >> system_path.log\nprintf \"%0.s-\" {1..10} >> system_path.log\necho \"${PATH}\" | tr : \\\\n >> system_path.log\n\n\n# Establish variables for more readable code\n\n## Input files and settings\nbase_name=Pgenerosa_v074\nbusco_db=/gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9\ngenome_fasta=/gscratch/srlab/sam/data/P_generosa/genomes/Pgenerosa_v074.fa\naugustus_species=fly\nthreads=28\n\n## Save working directory\nwd=$(pwd)\n\n## Set program paths\naugustus_bin=/gscratch/srlab/programs/Augustus-3.3.2/bin\naugustus_scripts=/gscratch/srlab/programs/Augustus-3.3.2/scripts\nblast_dir=/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin/\nbusco=/gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py\nhmm_dir=/gscratch/srlab/programs/hmmer-3.2.1/src/\n\n## Augustus configs\naugustus_dir=${wd}/augustus\naugustus_config_dir=${augustus_dir}/config\naugustus_orig_config_dir=/gscratch/srlab/programs/Augustus-3.3.2/config\n\n## BUSCO configs\nbusco_config_default=/gscratch/srlab/programs/busco-v3/config/config.ini.default\nbusco_config_ini=${wd}/config.ini\n\n# Export BUSCO config file location\nexport BUSCO_CONFIG_FILE=\"${busco_config_ini}\"\n\n# Export Augustus variable\nexport PATH=\"${augustus_bin}:$PATH\"\nexport PATH=\"${augustus_scripts}:$PATH\"\nexport AUGUSTUS_CONFIG_PATH=\"${augustus_config_dir}\"\n\n\n# Copy BUSCO config file\ncp ${busco_config_default} \"${busco_config_ini}\"\n\n# Make Augustus directory if it doesn't exist\nif [ ! -d \"${augustus_dir}\" ]; then\n  mkdir --parents \"${augustus_dir}\"\nfi\n\n# Copy Augustus config directory\ncp --preserve -r ${augustus_orig_config_dir} \"${augustus_dir}\"\n\n# Edit BUSCO config file\n## Set paths to various programs\n### The use of the % symbol sets the delimiter sed uses for arguments.\n### Normally, the delimiter that most examples use is a slash \"/\".\n### But, we need to expand the variables into a full path with slashes, which screws up sed.\n### Thus, the use of % symbol instead (it could be any character that is NOT present in the expanded variable; doesn't have to be \"%\").\nsed -i \"/^;cpu/ s/1/${threads}/\" \"${busco_config_ini}\"\nsed -i \"/^tblastn_path/ s%tblastn_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^makeblastdb_path/ s%makeblastdb_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^augustus_path/ s%augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^etraining_path/ s%etraining_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^gff2gbSmallDNA_path/ s%gff2gbSmallDNA_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^new_species_path/ s%new_species_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^optimize_augustus_path/ s%optimize_augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^hmmsearch_path/ s%hmmsearch_path = /home/osboxes/BUSCOVM/hmmer/hmmer-3.1b2-linux-intel-ia32/binaries/%path = ${hmm_dir}%\" \"${busco_config_ini}\"\n\n\n# Run BUSCO/Augustus training\n${busco} \\\n--in ${genome_fasta} \\\n--out ${base_name} \\\n--lineage_path ${busco_db} \\\n--mode genome \\\n--cpu ${threads} \\\n--long \\\n--species ${augustus_species} \\\n--tarzip \\\n--augustus_parameters='--progress=true'\n\n\nRESULTS\nThis took ~12hrs to run:\n\n\n\nBUSCO runtime screencap\n\n\nOutput folder:\n\n20190710_busco_pgen_v074_unannotated\n\nBUSCO scores:\n\n20190710_busco_pgen_v074_unannotated/run_Pgenerosa_v074/short_summary_Pgenerosa_v074.txt\n\n# BUSCO version is: 3.0.2\n# The lineage dataset is: metazoa_odb9 (Creation date: 2016-02-13, number of species: 65, number of BUSCOs: 978)\n# To reproduce this run: python /gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py -i /gscratch/srlab/sam/data/P_generosa/genomes/Pgenerosa_v074.fa -o Pgenerosa_v074 -l /gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9/ -m genome -c 28 --long -z -sp fly --augustus_parameters '--progress=true'\n#\n# Summarized benchmarking in BUSCO notation for file /gscratch/srlab/sam/data/P_generosa/genomes/Pgenerosa_v074.fa\n# BUSCO was run in mode: genome\n\n    C:71.6%[S:70.7%,D:0.9%],F:4.7%,M:23.7%,n:978\n\n    700 Complete BUSCOs (C)\n    691 Complete and single-copy BUSCOs (S)\n    9   Complete and duplicated BUSCOs (D)\n    46  Fragmented BUSCOs (F)\n    232 Missing BUSCOs (M)\n    978 Total BUSCO groups searched"
  },
  {
    "objectID": "posts/2019/2019-03-18-Transcriptome-Annotation---Geoduck-Gonad-with-BLASTx-on-Mox/index.html",
    "href": "posts/2019/2019-03-18-Transcriptome-Annotation---Geoduck-Gonad-with-BLASTx-on-Mox/index.html",
    "title": "Transcriptome Annotation - Geoduck Gonad with BLASTx on Mox",
    "section": "",
    "text": "I’ll be annotating the transcriptome assembly (from 20190215) using Trinotate and part of that process is having BLASTx output for the Trinity assembly, so have run BLASTx on Mox.\nSBATCH script:\n\n20190318_blastx_geoduck_gonad_01_RNAseq.sh\n\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=blastx_gonad_01\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=25-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --workdir=/gscratch/scrubbed/samwhite/outputs/20190318_blastx_geoduck_gonad_01_RNAseq\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\ndate >> system_path.log\necho \"\" >> system_path.log\necho \"System PATH for $SLURM_JOB_ID\" >> system_path.log\necho \"\" >> system_path.log\nprintf \"%0.s-\" {1..10} >> system_path.log\necho ${PATH} | tr : \\\\n >> system_path.log\n\n\nwd=\"$(pwd)\"\n\n\n# Paths to input/output files\nblastx_out=\"${wd}/blastx.outfmt6\"\nsp_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/uniprot_sprot.pep\"\n\ntrinity_fasta=\"/gscratch/scrubbed/samwhite/outputs/20190215_trinity_geoduck_gonad_01_RNAseq/trinity_out_dir/Trinity.fasta\"\n\n# Paths to programs\nblast_dir=\"/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin\"\nblastx=\"${blast_dir}/blastx\"\n\n\n# Run blastx on Trinity fasta\n${blastx} \\\n-query ${trinity_fasta} \\\n-db ${sp_db} \\\n-max_target_seqs 1 \\\n-outfmt 6 \\\n-evalue 1e-3 \\\n-num_threads 28 \\\n> ${blastx_out}\n\n\n\n\nRESULTS\nOutput folder:\n\n20190318_blastx_geoduck_gonad_01_RNAseq\n\nBLASTx output (output format 6):\n\n20190318_blastx_geoduck_gonad_01_RNAseq/blastx.outfmt6"
  },
  {
    "objectID": "posts/2019/2019-04-16-Metagenomics-Gene-Prediction---P.generosa-Water-Samples-Using-MetaGeneMark-on-Mox-to-Compare-pH-Treatments/index.html",
    "href": "posts/2019/2019-04-16-Metagenomics-Gene-Prediction---P.generosa-Water-Samples-Using-MetaGeneMark-on-Mox-to-Compare-pH-Treatments/index.html",
    "title": "Metagenomics Gene Prediction - P.generosa Water Samples Using MetaGeneMark on Mox to Compare pH Treatments",
    "section": "",
    "text": "Continuing with a relatively quick comparison of pH treatments (pH=7.1 vs. pH=8.2), I wanted to run gene prediction on the MEGAHIT assemblies I made yesterday. I ran MetaGeneMark on the two pH-specific assemblies on Mox. This should be a very fast process (I’m talking, like a couple of minutes fast), so it enhances the annotation with very little effort and time.\nThis will output a nucleotides FastA, proteins FastA, and a GFF for each of the two assemblies (i.e. pH treatments).\nHere’s how the sample names breakdown:\n\n\n\nSample\nDevelomental Stage (days post-fertilization)\npH Treatment\n\n\n\n\nMG1\n13\n8.2\n\n\nMG2\n17\n8.2\n\n\nMG3\n6\n7.1\n\n\nMG5\n10\n8.2\n\n\nMG6\n13\n7.1\n\n\nMG7\n17\n7.1\n\n\n\nSBATCH script (GitHub):\n\n20190416_metagenomics_pgen_metagenemark.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=mgm\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=20-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --workdir=/gscratch/scrubbed/samwhite/outputs/20190416_metagenomics_pgen_metagenemark\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Load Open MPI module for parallel, multi-node processing\n\nmodule load icc_19-ompi_3.1.2\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\n\ndate >> system_path.log\necho \"\" >> system_path.log\necho \"System PATH for $SLURM_JOB_ID\" >> system_path.log\necho \"\" >> system_path.log\nprintf \"%0.s-\" {1..10} >> system_path.log\necho ${PATH} | tr : \\\\n >> system_path.log\n\n# Programs\ngmhmmp=\"/gscratch/srlab/programs/MetaGeneMark_linux_64_3.38/mgm/gmhmmp\"\nmgm_mod=\"/gscratch/srlab/programs/MetaGeneMark_linux_64_3.38/mgm/MetaGeneMark_v1.mod\"\nsamtools=\"/gscratch/srlab/programs/samtools-1.9/samtools\"\n\n# Variables\nassemblies_dir=/gscratch/scrubbed/samwhite/outputs/20190415_metagenomics_pgen_megahit\n\n## Initialize array\nassemblies_array=()\n\n# Populate array with MegaHit FastAs\nassemblies_array=$(find ${assemblies_dir} -maxdepth 3 -name \"*.contigs.fa\")\n\n# List of files in array\nprintf \"%s\\n\" \"${assemblies_array[@]}\" >> fastas.list.txt\n\n# Loop through array and run MetaGeneMark\n# Parse out sample name by removing .contigs.fa from filename\n# and remove path\nfor sample in ${assemblies_array[@]}\ndo\n  no_ext=${sample%%.*}\n  sample_name=$(echo ${no_ext##*/})\n  # Run MetaGeneMark\n  ## Specifying the following:\n  ### -a : output predicted proteins\n  ### -A : write predicted proteins to designated file\n  ### -d : output predicted nucleotides\n  ### -D : write predicted nucleotides to designated file\n  ### -f 3 : Output format in GFF3\n  ### -m : Model file (supplied with software)\n  ### -o : write GFF3 to designated file\n  ${gmhmmp} \\\n  -a \\\n  -A ${sample_name}.mgm-proteins.fasta \\\n  -d \\\n  -D ${sample_name}.mgm-nucleotides.fasta \\\n  -f 3 \\\n  -m ${mgm_mod} \\\n  ${sample} \\\n  -o ${sample_name}.mgm.gff\ndone\n\n# Index FastAs\nfor fasta in *.fasta\ndo\n  ${samtools} faidx ${fasta}\ndone\n\n\nRESULTS\nAs predicted, this completed really quickly - 7.5 minutes!\nOutput folder:\n\n20190416_metagenomics_pgen_metagenemark/\n\npH=7.1 Outputs:\n\n20190416_metagenomics_pgen_metagenemark/pH71.mgm-nucleotides.fasta\n20190416_metagenomics_pgen_metagenemark/pH71.mgm-nucleotides.fasta.fai\n20190416_metagenomics_pgen_metagenemark/pH71.mgm-proteins.fasta\n20190416_metagenomics_pgen_metagenemark/pH71.mgm-proteins.fasta.fai\n20190416_metagenomics_pgen_metagenemark/pH71.mgm.gff\n\npH=8.2 Outputs:\n\n20190416_metagenomics_pgen_metagenemark/pH82.mgm-nucleotides.fasta\n20190416_metagenomics_pgen_metagenemark/pH82.mgm-nucleotides.fasta.fai\n20190416_metagenomics_pgen_metagenemark/pH82.mgm-proteins.fasta\n20190416_metagenomics_pgen_metagenemark/pH82.mgm-proteins.fasta.fai\n20190416_metagenomics_pgen_metagenemark/pH82.mgm.gff\n\nNext, annotate these using BLASTn (will probably do BLASTp eventually, too, but this will take significantly longer and Steven need’s some data from this comparison before the end of the week) and then visualize with KronaTools."
  },
  {
    "objectID": "posts/2019/2019-06-27-Transcriptome-Annotation---Geoduck-Ctenidia-with-Transdecoder-on-Mox/index.html",
    "href": "posts/2019/2019-06-27-Transcriptome-Annotation---Geoduck-Ctenidia-with-Transdecoder-on-Mox/index.html",
    "title": "Transcriptome Annotation - Geoduck Ctenidia with Transdecoder on Mox",
    "section": "",
    "text": "Used Transdecoder to identify open reading frames (ORFs) for use in annotating Pgenerosa_v074 genome assembly. Relies on BLASTp, Pfam, and HMM scanning to ID ORFs.\nTrinity notebook:\n\n20190409_trinity_geoduck_ctenidia_RNAseq\n\nSBATCH script (GitHub):\n\n20190627_transdecoder_geoduck_ctenidia_RNAseq.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=transdecoder\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=25-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --workdir=/gscratch/scrubbed/samwhite/outputs/20190627_transdecoder_geoduck_ctenidia_RNAseq\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\ndate >> system_path.log\necho \"\" >> system_path.log\necho \"System PATH for $SLURM_JOB_ID\" >> system_path.log\necho \"\" >> system_path.log\nprintf \"%0.s-\" {1..10} >> system_path.log\necho \"${PATH}\" | tr : \\\\n >> system_path.log\n\n\nwd=\"$(pwd)\"\n\n\n# Paths to input/output files\nblastp_out_dir=\"${wd}/blastp_out\"\ntransdecoder_out_dir=\"${wd}/Trinity.fasta.transdecoder_dir\"\npfam_out_dir=\"${wd}/pfam_out\"\nblastp_out=\"${blastp_out_dir}/blastp.outfmt6\"\n\npfam_out=\"${pfam_out_dir}/pfam.domtblout\"\nlORFs_pep=\"${transdecoder_out_dir}/longest_orfs.pep\"\npfam_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/Pfam-A.hmm\"\nsp_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/uniprot_sprot.pep\"\n\n# From 20190409 Trinity assembly\ntrinity_fasta=\"/gscratch/srlab/sam/data/P_generosa/transcriptomes/ctenidia/Trinity.fasta\"\n\n# Paths to programs\nblast_dir=\"/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin\"\nblastp=\"${blast_dir}/blastp\"\nhmmer_dir=\"/gscratch/srlab/programs/hmmer-3.2.1/src\"\nhmmscan=\"${hmmer_dir}/hmmscan\"\ntransdecoder_dir=\"/gscratch/srlab/programs/TransDecoder-v5.5.0\"\ntransdecoder_lORFs=\"${transdecoder_dir}/TransDecoder.LongOrfs\"\ntransdecoder_predict=\"${transdecoder_dir}/TransDecoder.Predict\"\n\n# Make output directories\nmkdir \"${blastp_out_dir}\"\nmkdir \"${pfam_out_dir}\"\n\n# Record FastA checksum for verification, if needed.\nmd5sum ${trinity_fasta} > fasta.md5\n\n# Extract long open reading frames\n${transdecoder_lORFs} \\\n-t ${trinity_fasta}\n\n# Run blastp on long ORFs\n${blastp} \\\n-query \"${lORFs_pep}\" \\\n-db ${sp_db} \\\n-max_target_seqs 1 \\\n-outfmt 6 \\\n-evalue 1e-5 \\\n-num_threads 28 \\\n> \"${blastp_out}\"\n\n# Run pfam search\n${hmmscan} \\\n--cpu 28 \\\n--domtblout \"${pfam_out}\" \\\n${pfam_db} \\\n\"${lORFs_pep}\"\n\n# Run Transdecoder with blastp and Pfam results\n${transdecoder_predict} \\\n-t ${trinity_fasta} \\\n--retain_pfam_hits \"${pfam_out}\" \\\n--retain_blastp_hits \"${blastp_out}\"\n\n\nRESULTS\nRun time:\n\n\n\nScreencap of Mox Transdecoder run time\n\n\nOutput folder:\n\n20190627_transdecoder_geoduck_ctenidia_RNAseq/\n\nCDS FastA:\n\n20190627_transdecoder_geoduck_ctenidia_RNAseq/Trinity.fasta.transdecoder.cds\n\nPeptide FastA:\n\n20190627_transdecoder_geoduck_ctenidia_RNAseq/Trinity.fasta.transdecoder.pep\n\nBED file:\n\n20190627_transdecoder_geoduck_ctenidia_RNAseq/Trinity.fasta.transdecoder.bed\n\nGFF file:\n\n20190627_transdecoder_geoduck_ctenidia_RNAseq/Trinity.fasta.transdecoder.gff3"
  },
  {
    "objectID": "posts/2019/2019-07-23-Genome-Annotation---Pgenerosa_v074-Hisat2-Transcript-Isoform-Index/index.html",
    "href": "posts/2019/2019-07-23-Genome-Annotation---Pgenerosa_v074-Hisat2-Transcript-Isoform-Index/index.html",
    "title": "Genome Annotation - Pgenerosa_v074 Hisat2 Transcript Isoform Index",
    "section": "",
    "text": "Essentially, the steps below (which is what was done here) are needed to prepare files for use with Stringtie:\n\nCreate GTF file (basically a GFF specifically for use with transcripts - thus the “T” in GTF) from input GFF file. Done with GFF utilities software.\nIdentify splice sites and exons in newly-created GTF. Done with Hisat2 software.\nCreate a Hisat2 reference index that utilizes the GTF. Done with Hisat2 software.\n\nThis was run on Mox.\nThe SBATCH script has a bunch of leftover extraneous steps that aren’t relevant to this step of the annotation process; specifically the FastQ manipulation steps. This is due to a copy/paste from a previous Hisat2 run that I neglected to edit out and I didn’t want to edit the script after I actually ran it, so have left it in here.\nSBATCH script (GitHub):\n\n20190723_hisat2-build_pgen_v074.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=oly_hisat2\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=25-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --workdir=/gscratch/scrubbed/samwhite/outputs/20190723_hisat2-build_pgen_v074\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\ndate >> system_path.log\necho \"\" >> system_path.log\necho \"System PATH for $SLURM_JOB_ID\" >> system_path.log\necho \"\" >> system_path.log\nprintf \"%0.s-\" {1..10} >> system_path.log\necho \"${PATH}\" | tr : \\\\n >> system_path.log\n\n\nthreads=28\ngenome_index_name=\"Pgenerosa_v074\"\n\n# Paths to programs\ngffread=\"/gscratch/srlab/programs/gffread-0.11.4.Linux_x86_64/gffread\"\nhisat2_dir=\"/gscratch/srlab/programs/hisat2-2.1.0\"\nhisat2_build=\"${hisat2_dir}/hisat2-build\"\nhisat2_exons=\"${hisat2_dir}/hisat2_extract_exons.py\"\nhisat2_splice_sites=\"${hisat2_dir}/hisat2_extract_splice_sites.py\"\n\n# Input/output files\nfastq_dir=\"/gscratch/scrubbed/samwhite/data/P_generosa/RNAseq\"\ngenome_dir=\"/gscratch/srlab/sam/data/P_generosa/genomes\"\n\ngenome_gff=\"${genome_dir}/Pgenerosa_v074_genome_snap02.all.renamed.putative_function.domain_added.gff\"\nexons=\"hisat2_exons.tab\"\ngenome_fasta=\"${genome_dir}/Pgenerosa_v074.fa\"\nsplice_sites=\"hisat2_splice_sites.tab\"\ntranscripts_gtf=\"Pgenerosa_v074_genome_snap02.all.renamed.putative_function.domain_added.gtf\"\n\n## Inititalize arrays\nfastq_array_R1=()\nfastq_array_R2=()\n\n# Create array of fastq R1 files\nfor fastq in \"${fastq_dir}\"/*R1*.gz\ndo\n  fastq_array_R1+=(\"${fastq}\")\ndone\n\n# Create array of fastq R2 files\nfor fastq in \"${fastq_dir}\"/*R2*.gz\ndo\n  fastq_array_R2+=(\"${fastq}\")\ndone\n\n# Create array of sample names\n## Uses parameter substitution to strip leading path from filename\n## Uses awk to parse out sample name from filename\nfor R1_fastq in \"${fastq_dir}\"/*R1*.gz\ndo\n  names_array+=($(echo \"${R1_fastq#${fastq_dir}}\" | awk -F\"[_.]\" '{print $1 \"_\" $5}'))\ndone\n\n# Create list of fastq files used in analysis\n## Uses parameter substitution to strip leading path from filename\nfor fastq in \"${fastq_dir}\"/*.gz\ndo\n  echo \"${fastq#${fastq_dir}}\" >> fastq.list.txt\ndone\n\n# Create transcipts GTF from genome FastA\n\"${gffread}\" -T \\\n\"${genome_gff}\" \\\n-o \"${transcripts_gtf}\"\n\n# Create Hisat2 exons tab file\n\"${hisat2_exons}\" \\\n\"${transcripts_gtf}\" \\\n> \"${exons}\"\n# Create Hisate2 splice sites tab file\n\"${hisat2_splice_sites}\" \\\n\"${transcripts_gtf}\" \\\n> \"${splice_sites}\"\n\n# Build Hisat2 reference index using splice sites and exons\n\"${hisat2_build}\" \\\n\"${genome_fasta}\" \\\n\"${genome_index_name}\" \\\n--exon \"${exons}\" \\\n--ss \"${splice_sites}\" \\\n-p \"${threads}\" \\\n2> hisat2_build.err\n\n# Copy Hisat2 index files to my data directory\nrsync -av \"${genome_index_name}\"*.ht2 \"${genome_dir}\"\n\n\nRESULTS\nThis took a shockingly short amount of time to complete: ~10mins!\n\n\n\nScreencap of Hisat2 pgen_v074 runtime\n\n\nOther Hisat indexing I’ve done with Ostrea lurida and the Pgen_v070 assemblies all took ~1hr.\nOutput folder:\n\n20190723_hisat2-build_pgen_v074/\n\nThe Hisat2 index files are: *.ht2. These will be used with Stringtie for transcript isoform annotation."
  },
  {
    "objectID": "posts/2019/2019-06-27-Transcriptome-Annotation---Geoduck-Juvenile-Super-Low-OA-EPI116-with-Transdecoder-on-Mox/index.html",
    "href": "posts/2019/2019-06-27-Transcriptome-Annotation---Geoduck-Juvenile-Super-Low-OA-EPI116-with-Transdecoder-on-Mox/index.html",
    "title": "Transcriptome Annotation - Geoduck Super Low OA EPI116 with Transdecoder on Mox",
    "section": "",
    "text": "Used Transdecoder to identify open reading frames (ORFs) for use in annotating Pgenerosa_v074 genome assembly. Relies on BLASTp, Pfam, and HMM scanning to ID ORFs.\nTrinity notebook:\n\n20190409_trinity_geoduck_EPI116_RNAseq\n\nSBATCH script (GitHub):\n\n20190627_transdecoder_geoduck_EPI116_RNAseq.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=transdecoder\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=25-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --workdir=/gscratch/scrubbed/samwhite/outputs/20190627_transdecoder_geoduck_EPI116_RNAseq\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\ndate >> system_path.log\necho \"\" >> system_path.log\necho \"System PATH for $SLURM_JOB_ID\" >> system_path.log\necho \"\" >> system_path.log\nprintf \"%0.s-\" {1..10} >> system_path.log\necho \"${PATH}\" | tr : \\\\n >> system_path.log\n\n\nwd=\"$(pwd)\"\n\n\n# Paths to input/output files\nblastp_out_dir=\"${wd}/blastp_out\"\ntransdecoder_out_dir=\"${wd}/Trinity.fasta.transdecoder_dir\"\npfam_out_dir=\"${wd}/pfam_out\"\nblastp_out=\"${blastp_out_dir}/blastp.outfmt6\"\n\npfam_out=\"${pfam_out_dir}/pfam.domtblout\"\nlORFs_pep=\"${transdecoder_out_dir}/longest_orfs.pep\"\npfam_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/Pfam-A.hmm\"\nsp_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/uniprot_sprot.pep\"\n\n# From 20190409 Trinity assembly\ntrinity_fasta=\"/gscratch/srlab/sam/data/P_generosa/transcriptomes/juvenile/EPI116/Trinity.fasta\"\n\n# Paths to programs\nblast_dir=\"/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin\"\nblastp=\"${blast_dir}/blastp\"\nhmmer_dir=\"/gscratch/srlab/programs/hmmer-3.2.1/src\"\nhmmscan=\"${hmmer_dir}/hmmscan\"\ntransdecoder_dir=\"/gscratch/srlab/programs/TransDecoder-v5.5.0\"\ntransdecoder_lORFs=\"${transdecoder_dir}/TransDecoder.LongOrfs\"\ntransdecoder_predict=\"${transdecoder_dir}/TransDecoder.Predict\"\n\n# Make output directories\nmkdir \"${blastp_out_dir}\"\nmkdir \"${pfam_out_dir}\"\n\n# Record FastA checksum for verification, if needed.\nmd5sum ${trinity_fasta} > fasta.md5\n\n# Extract long open reading frames\n${transdecoder_lORFs} \\\n-t ${trinity_fasta}\n\n# Run blastp on long ORFs\n${blastp} \\\n-query \"${lORFs_pep}\" \\\n-db ${sp_db} \\\n-max_target_seqs 1 \\\n-outfmt 6 \\\n-evalue 1e-5 \\\n-num_threads 28 \\\n> \"${blastp_out}\"\n\n# Run pfam search\n${hmmscan} \\\n--cpu 28 \\\n--domtblout \"${pfam_out}\" \\\n${pfam_db} \\\n\"${lORFs_pep}\"\n\n# Run Transdecoder with blastp and Pfam results\n${transdecoder_predict} \\\n-t ${trinity_fasta} \\\n--retain_pfam_hits \"${pfam_out}\" \\\n--retain_blastp_hits \"${blastp_out}\"\n\n\nRESULTS\nRun time:\n\n\n\nScreencap of Mox Transdecoder run time\n\n\nOutput folder:\n\n20190627_transdecoder_geoduck_EPI116_RNAseq/\n\nCDS FastA:\n\n20190627_transdecoder_geoduck_EPI116_RNAseq/Trinity.fasta.transdecoder.cds\n\nPeptide FastA:\n\n20190627_transdecoder_geoduck_EPI116_RNAseq/Trinity.fasta.transdecoder.pep\n\nBED file:\n\n20190627_transdecoder_geoduck_EPI116_RNAseq/Trinity.fasta.transdecoder.bed\n\nGFF file:\n\n20190627_transdecoder_geoduck_EPI116_RNAseq/Trinity.fasta.transdecoder.gff3"
  },
  {
    "objectID": "posts/2019/2019-03-18-Transcriptome-Annotation---Geoduck-Heart-with-BLASTx-on-Mox/index.html",
    "href": "posts/2019/2019-03-18-Transcriptome-Annotation---Geoduck-Heart-with-BLASTx-on-Mox/index.html",
    "title": "Transcriptome Annotation - Geoduck Heart with BLASTx on Mox",
    "section": "",
    "text": "I’ll be annotating the transcriptome assembly (from 20190215) using Trinotate and part of that process is having BLASTx output for the Trinity assembly, so have run BLASTx on Mox.\nSBATCH script:\n\n20190318_blastx_geoduck_heart_RNAseq.sh\n\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=blastx_heart\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=25-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --workdir=/gscratch/scrubbed/samwhite/outputs/20190318_blastx_geoduck_heart_RNAseq\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\ndate >> system_path.log\necho \"\" >> system_path.log\necho \"System PATH for $SLURM_JOB_ID\" >> system_path.log\necho \"\" >> system_path.log\nprintf \"%0.s-\" {1..10} >> system_path.log\necho ${PATH} | tr : \\\\n >> system_path.log\n\n\nwd=\"$(pwd)\"\n\n\n# Paths to input/output files\nblastx_out=\"${wd}/blastx.outfmt6\"\nsp_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/uniprot_sprot.pep\"\n\ntrinity_fasta=\"/gscratch/scrubbed/samwhite/outputs/20190215_trinity_geoduck_heart_RNAseq/trinity_out_dir/Trinity.fasta\"\n\n# Paths to programs\nblast_dir=\"/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin\"\nblastx=\"${blast_dir}/blastx\"\n\n\n# Run blastx on Trinity fasta\n${blastx} \\\n-query ${trinity_fasta} \\\n-db ${sp_db} \\\n-max_target_seqs 1 \\\n-outfmt 6 \\\n-evalue 1e-3 \\\n-num_threads 28 \\\n> ${blastx_out}\n\n\n\n\nRESULTS\nOutput folder:\n\n20190318_blastx_geoduck_heart_RNAseq\n\nBLASTx output (output format 6):\n\n20190318_blastx_geoduck_heart_RNAseq/blastx.outfmt6"
  },
  {
    "objectID": "posts/2019/2019-11-21-PCR---Crassostrea-gigas-and-sikamea-Mantle-gDNA-from-Marinelli-Shellfish-Company/index.html",
    "href": "posts/2019/2019-11-21-PCR---Crassostrea-gigas-and-sikamea-Mantle-gDNA-from-Marinelli-Shellfish-Company/index.html",
    "title": "PCR - Crassostrea gigas and sikamea Mantle gDNA from Marinelli Shellfish Company",
    "section": "",
    "text": "UPDATE 20191125\nSince the results I obtained on my final attempt to get this to work failed, I decided to double-check the primer sequences.\nWell, I ordered/used the wrong sequences! The two general Crassostrea spp. primers ordered were the 28s primers listed in that paper, instead of the cytochrome oxidase primers! I’ve ordered the correct universal CO primers, which are actually listed in this paper:\n\nFolmer, O., M. Black, W. Hoeh, R. Lutz & R. Vrijenhoek. 1994. DNA primers for amplification of mitochondrial cytochrome C oxidase subunit I from diverse metazoan invertebrate. Mol. Mar. Biol. Biotechnol. 3:294–299.\n\nWill re-run this.\nI’m leaving the original post below for posterity.\n\nAfter yesterday’s PCR debacles, I re-ran the PCRs with the original cylcing parameters, on a long 1.5% agarose (1x low TAE) gel.\nPrimers and cycling parameters were taken from this publication:\n\nHaiyan Wang and Ximing Guo “Identification of Crassostrea ariakensis and Related Oysters by Multiplex Species-Specific PCR,” Journal of Shellfish Research 27(3), 481-487, (1 May 2008).\n\n\n\n\nSR ID\nPrimer Name\nSequence\n\n\n\n\n1727\nCOreverse\nCAGGGGGCCGTTCGCGGTCAACGCT\n\n\n1726\nCOCsi546r\nAAGTAACCTTAATAGATCAGGGAACC\n\n\n1725\nCOCgi269r\nTCGAGGAAATTGCATGTCTGCTACAA\n\n\n1724\nCOforward\nGGGACTACCCCCTGAATTTAAGCAT\n\n\n\nThis is a multiplex PCR, where the COforward/reverse primers should amplify any Crassostrea spp. DNA (i.e. a positive control - 697bp) and the other two primers will amplify either C.gigas (Cgi269r - 269bp) or C.sikamea (Csi546r - 546bp).\nMaster mix calcs:\n\n\n\n\n\n\n\n\n\nComponent\nSingle Rxn Vol. (uL)\nNum. Rxns\nTotal Volumes (uL)\n\n\n\n\nDNA\n4\nNA\nNA\n\n\n2x Apex Master Mix\n12.5\n18\n225\n\n\nCOforward (100uM)\n0.15\n18\n2.7\n\n\nCOreverse (100uM)\n0.15\n18\n2.7\n\n\nCOCgi269r (100uM)\n0.1\n18\n1.8\n\n\nCOCsi546r (100uM)\n0.1\n18\n1.8\n\n\nH2O\n8\n18\n144\n\n\n\n25\n\nAdd 21uL to each PCR tube\n\n\n\nCycling params:\n95oC for 10mins\n30 cycles of:\n\n95oC 1min\n51oC 1min\n72oC 1min\n\n72oC 10mins\nUsed the GeneRuler DNA Ladder Mix (ThermoFisher) for all gels:\n\n\n\nGeneRuler DNA Ladder Mix\n\n\n\n\nRESULTS\nGel:\n\n\n\nGel of four PCRs from each group of oysters\n\n\nWell, despite the very clean appearance of this gel image (defined bands, no bands in NTC), the results are not helpful.\n\nBand of ~700bp should be present in all samples (OCforward/reverse primers should amplify any Crassostrea spp DNA)- it isn’t present in any of them.\nThe single band generated in each lane is ~500 - 500bp. This band size is relatively close to the expected product size for Crassostrea sikamea detection (546bp).\n\nThese results could suggest that they actually all are C.sikamea. However, the C.gigas 1191-SS are supposed to be verified C.gigas; the samples in question were the C.sikamea 1191-SS.\nWill discuss with Steven to see how much additional time he’d like to devote to this project to determine if I should re-run each of these samples with the species-specific primers only (i.e. no multiplex)."
  },
  {
    "objectID": "posts/2019/2019-06-25-Genome-Annotation---O.lurida-(v081)-Hisat2-Transcript-Isoforms-Index/index.html",
    "href": "posts/2019/2019-06-25-Genome-Annotation---O.lurida-(v081)-Hisat2-Transcript-Isoforms-Index/index.html",
    "title": "Genome Annotation - O.lurida (v081) Hisat2 Transcript Isoforms Index",
    "section": "",
    "text": "Per this thread in Slack, we realized that the “final” annotation of the Olurida_v081 genome only seemed to have singular mRNA annotations and no apparent isoforms. As such, I decided to see if I could tease out this type of info.\nI decided to use Stringtie, as it seemed robust and relatively straightforward. Plus, it had a decent user guide explaining how to tackle this exact problem.\nHowever, before being able to start in with Stringtie, a couple of things needed to be done first to prepare files for use with Stringtie:\n\nCreate GTF file (basically a GFF specifically for use with transcripts - thus the “T” in GTF) from input GFF file. Done with GFF utilities software.\nIdentify splice sites and exons in newly-created GTF. Done with Hisat2 software.\nCreate a Hisat2 reference index that utilizes the GTF. Done with Hisat2 software.\n\nThis was run on Mox. The SBATCH script has a bunch of leftover extraneous steps that aren’t relevant to this step of the annotation process; specifically the FastQ manipulation steps. Originally, I had a large script running both this and the subsequent Stringtie process. However, I was having issues with Stringtie and it made more sense to have these GTF/indexing steps as a separate script, so I chopped off the Stringtie stuff and neglected to remove the FastQ stuff. I didn’t want to edit the script after I actually ran it, so have left it in here.\nSBATCH script (GitHub):\n\n20190625_hisat2-build_oly_v081.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=oly_hisat2\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=25-00:00:00\n## Memory per node\n#SBATCH --mem=500G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --workdir=/gscratch/scrubbed/samwhite/outputs/20190625_hisat2-build_oly_v081\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\ndate >> system_path.log\necho \"\" >> system_path.log\necho \"System PATH for $SLURM_JOB_ID\" >> system_path.log\necho \"\" >> system_path.log\nprintf \"%0.s-\" {1..10} >> system_path.log\necho \"${PATH}\" | tr : \\\\n >> system_path.log\n\n\nthreads=27\ngenome_index_name=\"Olurida_v081\"\n\n# Paths to programs\ngffread=\"/gscratch/srlab/programs/gffread-0.11.4.Linux_x86_64/gffread\"\nhisat2_dir=\"/gscratch/srlab/programs/hisat2-2.1.0\"\nhisat2_build=\"${hisat2_dir}/hisat2-build\"\nhisat2_exons=\"${hisat2_dir}/hisat2_extract_exons.py\"\nhisat2_splice_sites=\"${hisat2_dir}/hisat2_extract_splice_sites.py\"\n\n# Input/output files\ngenome_gff=\"/gscratch/srlab/sam/data/O_lurida/genomes/Olurida_v081/20181127_oly_genome_snap02.all.renamed.putative_function.domain_added.gff\"\nexons=\"hisat2_exons.tab\"\nfastq_dir=\"/gscratch/srlab/sam/data/O_lurida/RNAseq/\"\ngenome_fasta=\"/gscratch/srlab/sam/data/O_lurida/genomes/Olurida_v081/Olurida_v081.fa\"\nsplice_sites=\"hisat2_splice_sites.tab\"\ntranscripts_gtf=\"20190620_oly_genome_snap02.all.renamed.putative_function.domain_added.transcripts.gtf\"\n\n## Inititalize arrays\nfastq_array_R1=()\nfastq_array_R2=()\n\n# Create array of fastq R1 files\nfor fastq in ${fastq_dir}/*R1*.gz\ndo\n  fastq_array_R1+=(${fastq})\ndone\n\n# Create array of fastq R2 files\nfor fastq in ${fastq_dir}/*R2*.gz\ndo\n  fastq_array_R2+=(${fastq})\ndone\n\n# Create array of sample names\n## Uses parameter substitution to strip leading path from filename\n## Uses awk to parse out sample name from filename\nfor R1_fastq in ${fastq_dir}/*R1*.gz\ndo\n  names_array+=($(echo ${R1_fastq#${fastq_dir}} | awk -F\"[_.]\" '{print $1 \"_\" $5}'))\ndone\n\n# Create list of fastq files used in analysis\n## Uses parameter substitution to strip leading path from filename\nfor fastq in ${fastq_dir}*.gz\ndo\n  echo \"${fastq#${fastq_dir}}\" >> fastq.list.txt\ndone\n\n# Create transcipts GTF from genome FastA\n\"${gffread}\" -T \\\n\"${genome_gff}\" \\\n-o \"${transcripts_gtf}\"\n\n# Create Hisat2 exons tab file\n\"${hisat2_exons}\" \\\n\"${transcripts_gtf}\" \\\n> \"${exons}\"\n# Create Hisate2 splice sites tab file\n\"${hisat2_splice_sites}\" \\\n\"${transcripts_gtf}\" \\\n> \"${splice_sites}\"\n\n# Build Hisat2 reference index using splice sites and exons\n\"${hisat2_build}\" \\\n\"${genome_fasta}\" \\\n\"${genome_index_name}\" \\\n--exon \"${exons}\" \\\n--ss \"${splice_sites}\" \\\n-p \"${threads}\" \\\n2> hisat2_build.err\n\n\nRESULTS\nOutput folder:\n\n20190625_hisat2-build_oly_v081/\n\nThe Hisat2 index files are: *.ht2. These will be used with Stringtie for transcript isoform annotation."
  },
  {
    "objectID": "posts/2020/2020-05-26-Transcriptome-Annotation---Trinotate-C.bairdi-Transcriptome-v3.0-on-Mox/index.html",
    "href": "posts/2020/2020-05-26-Transcriptome-Annotation---Trinotate-C.bairdi-Transcriptome-v3.0-on-Mox/index.html",
    "title": "Transcriptome Annotation - Trinotate C.bairdi Transcriptome-v3.0 on Mox",
    "section": "",
    "text": "After performing de novo assembly on all of our Tanner crab RNAseq data (no taxonomic filter applied, either) on 20200518, I continued the annotation process by running Trinotate.\nTrinotate will perform functional annotation of the transcriptome assembly, including GO terms and an annotation feature map that can be used in subsequent Trinity-based differential gene expression analysis so that functional annotations are carried downstream through that process.\nSBATCH script (GitHub):\n\n20200526_cbai_trinotate_transcriptome-v3.0.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=trinotate_cbai_v3.0\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=13-00:00:00\n## Memory per node\n#SBATCH --mem=500G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200526_cbai_trinotate_transcriptome-v3.0\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nwd=\"$(pwd)\"\ntimestamp=$(date +%Y%m%d)\n\n\n## Paths to input/output files\n\n## New folders for working directory\nrnammer_out_dir=\"${wd}/RNAmmer_out\"\nsignalp_out_dir=\"${wd}/signalp_out\"\ntmhmm_out_dir=\"${wd}/tmhmm_out\"\n\n# Input files\n## BLASTx\nblastx_out=\"/gscratch/scrubbed/samwhite/outputs/20200519_cbai_diamond_blastx_transcriptome_v3.0/20200518.C_bairdi.Trinity.blastx.outfmt6\"\n\n## TransDecoder\nblastp_out=\"/gscratch/scrubbed/samwhite/outputs/20200519_cbai_transdecoder_transcriptome-v3.0/blastp_out/20200519.cbai.blastp.outfmt6\"\npfam_out=\"/gscratch/scrubbed/samwhite/outputs/20200519_cbai_transdecoder_transcriptome-v3.0/pfam_out/20200519.cbai.pfam.domtblout\"\nlORFs_pep=\"/gscratch/scrubbed/samwhite/outputs/20200519_cbai_transdecoder_transcriptome-v3.0/cbai_transcriptome_v3.0.fasta.transdecoder_dir/longest_orfs.pep\"\n\n## Transcriptomics\ntrinity_fasta=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v3.0.fasta\"\ntrinity_gene_map=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v3.0.fasta.gene_trans_map\"\n\nrnammer_prefix=${trinity_fasta##*/}\nprefix=\"${timestamp}.${rnammer_prefix}.trinotate\"\n\n# Output files\nrnammer_out=\"${rnammer_out_dir}/${rnammer_prefix}.rnammer.gff\"\nsignalp_out=\"${signalp_out_dir}/${prefix}.signalp.out\"\ntmhmm_out=\"${tmhmm_out_dir}/${prefix}.tmhmm.out\"\ntrinotate_report=\"${wd}/${prefix}_annotation_report.txt\"\n\n# Paths to programs\nrnammer_dir=\"/gscratch/srlab/programs/RNAMMER-1.2\"\nrnammer=\"${rnammer_dir}/rnammer\"\nsignalp_dir=\"/gscratch/srlab/programs/signalp-4.1\"\nsignalp=\"${signalp_dir}/signalp\"\ntmhmm_dir=\"/gscratch/srlab/programs/tmhmm-2.0c/bin\"\ntmhmm=\"${tmhmm_dir}/tmhmm\"\ntrinotate_dir=\"/gscratch/srlab/programs/Trinotate-v3.1.1\"\ntrinotate=\"${trinotate_dir}/Trinotate\"\ntrinotate_rnammer=\"${trinotate_dir}/util/rnammer_support/RnammerTranscriptome.pl\"\ntrinotate_GO=\"${trinotate_dir}/util/extract_GO_assignments_from_Trinotate_xls.pl\"\ntrinotate_features=\"${trinotate_dir}/util/Trinotate_get_feature_name_encoding_attributes.pl\"\ntrinotate_sqlite_db=\"Trinotate.sqlite\"\n\n# Generate FastA checksum, for reference if needed.\nmd5sum ${trinity_fasta} > fasta.checksum.md5\n\n# Make output directories\nmkdir \"${rnammer_out_dir}\" \"${signalp_out_dir}\" \"${tmhmm_out_dir}\"\n\n# Copy sqlite database template\n\ncp ${trinotate_dir}/admin/Trinotate.sqlite .\n\n# Run signalp\n${signalp} \\\n-f short \\\n-n \"${signalp_out}\" \\\n${lORFs_pep}\n\n# Run tmHMM\n${tmhmm} \\\n--short \\\n< ${lORFs_pep} \\\n> \"${tmhmm_out}\"\n\n# Run RNAmmer\ncd \"${rnammer_out_dir}\" || exit\n${trinotate_rnammer} \\\n--transcriptome ${trinity_fasta} \\\n--path_to_rnammer ${rnammer}\ncd \"${wd}\" || exit\n\n# Run Trinotate\n## Load transcripts and coding regions into database\n${trinotate} \\\n${trinotate_sqlite_db} \\\ninit \\\n--gene_trans_map \"${trinity_gene_map}\" \\\n--transcript_fasta \"${trinity_fasta}\" \\\n--transdecoder_pep \"${lORFs_pep}\"\n\n## Load BLAST homologies\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_swissprot_blastp \\\n\"${blastp_out}\"\n\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_swissprot_blastx \\\n\"${blastx_out}\"\n\n## Load Pfam\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_pfam \\\n\"${pfam_out}\"\n\n## Load transmembrane domains\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_tmhmm \\\n\"${tmhmm_out}\"\n\n## Load signal peptides\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_signalp \\\n\"${signalp_out}\"\n\n## Load RNAmmer\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_rnammer \\\n\"${rnammer_out}\"\n\n## Creat annotation report\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nreport \\\n> \"${trinotate_report}\"\n\n# Extract GO terms from annotation report\n\"${trinotate_GO}\" \\\n--Trinotate_xls \"${trinotate_report}\" \\\n-G \\\n--include_ancestral_terms \\\n> \"${prefix}\".go_annotations.txt\n\n# Make transcript features annotation map\n\"${trinotate_features}\" \\\n\"${trinotate_report}\" \\\n> \"${prefix}\".annotation_feature_map.txt\n\n\nRESULTS\nThis was faster than I anticipated and completed in ~7.5hrs:\n\n\n\ncbai transcriptome v3.0 trinotate runtime\n\n\nOutput folder:\n\n20200526_cbai_trinotate_transcriptome-v3.0/\n\nAnnotation feature map. This can be used to update Trinity-based gene expression matrices like so:\n\n${TRINITY_HOME}/Analysis/DifferentialExpression/rename_matrix_feature_identifiers.pl Trinity_trans.counts.matrix annot_feature_map.txt > Trinity_trans.counts.wAnnot.matrix\n20200526.cbai.trinotate.annotation_feature_map.txt\n\nAnnotation report (CSV):\n\n20200526.cbai.trinotate_annotation_report.txt\n\nGene ontology (GO) annotations (TXT):\n\n20200526.cbai.trinotate.go_annotations.txt\n\nSQlite database:\n\nTrinotate.sqlite"
  },
  {
    "objectID": "posts/2020/2020-04-08-Transcriptome-Annotation---Trinotate-Hematodinium-MEGAN6-Taxonomic-specific-Trinity-Assembly-on-Mox/index.html",
    "href": "posts/2020/2020-04-08-Transcriptome-Annotation---Trinotate-Hematodinium-MEGAN6-Taxonomic-specific-Trinity-Assembly-on-Mox/index.html",
    "title": "Transcriptome Annotation - Trinotate Hematodinium MEGAN6 Taxonomic-specific Trinity Assembly on Mox",
    "section": "",
    "text": "After performing de novo assembly on our Hematodinium MEGAN6 taxonomic-specific RNAseq data on 20200330 and performing BLASTx annotation on 20200331, I continued the annotation process by running Trinotate.\nTrinotate will perform functional annotation of the transcriptome assembly, including GO terms and an annotation feature map that can be used in subsequent Trinity-based differential gene expression analysis so that functional annotations are carried downstream through that process.\nSBATCH script (GitHub):\n\n20200408_hemat_trinotate_megan.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=trinotate_hemat\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=05-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200408_hemat_trinotate_megan\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nwd=\"$(pwd)\"\ntimestamp=$(date +%Y%m%d)\nspecies=\"hemat\"\n\nprefix=\"${timestamp}.${species}.trinotate\"\n\n\n## Paths to input/output files\n\n## New folders for working directory\nrnammer_out_dir=\"${wd}/RNAmmer_out\"\nsignalp_out_dir=\"${wd}/signalp_out\"\ntmhmm_out_dir=\"${wd}/tmhmm_out\"\n\n# Input files\nblastp_out=\"/gscratch/scrubbed/samwhite/outputs/20200407_hemat_transdecoder_megan/blastp_out/20200408.hemat.blastp.outfmt6\"\nblastx_out=\"/gscratch/scrubbed/samwhite/outputs/20200331_hemat_diamond_blastx_megan/20200408.hemat.megan.Trinity.blastx.outfmt6\"\npfam_out=\"/gscratch/scrubbed/samwhite/outputs/20200407_hemat_transdecoder_megan/pfam_out/20200408.hemat.pfam.domtblout\"\nlORFs_pep=\"/gscratch/scrubbed/samwhite/outputs/20200407_hemat_transdecoder_megan/20200408.hemat.megan.Trinity.fasta.transdecoder_dir/longest_orfs.pep\"\ntrinity_fasta=\"/gscratch/srlab/sam/data/Hematodinium/transcriptomes/20200408.hemat.megan.Trinity.fasta\"\ntrinity_gene_map=\"/gscratch/srlab/sam/data/Hematodinium/transcriptomes/20200408.hemat.megan.Trinity.fasta.gene_trans_map\"\n\nrnammer_prefix=${trinity_fasta##*/}\n\n# Output files\nrnammer_out=\"${rnammer_out_dir}/${rnammer_prefix}.rnammer.gff\"\nsignalp_out=\"${signalp_out_dir}/${prefix}.signalp.out\"\ntmhmm_out=\"${tmhmm_out_dir}/${prefix}.tmhmm.out\"\ntrinotate_report=\"${wd}/${prefix}_annotation_report.txt\"\n\n# Paths to programs\nrnammer_dir=\"/gscratch/srlab/programs/RNAMMER-1.2\"\nrnammer=\"${rnammer_dir}/rnammer\"\nsignalp_dir=\"/gscratch/srlab/programs/signalp-4.1\"\nsignalp=\"${signalp_dir}/signalp\"\ntmhmm_dir=\"/gscratch/srlab/programs/tmhmm-2.0c/bin\"\ntmhmm=\"${tmhmm_dir}/tmhmm\"\ntrinotate_dir=\"/gscratch/srlab/programs/Trinotate-v3.1.1\"\ntrinotate=\"${trinotate_dir}/Trinotate\"\ntrinotate_rnammer=\"${trinotate_dir}/util/rnammer_support/RnammerTranscriptome.pl\"\ntrinotate_GO=\"${trinotate_dir}/util/extract_GO_assignments_from_Trinotate_xls.pl\"\ntrinotate_features=\"${trinotate_dir}/util/Trinotate_get_feature_name_encoding_attributes.pl\"\ntrinotate_sqlite_db=\"Trinotate.sqlite\"\n\n# Make output directories\nmkdir \"${rnammer_out_dir}\" \"${signalp_out_dir}\" \"${tmhmm_out_dir}\"\n\n# Copy sqlite database template\n\ncp ${trinotate_dir}/admin/Trinotate.sqlite .\n\n# Run signalp\n${signalp} \\\n-f short \\\n-n \"${signalp_out}\" \\\n${lORFs_pep}\n\n# Run tmHMM\n${tmhmm} \\\n--short \\\n< ${lORFs_pep} \\\n> \"${tmhmm_out}\"\n\n# Run RNAmmer\ncd \"${rnammer_out_dir}\" || exit\n${trinotate_rnammer} \\\n--transcriptome ${trinity_fasta} \\\n--path_to_rnammer ${rnammer}\ncd \"${wd}\" || exit\n\n# Run Trinotate\n## Load transcripts and coding regions into database\n${trinotate} \\\n${trinotate_sqlite_db} \\\ninit \\\n--gene_trans_map \"${trinity_gene_map}\" \\\n--transcript_fasta \"${trinity_fasta}\" \\\n--transdecoder_pep \"${lORFs_pep}\"\n\n## Load BLAST homologies\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_swissprot_blastp \\\n\"${blastp_out}\"\n\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_swissprot_blastx \\\n\"${blastx_out}\"\n\n## Load Pfam\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_pfam \\\n\"${pfam_out}\"\n\n## Load transmembrane domains\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_tmhmm \\\n\"${tmhmm_out}\"\n\n## Load signal peptides\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_signalp \\\n\"${signalp_out}\"\n\n## Load RNAmmer\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_rnammer \\\n\"${rnammer_out}\"\n\n## Creat annotation report\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nreport \\\n> \"${trinotate_report}\"\n\n# Extract GO terms from annotation report\n\"${trinotate_GO}\" \\\n--Trinotate_xls \"${trinotate_report}\" \\\n-G \\\n--include_ancestral_terms \\\n> \"${prefix}\".go_annotations.txt\n\n# Make transcript features annotation map\n\"${trinotate_features}\" \\\n\"${trinotate_report}\" \\\n> \"${prefix}\".annotation_feature_map.txt\n\n\nRESULTS\nVery quick, only 6.5 minutes:\n\n\n\nHemat Trinotate runtime\n\n\nOutput folder:\n\n20200408_hemat_trinotate_megan/\n\nAnnotation feature map. This can be used to update Trinity-based gene expression matrices like so:\n\n${TRINITY_HOME}/Analysis/DifferentialExpression/rename_matrix_feature_identifiers.pl Trinity_trans.counts.matrix annot_feature_map.txt > Trinity_trans.counts.wAnnot.matrix\n20200408.hemat.trinotate.annotation_feature_map.txt\n\nAnnotation report (CSV)\n\n20200408.hemat.trinotate_annotation_report.txt\n\nGene ontology (GO) annotations (TXT)\n\n20200408.hemat.trinotate.go_annotations.txt\n\nSQlite database:\n\nTrinotate.sqlite"
  },
  {
    "objectID": "posts/2020/2020-11-13-SRA-Submission---Ronits-C.gigas-Ploidy-WGBS/index.html",
    "href": "posts/2020/2020-11-13-SRA-Submission---Ronits-C.gigas-Ploidy-WGBS/index.html",
    "title": "SRA Submission - Ronits C.gigas Ploidy WGBS",
    "section": "",
    "text": "A few days ago, we received the whole genome bisulfite sequencing (WBGS) data (20201110) from Ronit’s C.gigas diploid/triploid dessication/heat stress experiment (GitHub repo).\nNow, I need to get these submitted to the NCBI short read archive (SRA).\nFor all publications, we should reference the SRA BioProject:\n\nPRJNA678408\n\nA summary table is provided below which includes individual SRA accessions for each sample:\n\n\n\nLibrary_Name\nSeqID\nTissue\nPloidy\nDessication\nHeat_Stress\nLibrary_kit\nSRA_BioProject\nSRA_accession\n\n\n\n\nD11-C\nzr3534_1\nctenidia\ndiploid\nyes\nno\nZymo-Seq WGBS Library Kit (Cat#: D5465)\nPRJNA678408\nSRX9508698\n\n\nD12-C\nzr3534_2\nctenidia\ndiploid\nyes\nno\nZymo-Seq WGBS Library Kit (Cat#: D5465)\nPRJNA678408\nSRX9508699\n\n\nD13-C\nzr3534_3\nctenidia\ndiploid\nyes\nno\nZymo-Seq WGBS Library Kit (Cat#: D5465)\nPRJNA678408\nSRX9508700\n\n\nD19-C\nzr3534_4\nctenidia\ndiploid\nyes\nyes\nZymo-Seq WGBS Library Kit (Cat#: D5465)\nPRJNA678408\nSRX9508701\n\n\nD20-C\nzr3534_5\nctenidia\ndiploid\nyes\nyes\nZymo-Seq WGBS Library Kit (Cat#: D5465)\nPRJNA678408\nSRX9508702\n\n\nT11-C\nzr3534_6\nctenidia\ntriploid\nyes\nno\nZymo-Seq WGBS Library Kit (Cat#: D5465)\nPRJNA678408\nSRX9508703\n\n\nT12-C\nzr3534_7\nctenidia\ntriploid\nyes\nno\nZymo-Seq WGBS Library Kit (Cat#: D5465)\nPRJNA678408\nSRX9508704\n\n\nT13-C\nzr3534_8\nctenidia\ntriploid\nyes\nno\nZymo-Seq WGBS Library Kit (Cat#: D5465)\nPRJNA678408\nSRX9508705\n\n\nT19-C\nzr3534_9\nctenidia\ntriploid\nyes\nyes\nZymo-Seq WGBS Library Kit (Cat#: D5465)\nPRJNA678408\nSRX9508706\n\n\nT20-C\nzr3534_10\nctenidia\ntriploid\nyes\nyes\nZymo-Seq WGBS Library Kit (Cat#: D5465)\nPRJNA678408\nSRX9508707"
  },
  {
    "objectID": "posts/2020/2020-07-29-qPCR---Testing-P.generosa-Reproduction-related-Primers/index.html",
    "href": "posts/2020/2020-07-29-qPCR---Testing-P.generosa-Reproduction-related-Primers/index.html",
    "title": "qPCR - Testing P.generosa Reproduction-related Primers",
    "section": "",
    "text": "Ran some qPCRs on some other primers on 20200723 and then Shelly has asked me to test some additional qPCR primers that might have acceptable melt curves and be usable as normalizing genes.\n\n\n\nSRID\nPrimer_name\n\n\n\n\n1771\nTIF3s12_FWD\n\n\n1770\nTIF3s12_REV\n\n\n1759\nTIF3s8_FWD-1\n\n\n1758\nTIF3s8_REV-1\n\n\n1757\nTIF3s8_FWD-2\n\n\n1756\nTIF3s8_REV-2\n\n\n\nNOTE: I accidentally ran the qPCR with the TIF3s8_FWD/REV-2 set, which we know is bad. So, had to perform another qPCR run with TIF3s8_FWD/REV-1. Doh!\nUsed pooled cDNA, created by combining 2uL from each of the following:\n\n11-08 1H (made by me from 20191125)\n11-08 2H (made by me from 20191125)\n57H (made by me from 20191125)\n11/15 Chew (made by Kaitlyn, no date on tube)\n11/21 Star (made by Kaitlyn, no date on tube)\n\nI also used geoduck gDNA (162ng/uL; from 20170105) as a potential positive control, and/or as confirmation that these primers will not amplify gDNA.\nAll qPCR reactions were run in duplicate. See qPCR Report (Results section below) for plate layout, cycling params, etc.\nUsed the same master mix calcs from 20200723:\n\n20200723_qPCR_geoduck_primer_tests (Google Sheet)\n\n\n\nRESULTS\nqPCR Reports (PDF):\n\nsam_2020-07-29_05-36-56_BR006896.pdf (TIF3s8_FWD/REV-2 and TIF3s12_FWD/REV)\nsam_2020-07-29_06-54-35_BR00689.pdf (TIF3s8_FWD/REV-1)\n\nCFX Data Files (PCRD):\n\nsam_2020-07-29_05-36-56_BR006896.pcrd (TIF3s8_FWD/REV-2 and TIF3s12_FWD/REV)\nsam_2020-07-29_06-54-35_BR006896.pcrd (TIF3s8_FWD/REV-1)\n\nCFX Results Files (CSV):\n\nsam_2020-07-29_05-36-56_BR006896-Quantification-Cq-Results.csv (TIF3s8_FWD/REV-2 and TIF3s12_FWD/REV)\nsam_2020-07-29_06-54-35_BR00689_Quantification-Cq-Results.csv (TIF3s8_FWD/REV-1)\n\n\nPlot color legend:\n\nTIF3s8_FWD/REV-2: BLUE\nTIF3s12_FWD/REV: GREEN\nNo Template Controls: RED\n\n\n\nTIF3s8_FWD/REV-2 and TIF3s12_FWD/REV Amplification plots\n\n\n\nTIF3s8_FWD/REV-2 (blue) and TIF3s12_FWD/REV (green) amplifcation plots\n\n\n\n\nTIF3s8_FWD/REV-2 and TIF3s12_FWD/REV Melt curves\n\n\n\nTIF3s8_FWD/REV-2 (blue) and TIF3s12_FWD/REV (green) melt curves\n\n\n\nPlot color legend:\n\nTIF3s8_FWD/REV-1: BLUE\nNo Template Controls: RED\n\n\n\nTIF3s8_FWD/REV-1 Amplification plots\n\n\n\nTIF3s8_FWD/REV-1 amplifcation plots\n\n\n\n\nTIF3s8_FWD/REV-1 Melt curves\n\n\n\nTIF3s8_FWD/REV-1 melt curves\n\n\n\nAlrighty, so if it’s not too confusing looking at the plots above, here’s how it breaks down, by primer set:\n\nTIF3s8_FWD/REV-1 (bottom pair of plots): Looks great. Come up ~34 Cq and has single, narrow melt curve peak. gDNA also amplifies and produces similar results, suggesting no intron present.\nTIF3s8_FWD/REV-2: Looks bad; has very broad melt curve. Not usable.\nTIF3s12_FWD/REV: Looks good. Comes up ~37 Cq and has single, narrow melt curve peak. No template control seems to begin amplifying very late (>40 Cq), but produce no detectable melt curve. gDNA also amplifies and produces similar results, suggesting no intron present. Due to late relatively late amplification, it might be preferable to use TIF3s8_FWD/REV-1 as normalizing gene instead."
  },
  {
    "objectID": "posts/2020/2020-11-24-MBD-BSseq-Library-Prep---M.magister-MBD-selected-DNA-Using-Pico-Methyl-Seq-Kit/index.html",
    "href": "posts/2020/2020-11-24-MBD-BSseq-Library-Prep---M.magister-MBD-selected-DNA-Using-Pico-Methyl-Seq-Kit/index.html",
    "title": "MBD BSseq Library Prep - M.magister MBD-selected DNA Using Pico Methyl-Seq Kit",
    "section": "",
    "text": "After finishing the final set of eight MBD selections on 20201103, I’m finally ready to make the BSseq libraries using the Pico Methyl-Seq Library Prep Kit (ZymoResearch) (PDF). I followed the manufacturer’s protocols with the following notes/changes (organized by each section in the protocol):\n\nGENERAL\n\nProtocol was followed for using input DNA range 1ng - 50ng.\nAll thermalcycling was performed on the Roberts Lab PTC-200 (MJ Research).\nAll thermalcycling used a heated lid temp of 104oC, unless a different temp was specified in the protocol.\nAll elution steps were performed with heated elution buffer (55oC).\nAll index primers not included with the kit were a mix of the Illumina TruSeq P5 primer (SRID: 1733) and an Illumina TruSeq P7 index primer (see table at bottom of page). The mix consisted of 10uM each of P5 and P7 primers. See the Roberts Lab Primer Database (Google Sheet) for info on the primers.\n\n\n\nSECTION 2\n\nUsed 0.5mL PCR tubes, since 0.2uL tubes were not specified and the 0.5mL tubes are easier to handle/work with.\nPrepAmp Mix was prepared as a master mix and then distributed to samples as required\n\n\n\n\nPrepAmp_component\nsingle_rxn_vol(uL)\nnum_rxns\ntotal_vol(uL)\n\n\n\n\nPrepAmp Buffer (5x)\n1\n26\n26\n\n\nPrepAmp Pre-mix\n3.75\n26\n97.5\n\n\nPrepAmp Polymerase\n0.3\n26\n7.8\n\n\n\n\n\nSECTION 3\n\nElutions consistently returned 1.5uL less volume than input (e.g 12uL input returned 10.5uL).\n\nThis was also noted by Shelly when she utilized this kit previously.\n\n\n\n\nSECTION 4\n\nRecovery from SECTION 3 elution was only 10.5uL (expected 11.5uL based on protocol), so added 1.5uL H2O to each sample.\nBased on input DNA range (1ng - 50ng), number of cycles was set to 8.\n\n\n\nSECTION 5\n\nAnticipating the loss in elution volume, samples were eluted with 13.5uL in the preceding cleanup step and yielded 12uL (the target input volume for this section).\n\n\nNOTE: Sample CH10-19 had a weird elution in SECTION 4 - only recovered 6.5uL. Brought volume up to 12uL with H2O for required input volume in SECTION 5.\nNext step, run the samples on the Bioanalyzer for QC to see how they look.\n\n\nSample - Sequencing Primer Index Table\n\n\n\n\n\n\n\n\n\nSample\nIllumina_TruSeq_index_num\nIllumina_TruSeq_Index_seq\nSRID/ZymoID\n\n\n\n\nCH01-06\n1\nCGTGAT\n1732\n\n\nCH01-14\n2\nCGATGT\nA\n\n\nCH01-22\n3\nGCCTAA\n1731\n\n\nCH01-38\n4\nTGACCA\nB\n\n\nCH03-04\n5\nACAGTG\nC\n\n\nCH03-15\n6\nGCCAAT\nD\n\n\nCH03-33\n7\nCAGATC\nE\n\n\nCH05-01\n8\nTCAAGT\n1730\n\n\nCH05-06\n9\nCTGATC\n1729\n\n\nCH05-21\n10\nAAGCTA\n1728\n\n\nCH05-24\n11\nGTAGCC\n1727\n\n\nCH05-26\n12\nCTTGTA\nF\n\n\nCH07-06\n13\nTTGACT\n1726\n\n\nCH07-11\n14\nGGAACT\n1725\n\n\nCH07-24\n15\nTGACAT\n1724\n\n\nCH09-02\n16\nGGACGG\n1723\n\n\nCH09-11\n17\nCTCTAC\n1722\n\n\nCH09-13\n18\nGCGGAC\n1721\n\n\nCH09-28\n19\nTTTCAC\n1720\n\n\nCH09-29\n20\nGGCCAC\n1719\n\n\nCH10-01\n21\nCGAAAC\n1718\n\n\nCH10-08\n22\nCGTACG\n1717\n\n\nCH10-11\n23\nCCACTC\n1805\n\n\nCH10-19\n25\nATCAGT\n1804\n\n\n\nAll sample processing info/history can currently be found here (Google Sheet):\n\nOA Crab Sample Collection 071119\n\nAny additional project info will end up in this GitHub repo:\n\nproject-dungeness-crab"
  },
  {
    "objectID": "posts/2020/2020-05-27-Transcriptome-Assembly---C.bairdi-All-Pooled-Arthropoda-only-RNAseq-Data-with-Trinity-on-Mox/index.html",
    "href": "posts/2020/2020-05-27-Transcriptome-Assembly---C.bairdi-All-Pooled-Arthropoda-only-RNAseq-Data-with-Trinity-on-Mox/index.html",
    "title": "Transcriptome Assembly - C.bairdi All Pooled Arthropoda-only RNAseq Data with Trinity on Mox",
    "section": "",
    "text": "For completeness sake, I wanted to create an additional C.bairdi transcriptome assembly that consisted of Arthropoda only sequences from just pooled RNAseq data (since I recently generated a similar assembly without taxonomically filtered reads on 20200518). This constitutes samples we have designated: 2018, 2019, 2020-UW. A de novo assembly was run using Trinity on Mox. Since all pooled RNAseq libraries were stranded, I added this option to Trinity command.\nThe resulting assembly will be referred to as:\n\ncbai_transcriptome_v1.7.fasta\n\nSBATCH script (GitHub):\n\n20200527_cbai_trinity_arthropoda_pooled_RNAseq.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=trinity_cbai_v1.7\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=9-00:00:00\n## Memory per node\n#SBATCH --mem=500G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200527_cbai_trinity_arthropoda_pooled_RNAseq\n\n\n### Trinity de novo assembly of all pooled C.bairdi Arthropoda-only RNAseq data.\n### Includes \"descriptor_1\" short-hand of: 2020-UW, 2019, 2018.\n### See fastq.list.txt file for list of input files used for assembly.\n\n# Exit script if a command fails\nset -e\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# User-defined variables\nreads_dir=/gscratch/srlab/sam/data/C_bairdi/RNAseq\ntranscriptome_dir=/gscratch/srlab/sam/data/C_bairdi/transcriptomes\nthreads=28\nassembly_stats=assembly_stats.txt\nfasta_name=\"cbai_transcriptome_v1.7.fasta\"\n\n# Paths to programs\ntrinity_dir=\"/gscratch/srlab/programs/trinityrnaseq-v2.9.0\"\nsamtools=\"/gscratch/srlab/programs/samtools-1.10/samtools\"\n\n\n## Inititalize arrays\nR1_array=()\nR2_array=()\n\n# Variables for R1/R2 lists\nR1_list=\"\"\nR2_list=\"\"\n\n# Create array of fastq R1 files\nR1_array=(\"${reads_dir}\"/*3[80][804]*R1.fq)\n\n# Create array of fastq R2 files\nR2_array=(\"${reads_dir}\"/*3[80][804]*R2.fq)\n\n# Create list of fastq files used in analysis\n## Uses parameter substitution to strip leading path from filename\nfor fastq in \"${reads_dir}\"/*3[80][804]*.fq\ndo\n  echo \"${fastq##*/}\" >> fastq.list.txt\ndone\n\n# Create comma-separated lists of FastQ reads\nR1_list=$(echo \"${R1_array[@]}\" | tr \" \" \",\")\nR2_list=$(echo \"${R2_array[@]}\" | tr \" \" \",\")\n\n\n# Run Trinity\n${trinity_dir}/Trinity \\\n--seqType fq \\\n--max_memory 500G \\\n--CPU ${threads} \\\n--SS_lib_type RF \\\n--left \"${R1_list}\" \\\n--right \"${R2_list}\"\n\n# Rename generic assembly FastA\nmv trinity_out_dir/Trinity.fasta trinity_out_dir/\"${fasta_name}\"\n\n# Assembly stats\n${trinity_dir}/util/TrinityStats.pl trinity_out_dir/\"${fasta_name}\" \\\n> ${assembly_stats}\n\n# Create gene map files\n${trinity_dir}/util/support_scripts/get_Trinity_gene_to_trans_map.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n> trinity_out_dir/\"${fasta_name}\".gene_trans_map\n\n# Create sequence lengths file (used for differential gene expression)\n${trinity_dir}/util/misc/fasta_seq_length.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n> trinity_out_dir/\"${fasta_name}\".seq_lens\n\n# Create FastA index\n${samtools} faidx \\\ntrinity_out_dir/\"${fasta_name}\"\n\n# Copy files to transcriptome directory\nrsync -av \\\ntrinity_out_dir/\"${fasta_name}\"* \\\n${transcriptome_dir}\n\n# Generate FastA MD5 checksum\n# See last line of SLURM output file\ncd trinity_out_dir/\nmd5sum \"${fasta_name}\" > \"${fasta_name}\".checksum.md5\n\n\nRESULTS\nRemarkably quick; only ~1.5hrs:\n\n\n\nTrinity pooled Arthropoda RNAseq runtime\n\n\nOutput folder:\n\n20200527_cbai_trinity_arthropoda_pooled_RNAseq\n\nInput FastQ list (text):\n\nfastq.list.txt\n\nFastA (412MB):\n\ncbai_transcriptome_v1.7.fasta\n\nMD5 = 032d1f81c7744736ebeefe7f63ed6d95\n\n\nFastA Index (text):\n\ncbai_transcriptome_v1.7.fasta.fai\n\nThe following sets of files are useful for downstream gene expression and annotation using Trinity.\nTrinity FastA Gene Trans Map (text):\n\ncbai_transcriptome_v1.7.fasta.gene_trans_map\n\nTrinity FastA Sequence Lengths (text):\n\ncbai_transcriptome_v1.7.fasta.seq_lens\n\nAssembly stats (text):\n\nassembly_stats.txt\n\n################################\n## Counts of transcripts, etc.\n################################\nTotal trinity 'genes':  14225\nTotal trinity transcripts:  20526\nPercent GC: 53.57\n\n########################################\nStats based on ALL transcript contigs:\n########################################\n\n    Contig N10: 3760\n    Contig N20: 2713\n    Contig N30: 2122\n    Contig N40: 1777\n    Contig N50: 1504\n\n    Median contig length: 777\n    Average contig: 1053.71\n    Total assembled bases: 21628372\n\n\n#####################################################\n## Stats based on ONLY LONGEST ISOFORM per 'GENE':\n#####################################################\n\n    Contig N10: 3373\n    Contig N20: 2449\n    Contig N30: 1958\n    Contig N40: 1645\n    Contig N50: 1371\n\n    Median contig length: 659\n    Average contig: 930.99\n    Total assembled bases: 13243346"
  },
  {
    "objectID": "posts/2020/2020-09-01-Samples-Submission---Supplemental-Ronits-C.gigas-Diploid-Triploid-Ctendidia-gDNA-for-WGBS-by-ZymoResearch/index.html",
    "href": "posts/2020/2020-09-01-Samples-Submission---Supplemental-Ronits-C.gigas-Diploid-Triploid-Ctendidia-gDNA-for-WGBS-by-ZymoResearch/index.html",
    "title": "Samples Submission - Supplemental Ronits C.gigas Diploid-Triploid Ctendidia gDNA for WGBS by ZymoResearch",
    "section": "",
    "text": "I re-quantified samples for Zymo whole genome bisulfite sequencing (WGBS) project 3534 earlier today due to ZymoResearch indicating there was insufficient DNA for most of the samples and submitted an additional 1ug of each sample. See table below for volume of DNA sent based on today’s (20200901) quants:\n\n\n\nSample_ID\ninitial\nZymo\n20200901\nVol_for_1ug(uL)\n\n\n\n\nD11-C\n181\n85.20\n269\n3.72\n\n\nD12-C\n192\n46.16\n289\n3.46\n\n\nD13-C\n288\n606.23\n332\n3.01\n\n\nD19-C\n63.6\n11.14\n51.3\n19.49\n\n\nD20-C\n123\n9.40\n77\n12.99\n\n\nT11-C\n130\n41.52\n88\n11.36\n\n\nT12-C\n262\n9.96\n139\n7.19\n\n\nT13-C\n250\n130.14\n148\n6.76\n\n\nT19-C\n173\n35.58\n92.9\n10.76\n\n\nT20-C\n109\n132.10\n78.4\n12.76"
  },
  {
    "objectID": "posts/2020/2020-07-08-ENA-Submission---Ostrea-lurida-draft-genome-Olurida_v081.fa/index.html",
    "href": "posts/2020/2020-07-08-ENA-Submission---Ostrea-lurida-draft-genome-Olurida_v081.fa/index.html",
    "title": "ENA Submission - Ostrea lurida draft genome Olurida_v081.fa",
    "section": "",
    "text": "Submitted our Ostrea lurida v081 genome assembly FastA to the European Nucloetide Archive.\nUsed the following manifest file:\nSTUDY   PRJEB39287\nSAMPLE   ERS4809621\nASSEMBLYNAME   v081\nASSEMBLY_TYPE   isolate\nCOVERAGE   10\nPROGRAM   SOAPdenovo2, PBjelly\nPLATFORM   Illumina HiSeq, PacBio\nMOLECULETYPE   genomic DNA\nFASTA   Olurida_v081.fa.gz\nI wasn’t entirely sure how much coverage we had, so I entered 10x as a value, since it’s a requirement for submission. Additionally, you can only supply a single SAMPLE, despite the fact that our sequencing efforts were derived from two tissues from the same animal.\nLinks to the STUDY and SAMPLE used for submission:\nStudy: PRJEB39287\nSample: SAMEA7048989\nLink to the assembly accession:\n\nGCA_903981925"
  },
  {
    "objectID": "posts/2020/2020-10-07-NanoPore-Reads-Extractions---C.bairdi-Taxonomic-Reads-Extractions-with-MEGAN6-on-201002558-2729-Q7-and-6129-403-26-Q7/index.html",
    "href": "posts/2020/2020-10-07-NanoPore-Reads-Extractions---C.bairdi-Taxonomic-Reads-Extractions-with-MEGAN6-on-201002558-2729-Q7-and-6129-403-26-Q7/index.html",
    "title": "NanoPore Reads Extractions - C.bairdi Taxonomic Reads Extractions with MEGAN6 on 201002558-2729-Q7 and 6129-403-26-Q7",
    "section": "",
    "text": "After completing the taxonomic comparisons of 201002558-2729-Q7 and 6129-403-26-Q7 on 20201002, I decided to extract reads assigned to the following taxa for further exploration (primarily to identify contigs/scaffolds in our cbai_genome_v1.0.fasta (19MB).\nUsed MEGAN6 to extract reads from the MEGAN6 RMA6 files from 201002558-2729-Q7 taxonomic assignments on 20200928 and from 6129-403-26-Q7 on 20200928.\n\n\nRESULTS\nOutput folders:\n\n20201007_cbai_megan-read-extractions_201002558-2729-Q7/\n\n20201007_cbai_megan-read-extractions_201002558-2729-Q7/201002558-2729-Q7_summarized-reads-Arthropoda.fasta\n20201007_cbai_megan-read-extractions_201002558-2729-Q7/201002558-2729-Q7_summarized-reads-Enterospora_canceri.fasta\n20201007_cbai_megan-read-extractions_201002558-2729-Q7/201002558-2729-Q7_summarized-reads-Aquifex_sp..fasta\n20201007_cbai_megan-read-extractions_201002558-2729-Q7/201002558-2729-Q7_summarized-reads-Sar.fasta\n\n20201007_cbai_megan-read-extractions_6129-403-26-Q7/\n\n20201007_cbai_megan-read-extractions_6129-403-26-Q7/6129-403-26-Q7_summarized-reads-Arthropoda.fasta\n20201007_cbai_megan-read-extractions_6129-403-26-Q7/6129-403-26-Q7_summarized-reads-Alveolata.fasta\n20201007_cbai_megan-read-extractions_6129-403-26-Q7/6129-403-26-Q7_summarized-reads-Aquifex_sp..fasta\n20201007_cbai_megan-read-extractions_6129-403-26-Q7/6129-403-26-Q7_summarized-reads-Enterospora_canceri.fasta\n\nHere are stats on the extracted FastAs, generated with the BBTools stats.sh script, using the format=5 output format.\nNOTE: The L50 and N50 values are swapped in the original output! I have manually changed the column labels to redue confusion. This seems to be a long-standing “bug” in this program, and exists in all output format options.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfile\nn_contigs\ncontig_bp\ngap_pct\nctg_L50\nctg_N50\nctg_L90\nctg_N90\nctg_max\ngc_avg\ngc_std\n\n\n\n\n201002558-2729-Q7_summarized-reads-Aquifex_sp..fasta\n280\n444988\n0\n70\n2050\n196\n846\n8255\n0.40435\n0.03572\n\n\n201002558-2729-Q7_summarized-reads-Arthropoda.fasta\n1850\n3398935\n0\n432\n2495\n1294\n957\n19092\n0.42579\n0.06937\n\n\n201002558-2729-Q7_summarized-reads-Enterospora_canceri.fasta\n1554\n2409480\n0\n349\n2216\n1074\n771\n8849\n0.40246\n0.04166\n\n\n201002558-2729-Q7_summarized-reads-Sar.fasta\n6\n14692\n0\n3\n2729\n5\n1559\n3969\n0.49442\n0.04577\n\n\n6129-403-26-Q7_summarized-reads-Alveolata.fasta\n461\n1753568\n0\n95\n5681\n293\n1997\n19921\n0.45848\n0.06894\n\n\n6129-403-26-Q7_summarized-reads-Aquifex_sp..fasta\n4187\n20911232\n0\n877\n7839\n2615\n2662\n32879\n0.41532\n0.03779\n\n\n6129-403-26-Q7_summarized-reads-Arthropoda.fasta\n29649\n160465929\n0\n6130\n8336\n18669\n2802\n51326\n0.43271\n0.05866\n\n\n6129-403-26-Q7_summarized-reads-Enterospora_canceri.fasta\n18111\n83280155\n0\n3589\n7369\n11022\n2357\n49825\n0.41499\n0.04149\n\n\n\n\nNow, I’ll try aligning these reads to the cbai_genome_v1.0 using BLAST to see if I can identify which contigs/scaffolds belong to each of these taxa."
  },
  {
    "objectID": "posts/2020/2020-01-24-RNA-Isolation-and-Quantification---C.bairdi-Hemocyte-Pellets-in-RNAlater/index.html",
    "href": "posts/2020/2020-01-24-RNA-Isolation-and-Quantification---C.bairdi-Hemocyte-Pellets-in-RNAlater/index.html",
    "title": "RNA Isolation and Quantification - C.bairdi Hemocyte Pellets in RNAlater",
    "section": "",
    "text": "Isolated RNA from the following hemolymph pellet samples:\n\n6174_233_12\n6258_261_12\n6270_269_12\n6161_302_12\n6115_307_12\n6206_319_12\n6241_323_12\n6158_324_12\n6272_338_12\n6152_344_12\n6275_372_12\n6218_373_12\n6153_404_26\n6132_406_26\n6162_407_26\n6178_410_26\n6163_424_26\n6140_429_26\n6174_433_26\n6199_445_26\n6156_446_26\n6106_450_26\n6151_454_26\n6177_456_26\n6119_461_26\n6124_464_26\n6134_465_26\n6168_466_26\n6152_467_26\n6121_472_26\n6205_475_26\n6155_476_26\n6143_479_26\n6158_483_26\n6169_486_26\n\nIsolated RNA using the Quick DNA/RNA Microprep Kit (ZymoResearch; PDF) according to the manufacturer’s protocol for liquids/cells in RNAlater.\n\nUsed 35uL from each RNAlater/hemocyte slurry.\nMixed with equal volume of H2O (35uL).\nRetained DNA on the Zymo-Spin IC-XM columns for isolation after RNA isolation.\nPerformed on-column DNase step.\nRNA was eluted in 15uL H2O\n\nRNA was quantified on the Roberts Lab Qubit 3.0 using the RNA High Sensitivity Assay (Invitrogen), using 2uL of each sample.\nRNA was stored in the -80oC freezer in Shellfish RNA Box #7 and Shellfish Box #8.\n\n\nRESULTS\nQubit restuls (Google Sheet):\n\n20200124_qubit_cbai_RNA\n\n\n\n\nSample ID\nRNA\n\n\n\n\n6258_261_12\n10.6\n\n\n6270_269_12\n31.7\n\n\n6161_302_12\n8.04\n\n\n6115_307_12\n7.89\n\n\n6206_319_12\n11.2\n\n\n6241_323_12\n22.2\n\n\n6158_324_12\n16.5\n\n\n6272_338_12\n10.6\n\n\n6152_344_12\n6.65\n\n\n6275_372_12\n10.1\n\n\n6218_373_12\n14.3\n\n\n6174_233_12\n17.8\n\n\n6153_404_26\n12.2\n\n\n6132_406_26\n12.3\n\n\n6162_407_26\n14.5\n\n\n6178_410_26\nOut of range\n\n\n6163_424_26\n21.4\n\n\n6140_429_26\n12\n\n\n6174_433_26\n17.6\n\n\n6199_445_26\n20.4\n\n\n6156_446_26\n20.7\n\n\n6106_450_26\n25.4\n\n\n6151_454_26\n11.4\n\n\n6177_456_26\n19.9\n\n\n6119_461_26\n11.2\n\n\n6124_464_26\n19.1\n\n\n6134_465_26\n9.1\n\n\n6168_466_26\n18.4\n\n\n6152_467_26\n5.45\n\n\n6121_472_26\n8.57\n\n\n6205_475_26\n13.1\n\n\n6155_476_26\n15.3\n\n\n6143_479_26\n15.3\n\n\n6158_483_26\n13.3\n\n\n6169_486_26\n5.87"
  },
  {
    "objectID": "posts/2020/2020-01-23-Transdecoder---C.bairdi-MEGAN6-Taxonomic-Specific-Reads-Assembly-from-20200122/index.html",
    "href": "posts/2020/2020-01-23-Transdecoder---C.bairdi-MEGAN6-Taxonomic-Specific-Reads-Assembly-from-20200122/index.html",
    "title": "Transdecoder - C.bairdi MEGAN6 Taxonomic-Specific Reads Assembly from 20200122",
    "section": "",
    "text": "Ran Trinity to de novo assembly on the the Hematodinium MEGAN6 taxonomic-specific RNAseq data on 201200122 and now will begin annotating the transcriptome using TransDecoder on Mox.\nSBATCH script (GitHub):\n\n20200123_cbai_transdecoder_megan.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=transdecoder_cbai\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200123_cbai_transdecoder_megan\n\n\n# Exit script if a command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# Set workind directory as current directory\nwd=\"$(pwd)\"\n\n# Capture date as YYYYMMDD\ntimestamp=$(date +%Y%m%d)\n\n# Set input file locations and species designation\ntrinity_fasta=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200122.C_bairdi.megan.Trinity.fasta\"\ntrinity_gene_map=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200122.C_bairdi.megan.Trinity.fasta.gene_trans_map\"\nspecies=\"cbai\"\n\n# Capture trinity file name\ntrinity_fasta_name=${trinity_fasta##*/}\n\n\n\n# Paths to input/output files\nblastp_out_dir=\"${wd}/blastp_out\"\ntransdecoder_out_dir=\"${wd}/${trinity_fasta_name}.transdecoder_dir\"\npfam_out_dir=\"${wd}/pfam_out\"\nblastp_out=\"${blastp_out_dir}/${timestamp}.${species}.blastp.outfmt6\"\npfam_out=\"${pfam_out_dir}/${timestamp}.${species}.pfam.domtblout\"\nlORFs_pep=\"${transdecoder_out_dir}/longest_orfs.pep\"\npfam_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/Pfam-A.hmm\"\nsp_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/uniprot_sprot.pep\"\n\n\n\n# Paths to programs\nblast_dir=\"/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin\"\nblastp=\"${blast_dir}/blastp\"\nhmmer_dir=\"/gscratch/srlab/programs/hmmer-3.2.1/src\"\nhmmscan=\"${hmmer_dir}/hmmscan\"\ntransdecoder_dir=\"/gscratch/srlab/programs/TransDecoder-v5.5.0\"\ntransdecoder_lORFs=\"${transdecoder_dir}/TransDecoder.LongOrfs\"\ntransdecoder_predict=\"${transdecoder_dir}/TransDecoder.Predict\"\n\n# Make output directories\nmkdir \"${blastp_out_dir}\"\nmkdir \"${pfam_out_dir}\"\n\n# Extract long open reading frames\n\"${transdecoder_lORFs}\" \\\n--gene_trans_map \"${trinity_gene_map}\" \\\n-t \"${trinity_fasta}\"\n\n# Run blastp on long ORFs\n\"${blastp}\" \\\n-query \"${lORFs_pep}\" \\\n-db \"${sp_db}\" \\\n-max_target_seqs 1 \\\n-outfmt 6 \\\n-evalue 1e-5 \\\n-num_threads 28 \\\n> \"${blastp_out}\"\n\n# Run pfam search\n\"${hmmscan}\" \\\n--cpu 28 \\\n--domtblout \"${pfam_out}\" \\\n\"${pfam_db}\" \\\n\"${lORFs_pep}\"\n\n# Run Transdecoder with blastp and Pfam results\n\"${transdecoder_predict}\" \\\n-t \"${trinity_fasta}\" \\\n--retain_pfam_hits \"${pfam_out}\" \\\n--retain_blastp_hits \"${blastp_out}\"\n\n\nRESULTS\nRuntime was ~5hrs:\n\n\n\nTransdecoder runtime\n\n\nOutput folder:\n\n20200123_cbai_transdecoder_megan\n\nCoding Sequences (FastA):\n\n20200123_cbai_transdecoder_megan/20200122.C_bairdi.megan.Trinity.fasta.transdecoder.cds\n\nPeptide Sequences (FastA):\n\n20200123_cbai_transdecoder_megan/20200122.C_bairdi.megan.Trinity.fasta.transdecoder.pep\n\nBLASTp output (tab):\n\n0200123_cbai_transdecoder_megan/blastp_out/20200123.cbai.blastp.outfmt6\n\nPfam output:\n\n20200123_cbai_transdecoder_megan/pfam_out/20200123.cbai.pfam.domtblout\n\nWill get ready to run Trinotate with these output files."
  },
  {
    "objectID": "posts/2020/2020-11-03-MBD-Selection---M.magister-Sheared-Gill-gDNA-16-of-24-Samples-Set-3-of-3/index.html",
    "href": "posts/2020/2020-11-03-MBD-Selection---M.magister-Sheared-Gill-gDNA-16-of-24-Samples-Set-3-of-3/index.html",
    "title": "MBD Selection - M.magister Sheared Gill gDNA 16 of 24 Samples Set 3 of 3",
    "section": "",
    "text": "Click here for notebook on the first eight samples processed. Click here for the second set of eight samples processed. M.magister (Dungeness crab) gill gDNA provided by Mackenzie Gavery was previously sheared on 20201026 and three samples were subjected to additional rounds of shearing on 20201027, in preparation for methyl bidning domain (MBD) selection using the MethylMiner Kit (Invitrogen).\nFollowed the manufacturer’s protocol for using <= 1ug of DNA (I’m using 1ug) with the following notes/changes:\n\nPrepared beads for all 8 samples in single prep. Combined the amount of beads/protein needed for 8, 1ug reactions. Protein calculations and wash volumes were based off of 8ug of input DNA. Prepared beads were resuspended in 80uL (instead of 100uL) and 10uL were distributed to each of 8 tubes. Volume was then brought up to 100uL with 1x binding/wash buffer.\nDNA capture incubation was performed overnight (~20hrs).\nNon-captured DNA and wash volumes were combined in a single tube for each sample. These were stored at 4oC, but were not precipitated.\nEthanol precipitations were incubated at -80oC overnight (~20hrs).\nPrecipitated DNA was resuspended in 21uL of H2O (this allows the usage of 1uL for Qubit and leave 20uL as the maximum input volume for the subsequent PicoMethylSeq Kit (ZymoResearch)).\n\nSamples were quantified using the Roberts Lab Qubit 3.0 with the Qubit 1x dsDNA HS Assay (Invitrogen), using 1uL of sample.\nAll samples were stored temporarily at 4oC.\nFor reference, all sample info for this project is here (Google Sheet):\n\nOA Crab Sample Collection 071119\n\n\n\nRESULTS\nQubit results (Google Sheet):\n\n20201105_qubit_DNA_mmag_MBD\n\n\n\n\n\n\n\n\n\n\nSample ID\nResuspension_vol(uL)\nTotal_recovery(ng)\nPercent_recovery(%)\n\n\n\n\nCH09-11\n21\n3.07\n0.31\n\n\nCH09-13\n21\n0.00\n0.00\n\n\nCH09-28\n21\n4.62\n0.46\n\n\nCH09-29\n21\n11.09\n1.11\n\n\nCH10-01\n21\n7.27\n0.73\n\n\nCH10-08\n21\n38.64\n3.86\n\n\nCH10-11\n21\n6.43\n0.64\n\n\nCH10-19\n21\n3.57\n0.36\n\n\n\nMost of the samples had similar recoveries to the first set and second set of samples.\nHowever, notable there are a few notable exceptions:\n\nCH09-13: No DNA recovered. I asked Mac about how to proceed and she has indicated to proceed to lbirary construction without this sample.\nCH09-29 and CH10-08: Significantly more recovery than all other samples. It’s difficult to say why this happened. The Bioanlyzer electropherograms for these samples don’t stand out as markedly different than the others."
  },
  {
    "objectID": "posts/2020/2020-11-30-Trimming---Ronits-C.gigas-Ploidy-WGBS-Using-fastp-and-MultiQC-on-Mox/index.html",
    "href": "posts/2020/2020-11-30-Trimming---Ronits-C.gigas-Ploidy-WGBS-Using-fastp-and-MultiQC-on-Mox/index.html",
    "title": "Trimming - Ronits C.gigas Ploidy WGBS Using fastp and MultiQC on Mox",
    "section": "",
    "text": "Steven asked me to trim (GitHub Issue) Ronit’s WGBS sequencing data we received on 20201110, according to Bismark guidelines for libraries made with the ZymoResearch Pico MethylSeq Kit.\nI trimmed the files using fastp.\nThe trimming trims adapters and 10bp from the 5’ ends of each read.\nJob was run on Mox.\nSBATCH script (GitHub):\n\n20201130_cgig_fastp_ronit-ploidy-wgbs.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=20201130_cgig_fastp_ronit-ploidy-wgbs\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20201130_cgig_fastp_ronit-ploidy-wgbs\n\n\n### Fastp trimming of Ronit's ploidy WGBS.\n\n### Trimming is performed according to recommendation for use with Bismark\n### for libraries created using ZymoResearch Pico MethylSeq Kit:\n### https://github.com/FelixKrueger/Bismark/blob/master/Docs/README.md#ix-notes-about-different-library-types-and-commercial-kits\n\n### Expects input filenames to be in format: zr3534_3_R1.fq.gz\n\n\n###################################################################################\n# These variables need to be set by user\n\n## Assign Variables\n\n# Set number of CPUs to use\nthreads=27\n\n# Input/output files\ntrimmed_checksums=trimmed_fastq_checksums.md5\nraw_reads_dir=/gscratch/srlab/sam/data/C_gigas/wgbs/\nfastq_checksums=raw_fastq_checksums.md5\n\n# Paths to programs\nfastp=/gscratch/srlab/programs/fastp-0.20.0/fastp\nmultiqc=/gscratch/srlab/programs/anaconda3/bin/multiqc\n\n## Inititalize arrays\nfastq_array_R1=()\nfastq_array_R2=()\nR1_names_array=()\nR2_names_array=()\n\n\n# Programs associative array\ndeclare -A programs_array\nprograms_array=(\n[fastp]=\"${fastp}\" \\\n[multiqc]=\"${multiqc}\"\n)\n\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Capture date\ntimestamp=$(date +%Y%m%d)\n\n# Sync raw FastQ files to working directory\nrsync --archive --verbose \\\n\"${raw_reads_dir}\"zr3534*.fq.gz .\n\n# Create arrays of fastq R1 files and sample names\nfor fastq in *R1.fq.gz\ndo\n  fastq_array_R1+=(\"${fastq}\")\n    R1_names_array+=(\"$(echo \"${fastq}\" | awk 'BEGIN {FS = \"[_.]\"; OFS = \"_\"} {print $1, $2, $3}')\")\ndone\n\n# Create array of fastq R2 files\nfor fastq in *R2.fq.gz\ndo\n  fastq_array_R2+=(\"${fastq}\")\n    R2_names_array+=(\"$(echo \"${fastq}\" | awk 'BEGIN {FS = \"[_.]\"; OFS = \"_\"} {print $1, $2, $3}')\")\ndone\n\n\n# Run fastp on files\n# Trim 10bp from 5' from each read\n# Adds JSON report output for downstream usage by MultiQC\nfor index in \"${!fastq_array_R1[@]}\"\ndo\n  R1_sample_name=$(echo \"${R1_names_array[index]}\")\n    R2_sample_name=$(echo \"${R2_names_array[index]}\")\n    ${fastp} \\\n    --in1 ${fastq_array_R1[index]} \\\n    --in2 ${fastq_array_R2[index]} \\\n    --detect_adapter_for_pe \\\n  --detect_adapter_for_pe \\\n  --trim_front1 10 \\\n  --trim_front2 10 \\\n    --thread ${threads} \\\n    --html \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".report.html \\\n    --json \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".report.json \\\n    --out1 \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz \\\n    --out2 \"${R2_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz\n\n    # Generate md5 checksums for newly trimmed files\n    {\n        md5sum \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz\n        md5sum \"${R2_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz\n    } >> \"${trimmed_checksums}\"\n\n  # Create list of fastq files used in analysis\n  # Create MD5 checksum for reference\n  echo \"${fastq_array_R1[index]}\" >> input.fastq.list.txt\n  echo \"${fastq_array_R2[index]}\" >> input.fastq.list.txt\n  md5sum \"${fastq_array_R1[index]}\" >> ${fastq_checksums}\n  md5sum \"${fastq_array_R2[index]}\" >> ${fastq_checksums}\n\n    # Remove original FastQ files\n    rm \"${fastq_array_R1[index]}\" \"${fastq_array_R2[index]}\"\ndone\n\n# Run MultiQC\n${multiqc} .\n\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n  # Handle samtools help menus\n  if [[ \"${program}\" == \"samtools_index\" ]] \\\n  || [[ \"${program}\" == \"samtools_sort\" ]] \\\n  || [[ \"${program}\" == \"samtools_view\" ]]\n  then\n    ${programs_array[$program]}\n  fi\n    ${programs_array[$program]} -h\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\n\n  # If MultiQC is in programs_array, copy the config file to this directory.\n  if [[ \"${program}\" == \"multiqc\" ]]; then\n    cp --preserve ~/.multiqc_config.yaml multiqc_config.yaml\n  fi\ndone\n\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nRESULTS\nA little under 2.5hrs to run:\n\n\n\nfastp runtime\n\n\nNOTE: The report files (MultiQC and fastp) all suffer from a naming error, but do contain data for both read 1 (R1) and read 2 (R2).\nOutput folder:\n\n20201130_cgig_fastp_ronit-ploidy-wgbs/\n\nMultiQC report (HTML; open with web browser):\n\n20201130_cgig_fastp_ronit-ploidy-wgbs/multiqc_report.html\n\n[fastp] Reports (HTML; open in web browser):\n\nzr3534_10_R1.fastp-trim.20201130.report.html\nzr3534_1_R1.fastp-trim.20201130.report.html\nzr3534_2_R1.fastp-trim.20201130.report.html\nzr3534_3_R1.fastp-trim.20201130.report.html\nzr3534_4_R1.fastp-trim.20201130.report.html\nzr3534_5_R1.fastp-trim.20201130.report.html\nzr3534_6_R1.fastp-trim.20201130.report.html\nzr3534_7_R1.fastp-trim.20201130.report.html\nzr3534_8_R1.fastp-trim.20201130.report.html\nzr3534_9_R1.fastp-trim.20201130.report.html\n\nTrimmed FastQ files (gzipped):\n\nzr3534_10_R1.fastp-trim.20201130.fq.gz (4.2G)\n\nMD5: 7324282409549a013c4b7b2a5a6a14a6\n\nzr3534_10_R2.fastp-trim.20201130.fq.gz (4.3G)\n\nMD5: 9fb1357e0af5e071c0dfe545499cccb7\n\nzr3534_1_R1.fastp-trim.20201130.fq.gz (4.2G)\n\nMD5: 33a32d98e98189f4acf068c7a76b86e0\n\nzr3534_1_R2.fastp-trim.20201130.fq.gz (4.2G)\n\nMD5: e979a919090cf463694ddbca7d016f5e\n\nzr3534_2_R1.fastp-trim.20201130.fq.gz (4.1G)\n\nMD5: 111d3d7c516c15a7d6915761bffd0260\n\nzr3534_2_R2.fastp-trim.20201130.fq.gz (4.2G)\n\nMD5: a2de2f420e8d580dcd419386adc2fca9\n\nzr3534_3_R1.fastp-trim.20201130.fq.gz (4.3G)\n\nMD5: 99cbaa5703cb44e2fb71c0793482ca39\n\nzr3534_3_R2.fastp-trim.20201130.fq.gz (4.4G)\n\nMD5: 91070b1e5f083430a9101e4874b6f72b\n\nzr3534_4_R1.fastp-trim.20201130.fq.gz (4.2G)\n\nMD5: c5ff85f06b374f8488f85af877e8ab33\n\nzr3534_4_R2.fastp-trim.20201130.fq.gz (4.1G)\n\nMD5: 1eb69d729f3511ab28a0bacc223623dd\n\nzr3534_5_R1.fastp-trim.20201130.fq.gz (4.5G)\n\nMD5: abfa3ceeddab59d82c9ed5734a6e83a5\n\nzr3534_5_R2.fastp-trim.20201130.fq.gz (4.7G)\n\nMD5: 846a177f02f08713186537ebd8101126\n\nzr3534_6_R1.fastp-trim.20201130.fq.gz (4.1G)\n\nMD5: 1cc04bf49ac933c18936ebfa8b1e30d5\n\nzr3534_6_R2.fastp-trim.20201130.fq.gz (4.2G)\n\nMD5: 1d287dfcdf57d28db4b1307aded2b592\n\nzr3534_7_R1.fastp-trim.20201130.fq.gz (3.7G)\n\nMD5: fd3ed000d01b71e3e85277f27e9a8df4\n\nzr3534_7_R2.fastp-trim.20201130.fq.gz (3.7G)\n\nMD5: f9aa2a37729b00c3789e29a742030cdb\n\nzr3534_8_R1.fastp-trim.20201130.fq.gz (5.3G)\n\nMD5: a75b297f5d0348c543e18e2b0e5bc460\n\nzr3534_8_R2.fastp-trim.20201130.fq.gz (4.9G)\n\nMD5: b4f5ec54b07285f11a7010bd1ec1e5f1\n\nzr3534_9_R1.fastp-trim.20201130.fq.gz (4.0G)\n\nMD5: 2e05bbd9c4b2b1b5e4f6f07c8a210bd6\n\nzr3534_9_R2.fastp-trim.20201130.fq.gz (4.1G)\n\nMD5: 4a9a112c87f49f32ae1b8e10841e0a50"
  },
  {
    "objectID": "posts/2020/2020-02-07-Gene-Expression---C.bairdi-MEGAN6-with-Trinity-and-EdgeR/index.html",
    "href": "posts/2020/2020-02-07-Gene-Expression---C.bairdi-MEGAN6-with-Trinity-and-EdgeR/index.html",
    "title": "Gene Expression - C.bairdi MEGAN6 with Trinity and EdgeR",
    "section": "",
    "text": "After completing annotation of the C.bairdi MEGAN6 taxonomic-specific Trinity assembly using Trinotate on 20200126, I performed differential gene expression analysis and gene ontology (GO) term enrichment analysis using Trinity’s scripts to run EdgeR and GOseq, respectively, across all of the various treatment comparisons. The comparison are listed below and link to each individual SBATCH script (GitHub) used to run these on Mox.\n\nD12_infected-vs-D12_uninfected\nD12_infected-vs-D26_infected\nD12_uninfected-vs-D26_uninfected\nD12-vs-D26\nD26_infected-vs-D26_uninfected\ninfected-vs-uninfected\n\nIt should be noted that most of these comparisons do not have any replicate samples (e.g. D12 infected vs D12 uninfected). I made a weak attempt to coerce some results from these by setting a dispersion value in the edgeR command. However, I’m not expecting much, nor am I certain I would really trust the results from those particular comparisons.\n\n\nRESULTS\nOutput folder:\n\n20200207_cbai_DEG/\n\nComparisons:\n\nD12_infected-vs-D12_uninfected\nTook a little less than 20mins to run:\n\n\n\nMox runtime for D12 infected vs D12 uninfeced\n\n\n\nD12_infected-vs-D12_uninfected/\n\nOnly a single DEG, which is upregulated in the infected set:\n\n\n\nMA/volcano plot of D12 infected vs D12 uninfeced\n\n\n\nsalmon.gene.counts.matrix.infected_vs_uninfected.edgeR.DE_results.P0.05_C1.DE.subset\n\nTRINITY_DN10191_c0_g1 - SPID: Q36421 (Cyctochrome c oxidase I)\n\nD12_infected-vs-D26_infected\nTook ~18mins to run:\n\n\n\nD12 infected vs D26 infected runtime\n\n\n\nD12_infected-vs-D26_infected/\n\nNo differentially expressed genes between these two groups.\nNOTE: Since no DEGs, that’s why this run shows as FAILED in the above runtime screencap. This log file captures the error message that kills the job and generates the FAILED indicator:\n\n20200207_cbai_DEG/D12_infected-vs-D26_infected/edgeR.21680.dir/diff_expr_stderr.txt\n\nError, no differentially expressed transcripts identified at cuttoffs: P:0.05, C:1 at /gscratch/srlab/programs/trinityrnaseq-v2.9.0/Analysis/DifferentialExpression/analyze_diff_expr.pl line 203.\n\nD12_uninfected-vs-D26_uninfected\nTook ~18mins to run:\n\n\n\nD12 uninfected vs D26 uninfected runtime\n\n\n\nD12_uninfected-vs-D26_uninfected/\n\nNo differentially expressed genes between these two groups.\nNOTE: Since no DEGs, that’s why this run shows as FAILED in the above runtime screencap. This log file captures the error message that kills the job and generates the FAILED indicator:\n\n20200207_cbai_DEG/D12_uninfected-vs-D26_uninfected/edgeR.27147.dir/diff_expr_stderr.txt\n\nError, no differentially expressed transcripts identified at cuttoffs: P:0.05, C:1 at /gscratch/srlab/programs/trinityrnaseq-v2.9.0/Analysis/DifferentialExpression/analyze_diff_expr.pl line 203.\n\nD12-vs-D26\nTook ~40mins to run:\n\n\n\nD12 vs D26 runtime\n\n\n\nD12-vs-D26/\n\n\n\n\nD12 vs D26 expression heatmap\n\n\nD12 upregulated genes:\n\n20200207_cbai_DEG/D12-vs-D26/edgeR.21229.dir/salmon.gene.counts.matrix.D12_vs_D26.edgeR.DE_results.P0.05_C1.D12-UP.subset\nFive genes:\n\nTRINITY_DN4239_c0_g1 - No annotation\nTRINITY_DN4669_c0_g2 - No annotation\nTRINITY_DN5346_c0_g2 - No annotation\nTRINITY_DN12453_c0_g1 - SP ID: Q6ING4(DEP domain-containing protein 1A)\nTRINITY_DN8311_c0_g1 - No annotation\n\n\nD12 GO enrichment identified zero enriched and five depleted:\n\n20200207_cbai_DEG/D12-vs-D26/edgeR.21229.dir/salmon.gene.counts.matrix.D12_vs_D26.edgeR.DE_results.P0.05_C1.D12-UP.subset.GOseq.enriched\n20200207_cbai_DEG/D12-vs-D26/edgeR.21229.dir/salmon.gene.counts.matrix.D12_vs_D26.edgeR.DE_results.P0.05_C1.D12-UP.subset.GOseq.depleted\n\nOnly one of these five is in the “biological process” category and it is uncharacterized (i.e. is identified as “biological process”).\n\n\nD26 upregulated genes:\n\n20200207_cbai_DEG/D12-vs-D26/edgeR.21229.dir/salmon.gene.counts.matrix.D12_vs_D26.edgeR.DE_results.P0.05_C1.D26-UP.subset\n11 genes:\n\nTRINITY_DN4610_c0_g1 - SP ID: Q9MFN9(Cytochrome b)\nTRINITY_DN10370_c0_g1 - SP ID: P20241(Neuroglian)\nTRINITY_DN2559_c1_g1 - No annotation.\nTRINITY_DN5386_c0_g1 - No annotation.\nTRINITY_DN400_c2_g1 - SP ID: Q8N587(Zinc finger protein 561)\nTRINITY_DN2969_c0_g2 - No annotation.\nTRINITY_DN4328_c0_g1 - No annotation.\nTRINITY_DN8_c11_g1 - No annotation.\nTRINITY_DN1107_c1_g1 - No annotation.\nTRINITY_DN2373_c0_g1 - SP ID: Q4AEI0(Glutathione peroxidase 2)\nTRINITY_DN2730_c0_g1 - No annotation.\n\n\nD26 GO enrichment identified four up-regulated enriched GO terms (all in the “molecular function” category) and five up-regulated depleted GO terms (all in the “biological process” category).\n\n20200207_cbai_DEG/D12-vs-D26/edgeR.21229.dir/salmon.gene.counts.matrix.D12_vs_D26.edgeR.DE_results.P0.05_C1.D26-UP.subset.GOseq.enriched\n20200207_cbai_DEG/D12-vs-D26/edgeR.21229.dir/salmon.gene.counts.matrix.D12_vs_D26.edgeR.DE_results.P0.05_C1.D26-UP.subset.GOseq.depleted\n\n\nD26_infected-vs-D26_uninfected\n\nD26_infected-vs-D26_uninfected/\n\nNo differentially expressed genes between these two groups.\nNOTE: Since no DEGs, that’s why this run shows as FAILED in the above runtime screencap. This log file captures the error message that kills the job and generates the FAILED indicator:\n20200207_cbai_DEG/D26_infected-vs-D26_uninfected/edgeR.20733.dir/diff_expr_stderr.txt\nError, no differentially expressed transcripts identified at cuttoffs: P:0.05, C:1 at /gscratch/srlab/programs/trinityrnaseq-v2.9.0/Analysis/DifferentialExpression/analyze_diff_expr.pl line 203.\n\ninfected-vs-uninfected\nTook ~40mins to run:\n\n\n\ninfected vs uninfected runtim\n\n\nOutput folder:\n\ninfected-vs-uninfected/\n\n\n\n\ninfected vs uninfected expression heatmap\n\n\nInfected upregulated DEGs:\n\n20200207_cbai_DEG/infected-vs-uninfected/edgeR.2317.dir/salmon.gene.counts.matrix.infected_vs_uninfected.edgeR.DE_results.P0.05_C1.infected-UP.subset\n\n345 genes\n\n\nInfected GO enrichment identified 374 enriched GO terms:\n\n20200207_cbai_DEG/infected-vs-uninfected/edgeR.2317.dir/salmon.gene.counts.matrix.infected_vs_uninfected.edgeR.DE_results.P0.05_C1.infected-UP.subset.GOseq.enriched\n\nUninfected upregulated genes:\n\n20200207_cbai_DEG/infected-vs-uninfected/edgeR.2317.dir/salmon.gene.counts.matrix.infected_vs_uninfected.edgeR.DE_results.P0.05_C1.uninfected-UP.subset\n\n20 genes\n\n\nUninfected GO enrichment identified zero enriched GO terms."
  },
  {
    "objectID": "posts/2020/2020-01-26-Transcriptome-Annotation---Trinotate-C.bairdi-MEGAN6-Taxonomic-specific-Trinity-Assembly-on-Mox/index.html",
    "href": "posts/2020/2020-01-26-Transcriptome-Annotation---Trinotate-C.bairdi-MEGAN6-Taxonomic-specific-Trinity-Assembly-on-Mox/index.html",
    "title": "Transcriptome Annotation - Trinotate C.bairdi MEGAN6 Taxonomic-specific Trinity Assembly on Mox",
    "section": "",
    "text": "After performing de novo assembly on our Tanner crab MEGAN6 taxonomic-specific RNAseq data on 20200122 and performing BLASTx annotation on 20200123, I continued the annotation process by running Trinotate.\nTrinotate will perform functional annotation of the transcriptome assembly, including GO terms and an annotation feature map that can be used in subsequent Trinity-based differential gene expression analysis so that functional annotations are carried downstream through that process.\nSBATCH script (GitHub):\n\n20200126_cbai_trinotate_megan.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=trinotate_cbi\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=05-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200126_cbai_trinotate_megan\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nwd=\"$(pwd)\"\ntimestamp=$(date +%Y%m%d)\nspecies=\"cbai\"\n\nprefix=\"${timestamp}.${species}.trinotate\"\n\n\n## Paths to input/output files\n\n## New folders for working directory\nrnammer_out_dir=\"${wd}/RNAmmer_out\"\nsignalp_out_dir=\"${wd}/signalp_out\"\ntmhmm_out_dir=\"${wd}/tmhmm_out\"\n\n# Input files\nblastp_out=\"/gscratch/scrubbed/samwhite/outputs/20200123_cbai_transdecoder_megan/blastp_out/20200123.cbai.blastp.outfmt6\"\nblastx_out=\"/gscratch/scrubbed/samwhite/outputs/20200123_cbai_diamond_blastx_megan/20200122.C_bairdi.megan.Trinity.blastx.outfmt6\"\npfam_out=\"/gscratch/scrubbed/samwhite/outputs/20200123_cbai_transdecoder_megan/pfam_out/20200123.cbai.pfam.domtblout\"\nlORFs_pep=\"/gscratch/scrubbed/samwhite/outputs/20200123_cbai_transdecoder_megan/20200122.C_bairdi.megan.Trinity.fasta.transdecoder_dir/longest_orfs.pep\"\ntrinity_fasta=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200122.C_bairdi.megan.Trinity.fasta\"\ntrinity_gene_map=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200122.C_bairdi.megan.Trinity.fasta.gene_trans_map\"\n\nrnammer_prefix=${trinity_fasta##*/}\n\n# Output files\nrnammer_out=\"${rnammer_out_dir}/${rnammer_prefix}.rnammer.gff\"\nsignalp_out=\"${signalp_out_dir}/${prefix}.signalp.out\"\ntmhmm_out=\"${tmhmm_out_dir}/${prefix}.tmhmm.out\"\ntrinotate_report=\"${wd}/${prefix}_annotation_report.txt\"\n\n# Paths to programs\nrnammer_dir=\"/gscratch/srlab/programs/RNAMMER-1.2\"\nrnammer=\"${rnammer_dir}/rnammer\"\nsignalp_dir=\"/gscratch/srlab/programs/signalp-4.1\"\nsignalp=\"${signalp_dir}/signalp\"\ntmhmm_dir=\"/gscratch/srlab/programs/tmhmm-2.0c/bin\"\ntmhmm=\"${tmhmm_dir}/tmhmm\"\ntrinotate_dir=\"/gscratch/srlab/programs/Trinotate-v3.1.1\"\ntrinotate=\"${trinotate_dir}/Trinotate\"\ntrinotate_rnammer=\"${trinotate_dir}/util/rnammer_support/RnammerTranscriptome.pl\"\ntrinotate_GO=\"${trinotate_dir}/util/extract_GO_assignments_from_Trinotate_xls.pl\"\ntrinotate_features=\"${trinotate_dir}/util/Trinotate_get_feature_name_encoding_attributes.pl\"\ntrinotate_sqlite_db=\"Trinotate.sqlite\"\n\n# Make output directories\nmkdir \"${rnammer_out_dir}\" \"${signalp_out_dir}\" \"${tmhmm_out_dir}\"\n\n# Copy sqlite database template\n\ncp ${trinotate_dir}/admin/Trinotate.sqlite .\n\n# Run signalp\n${signalp} \\\n-f short \\\n-n \"${signalp_out}\" \\\n${lORFs_pep}\n\n# Run tmHMM\n${tmhmm} \\\n--short \\\n< ${lORFs_pep} \\\n> \"${tmhmm_out}\"\n\n# Run RNAmmer\ncd \"${rnammer_out_dir}\" || exit\n${trinotate_rnammer} \\\n--transcriptome ${trinity_fasta} \\\n--path_to_rnammer ${rnammer}\ncd \"${wd}\" || exit\n\n# Run Trinotate\n## Load transcripts and coding regions into database\n${trinotate} \\\n${trinotate_sqlite_db} \\\ninit \\\n--gene_trans_map \"${trinity_gene_map}\" \\\n--transcript_fasta \"${trinity_fasta}\" \\\n--transdecoder_pep \"${lORFs_pep}\"\n\n## Load BLAST homologies\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_swissprot_blastp \\\n\"${blastp_out}\"\n\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_swissprot_blastx \\\n\"${blastx_out}\"\n\n## Load Pfam\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_pfam \\\n\"${pfam_out}\"\n\n## Load transmembrane domains\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_tmhmm \\\n\"${tmhmm_out}\"\n\n## Load signal peptides\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_signalp \\\n\"${signalp_out}\"\n\n## Load RNAmmer\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_rnammer \\\n\"${rnammer_out}\"\n\n## Creat annotation report\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nreport \\\n> \"${trinotate_report}\"\n\n# Extract GO terms from annotation report\n\"${trinotate_GO}\" \\\n--Trinotate_xls \"${trinotate_report}\" \\\n-G \\\n--include_ancestral_terms \\\n> \"${prefix}\".go_annotations.txt\n\n# Make transcript features annotation map\n\"${trinotate_features}\" \\\n\"${trinotate_report}\" \\\n> \"${prefix}\".annotation_feature_map.txt\n\n\nRESULTS\nRun time was ~30mins:\n\n\n\nCbai Trinotate runtime\n\n\nOutput folder:\n\n20200126_cbai_trinotate_megan/\n\nAnnotation feature map. This can be used to update Trinity-based gene expression matrices like so:\n\n${TRINITY_HOME}/Analysis/DifferentialExpression/rename_matrix_feature_identifiers.pl\n20200126.cbai.trinotate.annotation_feature_map.txt\n\nAnnotation report (CSV)\n\n20200126.cbai.trinotate_annotation_report.txt\n\nGene ontology (GO) annotations (TXT)\n\n20200126.cbai.trinotate.go_annotations.txt\n\nSQlite database:\n\nTrinotate.sqlite"
  },
  {
    "objectID": "posts/2020/2020-01-26-RNA-Isolation-and-Quantification---C.bairdi-Hemocyte-Pellets-in-RNAlater/index.html",
    "href": "posts/2020/2020-01-26-RNA-Isolation-and-Quantification---C.bairdi-Hemocyte-Pellets-in-RNAlater/index.html",
    "title": "RNA Isolation and Quantification - C.bairdi Hemocyte Pellets in RNAlater",
    "section": "",
    "text": "Isolated RNA from the following hemolymph pellet samples:\n\n6202_337_12\n6142_474_26\n6144_477_26\n6122_489_26\n6176_490_26\n6136_491_26\n6137_500_26\n6125_503_26\n6145_505_26\n6131_507_26\n6159_508_26\n6206_509_26\n6150_511_26\n6161_512_26\n6115_514_26\n6179_515_26\n6172_517_26\n\nIsolated RNA using the Quick DNA/RNA Microprep Kit (ZymoResearch; PDF) according to the manufacturer’s protocol for liquids/cells in RNAlater.\n\nUsed 35uL from each RNAlater/hemocyte slurry.\nMixed with equal volume of H2O (35uL).\nRetained DNA on the Zymo-Spin IC-XM columns for isolation after RNA isolation.\nPerformed on-column DNase step.\nRNA was eluted in 15uL H2O\n\nRNA was quantified on the Roberts Lab Qubit 3.0 using the RNA High Sensitivity Assay (Invitrogen), using 2uL of each sample.\nRNA was stored in the -80oC freezer in Shellfish Box #8.\n\n\nRESULTS\nQubit restuls (Google Sheet):\n\n20200126_qubit_cbai_RNA\n\n\n\n\nSample ID\nRNA\n\n\n\n\n6202_337_12\n23.7\n\n\n6142_474_26\n14.4\n\n\n6144_477_26\n20.3\n\n\n6122_489_26\n8.32\n\n\n6176_490_26\n10.7\n\n\n6136_491_26\n7.37\n\n\n6137_500_26\n13.8\n\n\n6125_503_26\n7.12\n\n\n6145_505_26\n4.7\n\n\n6131_507_26\n8.9\n\n\n6159_508_26\n7.74\n\n\n6206_509_26\n9.75\n\n\n6150_511_26\n4.12\n\n\n6161_512_26\n10.9\n\n\n6115_514_26\n5.96\n\n\n6179_515_26\n7.23\n\n\n6172_517_26\nOut of range"
  },
  {
    "objectID": "posts/2020/2020-11-10-Data-Received---C.gigas-Ploidy-WGBS-from-Ronits-Project-via-ZymoResearch/index.html",
    "href": "posts/2020/2020-11-10-Data-Received---C.gigas-Ploidy-WGBS-from-Ronits-Project-via-ZymoResearch/index.html",
    "title": "Data Received - C.gigas Ploidy WGBS from Ronits Project via ZymoResearch",
    "section": "",
    "text": "We received the data from our whole genome bisulfite sequencing (WGBS) submission to ZymoResearch on 2020820 for Ronit’s C.gigas diploid/triploid dessication/heat stress project.\nSamples were sequenced using 150bp paired-end, on the Illumina NovaSeq.\nFiles have been added to the C.gigas folder in nightingales on Owl (Synology server).\nI’ve updated the nightingales Google Sheet database as well.\nNext up:\n\nRun FatQC\nSubmit to NCBI sequence read archive (SRA).\n\n\n\n\n\n\n\n\n\n\n\n\nSeqID\nLibrary_Name\nTissue\nPloidy\nDessication\nHeat_Stress\n\n\n\n\nzr3534_1\nD11-C\nctenidia\ndiploid\nyes\nno\n\n\nzr3534_2\nD12-C\nctenidia\ndiploid\nyes\nno\n\n\nzr3534_3\nD13-C\nctenidia\ndiploid\nyes\nno\n\n\nzr3534_4\nD19-C\nctenidia\ndiploid\nyes\nyes\n\n\nzr3534_5\nD20-C\nctenidia\ndiploid\nyes\nyes\n\n\nzr3534_6\nT11-C\nctenidia\ntriploid\nyes\nno\n\n\nzr3534_7\nT12-C\nctenidia\ntriploid\nyes\nno\n\n\nzr3534_8\nT13-C\nctenidia\ntriploid\nyes\nno\n\n\nzr3534_9\nT19-C\nctenidia\ntriploid\nyes\nyes\n\n\nzr3534_10\nT20-C\nctenidia\ntriploid\nyes\nyes"
  },
  {
    "objectID": "posts/2020/2020-09-28-Taxonomic-Assignments---C.bairdi-20102558-2729-Q7-NanoPore-Reads-Using-DIAMOND-BLASTx-on-Mox-and-MEGAN6-daa2rma-on-emu/index.html",
    "href": "posts/2020/2020-09-28-Taxonomic-Assignments---C.bairdi-20102558-2729-Q7-NanoPore-Reads-Using-DIAMOND-BLASTx-on-Mox-and-MEGAN6-daa2rma-on-emu/index.html",
    "title": "Taxonomic Assignments - C.bairdi 20102558-2729-Q7 NanoPore Reads Using DIAMOND BLASTx on Mox and MEGAN6 daa2rma on emu",
    "section": "",
    "text": "After noticing that the initial MEGAN6 taxonomic assignments for our combined C.bairdi NanoPore data from 20200917 revealed a high number of bases assigned to E.canceri and Aquifex sp., I decided to explore the taxonomic breakdown of just the individual samples to see which of the samples was contributing to these taxonomic assignments most.\nRan the muscle (no Hematodinium infection; (20102558-2729-Q7) NanoPore sequencing data through DIAMOND BLASTx (on Mox) and subsequent output conversion to the MEGAN6 RMA6 format (on swoose due to program Java X11 requirement which is not functional on Mox) to obtain taxonomic assignments.\nSBATCH script (GitHub):\n\n20200928_cbai_diamond_blastx_nanopore_20102558-2729_Q7.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_blastx_DIAMOND_nanopore_20102558-2729_Q7\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=200G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200928_cbai_diamond_blastx_nanopore_20102558-2729_Q7\n\n# Script to run DIAMOND BLASTx on 20102558-2729 quality filtered (Q7) C.bairdi NanoPore reads\n# from 20200928 using the --long-reads option\n# for subsequent import into MEGAN6 to evaluate reads taxonomically.\n\n###################################################################################\n# These variables need to be set by user\n\n# Input FastQ file\nfastq=/gscratch/srlab/sam/data/C_bairdi/DNAseq/20200928_cbai_nanopore_20102558-2729_quality-7.fastq\n\n# DIAMOND Output filename prefix\nprefix=20200928_cbai_nanopore_20102558-2729_Q7\n\n# Set number of CPUs to use\nthreads=28\n\n# Program paths\ndiamond=/gscratch/srlab/programs/diamond-2.0.4/diamond\n\n# DIAMOND NCBI nr database with taxonomy dumps\ndmnd_db=/gscratch/srlab/blastdbs/ncbi-nr-20190925/nr.dmnd\n\n\n###################################################################################\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n\n# Inititalize arrays\nprograms_array=()\n\n\n# Programs array\nprograms_array=(\"${diamond}\")\n\n\nmd5sum \"${fastq}\" > fastq_checksums.md5\n\n\n# Run DIAMOND with blastx\n# Output format 6 produces a standard BLAST tab-delimited file\n# Run DIAMOND with blastx\n# Output format 100 produces a DAA binary file for use with MEGAN\n${diamond} blastx \\\n--long-reads \\\n--db ${dmnd_db} \\\n--query \"${fastq}\" \\\n--out \"${prefix}\".blastx.daa \\\n--outfmt 100 \\\n--top 5 \\\n--block-size 8.0 \\\n--index-chunks 1 \\\n--threads ${threads}\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${programs_array[program]}: \"\n    echo \"\"\n    ${programs_array[program]} help\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\nBash script (GitHub) for daa2rma on Emu:\n\n20200928_cbai_nanopore_20102558-2729-Q7_diamond_blastx_daa2rma.sh\n\n#!/bin/bash\n\n# Script to run MEGAN6 daa2rma on DIAMOND DAA files from\n# 20200928_cbai_diamond_blastx_nanopore_20102558-2729_Q7.\n# Utilizes the --longReads option\n\n# Requires MEGAN mapping file from:\n# http://ab.inf.uni-tuebingen.de/data/software/megan6/download/\n\n\n# MEGAN mapping file\nmegan_map=/home/sam/data/databases/MEGAN6/megan-map-Jul2020-2.db\n\n# Programs array\ndeclare -A programs_array\nprograms_array=(\n[daa2rma]=\"/home/shared/megan_6.19.9/tools/daa2rma\"\n)\n\nthreads=16\n\n#########################################################################\n\n# Exit script if any command fails\nset -e\n\n\n## Run daa2rma\n\n# Capture start \"time\"\n# Uses builtin bash variable called ${SECONDS}\nstart=${SECONDS}\n\nfor daa in *.daa\ndo\n  start_loop=${SECONDS}\n  sample_name=$(basename --suffix \".blastx.daa\" \"${daa}\")\n\n  echo \"Now processing ${sample_name}.daa2rma.rma6\"\n  echo \"\"\n\n  # Run daa2rma with long reads option\n  ${programs_array[daa2rma]} \\\n  --in \"${daa}\" \\\n  --longReads \\\n  --mapDB ${megan_map} \\\n  --out \"${sample_name}\".daa2rma.rma6 \\\n  --threads ${threads} \\\n  2>&1 | tee --append daa2rma_log.txt\n\n  end_loop=${SECONDS}\n  loop_runtime=$((end_loop-start_loop))\n\n\n  echo \"Finished processing ${sample_name}.daa2rma.rma6 in ${loop_runtime} seconds.\"\n  echo \"\"\n\ndone\n\n# Caputure end \"time\"\nend=${SECONDS}\n\nruntime=$((end-start))\n\n# Print daa2rma runtime, in seconds\n\n{\n  echo \"\"\n  echo \"---------------------\"\n  echo \"\"\n  echo \"Total runtime was: ${runtime} seconds\"\n} >> daa2rma_log.txt\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n    ${programs_array[$program]} --help\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n# Document programs in PATH\n{\ndate\necho \"\"\necho \"System PATH:\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nRESULTS\nPretty quick, a little over 17mins:\n\n\n\nDIAMOND BLASTx and MEGAN daa2rma conversion for 20102558-2729-Q7 runtime\n\n\nDIAMOND BLASTx Output folder:\n\n20200928_cbai_nanopore_20102558-2729-Q7_diamond_blastx_daa2rma/\n\nDIAMOND BLASTx DAA file:\n\n20200928_cbai_nanopore_20102558-2729-Q7_diamond_blastx_daa2rma/20200928_cbai_nanopore_20102558-2729_Q7.blastx.daa (9.3MB)\n\nRMA6 file:\n\n20200928_cbai_nanopore_20102558-2729-Q7_diamond_blastx_daa2rma/20200928_cbai_nanopore_20102558-2729_Q7.daa2rma.rma6 (8.1MB)\n\n\n\n\nTaxonomic tree\n\n\n\n20102558-2729-Q7 MEGAN6 taxonomic assignments\n\n\nAlrighty, we see both E.canceri and Aquifex sp. taxonomic assignments (and, of course Arthropoda). Surprisingly, there’re a relatively low number of bases assigned to Arthropoda (~1Mbp) and nearly the same assigned to E.canceri (~900kbp).\nI’ve also highlighted the SAR supergroup (this is where we’d find Alveolata/Hematodinium), just to show that there’s essentially no assignments there. Now, need to see what the other sample looks like…\nUPDATE 20201006: Taxonomic comparison between the two samples is here."
  },
  {
    "objectID": "posts/2020/2020-01-26-Transcriptome-Annotation---Trinotate-Hematodinium-MEGAN6-Taxonomic-specific-Trinity-Assembly-on-Mox/index.html",
    "href": "posts/2020/2020-01-26-Transcriptome-Annotation---Trinotate-Hematodinium-MEGAN6-Taxonomic-specific-Trinity-Assembly-on-Mox/index.html",
    "title": "Transcriptome Annotation - Trinotate Hematodinium MEGAN6 Taxonomic-specific Trinity Assembly on Mox",
    "section": "",
    "text": "After performing de novo assembly on our Hematodinium MEGAN6 taxonomic-specific RNAseq data on 20200122 and performing BLASTx annotation on 20200123, I continued the annotation process by running Trinotate.\nTrinotate will perform functional annotation of the transcriptome assembly, including GO terms and an annotation feature map that can be used in subsequent Trinity-based differential gene expression analysis so that functional annotations are carried downstream through that process.\nSBATCH script (GitHub):\n\n20191226_hemat_trinotate.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=trinotate_hemat\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=05-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200126_hemat_trinotate_megan\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nwd=\"$(pwd)\"\ntimestamp=$(date +%Y%m%d)\nspecies=\"hemat\"\n\nprefix=\"${timestamp}.${species}.trinotate\"\n\n\n## Paths to input/output files\n\n## New folders for working directory\nrnammer_out_dir=\"${wd}/RNAmmer_out\"\nsignalp_out_dir=\"${wd}/signalp_out\"\ntmhmm_out_dir=\"${wd}/tmhmm_out\"\n\n# Input files\nblastp_out=\"/gscratch/scrubbed/samwhite/outputs/20200123_hemat_transdecoder_megan/blastp_out/20200123.hemat.blastp.outfmt6\"\nblastx_out=\"/gscratch/scrubbed/samwhite/outputs/20200123_hemat_diamond_blastx_megan/20200122.hemat.megan.Trinity.blastx.outfmt6\"\npfam_out=\"/gscratch/scrubbed/samwhite/outputs/20200123_hemat_transdecoder_megan/pfam_out/20200123.hemat.pfam.domtblout\"\nlORFs_pep=\"/gscratch/scrubbed/samwhite/outputs/20200123_hemat_transdecoder_megan/20200122.hemat.megan.Trinity.fasta.transdecoder_dir/longest_orfs.pep\"\ntrinity_fasta=\"/gscratch/srlab/sam/data/Hematodinium/transcriptomes/20200122.hemat.megan.Trinity.fasta\"\ntrinity_gene_map=\"/gscratch/srlab/sam/data/Hematodinium/transcriptomes/20200122.hemat.megan.Trinity.fasta.gene_trans_map\"\n\nrnammer_prefix=${trinity_fasta##*/}\n\n# Output files\nrnammer_out=\"${rnammer_out_dir}/${rnammer_prefix}.rnammer.gff\"\nsignalp_out=\"${signalp_out_dir}/${prefix}.signalp.out\"\ntmhmm_out=\"${tmhmm_out_dir}/${prefix}.tmhmm.out\"\ntrinotate_report=\"${wd}/${prefix}_annotation_report.txt\"\n\n# Paths to programs\nrnammer_dir=\"/gscratch/srlab/programs/RNAMMER-1.2\"\nrnammer=\"${rnammer_dir}/rnammer\"\nsignalp_dir=\"/gscratch/srlab/programs/signalp-4.1\"\nsignalp=\"${signalp_dir}/signalp\"\ntmhmm_dir=\"/gscratch/srlab/programs/tmhmm-2.0c/bin\"\ntmhmm=\"${tmhmm_dir}/tmhmm\"\ntrinotate_dir=\"/gscratch/srlab/programs/Trinotate-v3.1.1\"\ntrinotate=\"${trinotate_dir}/Trinotate\"\ntrinotate_rnammer=\"${trinotate_dir}/util/rnammer_support/RnammerTranscriptome.pl\"\ntrinotate_GO=\"${trinotate_dir}/util/extract_GO_assignments_from_Trinotate_xls.pl\"\ntrinotate_features=\"${trinotate_dir}/util/Trinotate_get_feature_name_encoding_attributes.pl\"\ntrinotate_sqlite_db=\"Trinotate.sqlite\"\n\n# Make output directories\nmkdir \"${rnammer_out_dir}\" \"${signalp_out_dir}\" \"${tmhmm_out_dir}\"\n\n# Copy sqlite database template\n\ncp ${trinotate_dir}/admin/Trinotate.sqlite .\n\n# Run signalp\n${signalp} \\\n-f short \\\n-n \"${signalp_out}\" \\\n${lORFs_pep}\n\n# Run tmHMM\n${tmhmm} \\\n--short \\\n< ${lORFs_pep} \\\n> \"${tmhmm_out}\"\n\n# Run RNAmmer\ncd \"${rnammer_out_dir}\" || exit\n${trinotate_rnammer} \\\n--transcriptome ${trinity_fasta} \\\n--path_to_rnammer ${rnammer}\ncd \"${wd}\" || exit\n\n# Run Trinotate\n## Load transcripts and coding regions into database\n${trinotate} \\\n${trinotate_sqlite_db} \\\ninit \\\n--gene_trans_map \"${trinity_gene_map}\" \\\n--transcript_fasta \"${trinity_fasta}\" \\\n--transdecoder_pep \"${lORFs_pep}\"\n\n## Load BLAST homologies\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_swissprot_blastp \\\n\"${blastp_out}\"\n\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_swissprot_blastx \\\n\"${blastx_out}\"\n\n## Load Pfam\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_pfam \\\n\"${pfam_out}\"\n\n## Load transmembrane domains\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_tmhmm \\\n\"${tmhmm_out}\"\n\n## Load signal peptides\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_signalp \\\n\"${signalp_out}\"\n\n## Load RNAmmer\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_rnammer \\\n\"${rnammer_out}\"\n\n## Creat annotation report\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nreport \\\n> \"${trinotate_report}\"\n\n# Extract GO terms from annotation report\n\"${trinotate_GO}\" \\\n--Trinotate_xls \"${trinotate_report}\" \\\n-G \\\n--include_ancestral_terms \\\n> \"${prefix}\".go_annotations.txt\n\n# Make transcript features annotation map\n\"${trinotate_features}\" \\\n\"${trinotate_report}\" \\\n> \"${prefix}\".annotation_feature_map.txt\n\n\nRESULTS\nRumtime was ~6mins:\n~Hemat Trinotate runtime\nOutput folder:\n\n20200126_hemat_trinotate_megan/\n\nAnnotation feature map. This can be used to update Trinity-based gene expression matrices like so:\n\n${TRINITY_HOME}/Analysis/DifferentialExpression/rename_matrix_feature_identifiers.pl\n20200126.hemat.trinotate.annotation_feature_map.txt\n\nAnnotation report (CSV)\n\n20200126.hemat.trinotate_annotation_report.txt\n\nGene ontology (GO) annotations (TXT)\n\n20200126.hemat.trinotate.go_annotations.txt\n\nSQlite database:\n\nTrinotate.sqlite"
  },
  {
    "objectID": "posts/2020/2020-11-02-MBD-Selection---M.magister-Sheared-Gill-gDNA-8-of-24-Samples-Set-2-of-3/index.html",
    "href": "posts/2020/2020-11-02-MBD-Selection---M.magister-Sheared-Gill-gDNA-8-of-24-Samples-Set-2-of-3/index.html",
    "title": "MBD Selection - M.magister Sheared Gill gDNA 8 of 24 Samples Set 2 of 3",
    "section": "",
    "text": "Click here for notebook on the first eight samples processed. M.magister (Dungeness crab) gill gDNA provided by Mackenzie Gavery was previously sheared on 20201026 and three samples were subjected to additional rounds of shearing on 20201027, in preparation for methyl bidning domain (MBD) selection using the MethylMiner Kit (Invitrogen).\nFollowed the manufacturer’s protocol for using <= 1ug of DNA (I’m using 1ug) with the following notes/changes:\n\nPrepared beads for all 8 samples in single prep. Combined the amount of beads/protein needed for 8, 1ug reactions. Protein calculations and wash volumes were based off of 8ug of input DNA. Prepared beads were resuspended in 80uL (instead of 100uL) and 10uL were distributed to each of 8 tubes. Volume was then brought up to 100uL with 1x binding/wash buffer.\nDNA capture incubation was performed overnight (~20hrs).\nNon-captured DNA and wash volumes were combined in a single tube for each sample. These were stored at 4oC, but were not precipitated.\nEthanol precipitations were incubated at -80oC overnight (~20hrs).\nPrecipitated DNA was resuspended in 21uL of H2O (this allows the usage of 1uL for Qubit and leave 20uL as the maximum input volume for the subsequent PicoMethylSeq Kit (ZymoResearch)).\n\nSamples were quantified using the Roberts Lab Qubit 3.0 with the Qubit 1x dsDNA HS Assay (Invitrogen), using 1uL of sample.\nAll samples were stored temporarily at 4oC.\nFor reference, all sample info for this project is here (Google Sheet):\n\nOA Crab Sample Collection 071119\n\n\n\nRESULTS\nQubit results (Google Sheet):\n\n20201104_qubit_DNA_mmag_MBD\n\n\n\n\n\n\n\n\n\n\nSample ID\nResuspension_vol(uL)\nTotal_recovery(ng)\nPercent_recovery(%)\n\n\n\n\nCH05-06\n21\n2.44\n0.24\n\n\nCH05-21\n21\n7.18\n0.72\n\n\nCH05-24\n21\n3.99\n0.40\n\n\nCH05-26\n21\n2.52\n0.25\n\n\nCH07-06\n21\n3.02\n0.30\n\n\nCH07-11\n21\n2.98\n0.30\n\n\nCH07-24\n21\n2.44\n0.24\n\n\nCH09-02\n21\n4.24\n0.42\n\n\n\nYields are in line with what I got with [the first set of samples(https://robertslab.github.io/sams-notebook/2020/10/28/MBD-Selection-M.magister-Sheared-Gill-gDNA-8-of-24-Samples-Set-1-of-3.html)]."
  },
  {
    "objectID": "posts/2020/2020-11-25-Bioanalyzer---M.magister-MBD-BSseq-Libraries/index.html",
    "href": "posts/2020/2020-11-25-Bioanalyzer---M.magister-MBD-BSseq-Libraries/index.html",
    "title": "Bioanalyzer - M.magister MBD BSseq Libraries",
    "section": "",
    "text": "MBD BSseq library construction was completed yesterday (20201124). Next, I needed to evaluate the libraries using the Roberts Lab Bioanalyzer 2100 (Agilent) to assess library sizes, yields, and qualities (i.e. primer dimers).\nZymoResearch recommends using the TapeStation (Agilent), but if a lab doesn’t have access to that, they indicated that either of the regular DNA assays will work (verbal communication). I ran the libraries on the High Sensitivity DNA Assay (Agilent), since that’s what we had in the lab. It should work relatively OK.\nAll data (including Bioanalyzer electropherograms) will be added to the Google Sheet for this project:\n\nOA Crab Sample Collection 071119\n\nAdditional details are available in this GitHub repo:\n\nproject-dungeness-crab\n\n\n\nRESULTS\nMost samples ([including CH09-13 which had no detectable DNA via Qubit(https://robertslab.github.io/sams-notebook/2020/11/03/MBD-Selection-M.magister-Sheared-Gill-gDNA-16-of-24-Samples-Set-3-of-3.html)]) exhibited the expected profiles. Admittedly, a number of samples were probably slightly too concentrated for the High Sensitivity DNA Assay (Agilent), leading to skewed baselines. However, the software does a good job of detecting, and accounting for, this.\nOne sample failed: CH10-19\nAlthough I did not expect it to fail, this sample did have a wonky elution at the end of SECTION 4 of the library prep..\nFor generating Bioanalyzer reports, a region was set for each sample from 44.52s to 109.57s (corresponding to 50bp and 8000bp, respecctively). A couple of samples had to be slightly adjusted due to the software having difficulty automatically identifying the lower marker. In the reports, each sample has a “Region Table” section and a corresponding “Region 1” which lists the following data (most are self-explanatory; the Color is simply the color selected to define “Region 1” on the electropherograms):\n\nFrom [s]\nTo [s]\nCorr. Area\n% of Total\nAverage Size [bp]\nSize distribution in CV [%]\nConc. [pg/ul]\nMolarity [pmol/l]\nColor\n\nOnce a sequencing facility is decided upon, will make decisions about sample pooling and desired sequencing output.\nOutput folder:\n\n20201125_mmag_bioanalyzer_mbd-bsseq-libraries/\n\nBioanalyzer data files (XAD; requires 2100 Expert software):\n\n2100-expert_High-Sensitivity-DNA-Assay_DE72902486_2020-11-25_05-16-07.xad\n2100-expert_High-Sensitivity-DNA-Assay_DE72902486_2020-11-25_06-12-38.xad\n2100-expert_High-Sensitivity-DNA-Assay_DE72902486_2020-11-25_07-00-25.xad\n\nBioanalyzer report files (includes fragment lengths, concentration, and molarity; CSV):\n\n2100-expert_High-Sensitivity-DNA-Assay_DE72902486_2020-11-25_05-16-07_Results.csv\n2100-expert_High-Sensitivity-DNA-Assay_DE72902486_2020-11-25_06-12-38_Results.csv\n2100-expert_High-Sensitivity-DNA-Assay_DE72902486_2020-11-25_07-00-25_Results.csv\n\n\n\n\n\nElectropherograms and gels (full chips)\n\nDE72902486_2020-11-25_05-16-07\n\n\n\nBioanalyzer electrophergrams for all samples in DE72902486_2020-11-25_05-16-07\n\n\n\n\n\nBioanalyzer gel for all samples in DE72902486_2020-11-25_05-16-07\n\n\n\n\nDE72902486_2020-11-25_06-12-38\n\n\n\nBioanalyzer electrophergrams for all samples in DE72902486_2020-11-25_06-12-38\n\n\n\n\n\nBioanalyzer electrophergrams for all samples in DE72902486_2020-11-25_06-12-38\n\n\n\n\nDE72902486_2020-11-25_07-00-25\n\n\n\nBioanalyzer electrophergrams for all samples in DE72902486_2020-11-25_07-00-25\n\n\n\n\n\nBioanalyzer gel for all samples in DE72902486_2020-11-25_07-00-25\n\n\n\n\n\n\nElectropherograms (individual samples)\n\n\n\nBioanalyzer 2100 electropherogram for MBD BSseq library CH01-06\n\n\n\n\n\nBioanalyzer 2100 electropherogram for MBD BSseq library CH01-14\n\n\n\n\n\nBioanalyzer 2100 electropherogram for MBD BSseq library CH01-22\n\n\n\n\n\nBioanalyzer 2100 electropherogram for MBD BSseq library CH01-38\n\n\n\n\n\nBioanalyzer 2100 electropherogram for MBD BSseq library CH03-04\n\n\n\n\n\nBioanalyzer 2100 electropherogram for MBD BSseq library CH03-15\n\n\n\n\n\nBioanalyzer 2100 electropherogram for MBD BSseq library CH03-33\n\n\n\n\n\nBioanalyzer 2100 electropherogram for MBD BSseq library CH05-01\n\n\n\n\n\nBioanalyzer 2100 electropherogram for MBD BSseq library CH05-06\n\n\n\n\n\nBioanalyzer 2100 electropherogram for MBD BSseq library CH05-21\n\n\n\n\n\nBioanalyzer 2100 electropherogram for MBD BSseq library CH05-24\n\n\n\n\n\nBioanalyzer 2100 electropherogram for MBD BSseq library CH05-26\n\n\n\n\n\nBioanalyzer 2100 electropherogram for MBD BSseq library CH07-06\n\n\n\n\n\nBioanalyzer 2100 electropherogram for MBD BSseq library CH07-11\n\n\n\n\n\nBioanalyzer 2100 electropherogram for MBD BSseq library CH07-24\n\n\n\n\n\nBioanalyzer 2100 electropherogram for MBD BSseq library CH09-02\n\n\n\n\n\nBioanalyzer 2100 electropherogram for MBD BSseq library CH09-11\n\n\n\n\n\nBioanalyzer 2100 electropherogram for MBD BSseq library CH09-13\n\n\n\n\n\nBioanalyzer 2100 electropherogram for MBD BSseq library CH09-28\n\n\n\n\n\nBioanalyzer 2100 electropherogram for MBD BSseq library CH09-29\n\n\n\n\n\nBioanalyzer 2100 electropherogram for MBD BSseq library CH10-01\n\n\n\n\n\nBioanalyzer 2100 electropherogram for MBD BSseq library CH10-08\n\n\n\n\n\nBioanalyzer 2100 electropherogram for MBD BSseq library CH10-11\n\n\n\n\n\nBioanalyzer 2100 electropherogram for MBD BSseq library CH10-19"
  },
  {
    "objectID": "posts/2020/2020-01-22-DNA-Isolation---C.bairdi-20102558-2729-EtOH-preserved-Tissue-via-Three-Variations-Using-Quick-DNA-RNA-MicroPrep-Kit/index.html",
    "href": "posts/2020/2020-01-22-DNA-Isolation---C.bairdi-20102558-2729-EtOH-preserved-Tissue-via-Three-Variations-Using-Quick-DNA-RNA-MicroPrep-Kit/index.html",
    "title": "DNA Isolation - C.bairdi 20102558-2729 EtOH-preserved Tissue via Three Variations Using Quick DNA-RNA MicroPrep Kit",
    "section": "",
    "text": "Previously, I isolated gDNA from a C.bairdi EtOH-preserved muscle sample (20102558-2729) on 20200108 using the E.Z.N.A. Mollusc DNA Kit (Omega). Although the yields were excellent, the DNA looked completely degraded on a gel and running that DNA on a minION flowcell yielded relatively short reads (which wasn’t terribly surprising).\nSo, to test out whether or not the degradation was due to the inherent age/preservation method of the sample, I decided to try another kit for gDNA isolation: Quick DNA/RNA MicroPrep Kit (ZymoResearch). I also decided to try three variations of the isolation protocol with very small pieces of tissue (~5 - 10mg):\n\n“damp”: where the ethanol has not been allowed to dry and homogenized with disposable mortar/pestle 1.5mL tube in 800uL of 1x DNA/RNA Shield.\n“dry”: where the sample is allowed to dry (per the “FFPE Tissue” guidelines) and homogenized with disposable mortar/pestle 1.5mL tube in 800uL of 1x DNA/RNA Shield.\nminced: where the damp sample was minced with a razor blade and incubate in 300uL of 1x DNA/RNA Shield with 30uL PK Digestion Buffer and 15uL of Proteinase K solution at 55oC for 5hrs.\n\nThe remainder of the manufacturer’s protocol was followed.\nSamples were eluted in 30uL of H2O.\nSamples were quantified on the Roberts Lab Qubit 3.0 using 1uL of each sample with the 1x dsDNA High Sensitivity Assay.\n\n\nRESULTS\nQubit data (Google Sheet):\n\n20200122_qubit_cbai_quick-DNA\n\nGot DNA, decent yields (165ng, 138ng, and 510ng). Will proceed with checking quality on gel.\nSamples were stored at -80oC in:\nRack 6, 4, 1 in C.bairdi gDNA Box #1"
  },
  {
    "objectID": "posts/2020/2020-08-06-qPCR---P.generosa-APLP-and-TIF3s8-1-with-cDNA/index.html",
    "href": "posts/2020/2020-08-06-qPCR---P.generosa-APLP-and-TIF3s8-1-with-cDNA/index.html",
    "title": "qPCR - P.generosa APLP and TIF3s8-1 with cDNA",
    "section": "",
    "text": "Shelly asked me to run some qPCRs (GitHub Issue), after some of the qPCR results I got from primer tests with normalzing genes and potential gene targets.\nPrimers used:\n\n\n\nSRID\nPrimer_Name\n\n\n\n\n1769\nAPLP_FWD\n\n\n1768\nAPLP_REV\n\n\n1773\nTIF3s8_FWD-1\n\n\n1772\nTIF3s8_REV-1\n\n\n\n\nTIF3s8 is expected to be used as a normalizing gene.\n\nThe cDNA being used will be samples made by Kaitlyn on 20200212. Samples used are those lined up towards the top of the sample box. It’s unclear to me why there are some samples in 0.5mL tubes and others in 1.7mL tubes:\n\n\n\nPic of Kaitlyn’s geoduck samples box\n\n\nPositive control was pooled cDNA, created by combining 2uL from each of the following:\n\n11-08 1H (made by me from 20191125)\n11-08 2H (made by me from 20191125)\n57H (made by me from 20191125)\n11/15 Chew (made by Kaitlyn, no date on tube)\n11/21 Star (made by Kaitlyn, no date on tube)\n\nAll qPCR reactions were run in duplicate. See qPCR Report (Results section below) for plate layout, cycling params, etc.\nMaster mix calcs are here:\n\n20200806_qPCR_geoduck_APLP_TIF3s8 (Google Sheet)\n\n\n\nRESULTS\nqPCR Report (PDF):\n\nsam_2020-08-06_05-44-24_BR006896.pdf\n\nCFX Data File (PCRD):\n\nsam_2020-08-06%2005-44-24_BR006896.pcrd\n\nCFX Results File (CSV):\n\nsam_2020-08-06_05-44-24_BR006896-Quantification_Cq_Results.csv\n\n\nPlot color legend:\n\nAPLP: BLACK\nPositive control: GREEN\nNo Template Controls: RED\n\n\n\nAPLP Amplification plots\n\n\n\nAPLP amplifcation plots\n\n\n\n\nAPLP Melt curves\n\n\n\nAPLP melt curves\n\n\n\nPlot color legend:\n\nTIF3s8-1: ORANGE\nPositive control: GREEN\nNo Template Controls: RED\n\n\n\nTIF3s8-1 Amplification plots\n\n\n\nTIF3s8-1 amplifcation plots\n\n\n\n\nTIF3s8-1 Melt curves\n\n\n\nTIF3s8-1 melt curves\n\n\n\nOverall, the data itself looks fine. There are a few samples here and there where the replicates aren’t great; primarily those that amplify very late (>37 Cq). This isn’t terribly unusual, but as a mild perfectionist, it annoys me.\nHowever, upon some brief analysis, it’s clear that using TIF3s8-1 as a normalizing gene will not work. It fails to amplify in the majority of samples. Cross-checking with the results of APLP amplification in those same samples shows that APLP did amplify in most of those same samples; thus ruling out an issue with the samples themselves.\nWill let Shelly know and will probably come up with a plan for identifying new normalizing gene targets."
  },
  {
    "objectID": "posts/2020/2020-04-13-Data-Received---C.bairdi-RNAseq-from-NWGSC/index.html",
    "href": "posts/2020/2020-04-13-Data-Received---C.bairdi-RNAseq-from-NWGSC/index.html",
    "title": "Data Received - C.bairdi RNAseq from NWGSC",
    "section": "",
    "text": "Received the C.bairdi RNAseq data from UW NWGSC that Grace submitted on 20200131. Below is a table of NWGSC sample name and corresponding labels that Grace provided. The 0/1 indicates uninfected/infected, respectively.\n\n\n\nSample/Name\nInvestigator Sample Name\n\n\n\n\n380820\nD9_0\n\n\n380821\nD9_1\n\n\n380822\nD12_cold_0\n\n\n380823\nD12_cold_1\n\n\n380824\nD12_warm_0\n\n\n380825\nD12_warm_1\n\n\n\nData has been uploaded to Nightingales and the checksums verified:\n\n\n\nchecksum verification screenshot\n\n\nWill update nightingales Google Sheet with info."
  },
  {
    "objectID": "posts/2020/2020-09-18-Assembly-Assessment---BUSCO-C.bairdi-Genome-v1.0-on-Mox/index.html",
    "href": "posts/2020/2020-09-18-Assembly-Assessment---BUSCO-C.bairdi-Genome-v1.0-on-Mox/index.html",
    "title": "Assembly Assessment - BUSCO C.bairdi Genome v1.0 on Mox",
    "section": "",
    "text": "After using Flye to perform a de novo assembly of our Q7 filtered NanoPore sequencing data on 20200917, I decided to check the “completeness” of the assembly using BUSCO on Mox.\nSBATCH script (GitHub):\n\n20200918_cbai_genome_v1.0_busco_.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_genome_v1.0_busco\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=3-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200918_cbai_genome_v1.0_busco\n###################################################################################\n\n\n\n\n\n# These variables need to be set by user\n\n## Save working directory\nwd=$(pwd)\n\n# Genomes directory\ngenomes_dir=/gscratch/srlab/sam/data/C_bairdi/genomes\n\n# Genomes array\ngenomes_array=(\n\"${genomes_dir}\"/cbai_genome_v1.0.fasta \\\n)\n\n\n\n## Input files and settings\nbusco_db=/gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9\naugustus_species=fly\nthreads=28\n\n# Programs associative array\ndeclare -A programs_array\nprograms_array=(\n[busco]=\"/gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py\"\n)\n\n\n## Set program paths\naugustus_bin=/gscratch/srlab/programs/Augustus-3.3.2/bin\naugustus_orig_config_dir=/gscratch/srlab/programs/Augustus-3.3.2/config\naugustus_scripts=/gscratch/srlab/programs/Augustus-3.3.2/scripts\nblast_dir=/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin/\nhmm_dir=/gscratch/srlab/programs/hmmer-3.2.1/src/\n\n# Export Augustus variable\nexport PATH=\"${augustus_bin}:$PATH\"\nexport PATH=\"${augustus_scripts}:$PATH\"\n\n## BUSCO configs\nbusco_config_default=/gscratch/srlab/programs/busco-v3/config/config.ini.default\nbusco_config_ini=${wd}/config.ini\n\n# Export BUSCO config file location\nexport BUSCO_CONFIG_FILE=\"${busco_config_ini}\"\n\n# Copy BUSCO config file\ncp ${busco_config_default} \"${busco_config_ini}\"\n\n# Edit BUSCO config file\n## Set paths to various programs\n### The use of the % symbol sets the delimiter sed uses for arguments.\n### Normally, the delimiter that most examples use is a slash \"/\".\n### But, we need to expand the variables into a full path with slashes, which screws up sed.\n### Thus, the use of % symbol instead (it could be any character that is NOT present in the expanded variable; doesn't have to be \"%\").\nsed -i \"/^;cpu/ s/1/${threads}/\" \"${busco_config_ini}\"\nsed -i \"/^tblastn_path/ s%tblastn_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^makeblastdb_path/ s%makeblastdb_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^augustus_path/ s%augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^etraining_path/ s%etraining_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^gff2gbSmallDNA_path/ s%gff2gbSmallDNA_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^new_species_path/ s%new_species_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^optimize_augustus_path/ s%optimize_augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^hmmsearch_path/ s%hmmsearch_path = /home/osboxes/BUSCOVM/hmmer/hmmer-3.1b2-linux-intel-ia32/binaries/%path = ${hmm_dir}%\" \"${busco_config_ini}\"\n\n###################################################################################\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Load Open MPI module for parallel, multi-node processing\nmodule load icc_19-ompi_3.1.2\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\nfor genome in \"${!genomes_array[@]}\"\ndo\n\n  # Remove path from genome using parameter substitution\n  genome_name=\"${genomes_array[$genome]##*/}\"\n\n  ## Augustus config directories\n  augustus_dir=${wd}/${genome_name}_augustus\n  augustus_config_dir=${augustus_dir}/config\n\n\n  export AUGUSTUS_CONFIG_PATH=\"${augustus_config_dir}\"\n\n\n  # Make Augustus directory if it doesn't exist\n  if [ ! -d \"${augustus_dir}\" ]; then\n    mkdir --parents \"${augustus_dir}\"\n  fi\n\n  # Copy Augustus config directory\n  cp --preserve -r ${augustus_orig_config_dir} \"${augustus_dir}\"\n\n\n  # Run BUSCO/Augustus training\n  ${programs_array[busco]} \\\n  --in ${genomes_array[$genome]} \\\n  --out ${genome_name} \\\n  --lineage_path ${busco_db} \\\n  --mode genome \\\n  --cpu ${threads} \\\n  --long \\\n  --species ${augustus_species} \\\n  --tarzip \\\n  --augustus_parameters='--progress=true'\n\n  # Capture FastA checksums for verification\n  echo \"\"\n  echo \"Generating checksum for ${genome_name}\"\n  md5sum \"${genomes_array[$genome]}\" > \"${genome_name}\".checksum.md5\n  echo \"Finished generating checksum for ${genome_name}\"\n  echo \"\"\n\ndone\n\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n    ${programs_array[$program]} --help\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n\nRESULTS\nOutput folder:\n\n20200918_cbai_genome_v1.0_busco/\n\nSummary file (text):\n\n20200918_cbai_genome_v1.0_busco/run_cbai_genome_v1.0.fasta/short_summary_cbai_genome_v1.0.fasta.txt\n\n# BUSCO version is: 3.0.2\n# The lineage dataset is: metazoa_odb9 (Creation date: 2016-02-13, number of species: 65, number of BUSCOs: 978)\n# To reproduce this run: python /gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py -i /gscratch/srlab/sam/data/C_bairdi/genomes/cbai_genome_v1.0.fasta -o cbai_genome_v1.0.fasta -l /gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9/ -m genome -c 28 --long -z -sp fly --augustus_parameters '--progress=true'\n#\n# Summarized benchmarking in BUSCO notation for file /gscratch/srlab/sam/data/C_bairdi/genomes/cbai_genome_v1.0.fasta\n# BUSCO was run in mode: genome\n\nC:0.4%[S:0.3%,D:0.1%],F:0.3%,M:99.3%,n:978\n\n4   Complete BUSCOs (C)\n3   Complete and single-copy BUSCOs (S)\n1   Complete and duplicated BUSCOs (D)\n3   Fragmented BUSCOs (F)\n971 Missing BUSCOs (M)\n978 Total BUSCO groups searched\n\n\nThe results are a tad disappointing (would’ve been awesome if we had actually gotten a nearly complete genome), but not terribly surprising. Crab/crustacean genomes are known to be rather large, the NanoPore runs didn’t generate a ton of data, and the assembly didn’t produce any appreciably large scaffolds/contigs.\nDespite this, I’m still interested in seeing what a graph-based assembly looks like using a visualization package like Bandage to gain a better understanding of what to expect.\nIt would also be great to perform some additional NanoPore sequencing. The flowcells aren’t terribly expensive, the library prep/sequencing is fast, and the downstream analysis is pretty quick and painless (assuming what I’ve done so far is the appropriate way to process this data)."
  },
  {
    "objectID": "posts/2020/2020-04-26-FastQC-MultiQC---Laura-Spencers-QuantSeq-Data/index.html",
    "href": "posts/2020/2020-04-26-FastQC-MultiQC---Laura-Spencers-QuantSeq-Data/index.html",
    "title": "FastQC-MultiQC - Laura Spencer’s QuantSeq Data",
    "section": "",
    "text": "Laura Spencer received her O.lurida QuantSeq data, so I put it through FastQC/MultiQC and put the pertinent info in the nightingales Google Sheet. I also moved the data to /owl/nightingales/O_lurida, updated the readme file and checksums file. There were 148 individual samples, so I won’t list them all here.\n\n\nRESULTS\nOutput folder:\n\n20200426_olur_fastqc_quantseq/\n\nMultiQC Report (HTML):\n\n20200426_olur_fastqc_quantseq/multiqc_report.html"
  },
  {
    "objectID": "posts/2020/2020-08-17-TransDecoder---Hematodinium-Transcriptomes--v1.6-v1.7-v2.1-and-v3.1-on-Mox/index.html",
    "href": "posts/2020/2020-08-17-TransDecoder---Hematodinium-Transcriptomes--v1.6-v1.7-v2.1-and-v3.1-on-Mox/index.html",
    "title": "TransDecoder - Hematodinium Transcriptomes v1.6, v1.7, v2.1 and v3.1 on Mox",
    "section": "",
    "text": "To continue annotation of our Hematodinium v1.6, v1.7, v2.1 & v3.1 transcriptome assemblies, I needed to run TransDecoder before performing the more thorough annotation with Trinotate.\nInfo for each transcriptome version (library composition, assembly dates, BUSCO, etc) can be found in this table:\n\nhemat_transcriptome_comp\n\nThis was run on Mox.\nSBATCH script (GitHub):\n\n20200817_hemat_transdecoder_transcriptomes_v1.6_v1.7_v2.1_v.3.1.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=hemat_transdecoder_transcriptomes_v1.6_v1.7_v2.1_v.3.1\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=14-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200817_hemat_transdecoder_transcriptomes_v1.6_v1.7_v2.1_v.3.1\n\n# Script to run TransDecoder on Hematodinium transcriptomes:\n# v1.6, v1.7, v2.1, v3.1\n\n###################################################################################\n# These variables need to be set by user\n\n# Capture date. E.g. format is: 20190820\ntimestamp=$(date +\"%Y%m%d\")\n\ntranscriptomes_dir=/gscratch/srlab/sam/data/Hematodinium/transcriptomes\n\n# Paths to program directories\nblast_dir=\"/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin\"\nhmmer_dir=\"/gscratch/srlab/programs/hmmer-3.2.1/src\"\ntransdecoder_dir=\"/gscratch/srlab/programs/TransDecoder-v5.5.0\"\n\n# Paths to Trinotate databases\npfam_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/Pfam-A.hmm\"\nsp_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/uniprot_sprot.pep\"\n\n# Array of the various comparisons to evaluate\n# Each condition in each comparison should be separated by a \"-\"\ndeclare -A transcriptomes_gene_maps_array\ntranscriptomes_gene_maps_array=(\n[\"${transcriptomes_dir}/hemat_transcriptome_v1.6.fasta\"]=\"${transcriptomes_dir}/hemat_transcriptome_v1.6.fasta.gene_trans_map\" \\\n[\"${transcriptomes_dir}/hemat_transcriptome_v1.7.fasta\"]=\"${transcriptomes_dir}/hemat_transcriptome_v1.7.fasta.gene_trans_map\" \\\n[\"${transcriptomes_dir}/hemat_transcriptome_v2.1.fasta\"]=\"${transcriptomes_dir}/hemat_transcriptome_v2.1.fasta.gene_trans_map\" \\\n[\"${transcriptomes_dir}/hemat_transcriptome_v3.1.fasta\"]=\"${transcriptomes_dir}/hemat_transcriptome_v3.1.fasta.gene_trans_map\"\n)\n\n\ndeclare -A programs_array\nprograms_array=(\n[blastp]=\"${blast_dir}/blastp\" \\\n[hmmscan]=\"${hmmer_dir}/hmmscan\" \\\n[transdecoder_lORFs]=\"${transdecoder_dir}/TransDecoder.LongOrfs\" \\\n[transdecoder_predict]=\"${transdecoder_dir}/TransDecoder.Predict\"\n)\n\nthreads=28\n\n###################################################################################\n\n# Exit script if a command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n\nfor transcriptome in \"${!transcriptomes_gene_maps_array[@]}\"\ndo\n\n  # Remove path from transcriptome using parameter substitution\n  transcriptome_name=\"${transcriptome##*/}\"\n\n  # Set a prefix that utilizes timestamp and name of transcriptome\n  prefix=\"${timestamp}_${transcriptome_name}\"\n\n  # Make output directory and change to directory\n  mkdir --parents \"${prefix}.transdecoder\" && cd \"$_\"\n\n  # Paths to input/output files\n\n  blastp_out_dir=\"${prefix}.blastp_out\"\n  pfam_out_dir=\"${prefix}.pfam_out\"\n\n  # Make output directories\n  mkdir \"${blastp_out_dir}\"\n  mkdir \"${pfam_out_dir}\"\n\n  blastp_out=\"${blastp_out_dir}/${prefix}.blastp.outfmt6\"\n  pfam_out=\"${pfam_out_dir}/${prefix}.pfam.domtblout\"\n  lORFs_pep=\"${transcriptome_name}.transdecoder_dir/longest_orfs.pep\"\n\n\n\n  # Extract long open reading frames\n  \"${programs_array[transdecoder_lORFs]}\" \\\n  --gene_trans_map \"${transcriptomes_gene_maps_array[$transcriptome]}\" \\\n  -t \"${transcriptome}\"\n\n  # Run blastp on long ORFs\n  \"${programs_array[blastp]}\" \\\n  -query \"${lORFs_pep}\" \\\n  -db \"${sp_db}\" \\\n  -max_target_seqs 1 \\\n  -outfmt 6 \\\n  -evalue 1e-5 \\\n  -num_threads ${threads} \\\n  > \"${blastp_out}\"\n\n  # Run pfam search\n  \"${programs_array[hmmscan]}\" \\\n  --cpu ${threads} \\\n  --domtblout \"${pfam_out}\" \\\n  \"${pfam_db}\" \\\n  \"${lORFs_pep}\"\n\n  # Run Transdecoder with blastp and Pfam results\n  \"${programs_array[transdecoder_predict]}\" \\\n  -t \"${transcriptome}\" \\\n  --retain_pfam_hits \"${pfam_out}\" \\\n  --retain_blastp_hits \"${blastp_out}\"\n\n  # Capture FastA MD5 checksum for future reference\n  md5sum \"${transcriptome}\" > \"${prefix}\".checksum.md5\n\n  # Move back up to main directory\n  cd ..\n\ndone\n\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n    ${programs_array[$program]} -h\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\nDue to a colossal error in the original v1.6 and v1.7 assemblies (used the wrong FastQ files!), I re-ran this analysis just on the v1.6 and v1.7 and integrated the results in this post/output directory. I have not created a separate notebook entry for this re-analysis to minimize confusion.\n\n\nRESULTS\nTook 1.25 days to process:\n\n\n\nCumulative Transdecoder runtime for all transcriptomes\n\n\nOutput folder:\n\n20200817_hemat_transdecoder_transcriptomes_v1.6_v1.7_v2.1_v.3.1\n\n\nhemat_transcriptome_v1.6\nCoding Sequences (FastA):\n\nhemat_transcriptome_v1.6.fasta.transdecoder.cds\n\nPeptide Sequences (FastA):\n\nhemat_transcriptome_v1.6.fasta.transdecoder.pep\n\nBLASTp output (tab):\n\n20210309_hemat_transcriptome_v1.6.fasta.blastp.outfmt6\n\nPfam output:\n\n20210309_hemat_transcriptome_v1.6.fasta.pfam.domtblout\n\n\n\nhemat_transcriptome_v1.7\nCoding Sequences (FastA):\n\nhemat_transcriptome_v1.7.fasta.transdecoder.cds\n\nPeptide Sequences (FastA):\n\nhemat_transcriptome_v1.7.fasta.transdecoder.pep\n\nBLASTp output (tab):\n\n20210309_hemat_transcriptome_v1.7.fasta.blastp.outfmt6\n\nPfam output:\n\n20210309_hemat_transcriptome_v1.7.fasta.pfam.domtblout\n\n\n\nhemat_transcriptome_v2.1\nCoding Sequences (FastA):\n\nhemat_transcriptome_v2.1.fasta.transdecoder.cds\n\nPeptide Sequences (FastA):\n\nhemat_transcriptome_v2.1.fasta.transdecoder.pep\n\nBLASTp output (tab):\n\n20200817_hemat_transcriptome_v2.1.fasta.blastp.outfmt6\n\nPfam output:\n\n20200817_hemat_transcriptome_v2.1.fasta.pfam.domtblout\n\n\n\nhemat_transcriptome_v3.1\nCoding Sequences (FastA):\n\nhemat_transcriptome_v3.1.fasta.transdecoder.cds\n\nPeptide Sequences (FastA):\n\nhemat_transcriptome_v3.1.fasta.transdecoder.pep\n\nBLASTp output (tab):\n\n20200817_hemat_transcriptome_v3.1.fasta.blastp.outfmt6\n\nPfam output:\n\n20200817_hemat_transcriptome_v3.1.fasta.pfam.domtblout"
  },
  {
    "objectID": "posts/2020/2020-01-22-DNA-Quality-Assessment---Agarose-Gel-for-C.bairdi-20102558-2729-gDNA-from-20200122/index.html",
    "href": "posts/2020/2020-01-22-DNA-Quality-Assessment---Agarose-Gel-for-C.bairdi-20102558-2729-gDNA-from-20200122/index.html",
    "title": "DNA Quality Assessment - Agarose Gel for C.bairdi 20102558-2729 gDNA from 20200122",
    "section": "",
    "text": "Earlier today, I isolated gDNA from C.bairdi 20102558-2729 ethanol-preserved muscle tissue using the Quick DNA/RNA MicroPrep Plus Kit (ZymoResearch) and prepared the tissue in three different ways to see how they would compare:\nRan 10uL of each sample on a 0.8% agarose, 1x low TAE gel with ethidium bromide.\nUsed the GeneRuler DNA Ladder Mix (ThermoFisher) as ladder.\n\n\nRESULTS\nLadder:\n\n\n\nThermoFisher GeneRuler DNA Ladder Mix\n\n\n\nFrom left to right, gel was loaded:\n\nLadder\n“damp” sample prep\n“dry” sample prep\n“minced” sample prep\n\n\n\n\nGel image\n\n\nWell, all three preps look the same - very degraded. This is virtually the same as what I saw using the E.Z.N.A. Mollusc Kit (Omega). Looke like we’ll have to pursue a different route to get high quality gDNA for long read sequencing.\nWill talk to Grace to see if we have extra hemolymph samples in RNAlater that I can try to get gDNA from and see if that gDNA looks any better."
  },
  {
    "objectID": "posts/2020/2020-02-11-RNA-Isolation-and-Quantification---C.bairdi-RNA-from-Samples-6212_132_9-6212_334_12-6212_485_26/index.html",
    "href": "posts/2020/2020-02-11-RNA-Isolation-and-Quantification---C.bairdi-RNA-from-Samples-6212_132_9-6212_334_12-6212_485_26/index.html",
    "title": "RNA Isolation & Quantification - C.bairdi RNA from Samples 6212_132_9 6212_334_12 6212_485_26",
    "section": "",
    "text": "We are supposed to get RNA sent out for sequencing today, but it turns out that a few of the designated samples have insufficient RNA in them. So, I’m going to attempt to isolate enough RNA from the following samples in order to have enough RNA to send to Genewiz today:\n\n6212_132_9\n6212_334_12\n6212_485_2\n\nIsolated RNA using the Quick DNA/RNA Microprep Kit (ZymoResearch; PDF) according to the manufacturer’s protocol for liquids/cells in RNAlater.\n\nUsed 35uL from each RNAlater/hemocyte slurry.\nMixed with equal volume of H2O (35uL).\nRetained DNA on the Zymo-Spin IC-XM columns for isolation after RNA isolation.\nPerformed on-column DNase step.\nRNA was eluted in 15uL H2O\n\nRNA was quantified on the Roberts Lab Qubit 3.0 using the RNA High Sensitivity Assay (Invitrogen), using 2uL of each sample.\nRNA was stored in a temporary box in the -80oC freezer with the rest of the samples intended to be sent for sequencing.\n\n\nRESULTS\nQubit restuls (Google Sheet):\n\n20200211_qubit_crab_RNA\n\n\n\n\nSample ID\n[RNA] (ng/uL)\n\n\n\n\n6212_485_26\n5.46\n\n\n6212_132_9\n7.21\n\n\n6212_334_12\n8.38\n\n\n\nWill pass these off to Grace to get prepped to send out for sequencing."
  },
  {
    "objectID": "posts/2020/2020-04-22-Gene-Expression---C.bairdi-Pairwise-DEG-Comparisons-with-2019-RNAseq-using-Trinity-Salmon-EdgeR-on-Mox/index.html",
    "href": "posts/2020/2020-04-22-Gene-Expression---C.bairdi-Pairwise-DEG-Comparisons-with-2019-RNAseq-using-Trinity-Salmon-EdgeR-on-Mox/index.html",
    "title": "Gene Expression - C.bairdi Pairwise DEG Comparisons with 2019 RNAseq using Trinity-Salmon-EdgeR on Mox",
    "section": "",
    "text": "Per a Slack request, Steven asked me to take the Genewize RNAseq data (received 2020318) through edgeR. Ran the analysis using the Trinity differential expression pipeline:\n\nSalmon alignment-free transcript quantification\nedgeR differential expression\n\nHere’re the core input files used for this analysis:\n\nTranscriptome: cbai_transcriptome_v1.5.fasta\nMEGAN6 Arthropoda taxonomic reads: 20200413_C_bairdi_megan_reads/\n\nThe analyses will perform the following pairwise comparisons:\n\ninfected-uninfected\nD9-D12\nD9-D26\nD12-D26\nambient-cold\nambient-warm\ncold-warm\n\nIt will identify differentially expressed genes with >=2-fold log change in expression and a false discovery rate of <=0.05. Additionally, it will perform gene ontology (GO) enrichment analysis using GOseq.\nAs a brief aside, I’m pretty stoked about the SBATCH script below! It automates FastQ file selection for each comparison, creates appropriately named subdirectories and creates proper Trinity samples list file needed.\nAfter running the DEG analysis, I “flattened” the enriched GO terms files for later use in R to map these GO terms to GOslims. That was run separately and the script is after the SBATCH script.\nSBATCH script (GitHub):\n\n20200422_cbai_DEG_basic_comparisons.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_DEG_basic\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200422_cbai_DEG_basic_comparisons\n\n# This is a script to identify differentially expressed genes (DEGs) in C.bairdi\n# using pairwise comparisions of from just the \"2020-GW\" (i.e. just Genewiz) RNAseq data\n# which has been taxonomically selected for all Arthropoda reads. See Sam's notebook from 20200419\n# https://robertslab.github.io/sams-notebook/\n\n# Script will run Trinity's builtin differential gene expression analysis using:\n# - Salmon alignment-free transcript abundance estimation\n# - edgeR\n# Cutoffs of 2-fold difference in expression and FDR of <=0.05.\n\n###################################################################################\n# These variables need to be set by user\nfastq_dir=\"/gscratch/srlab/sam/data/C_bairdi/RNAseq/\"\nfasta_prefix=\"20200408.C_bairdi.megan.Trinity\"\ntranscriptome_dir=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes\"\ntrinotate_feature_map=\"${transcriptome_dir}/20200409.cbai.trinotate.annotation_feature_map.txt\"\ngo_annotations=\"${transcriptome_dir}/20200409.cbai.trinotate.go_annotations.txt\"\n\n# Array of the various comparisons to evaluate\n# Each condition in each comparison should be separated by a \"-\"\ncomparisons_array=(\ninfected-uninfected \\\nD9-D12 \\\nD9-D26 \\\nD12-D26 \\\nambient-cold \\\nambient-warm \\\ncold-warm\n)\n\n# Functions\n# Expects input (i.e. \"$1\") to be in the following format:\n# e.g. 20200413.C_bairdi.113.D9.uninfected.cold.megan_R2.fq\nget_day () { day=$(echo \"$1\" | awk -F\".\" '{print $4}'); }\nget_inf () { inf=$(echo \"$1\" | awk -F\".\" '{print $5}'); }\nget_temp () { temp=$(echo \"$1\" | awk -F\".\" '{print $6}'); }\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nwd=\"$(pwd)\"\nthreads=28\n\n\n## Designate input file locations\ntranscriptome=\"${transcriptome_dir}/${fasta_prefix}.fasta\"\nfasta_seq_lengths=\"${transcriptome_dir}/${fasta_prefix}.fasta.seq_lens\"\ngene_map=\"${transcriptome_dir}/${fasta_prefix}.fasta.gene_trans_map\"\ntranscriptome=\"${transcriptome_dir}/${fasta_prefix}.fasta\"\n\n\n# Standard output/error files\ndiff_expr_stdout=\"diff_expr_stdout.txt\"\ndiff_expr_stderr=\"diff_expr_stderr.txt\"\nmatrix_stdout=\"matrix_stdout.txt\"\nmatrix_stderr=\"matrix_stderr.txt\"\nsalmon_stdout=\"salmon_stdout.txt\"\nsalmon_stderr=\"salmon_stderr.txt\"\ntpm_length_stdout=\"tpm_length_stdout.txt\"\ntpm_length_stderr=\"tpm_length_stderr.txt\"\ntrinity_DE_stdout=\"trinity_DE_stdout.txt\"\ntrinity_DE_stderr=\"trinity_DE_stderr.txt\"\n\nedgeR_dir=\"\"\n\n#programs\ntrinity_home=/gscratch/srlab/programs/trinityrnaseq-v2.9.0\ntrinity_annotate_matrix=\"${trinity_home}/Analysis/DifferentialExpression/rename_matrix_feature_identifiers.pl\"\ntrinity_abundance=${trinity_home}/util/align_and_estimate_abundance.pl\ntrinity_matrix=${trinity_home}/util/abundance_estimates_to_matrix.pl\ntrinity_DE=${trinity_home}/Analysis/DifferentialExpression/run_DE_analysis.pl\ndiff_expr=${trinity_home}/Analysis/DifferentialExpression/analyze_diff_expr.pl\ntrinity_tpm_length=${trinity_home}/util/misc/TPM_weighted_gene_length.py\n\n# Loop through each comparison\n# Will create comparison-specific direcctories and copy\n# appropriate FastQ files for each comparison.\n\n# After file transfer, will create necessary sample list file for use\n# by Trinity for running differential gene expression analysis and GO enrichment.\nfor comparison in \"${!comparisons_array[@]}\"\ndo\n\n  # Assign variables\n  cond1_count=0\n  cond2_count=0\n  comparison=${comparisons_array[${comparison}]}\n  comparison_dir=${wd}/${comparison}/\n  salmon_gene_matrix=${comparison_dir}/salmon.gene.TMM.EXPR.matrix\n  salmon_iso_matrix=${comparison_dir}/salmon.isoform.TMM.EXPR.matrix\n  samples=${comparison_dir}${comparison}.samples.txt\n\n  # Extract each comparison from comparisons array\n  # Conditions must be separated by a \"-\"\n  cond1=$(echo \"${comparison}\" | awk -F\"-\" '{print $1}')\n  cond2=$(echo \"${comparison}\" | awk -F\"-\" '{print $2}')\n\n\n  mkdir --parents \"${comparison}\"\n\n  cd \"${comparison}\" || exit\n\n  # Series of if statements to identify which FastQ files to rsync to working directory\n  if [[ \"${comparison}\" == \"infected-uninfected\" ]]; then\n    rsync --archive --verbose ${fastq_dir}*.fq .\n  fi\n\n  if [[ \"${comparison}\" == \"D9-D12\" ]]; then\n    for fastq in \"${fastq_dir}\"*.fq\n    do\n      get_day \"${fastq}\"\n      if [[ \"${day}\" == \"D9\" || \"${day}\" == \"D12\" ]]; then\n        rsync --archive --verbose \"${fastq}\" .\n      fi\n    done\n  fi\n\n  if [[ \"${comparison}\" == \"D9-D26\" ]]; then\n    for fastq in \"${fastq_dir}\"*.fq\n    do\n      get_day \"${fastq}\"\n      if [[ \"${day}\" == \"D9\" || \"${day}\" == \"D26\" ]]; then\n        rsync --archive --verbose \"${fastq}\" .\n      fi\n    done\n  fi\n\n  if [[ \"${comparison}\" == \"D12-D26\" ]]; then\n    for fastq in \"${fastq_dir}\"*.fq\n    do\n      get_day \"${fastq}\"\n      if [[ \"${day}\" == \"D12\" || \"${day}\" == \"D26\" ]]; then\n        rsync --archive --verbose \"${fastq}\" .\n      fi\n    done\n  fi\n\n  if [[ \"${comparison}\" == \"ambient-cold\" ]]; then\n    #statements\n    for fastq in \"${fastq_dir}\"*.fq\n    do\n      get_temp \"${fastq}\"\n      if [[ \"${temp}\" == \"ambient\" || \"${temp}\" == \"cold\" ]]; then\n        rsync --archive --verbose \"${fastq}\" .\n      fi\n    done\n  fi\n\n  if [[ \"${comparison}\" == \"ambient-warm\" ]]; then\n    for fastq in \"${fastq_dir}\"*.fq\n    do\n      get_temp \"${fastq}\"\n      if [[ \"${temp}\" == \"ambient\" || \"${temp}\" == \"warm\" ]]; then\n        rsync --archive --verbose \"${fastq}\" .\n      fi\n    done\n  fi\n\n  if [[ \"${comparison}\" == \"cold-warm\" ]]; then\n    for fastq in \"${fastq_dir}\"*.fq\n    do\n      get_temp \"${fastq}\"\n      if [[ \"${temp}\" == \"cold\" || \"${temp}\" == \"warm\" ]]; then\n        rsync --archive --verbose \"${fastq}\" .\n      fi\n    done\n  fi\n\n  # Create reads array\n  # Paired reads files will be sequentially listed in array (e.g. 111_R1 111_R2)\n  reads_array=(*.fq)\n\n  echo \"\"\n  echo \"Created reads_array\"\n\n  # Loop to create sample list file\n  # Sample file list is tab-delimited like this:\n\n  # cond_A    cond_A_rep1    A_rep1_left.fq    A_rep1_right.fq\n  # cond_A    cond_A_rep2    A_rep2_left.fq    A_rep2_right.fq\n  # cond_B    cond_B_rep1    B_rep1_left.fq    B_rep1_right.fq\n  # cond_B    cond_B_rep2    B_rep2_left.fq    B_rep2_right.fq\n\n\n\n  # Increment by 2 to process next pair of FastQ files\n  for (( i=0; i<${#reads_array[@]} ; i+=2 ))\n  do\n    echo \"\"\n    echo \"Evaluating ${reads_array[i]} and ${reads_array[i+1]}\"\n    get_day \"${reads_array[i]}\"\n    get_inf \"${reads_array[i]}\"\n    get_temp \"${reads_array[i]}\"\n\n    echo \"\"\n    echo \"Got day (${day}), infection status (${inf}), and temp (${temp}).\"\n    echo \"\"\n    echo \"Condition 1 is: ${cond1}\"\n    echo \"condition 2 is: ${cond2}\"\n\n    # Evaluate specified treatment conditions and format sample file list appropriately.\n    if [[ \"${cond1}\" == \"${day}\" || \"${cond1}\" == \"${inf}\" || \"${cond1}\" == \"${temp}\" ]]; then\n      cond1_count=$((cond1_count+1))\n\n\n      echo \"\"\n      echo \"Condition 1 evaluated.\"\n      # Create tab-delimited samples file.\n      printf \"%s\\t%s%02d\\t%s\\t%s\\n\" \"${cond1}\" \"${cond1}_\" \"${cond1_count}\" \"${comparison_dir}${reads_array[i]}\" \"${comparison_dir}${reads_array[i+1]}\" \\\n      >> \"${samples}\"\n    elif [[ \"${cond2}\" == \"${day}\" || \"${cond2}\" == \"${inf}\" || \"${cond2}\" == \"${temp}\" ]]; then\n      cond2_count=$((cond2_count+1))\n\n\n      echo \"\"\n      echo \"Condition 2 evaluated.\"\n      # Create tab-delimited samples file.\n      printf \"%s\\t%s%02d\\t%s\\t%s\\n\" \"${cond2}\" \"${cond2}_\" \"${cond2_count}\" \"${comparison_dir}${reads_array[i]}\" \"${comparison_dir}${reads_array[i+1]}\" \\\n      >> \"${samples}\"\n    fi\n\n    # Copy sample list file to transcriptome directory\n    cp \"${samples}\" \"${transcriptome_dir}\"\n  done\n\n  echo \"Created ${comparison} sample list file.\"\n\n\n  # Create directory/sample list for ${trinity_matrix} command\n  trin_matrix_list=$(awk '{printf \"%s%s\", $2, \"/quant.sf \" }' \"${samples}\")\n\n\n  # Determine transcript abundances using Salmon alignment-free\n  # abundance estimate.\n  ${trinity_abundance} \\\n  --output_dir \"${comparison_dir}\" \\\n  --transcripts ${transcriptome} \\\n  --seqType fq \\\n  --samples_file \"${samples}\" \\\n  --est_method salmon \\\n  --aln_method bowtie2 \\\n  --gene_trans_map \"${gene_map}\" \\\n  --prep_reference \\\n  --thread_count \"${threads}\" \\\n  1> \"${comparison_dir}\"${salmon_stdout} \\\n  2> \"${comparison_dir}\"${salmon_stderr}\n\n  # Convert abundance estimates to matrix\n  ${trinity_matrix} \\\n  --est_method salmon \\\n  --gene_trans_map ${gene_map} \\\n  --out_prefix salmon \\\n  --name_sample_by_basedir \\\n  ${trin_matrix_list} \\\n  1> ${matrix_stdout} \\\n  2> ${matrix_stderr}\n\n  # Integrate Trinotate functional annotations\n  \"${trinity_annotate_matrix}\" \\\n  \"${trinotate_feature_map}\" \\\n  salmon.gene.counts.matrix \\\n  > salmon.gene.counts.annotated.matrix\n\n\n  # Generate weighted gene lengths\n  \"${trinity_tpm_length}\" \\\n  --gene_trans_map \"${gene_map}\" \\\n  --trans_lengths \"${fasta_seq_lengths}\" \\\n  --TPM_matrix \"${salmon_iso_matrix}\" \\\n  > Trinity.gene_lengths.txt \\\n  2> ${tpm_length_stderr}\n\n  # Differential expression analysis\n  # Utilizes edgeR.\n  # Needs to be run in same directory as transcriptome.\n  cd ${transcriptome_dir} || exit\n  ${trinity_DE} \\\n  --matrix \"${comparison_dir}salmon.gene.counts.matrix\" \\\n  --method edgeR \\\n  --samples_file \"${samples}\" \\\n  1> ${trinity_DE_stdout} \\\n  2> ${trinity_DE_stderr}\n\n  mv edgeR* \"${comparison_dir}\"\n\n\n  # Run differential expression on edgeR output matrix\n  # Set fold difference to 2-fold (ie. -C 1 = 2^1)\n  # P value <= 0.05\n  # Has to run from edgeR output directory\n\n  # Pulls edgeR directory name and removes leading ./ in find output\n  # Using find is required because edgeR names directory using PID\n  # and I don't know how to find that out\n  cd \"${comparison_dir}\" || exit\n  edgeR_dir=$(find . -type d -name \"edgeR*\" | sed 's%./%%')\n  cd \"${edgeR_dir}\" || exit\n  mv \"${transcriptome_dir}/${trinity_DE_stdout}\" .\n  mv \"${transcriptome_dir}/${trinity_DE_stderr}\" .\n  ${diff_expr} \\\n  --matrix \"${salmon_gene_matrix}\" \\\n  --samples \"${samples}\" \\\n  --examine_GO_enrichment \\\n  --GO_annots \"${go_annotations}\" \\\n  --include_GOplot \\\n  --gene_lengths \"${comparison_dir}Trinity.gene_lengths.txt\" \\\n  -C 1 \\\n  -P 0.05 \\\n  1> ${diff_expr_stdout} \\\n  2> ${diff_expr_stderr}\n\n\n\n  cd \"${wd}\" || exit\ndone\nFlatten enriched GO terms file (GitHub):\n\ntrinity_deg_to_go.sh\n\n#!/bin/bash\n\n#############################################################\n# Script to \"flatten\" Trinity edgeR GOseq enrichment format\n# so each line contains a single gene/transcript ID\n# and associated GO term\n#############################################################\n\n# Enable globstar for recursive searching\nshopt -s globstar\n\n# Declare variables\noutput_file=\"\"\nwd=$(pwd)\n\n# Input file\n## Expects Trinity edgeR GOseq enrichment format:\n## category over_represented_pvalue under_represented_pvalue    numDEInCat  numInCat    term    ontology    over_represented_FDR    go_term gene_ids\n## Field 10 (gene_ids) contains comma separated gene_ids that fall in the given GO term in the \"category\" column\n\nfor goseq in **/*UP.subset*.enriched\ndo\n    # Capture path to file\n    dir=${goseq%/*}\n\n    cd \"${dir}\" || exit\n\n    tmp_file=$(mktemp)\n\n    # Count lines in file\n  linecount=$(cat \"${goseq}\" | wc -l)\n\n    # If file is not empty\n  if (( \"${linecount}\" > 1 ))\n    then\n        output_file=\"${goseq}.flattened\"\n\n\n        # 1st: Convert comma-delimited gene IDs in column 10 to tab-delimited\n        # Also, set output (OFS) to be tab-delimited\n        # 2nd: Convert spaces to underscores and keep output as tab-delimited\n        # 3rd: Sort on Trinity IDs (column 10) and keep only uniques\n        awk 'BEGIN{FS=\"\\t\";OFS=\"\\t\"} {gsub(/, /, \"\\t\", $10); print}' \"${goseq}\" \\\n        | awk 'BEGIN{F=\"\\t\";OFS=\"\\t\"} NR==1; NR > 1 {gsub(/ /, \"_\", $0); print}' \\\n        > \"${tmp_file}\"\n\n        # Identify the first line number which contains a gene_id\n        begin_goterms=$(grep --line-number \"TRINITY\" \"${tmp_file}\" \\\n        | awk '{for (i=1;i<=NF;i++) if($i ~/TRINITY/) print i}' \\\n        | sort --general-numeric-sort --unique | head -n1)\n\n        # \"Unfolds\" gene_ids to a single gene_id per row\n        while read -r line\n        do\n            # Capture the length of the longest row\n            max_field=$(echo \"$line\" | awk -F \"\\t\" '{print NF}')\n\n            # Retain the first 8 fields (i.e. categories)\n            fixed_fields=$(echo \"$line\" | cut -f1-8)\n\n            # Since not all the lines contain the same number of fields (e.g. may not have GO terms),\n            # evaluate the number of fields in each line to determine how to handle current line.\n\n            # If the value in max_field is less than the field number where the GO terms begin,\n            # then just print the current line (%s) followed by a newline (\\n).\n            if (( \"$max_field\" < \"$begin_goterms\" ))\n            then\n                printf \"%s\\n\" \"$line\"\n            else goterms=$(echo \"$line\" | cut -f\"$begin_goterms\"-\"$max_field\")\n\n          # Assign values in the variable \"goterms\" to a new indexed array (called \"array\"),\n          # with tab delimiter (IFS=$'\\t')\n          IFS=$'\\t' read -r -a array <<<\"$goterms\"\n\n          # Iterate through each element of the array.\n          # Print the first n fields (i.e. the fields stored in \"fixed_fields\") followed by a tab (%s\\t).\n          # Print the current element in the array (i.e. the current GO term) followed by a new line (%s\\n).\n          for element in \"${!array[@]}\"\n          do\n              printf \"%s\\t%s\\n\" \"$fixed_fields\" \"${array[$element]}\"\n          done\n          fi\n        done < \"${tmp_file}\" > \"${output_file}\"\n    fi\n\n  # Cleanup\n  rm \"${tmp_file}\"\n\n    cd \"${wd}\" || exit\ndone\n\n\nRESULTS\nTook about 17.5hrs to run:\n\n\n\nruntime screencap\n\n\nOutput folder:\n\n20200422_cbai_DEG_basic_comparisons/\n\n\n\nD9-D12\nUp-regulated genes:\n\nsalmon.gene.counts.matrix.D12_vs_D9.edgeR.DE_results.P0.05_C1.D9-UP.subset\nsalmon.gene.counts.matrix.D12_vs_D9.edgeR.DE_results.P0.05_C1.D12-UP.subset\n\nEnriched GO terms:\n\nsalmon.gene.counts.matrix.D12_vs_D9.edgeR.DE_results.P0.05_C1.D12-UP.subset.GOseq.enriched\nsalmon.gene.counts.matrix.D12_vs_D9.edgeR.DE_results.P0.05_C1.D9-UP.subset.GOseq.enriched\n\n\n\n\nD9-D12 deg heatmap\n\n\n\n\n\nD9-D12 volcano plot\n\n\n\n\n\nD9-D12 correlation heatmap\n\n\n\n\n\nD9-D26\nUp-regulated genes:\n\nsalmon.gene.counts.matrix.D26_vs_D9.edgeR.DE_results.P0.05_C1.D9-UP.subset\nsalmon.gene.counts.matrix.D26_vs_D9.edgeR.DE_results.P0.05_C1.D26-UP.subset\n\nEnriched GO terms:\n\nsalmon.gene.counts.matrix.D26_vs_D9.edgeR.DE_results.P0.05_C1.D9-UP.subset.GOseq.enriched\nsalmon.gene.counts.matrix.D26_vs_D9.edgeR.DE_results.P0.05_C1.D26-UP.subset.GOseq.enriched\n\n\n\n\nD9-D26 deg heatmap\n\n\n\n\n\nD9-D26 volcano plot\n\n\n\n\n\nD9-D26 correlation heatmap\n\n\n\n\n\nD12-D26\nUp-regulated genes:\n\nsalmon.gene.counts.matrix.D12_vs_D26.edgeR.DE_results.P0.05_C1.D26-UP.subset\nsalmon.gene.counts.matrix.D12_vs_D26.edgeR.DE_results.P0.05_C1.D12-UP.subset\n\nEnriched GO terms:\n\nsalmon.gene.counts.matrix.D12_vs_D26.edgeR.DE_results.P0.05_C1.D26-UP.subset.GOseq.enriched\nsalmon.gene.counts.matrix.D12_vs_D26.edgeR.DE_results.P0.05_C1.D12-UP.subset.GOseq.enriched\n\n\n\n\nD12-D26 deg heatmap\n\n\n\n\n\nD12-D26 volcano plot\n\n\n\n\n\nD12-D26 correlation heatmap\n\n\n\n\n\nambient-cold\nUp-regulated genes:\n\nsalmon.gene.counts.matrix.ambient_vs_cold.edgeR.DE_results.P0.05_C1.cold-UP.subset\nsalmon.gene.counts.matrix.ambient_vs_cold.edgeR.DE_results.P0.05_C1.ambient-UP.subset\n\nEnriched GO terms:\n\nsalmon.gene.counts.matrix.ambient_vs_cold.edgeR.DE_results.P0.05_C1.cold-UP.subset.GOseq.enriched\nsalmon.gene.counts.matrix.ambient_vs_cold.edgeR.DE_results.P0.05_C1.ambient-UP.subset.GOseq.enriched\n\n\n\n\nambient-cold deg heatmap\n\n\n\n\n\nambient-cold volcano plot\n\n\n\n\n\nambient-cold correlation heatmap\n\n\n\n\n\nambient-warm\nUp-regulated genes:\n\nsalmon.gene.counts.matrix.ambient_vs_warm.edgeR.DE_results.P0.05_C1.ambient-UP.subset\nsalmon.gene.counts.matrix.ambient_vs_warm.edgeR.DE_results.P0.05_C1.warm-UP.subset\n\nEnriched GO terms:\n\nsalmon.gene.counts.matrix.ambient_vs_warm.edgeR.DE_results.P0.05_C1.warm-UP.subset.GOseq.enriched\nsalmon.gene.counts.matrix.ambient_vs_warm.edgeR.DE_results.P0.05_C1.ambient-UP.subset.GOseq.enriched\n\n\n\n\nambient-warm deg heatmap\n\n\n\n\n\nambient-warm volcano plot\n\n\n\n\n\nambient-warm correlation heatmap\n\n\n\n\n\ncold-warm\nUp-regulated genes:\n\nsalmon.gene.counts.matrix.cold_vs_warm.edgeR.DE_results.P0.05_C1.warm-UP.subset\nsalmon.gene.counts.matrix.cold_vs_warm.edgeR.DE_results.P0.05_C1.cold-UP.subset\n\nEnriched GO terms:\n\nsalmon.gene.counts.matrix.cold_vs_warm.edgeR.DE_results.P0.05_C1.warm-UP.subset.GOseq.enriched\nsalmon.gene.counts.matrix.cold_vs_warm.edgeR.DE_results.P0.05_C1.cold-UP.subset.GOseq.enriched\n\n\n\n\ncold-warm deg heatmap\n\n\n\n\n\ncold-warm volcano plot\n\n\n\n\n\ncold-warm correlation heatmap\n\n\n\n\n\ninfected-uninfected\nUp-regulated genes:\n\nsalmon.gene.counts.matrix.infected_vs_uninfected.edgeR.DE_results.P0.05_C1.infected-UP.subset\nsalmon.gene.counts.matrix.infected_vs_uninfected.edgeR.DE_results.P0.05_C1.uninfected-UP.subset\n\nEnriched GO terms:\n\nsalmon.gene.counts.matrix.infected_vs_uninfected.edgeR.DE_results.P0.05_C1.uninfected-UP.subset.GOseq.enriched\nsalmon.gene.counts.matrix.infected_vs_uninfected.edgeR.DE_results.P0.05_C1.infected-UP.subset.GOseq.enriched\n\n\n\n\ninfected-uninfected deg heatmap\n\n\n\n\n\ninfected-uninfected volcano plot\n\n\n\n\n\ninfected-uninfected correlation heatmap"
  },
  {
    "objectID": "posts/2020/2020-07-30-Primer-Design-and-In-Silico-Testing---Geoduck-Reproduction-Primers/index.html",
    "href": "posts/2020/2020-07-30-Primer-Design-and-In-Silico-Testing---Geoduck-Reproduction-Primers/index.html",
    "title": "Primer Design and In-Silico Testing - Geoduck Reproduction Primers",
    "section": "",
    "text": "Shelly asked that I re-run the primer design pipeline that Kaitlyn had previously run to design a set of reproduction-related qPCR primers. Unfortunately, Kaitlyn’s Jupyter Notebook wasn’t backed up and she accidentally deleted it, I believe, so there’s no real record of how she designed the primers. However, I do know that she was unable to run the EMBOSS primersearch tool, which will check your primers against a set of sequences for any other matches. This is useful for confirming specificity.\nIn an attempt to replicate what Katilyn previously did, I used the following:\n\nList of sequence IDs from P.generosa genes FastA (GitHub Issue comment from Steven)\nP.generosa genes FastA (OSF repo)\nAbbreviated gene names used to name primers (Google Sheet)\n\nPrimers were designed using Primer3.\nPrimers were checked for specificity, allowing a 20 percent mismatch, using the EMBOSS primersearch program.\nThis was all documented and run in a Jupyter Notebook (GitHub):\n\n20200730_swoose_geoduck_repro_check.ipynb\n\n\n\nRESULTS\nOutput folder:\n\n20200730_pgen_primer_design\n\nThe number of matches identified in the P.generosa genes FastA file for each primer set are in the table below. Note the following:\n\nPrimer sets selected/tested were the first primer set generated by Primer3.\nThere was a 20% mismatch allowed when checking specificity.\nCounts listed in table should be divided by 2 (this is explained in the Jupyter Notebook). Thus, an entry with a value of 2 only has a single match in the entire P.generosa genes FastA file.\n\n\n\n\nSeqID\nPrimerName\nMatches\n\n\n\n\nPGEN_.00g025890-vv0.74.a\nTIF3s12\n2\n\n\nPGEN_.00g070040-vv0.74.a\nAPLP\n2\n\n\nPGEN_.00g188130-vv0.74.a\nFEN1\n2\n\n\nPGEN_.00g194630-vv0.74.a\nECHD3\n2\n\n\nPGEN_.00g338640-vv0.74.a\nNSF\n2\n\n\nPGEN_.00g288180-vv0.74.a\nTIF3s4a\n4\n\n\nPGEN_.00g245080-vv0.74.a\nTIF3s10\n8\n\n\nPGEN_.00g132030-vv0.74.a\nTIF3s8-1\n10\n\n\nPGEN_.00g079690-vv0.74.a\nTIF3s7\n14\n\n\nPGEN_.00g088260-vv0.74.a\nNFIP1\n36\n\n\nPGEN_.00g224740-vv0.74.a\nGLYG\n46\n\n\nPGEN_.00g280110-vv0.74.a\nSPTN1\n496\n\n\nPGEN_.00g082590-vv0.74.a\nTIF3s5\n742\n\n\nPGEN_.00g287540-vv0.74.a\nRPL5\n2570\n\n\nPGEN_.00g132040-vv0.74.a\nTIF3s8-2\n7800\n\n\nPGEN_.00g114060-vv0.74.a\nGSK3B\n8596\n\n\nPGEN_.00g000750-vv0.74.a\nTIF3s6b\n15512"
  },
  {
    "objectID": "posts/2020/2020-12-05-Data-Received---C.gigas-Diploid-Triploid-pH-Treatments-Ctenidia-WGBS-from-ZymoResearch/index.html",
    "href": "posts/2020/2020-12-05-Data-Received---C.gigas-Diploid-Triploid-pH-Treatments-Ctenidia-WGBS-from-ZymoResearch/index.html",
    "title": "Data Received - C.gigas Diploid-Triploid pH Treatments Ctenidia WGBS from ZymoResearch",
    "section": "",
    "text": "Today we received the whole genome bisulfite sequencing (WGBS) from the 24 C.gigas diploid-triploid samples subjected to different pH that were submitted 20200824. The lengthy turnaround time was due to a bad lot of reagents, which forced them Zymo to find a different manufacturer in order to generate libraries.\nSequencing consisted of WGBS 150bp paired end (PE) reads for each library. All files were downloaded to the C_gigas folder on Owl(Synology server). MD5 checksums were confirmed:\n\n\n\nscreencap of md5 checksum verification\n\n\nPrincipal spreadsheet for this project was updated (Google Sheet):\n\n20200816_hawaii_ploidy_samples\n\nHave added files to our high-throughput sequencing database (Google Sheet):\n\nnightingales\n\nNext up:\n\nFastQC\nSubmit to NCBI sequence read archive (SRA).\n\n\n\n\nZymo_ID\nSample_ID\nPloidy\npH_treatment\n\n\n\n\nzr3644_1\n2N_HI_5\ndiploid\nhigh\n\n\nzr3644_2\n2N_HI_8\ndiploid\nhigh\n\n\nzr3644_3\n2N_HI_9\ndiploid\nhigh\n\n\nzr3644_4\n2N_HI_10\ndiploid\nhigh\n\n\nzr3644_5\n2N_HI_11\ndiploid\nhigh\n\n\nzr3644_6\n2N_HI_12\ndiploid\nhigh\n\n\nzr3644_7\n2N_LOW_1\ndiploid\nlow\n\n\nzr3644_8\n2N_LOW_2\ndiploid\nlow\n\n\nzr3644_9\n2N_LOW_3\ndiploid\nlow\n\n\nzr3644_10\n2N_LOW_4\ndiploid\nlow\n\n\nzr3644_11\n2N_LOW_5\ndiploid\nlow\n\n\nzr3644_12\n2N_LOW_6\ndiploid\nlow\n\n\nzr3644_13\n3N_HI_2\ntriploid\nhigh\n\n\nzr3644_14\n3N_HI_3\ntriploid\nhigh\n\n\nzr3644_15\n3N_HI_5\ntriploid\nhigh\n\n\nzr3644_16\n3N_HI_8\ntriploid\nhigh\n\n\nzr3644_17\n3N_HI_10\ntriploid\nhigh\n\n\nzr3644_18\n3N_HI_11\ntriploid\nhigh\n\n\nzr3644_19\n3N_LOW_6\ntriploid\nlow\n\n\nzr3644_20\n3N_LOW_7\ntriploid\nlow\n\n\nzr3644_21\n3N_LOW_8\ntriploid\nlow\n\n\nzr3644_22\n3N_LOW_10\ntriploid\nlow\n\n\nzr3644_23\n3N_LOW_11\ntriploid\nlow\n\n\nzr3644_24\n3N_LOW_12\ntriploid\nlow"
  },
  {
    "objectID": "posts/2020/2020-09-24-Assembly-Assessment---BUSCO-C.bairdi-Genome-v1.01-on-Mox/index.html",
    "href": "posts/2020/2020-09-24-Assembly-Assessment---BUSCO-C.bairdi-Genome-v1.01-on-Mox/index.html",
    "title": "Assembly Assessment - BUSCO C.bairdi Genome v1.01 on Mox",
    "section": "",
    "text": "After creating a subset of the cbai_genome_v1.0 of contigs >100bp yesterday (subset named cbai_genome_v1.01), I wanted to generate BUSCO scores for cbai_genome_v1.01. This is primarily just to keep info consistent on our Genomic Resources wiki, as I don’t expect these scores to differ at all from the cbai_genome_v1.0 BUSCO scores.\nAnalysis was run on Mox.\nSBATCH script (GitHub):\n\n20200924_cbai_genome_v1.01_busco.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_genome_v1.01_busco\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=3-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200924_cbai_genome_v1.01_busco\n###################################################################################\n\n# Script to generate BUSCO score(s) for genome(s).\n\n\n\n# These variables need to be set by user\n\n## Save working directory\nwd=$(pwd)\n\n# Genomes directory\ngenomes_dir=/gscratch/srlab/sam/data/C_bairdi/genomes\n\n# Genomes array\ngenomes_array=(\n\"${genomes_dir}\"/cbai_genome_v1.01.fasta \\\n)\n\n\n\n## Input files and settings\nbusco_db=/gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9\naugustus_species=fly\nthreads=28\n\n# Programs associative array\ndeclare -A programs_array\nprograms_array=(\n[busco]=\"/gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py\"\n)\n\n\n## Set program paths\naugustus_bin=/gscratch/srlab/programs/Augustus-3.3.2/bin\naugustus_orig_config_dir=/gscratch/srlab/programs/Augustus-3.3.2/config\naugustus_scripts=/gscratch/srlab/programs/Augustus-3.3.2/scripts\nblast_dir=/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin/\nhmm_dir=/gscratch/srlab/programs/hmmer-3.2.1/src/\n\n# Export Augustus variable\nexport PATH=\"${augustus_bin}:$PATH\"\nexport PATH=\"${augustus_scripts}:$PATH\"\n\n## BUSCO configs\nbusco_config_default=/gscratch/srlab/programs/busco-v3/config/config.ini.default\nbusco_config_ini=${wd}/config.ini\n\n# Export BUSCO config file location\nexport BUSCO_CONFIG_FILE=\"${busco_config_ini}\"\n\n# Copy BUSCO config file\ncp ${busco_config_default} \"${busco_config_ini}\"\n\n# Edit BUSCO config file\n## Set paths to various programs\n### The use of the % symbol sets the delimiter sed uses for arguments.\n### Normally, the delimiter that most examples use is a slash \"/\".\n### But, we need to expand the variables into a full path with slashes, which screws up sed.\n### Thus, the use of % symbol instead (it could be any character that is NOT present in the expanded variable; doesn't have to be \"%\").\nsed -i \"/^;cpu/ s/1/${threads}/\" \"${busco_config_ini}\"\nsed -i \"/^tblastn_path/ s%tblastn_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^makeblastdb_path/ s%makeblastdb_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^augustus_path/ s%augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^etraining_path/ s%etraining_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^gff2gbSmallDNA_path/ s%gff2gbSmallDNA_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^new_species_path/ s%new_species_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^optimize_augustus_path/ s%optimize_augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^hmmsearch_path/ s%hmmsearch_path = /home/osboxes/BUSCOVM/hmmer/hmmer-3.1b2-linux-intel-ia32/binaries/%path = ${hmm_dir}%\" \"${busco_config_ini}\"\n\n###################################################################################\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Load Open MPI module for parallel, multi-node processing\nmodule load icc_19-ompi_3.1.2\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\nfor genome in \"${!genomes_array[@]}\"\ndo\n\n  # Remove path from genome using parameter substitution\n  genome_name=\"${genomes_array[$genome]##*/}\"\n\n  ## Augustus config directories\n  augustus_dir=${wd}/${genome_name}_augustus\n  augustus_config_dir=${augustus_dir}/config\n\n\n  export AUGUSTUS_CONFIG_PATH=\"${augustus_config_dir}\"\n\n\n  # Make Augustus directory if it doesn't exist\n  if [ ! -d \"${augustus_dir}\" ]; then\n    mkdir --parents \"${augustus_dir}\"\n  fi\n\n  # Copy Augustus config directory\n  cp --preserve -r ${augustus_orig_config_dir} \"${augustus_dir}\"\n\n\n  # Run BUSCO/Augustus training\n  ${programs_array[busco]} \\\n  --in ${genomes_array[$genome]} \\\n  --out ${genome_name} \\\n  --lineage_path ${busco_db} \\\n  --mode genome \\\n  --cpu ${threads} \\\n  --long \\\n  --species ${augustus_species} \\\n  --tarzip \\\n  --augustus_parameters='--progress=true'\n\n  # Capture FastA checksums for verification\n  echo \"\"\n  echo \"Generating checksum for ${genome_name}\"\n  md5sum \"${genomes_array[$genome]}\" > \"${genome_name}\".checksum.md5\n  echo \"Finished generating checksum for ${genome_name}\"\n  echo \"\"\n\ndone\n\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n    ${programs_array[$program]} --help\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n\nRESULTS\nAs usual, very fast, ~1.5mins:\n\n\n\nBUSCO runtime on Mox\n\n\nOutput folder:\n\n20200924_cbai_genome_v1.01_busco/\n\n20200924_cbai_genome_v1.01_busco/run_cbai_genome_v1.01.fasta/short_summary_cbai_genome_v1.01.fasta.txt\n\n\n# BUSCO version is: 3.0.2\n# The lineage dataset is: metazoa_odb9 (Creation date: 2016-02-13, number of species: 65, number of BUSCOs: 978)\n# To reproduce this run: python /gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py -i /gscratch/srlab/sam/data/C_bairdi/genomes/cbai_genome_v1.01.fasta -o cbai_genome_v1.01.fasta -l /gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9/ -m genome -c 28 --long -z -sp fly --augustus_parameters '--progress=true'\n#\n# Summarized benchmarking in BUSCO notation for file /gscratch/srlab/sam/data/C_bairdi/genomes/cbai_genome_v1.01.fasta\n# BUSCO was run in mode: genome\n\n    C:0.4%[S:0.3%,D:0.1%],F:0.2%,M:99.4%,n:978\n\n    4   Complete BUSCOs (C)\n    3   Complete and single-copy BUSCOs (S)\n    1   Complete and duplicated BUSCOs (D)\n    2   Fragmented BUSCOs (F)\n    972 Missing BUSCOs (M)\n    978 Total BUSCO groups searched\nAs expected, no differences in BUSCO scores between cbai_genome_v1.0 and cbai_genome_v1.01. Will add info to Genomic Resources wiki."
  },
  {
    "objectID": "posts/2020/2020-09-28-Taxonomic-Assignments---C.bairdi-6129-403-26-Q7-NanoPore-Reads-Using-DIAMOND-BLASTx-on-Mox-and-MEGAN6-daa2rma-on-emu/index.html",
    "href": "posts/2020/2020-09-28-Taxonomic-Assignments---C.bairdi-6129-403-26-Q7-NanoPore-Reads-Using-DIAMOND-BLASTx-on-Mox-and-MEGAN6-daa2rma-on-emu/index.html",
    "title": "Taxonomic Assignments - C.bairdi 6129-403-26-Q7 NanoPore Reads Using DIAMOND BLASTx on Mox and MEGAN6 daa2rma on emu",
    "section": "",
    "text": "After noticing that the initial MEGAN6 taxonomic assignments for our combined C.bairdi NanoPore data from 20200917 revealed a high number of bases assigned to E.canceri and Aquifex sp., I decided to explore the taxonomic breakdown of just the individual samples to see which of the samples was contributing to these taxonomic assignments most.\nRan the Hematodinium-infected (6129_403_26_Q7) hemolymph NanoPore sequencing data through DIAMOND BLASTx (on Mox) and subsequent output conversion to the MEGAN6 RMA6 format (on swoose due to program Java X11 requirement which is not functional on Mox) to obtain taxonomic assignments.\nSBATCH script (GitHub):\n\n20200928_cbai_diamond_blastx_nanopore_6129_403_26_Q7.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_blastx_DIAMOND_nanopore_6129_403_26_Q7\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=200G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200928_cbai_diamond_blastx_nanopore_6129_403_26_Q7\n\n# Script to run DIAMOND BLASTx on 6129_403_26 quality filtered (Q7) C.bairdi NanoPore reads\n# from 20200928 using the --long-reads option\n# for subsequent import into MEGAN6 to evaluate reads taxonomically.\n\n###################################################################################\n# These variables need to be set by user\n\n# Input FastQ file\nfastq=/gscratch/srlab/sam/data/C_bairdi/DNAseq/20200928_cbai_nanopore_6129_403_26_quality-7.fastq\n\n# DIAMOND Output filename prefix\nprefix=20200928_cbai_nanopore_6129_403_26_Q7\n\n# Set number of CPUs to use\nthreads=28\n\n# Program paths\ndiamond=/gscratch/srlab/programs/diamond-2.0.4/diamond\n\n# DIAMOND NCBI nr database with taxonomy dumps\ndmnd_db=/gscratch/srlab/blastdbs/ncbi-nr-20190925/nr.dmnd\n\n\n###################################################################################\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n\n# Inititalize arrays\nprograms_array=()\n\n\n# Programs array\nprograms_array=(\"${diamond}\")\n\n\nmd5sum \"${fastq}\" > fastq_checksums.md5\n\n\n# Run DIAMOND with blastx\n# Output format 6 produces a standard BLAST tab-delimited file\n# Run DIAMOND with blastx\n# Output format 100 produces a DAA binary file for use with MEGAN\n${diamond} blastx \\\n--long-reads \\\n--db ${dmnd_db} \\\n--query \"${fastq}\" \\\n--out \"${prefix}\".blastx.daa \\\n--outfmt 100 \\\n--top 5 \\\n--block-size 8.0 \\\n--index-chunks 1 \\\n--threads ${threads}\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${programs_array[program]}: \"\n    echo \"\"\n    ${programs_array[program]} help\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\nBash script (GitHub) for daa2rma on Emu:\n\n20200928_cbai_nanopore_6129-403-26-Q7_diamond_blastx_daa2rma.sh\n\n#!/bin/bash\n\n# Script to run MEGAN6 daa2rma on DIAMOND DAA files from\n# 20200928_cbai_diamond_blastx_nanopore_6129_403_26_Q7.\n# Utilizes the --longReads option\n\n# Requires MEGAN mapping file from:\n# http://ab.inf.uni-tuebingen.de/data/software/megan6/download/\n\n\n# MEGAN mapping file\nmegan_map=/home/sam/data/databases/MEGAN6/megan-map-Jul2020-2.db\n\n# Programs array\ndeclare -A programs_array\nprograms_array=(\n[daa2rma]=\"/home/shared/megan_6.19.9/tools/daa2rma\"\n)\n\nthreads=16\n\n#########################################################################\n\n# Exit script if any command fails\nset -e\n\n\n## Run daa2rma\n\n# Capture start \"time\"\n# Uses builtin bash variable called ${SECONDS}\nstart=${SECONDS}\n\nfor daa in *.daa\ndo\n  start_loop=${SECONDS}\n  sample_name=$(basename --suffix \".blastx.daa\" \"${daa}\")\n\n  echo \"Now processing ${sample_name}.daa2rma.rma6\"\n  echo \"\"\n\n  # Run daa2rma with long reads option\n  ${programs_array[daa2rma]} \\\n  --in \"${daa}\" \\\n  --longReads \\\n  --mapDB ${megan_map} \\\n  --out \"${sample_name}\".daa2rma.rma6 \\\n  --threads ${threads} \\\n  2>&1 | tee --append daa2rma_log.txt\n\n  end_loop=${SECONDS}\n  loop_runtime=$((end_loop-start_loop))\n\n\n  echo \"Finished processing ${sample_name}.daa2rma.rma6 in ${loop_runtime} seconds.\"\n  echo \"\"\n\ndone\n\n# Caputure end \"time\"\nend=${SECONDS}\n\nruntime=$((end-start))\n\n# Print daa2rma runtime, in seconds\n\n{\n  echo \"\"\n  echo \"---------------------\"\n  echo \"\"\n  echo \"Total runtime was: ${runtime} seconds\"\n} >> daa2rma_log.txt\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n    ${programs_array[$program]} --help\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n# Document programs in PATH\n{\ndate\necho \"\"\necho \"System PATH:\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nRESULTS\nPretty quick, a little over 31mins:\n\n\n\nDIAMOND BLASTx and MEGAN daa2rma conversion for 6129-403-26-Q7 runtime\n\n\nDIAMOND BLASTx Output folder:\n\n20200928_cbai_nanopore_6129-403-26-Q7_diamond_blastx_daa2rma/\n\nDIAMOND BLASTx DAA file:\n\n20200928_cbai_nanopore_6129-403-26-Q7_diamond_blastx_daa2rma/20200928_cbai_nanopore_6129-403-26_Q7.blastx.daa (265MB)\n\nRMA6 file:\n\n20200928_cbai_nanopore_6129-403-26-Q7_diamond_blastx_daa2rma/20200928_cbai_nanopore_6129-403-26_Q7.daa2rma.rma6 (256MB)\n\n\n\n\nTaxonomic tree\n\n\n\n6129-403-26-Q7 MEGAN6 taxonomic assignments\n\n\nAlrighty, we see both Alveolata/Hematodinium sp., E.canceri_ Aquifex sp. taxonomic assignments (and, of course Arthropoda).\nA large number of bases (~34Mbp) are assigned to Arthropoda. Alveolata only has ~400kbp assigned, while E.canceri has ~17Mbp (!) and Aquifex sp. has ~6Mbp!\nVery surprising.\nThe other sample is here.\nNext, I’ll run a comparison of the two sets of sequencing read taxonomic assignments for an easier overview."
  },
  {
    "objectID": "posts/2020/2020-12-02-Trimming---Ronits-C.gigas-Ploidy-WGBS-10bp-5-and-3-Prime-Ends-Using-fastp-and-MultiQC-on-Mox/index.html",
    "href": "posts/2020/2020-12-02-Trimming---Ronits-C.gigas-Ploidy-WGBS-10bp-5-and-3-Prime-Ends-Using-fastp-and-MultiQC-on-Mox/index.html",
    "title": "Trimming - Ronits C.gigas Ploidy WGBS 10bp 5 and 3 Prime Ends Using fastp and MultiQC on Mox",
    "section": "",
    "text": "Steven asked me to trim (GitHub Issue) Ronit’s WGBS sequencing data we received on 20201110, according to Bismark guidelines for libraries made with the ZymoResearch Pico MethylSeq Kit.\nI trimmed the files using fastp.\nThe trimming trims adapters and 10bp from both the 5’ and 3’ ends of each read.\nI previously ran a trimming where I trimmed only from the 5’ end. Reading the Bismark documentation more carefully, the documentation suggests that a user “should probably perform 3’ trimming”. So, I’m doing that here.\nJob was run on Mox.\nSBATCH script (GitHub):\n\n20201202_cgig_fastp-10bp-5-3-prime_ronit-ploidy-wgbs.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=20201202_cgig_fastp-10bp-5-3-prime_ronit-ploidy-wgbs\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20201202_cgig_fastp-10bp-5-3-prime_ronit-ploidy-wgbs\n\n\n### Fastp trimming of Ronit's ploidy WGBS.\n\n### Trims adapters, 10bp from 5' and 3' ends of reads\n\n### Trimming is performed according to recommendation for use with Bismark\n### for libraries created using ZymoResearch Pico MethylSeq Kit:\n### https://github.com/FelixKrueger/Bismark/blob/master/Docs/README.md#ix-notes-about-different-library-types-and-commercial-kits\n\n\n### Expects input filenames to be in format: zr3534_3_R1.fq.gz\n\n\n###################################################################################\n# These variables need to be set by user\n\n## Assign Variables\n\n# Set number of CPUs to use\nthreads=27\n\n# Input/output files\ntrimmed_checksums=trimmed_fastq_checksums.md5\nraw_reads_dir=/gscratch/srlab/sam/data/C_gigas/wgbs/\nfastq_checksums=raw_fastq_checksums.md5\n\n# Paths to programs\nfastp=/gscratch/srlab/programs/fastp-0.20.0/fastp\nmultiqc=/gscratch/srlab/programs/anaconda3/bin/multiqc\n\n## Inititalize arrays\nfastq_array_R1=()\nfastq_array_R2=()\nR1_names_array=()\nR2_names_array=()\n\n\n# Programs associative array\ndeclare -A programs_array\nprograms_array=(\n[fastp]=\"${fastp}\" \\\n[multiqc]=\"${multiqc}\"\n)\n\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Capture date\ntimestamp=$(date +%Y%m%d)\n\n# Sync raw FastQ files to working directory\nrsync --archive --verbose \\\n\"${raw_reads_dir}\"zr3534*.fq.gz .\n\n# Create arrays of fastq R1 files and sample names\nfor fastq in *R1.fq.gz\ndo\n  fastq_array_R1+=(\"${fastq}\")\n    R1_names_array+=(\"$(echo \"${fastq}\" | awk 'BEGIN {FS = \"[_.]\"; OFS = \"_\"} {print $1, $2, $3}')\")\ndone\n\n# Create array of fastq R2 files\nfor fastq in *R2.fq.gz\ndo\n  fastq_array_R2+=(\"${fastq}\")\n    R2_names_array+=(\"$(echo \"${fastq}\" | awk 'BEGIN {FS = \"[_.]\"; OFS = \"_\"} {print $1, $2, $3}')\")\ndone\n\n\n# Run fastp on files\n# Trim 10bp from 5' from each read\n# Adds JSON report output for downstream usage by MultiQC\nfor index in \"${!fastq_array_R1[@]}\"\ndo\n  R1_sample_name=$(echo \"${R1_names_array[index]}\")\n    R2_sample_name=$(echo \"${R2_names_array[index]}\")\n    ${fastp} \\\n    --in1 ${fastq_array_R1[index]} \\\n    --in2 ${fastq_array_R2[index]} \\\n    --detect_adapter_for_pe \\\n  --detect_adapter_for_pe \\\n  --trim_front1 10 \\\n  --trim_front2 10 \\\n  --trim_tail1 10 \\\n  --trim_tail2 10 \\\n    --thread ${threads} \\\n    --html \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".report.html \\\n    --json \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".report.json \\\n    --out1 \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz \\\n    --out2 \"${R2_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz\n\n    # Generate md5 checksums for newly trimmed files\n    {\n        md5sum \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz\n        md5sum \"${R2_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz\n    } >> \"${trimmed_checksums}\"\n\n  # Create list of fastq files used in analysis\n  # Create MD5 checksum for reference\n  echo \"${fastq_array_R1[index]}\" >> input.fastq.list.txt\n  echo \"${fastq_array_R2[index]}\" >> input.fastq.list.txt\n  md5sum \"${fastq_array_R1[index]}\" >> ${fastq_checksums}\n  md5sum \"${fastq_array_R2[index]}\" >> ${fastq_checksums}\n\n    # Remove original FastQ files\n    rm \"${fastq_array_R1[index]}\" \"${fastq_array_R2[index]}\"\ndone\n\n# Run MultiQC\n${multiqc} .\n\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n  # Handle samtools help menus\n  if [[ \"${program}\" == \"samtools_index\" ]] \\\n  || [[ \"${program}\" == \"samtools_sort\" ]] \\\n  || [[ \"${program}\" == \"samtools_view\" ]]\n  then\n    ${programs_array[$program]}\n  fi\n    ${programs_array[$program]} -h\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\n\n  # If MultiQC is in programs_array, copy the config file to this directory.\n  if [[ \"${program}\" == \"multiqc\" ]]; then\n    cp --preserve ~/.multiqc_config.yaml multiqc_config.yaml\n  fi\ndone\n\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nRESULTS\nRuntime was actually faster than just the 10bp 5’ trimming from the other day; just over 2hrs:\n\n\n\nfastp runtime\n\n\nNOTE: The report files (MultiQC and fastp) all suffer from a naming error, but do contain data for both read 1 (R1) and read 2 (R2).\nOutput folder:\n\n20201202_cgig_fastp-10bp-5-3-prime_ronit-ploidy-wgbs/\nMultiQC report (HTML; open with web browser):\n\n20201202_cgig_fastp-10bp-5-3-prime_ronit-ploidy-wgbs/multiqc_report.html\n\n[fastp] Reports (HTML; open in web browser):\n\nzr3534_10_R1.fastp-trim.20201202.report.html\nzr3534_1_R1.fastp-trim.20201202.report.html\nzr3534_2_R1.fastp-trim.20201202.report.html\nzr3534_3_R1.fastp-trim.20201202.report.html\nzr3534_4_R1.fastp-trim.20201202.report.html\nzr3534_5_R1.fastp-trim.20201202.report.html\nzr3534_6_R1.fastp-trim.20201202.report.html\nzr3534_7_R1.fastp-trim.20201202.report.html\nzr3534_8_R1.fastp-trim.20201202.report.html\nzr3534_9_R1.fastp-trim.20201202.report.html\n\nTrimmed FastQ files (gzipped):\n\nzr3534_10_R1.fastp-trim.20201202.fq.gz (4.0G)\n\nMD5: a16658d4c034361963a6def0ff266189\n\nzr3534_10_R2.fastp-trim.20201202.fq.gz (4.0G)\n\nMD5: 8a994705dada067c8440aba9fe9d23f4\n\nzr3534_1_R1.fastp-trim.20201202.fq.gz (3.9G)\n\nMD5: 9c0a247865d2c4f508f285c7835c09e4\n\nzr3534_1_R2.fastp-trim.20201202.fq.gz (4.0G)\n\nMD5: aa4b80519c65404867c91aa037bb7aa0\n\nzr3534_2_R1.fastp-trim.20201202.fq.gz (3.9G)\n\nMD5: c0bb9cf83cec7d2e52c1e43300da6d4e\n\nzr3534_2_R2.fastp-trim.20201202.fq.gz (4.0G)\n\nMD5: 4208221b6ad68f1f75c031a4b376a68d\n\nzr3534_3_R1.fastp-trim.20201202.fq.gz (4.0G)\n\nMD5: 5362e40e1a021655116d6419bcfd0e8c\n\nzr3534_3_R2.fastp-trim.20201202.fq.gz (4.1G)\n\nMD5: df82bdae0560fbb879dbcb1820072df5\n\nzr3534_4_R1.fastp-trim.20201202.fq.gz (4.0G)\n\nMD5: c26217872bb0c67b7fc2c117aa455f6c\n\nzr3534_4_R2.fastp-trim.20201202.fq.gz (3.9G)\n\nMD5: d59224bf610b1cf55515fe19b0d3acc0\n\nzr3534_5_R1.fastp-trim.20201202.fq.gz (4.3G)\n\nMD5: e585a649d232f24ac12d272cff970eaf\n\nzr3534_5_R2.fastp-trim.20201202.fq.gz (4.4G)\n\nMD5: 876bcdc27fed414a3d130a0061973fac\n\nzr3534_6_R1.fastp-trim.20201202.fq.gz (3.8G)\n\nMD5: 3347544555a559f8e5b263d71635f525\n\nzr3534_6_R2.fastp-trim.20201202.fq.gz (4.0G)\n\nMD5: b57dc21e6d77f1b838398b8bccad6d73\n\nzr3534_7_R1.fastp-trim.20201202.fq.gz (3.5G)\n\nMD5: 79c2fd1f561254546a2472a5576d0d1d\n\nzr3534_7_R2.fastp-trim.20201202.fq.gz (3.5G)\n\nMD5: 8f46aa267de3f0cbd43636220187a034\n\nzr3534_8_R1.fastp-trim.20201202.fq.gz (5.0G)\n\nMD5: df74f3d43e3e9c695f7cb2f5aca4dedb\n\nzr3534_8_R2.fastp-trim.20201202.fq.gz (4.6G)\n\nMD5: 88ed7c05649cf08e0cf74ce5db5bdb2a\n\nzr3534_9_R1.fastp-trim.20201202.fq.gz (3.8G)\n\nMD5: c95c26e4b9cc9cc09265ddff41a9b32f\n\nzr3534_9_R2.fastp-trim.20201202.fq.gz (3.8G)\n\nMD5: f3b82d620ebda578a5e70314bcf2bcdb"
  },
  {
    "objectID": "posts/2020/2020-04-14-FastQC-MultiQC---C.bairdi-Raw-RNAseq-from-NWGSC/index.html",
    "href": "posts/2020/2020-04-14-FastQC-MultiQC---C.bairdi-Raw-RNAseq-from-NWGSC/index.html",
    "title": "FastQC-MultiQC - C.bairdi Raw RNAseq from NWGSC",
    "section": "",
    "text": "Yesterday, we received the last of the RNAseq data for the C.bairdi crab project from NWGSC. FastQC, followed by MultiQC was run on the raw FastQ reads on my computer (swoose).\n\n\nRESULTS\nOutput folder:\n\n20200414_cbai_RNAseq_fastqc_multiqc/\n\nMultiQC report (HTML):\n\n20200414_cbai_RNAseq_fastqc_multiqc/multiqc_report.html\n\nWill get the FastQC results URLs put in the nightingales Google Sheet."
  },
  {
    "objectID": "posts/2020/2020-05-27-Transcriptome-Annotation---C.bairdi-Transcriptome-v1.7-Using-DIAMOND-BLASTx-on-Mox/index.html",
    "href": "posts/2020/2020-05-27-Transcriptome-Annotation---C.bairdi-Transcriptome-v1.7-Using-DIAMOND-BLASTx-on-Mox/index.html",
    "title": "Transcriptome Annotation - C.bairdi Transcriptome v1.7 Using DIAMOND BLASTx on Mox",
    "section": "",
    "text": "As part of annotating cbai_transcriptome_v1.7.fasta from 20200527, I need to run DIAMOND BLASTx to use with Trinotate.\nRan DIAMOND BLASTx against the UniProt/SwissProt database (downloaded 20200123) on Mox.\nSBATCH script (GitHub):\n\n20200527_cbai_diamond_blastx_transcriptome_v1.7.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=blastx_DIAMOND_cbai-v1.7\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200527_cbai_diamond_blastx_transcriptome_v1.7\n\n### BLASTx of Trinity de novo assembly of all C.bairdi pooled RNAseq data, Arthropoda only:\n### cbai_transcriptome_v1.7.fasta\n### Includes \"descriptor_1\" short-hand of: 2020-UW, 2019, 2018.\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\n# Program paths\ndiamond=/gscratch/srlab/programs/diamond-0.9.29/diamond\n\n# DIAMOND UniProt database\ndmnd=/gscratch/srlab/blastdbs/uniprot_sprot_20200123/uniprot_sprot.dmnd\n\n\n# Trinity assembly (FastA)\nfasta=/gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v1.7.fasta\n\n# Strip leading path and extensions\nno_path=$(echo \"${fasta##*/}\")\nno_ext=$(echo \"${no_path%.*}\")\n\n# Run DIAMOND with blastx\n# Output format 6 produces a standard BLAST tab-delimited file\n${diamond} blastx \\\n--db ${dmnd} \\\n--query \"${fasta}\" \\\n--out \"${no_ext}\".blastx.outfmt6 \\\n--outfmt 6 \\\n--evalue 1e-4 \\\n--max-target-seqs 1 \\\n--block-size 15.0 \\\n--index-chunks 4\n\n\nRESULTS\nAs usual, ridiculously fast - 6 seconds!\n\n\n\ncbai v1.7 diamond blastx runtime\n\n\nOutput folder:\n\n20200527_cbai_diamond_blastx_transcriptome_v1.7/\n\nBLASTx output (outfmt6; text; 1.9MB):\n\n20200527_cbai_diamond_blastx_transcriptome_v1.7/cbai_transcriptome_v1.6.blastx.outfmt6"
  },
  {
    "objectID": "posts/2020/2020-05-27-TransDecoder---C.bairdi-Transcriptome-v1.7-on-Mox/index.html",
    "href": "posts/2020/2020-05-27-TransDecoder---C.bairdi-Transcriptome-v1.7-on-Mox/index.html",
    "title": "TransDecoder - C.bairdi Transcriptome v1.7 on Mox",
    "section": "",
    "text": "Need to run TransDecoder on Mox on the C.bairdi transcriptome v1.7 from 20200527.\nSBATCH script (GitHub):\n\n20200519_cbai_transdecoder_transcriptome-v1.7.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=transdecoder_cbai\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=8-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200527_cbai_transdecoder_transcriptome-v1.7\n\n\n# Exit script if a command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# Set workind directory as current directory\nwd=\"$(pwd)\"\n\n\n# Set input file locations\ntrinity_fasta=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v1.7.fasta\"\ntrinity_gene_map=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v1.7.fasta.gene_trans_map\"\n\n\n# Capture trinity file name\ntrinity_fasta_name=${trinity_fasta##*/}\n\n\n\n# Paths to input/output files\nblastp_out_dir=\"${wd}/blastp_out\"\ntransdecoder_out_dir=\"${wd}/${trinity_fasta_name}.transdecoder_dir\"\npfam_out_dir=\"${wd}/pfam_out\"\nblastp_out=\"${blastp_out_dir}/${trinity_fasta_name}.blastp.outfmt6\"\npfam_out=\"${pfam_out_dir}/${trinity_fasta_name}.pfam.domtblout\"\nlORFs_pep=\"${transdecoder_out_dir}/longest_orfs.pep\"\npfam_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/Pfam-A.hmm\"\nsp_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/uniprot_sprot.pep\"\n\n\n\n# Paths to programs\nblast_dir=\"/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin\"\nblastp=\"${blast_dir}/blastp\"\nhmmer_dir=\"/gscratch/srlab/programs/hmmer-3.2.1/src\"\nhmmscan=\"${hmmer_dir}/hmmscan\"\ntransdecoder_dir=\"/gscratch/srlab/programs/TransDecoder-v5.5.0\"\ntransdecoder_lORFs=\"${transdecoder_dir}/TransDecoder.LongOrfs\"\ntransdecoder_predict=\"${transdecoder_dir}/TransDecoder.Predict\"\n\n# Capture FastA MD5 checksum for future reference\nmd5sum \"${trinity_fasta}\" >> \"${trinity_fasta_name}\".checksum.md5\n\n# Make output directories\nmkdir \"${blastp_out_dir}\"\nmkdir \"${pfam_out_dir}\"\n\n# Extract long open reading frames\n\"${transdecoder_lORFs}\" \\\n--gene_trans_map \"${trinity_gene_map}\" \\\n-t \"${trinity_fasta}\"\n\n# Run blastp on long ORFs\n\"${blastp}\" \\\n-query \"${lORFs_pep}\" \\\n-db \"${sp_db}\" \\\n-max_target_seqs 1 \\\n-outfmt 6 \\\n-evalue 1e-5 \\\n-num_threads 28 \\\n> \"${blastp_out}\"\n\n# Run pfam search\n\"${hmmscan}\" \\\n--cpu 28 \\\n--domtblout \"${pfam_out}\" \\\n\"${pfam_db}\" \\\n\"${lORFs_pep}\"\n\n# Run Transdecoder with blastp and Pfam results\n\"${transdecoder_predict}\" \\\n-t \"${trinity_fasta}\" \\\n--retain_pfam_hits \"${pfam_out}\" \\\n--retain_blastp_hits \"${blastp_out}\"\n\n\nRESULTS\nTook about 4hrs:\n\n\n\ncbai v1.7 transdecoder runtime\n\n\nOutput folder:\n\n20200527_cbai_transdecoder_transcriptome-v1.7/\n\nCoding Sequences (FastA):\n\ncbai_transcriptome_v1.7.fasta.transdecoder.cds\n\nPeptide Sequences (FastA):\n\ncbai_transcriptome_v1.7.fasta.transdecoder.pep\n\nBLASTp output (tab):\n\n20200527_cbai_transdecoder_transcriptome-v1.7/blastp_out/20200519.cbai.blastp.outfmt6\n\nPfam output:\n\n20200527_cbai_transdecoder_transcriptome-v1.7/pfam_out/20200519.cbai.pfam.domtblout\n\nWill get ready to run Trinotate with these output files."
  },
  {
    "objectID": "posts/2020/2020-05-18-Data-Wrangling---Arthropoda-and-Alveolata-D26-Pool-RNAseq-FastQ-Extractions/index.html",
    "href": "posts/2020/2020-05-18-Data-Wrangling---Arthropoda-and-Alveolata-D26-Pool-RNAseq-FastQ-Extractions/index.html",
    "title": "Data Wrangling - Arthropoda and Alveolata D26 Pool RNAseq FastQ Extractions",
    "section": "",
    "text": "After using MEGAN6 to extract Arthropoda and Alveolata reads from our RNAseq data on 20200114, I had then extracted taxonomic-specific reads and aggregated each into basic Read 1 and Read 2 FastQs to simplify transcriptome assembly for C.bairdi and for Hematodinium. That was fine and all, but wasn’t fully thought through.\nFor completeness, I realized that I had not run this taxonomic extraction on the 2018 RNAseq data.\nFor reference, these only include RNAseq data using a newly established “shorthand”: 2018)\nAs a reminder, the reason I’m doing this is that I realized that the FastA headers were incomplete and did not distinguish between paired reads. Here’s an example:\nR1 FastQ header:\n@A00147:37:HG2WLDMXX:1:1101:5303:1000 1:N:0:AGGCGAAG+AGGCGAAG\nR2 FastQ header:\n@A00147:37:HG2WLDMXX:1:1101:5303:1000 2:N:0:AGGCGAAG+AGGCGAAG\nHowever, the reads extracted via MEGAN have FastA headers like this:\n>A00147:37:HG2WLDMXX:1:1101:5303:1000\nSEQUENCE1\n>A00147:37:HG2WLDMXX:1:1101:5303:1000\nSEQUENCE2\nThose are a set of paired reads, but there’s no way to distinguish between R1/R2. This may not be an issue, but I’m not sure how downstream programs (i.e. Trinity) will handle duplicate FastA IDs as inputs. To avoid any headaches, I’ve decided to parse out the corresponding FastQ reads which have the full header info.\nAnyway, here’s a brief rundown of the approach:\n\nCreate list of unique read headers from MEGAN6 FastA files.\nUse list with seqtk program to pull out corresponding FastQ reads from the trimmed FastQ R1 and R2 files.\n\nThe entire procedure is documented in a Jupyter Notebook below.\nJupyter notebook (GitHub):\n\n20200518_swoose_cbai_megan_read_extractions.ipynb\n\n\n\nRESULTS\nOutput folders:\n\n20200518.C_bairdi_megan_reads\n20200518.Hematodinium_megan_reads/\n\nWe now have two distinct sets of RNAseq reads from C.bairdi (Arhtropoda) and Hematodinium (Alveolata).\nI’ll use these to supplement/update our existing species-specific transcriptomes, since it takes very little time/effort to generate them and run them through the assembly/annotation pipeline."
  },
  {
    "objectID": "posts/2020/2020-02-07-Transcriptome-Assessment--BUSCO-Metazoa-on-C.bairdi-MEGAN-Transcriptome/index.html",
    "href": "posts/2020/2020-02-07-Transcriptome-Assessment--BUSCO-Metazoa-on-C.bairdi-MEGAN-Transcriptome/index.html",
    "title": "Transcriptome Assessment - BUSCO Metazoa on C.bairdi MEGAN Transcriptome",
    "section": "",
    "text": "I previously created a C.bairdi de novo transcriptome assembly with Trinity from the MEGAN6 taxonomic-specific reads for Arthropoda on 20200122 and decided to assess its “completeness” using BUSCO and the metazoa_odb9 database.\nBUSCO was run with the --mode transcriptome option on Mox.\nSBATCH script (GitHub):\n\n20200207_cbai_busco_megan.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_busco_megan_transcriptome\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=3-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200207_cbai_busco_megan\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Load Open MPI module for parallel, multi-node processing\nmodule load icc_19-ompi_3.1.2\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\n# Establish variables for more readable code\ntimestamp=$(date +%Y%m%d)\nspecies=\"cbai\"\nprefix=\"${timestamp}.${species}\"\n\n## Input files and settings\nbase_name=\"${prefix}.megan\"\nbusco_db=/gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9\ntranscriptome_fasta=/gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200122.C_bairdi.megan.Trinity.fasta\naugustus_species=fly\nthreads=28\n\n## Save working directory\nwd=$(pwd)\n\n## Set program paths\naugustus_bin=/gscratch/srlab/programs/Augustus-3.3.2/bin\naugustus_scripts=/gscratch/srlab/programs/Augustus-3.3.2/scripts\nblast_dir=/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin/\nbusco=/gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py\nhmm_dir=/gscratch/srlab/programs/hmmer-3.2.1/src/\n\n## Augustus configs\naugustus_dir=${wd}/augustus\naugustus_config_dir=${augustus_dir}/config\naugustus_orig_config_dir=/gscratch/srlab/programs/Augustus-3.3.2/config\n\n## BUSCO configs\nbusco_config_default=/gscratch/srlab/programs/busco-v3/config/config.ini.default\nbusco_config_ini=${wd}/config.ini\n\n# Export BUSCO config file location\nexport BUSCO_CONFIG_FILE=\"${busco_config_ini}\"\n\n# Export Augustus variable\nexport PATH=\"${augustus_bin}:$PATH\"\nexport PATH=\"${augustus_scripts}:$PATH\"\nexport AUGUSTUS_CONFIG_PATH=\"${augustus_config_dir}\"\n\n\n# Copy BUSCO config file\ncp ${busco_config_default} \"${busco_config_ini}\"\n\n# Make Augustus directory if it doesn't exist\nif [ ! -d \"${augustus_dir}\" ]; then\n  mkdir --parents \"${augustus_dir}\"\nfi\n\n# Copy Augustus config directory\ncp --preserve -r ${augustus_orig_config_dir} \"${augustus_dir}\"\n\n# Edit BUSCO config file\n## Set paths to various programs\n### The use of the % symbol sets the delimiter sed uses for arguments.\n### Normally, the delimiter that most examples use is a slash \"/\".\n### But, we need to expand the variables into a full path with slashes, which screws up sed.\n### Thus, the use of % symbol instead (it could be any character that is NOT present in the expanded variable; doesn't have to be \"%\").\nsed -i \"/^;cpu/ s/1/${threads}/\" \"${busco_config_ini}\"\nsed -i \"/^tblastn_path/ s%tblastn_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^makeblastdb_path/ s%makeblastdb_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^augustus_path/ s%augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^etraining_path/ s%etraining_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^gff2gbSmallDNA_path/ s%gff2gbSmallDNA_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^new_species_path/ s%new_species_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^optimize_augustus_path/ s%optimize_augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^hmmsearch_path/ s%hmmsearch_path = /home/osboxes/BUSCOVM/hmmer/hmmer-3.1b2-linux-intel-ia32/binaries/%path = ${hmm_dir}%\" \"${busco_config_ini}\"\n\n\n# Run BUSCO/Augustus training\n${busco} \\\n--in ${transcriptome_fasta} \\\n--out ${base_name} \\\n--lineage_path ${busco_db} \\\n--mode transcriptome \\\n--cpu ${threads} \\\n--long \\\n--species ${augustus_species} \\\n--tarzip \\\n--augustus_parameters='--progress=true'\n\n\nRESULTS\nThis was very quick - 1m42s:\n\n\n\nBUSCO runtime\n\n\nOutput folder:\n\n20200207_cbai_busco_megan/\n\nBUSCO short summary (text):\n\n20200207_cbai_busco_megan/run_20200207.cbai.megan/short_summary_20200207.cbai.megan.txt\n\n# BUSCO version is: 3.0.2\n# The lineage dataset is: metazoa_odb9 (Creation date: 2016-02-13, number of species: 65, number of BUSCOs: 978)\n# To reproduce this run: python /gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py -i /gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200122.C_bairdi.megan.Trinity.fasta -o 20200207.cbai.megan -l /gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9/ -m transcriptome -c 28 --long -z\n#\n# Summarized benchmarking in BUSCO notation for file /gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200122.C_bairdi.megan.Trinity.fasta\n# BUSCO was run in mode: transcriptome\n\n    C:85.5%[S:64.7%,D:20.8%],F:9.3%,M:5.2%,n:978\n\n    836 Complete BUSCOs (C)\n    633 Complete and single-copy BUSCOs (S)\n    203 Complete and duplicated BUSCOs (D)\n    91  Fragmented BUSCOs (F)\n    51  Missing BUSCOs (M)\n    978 Total BUSCO groups searched"
  },
  {
    "objectID": "posts/2020/2020-05-19-Transcriptome-Annotation---C.bairdi-Transcriptome-v1.6-Using-DIAMOND-BLASTx-on-Mox/index.html",
    "href": "posts/2020/2020-05-19-Transcriptome-Annotation---C.bairdi-Transcriptome-v1.6-Using-DIAMOND-BLASTx-on-Mox/index.html",
    "title": "Transcriptome Annotation - C.bairdi Transcriptome v1.6 Using DIAMOND BLASTx on Mox",
    "section": "",
    "text": "As part of annotating cbai_transcriptome_v1.6.fasta from 20200518, I need to run DIAMOND BLASTx to use with Trinotate.\nRan DIAMOND BLASTx against the UniProt/SwissProt database (downloaded 20200123) on Mox.\nSBATCH script (GitHub):\n\n20200519_cbai_diamond_blastx_transcriptome_v1.6.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_blastx_DIAMOND\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200519_cbai_diamond_blastx_transcriptome_v1.6\n\n### BLASTx of Trinity de novo assembly of all C.bairdi RNAseq data, Arthropoda only:\n### cbai_transcriptome_v1.6.fasta\n### Includes \"descriptor_1\" short-hand of: 2020-GW, 2020-UW, 2019, 2018.\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\n# Program paths\ndiamond=/gscratch/srlab/programs/diamond-0.9.29/diamond\n\n# DIAMOND UniProt database\ndmnd=/gscratch/srlab/blastdbs/uniprot_sprot_20200123/uniprot_sprot.dmnd\n\n\n# Trinity assembly (FastA)\nfasta=/gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v1.6.fasta\n\n# Strip leading path and extensions\nno_path=$(echo \"${fasta##*/}\")\nno_ext=$(echo \"${no_path%.*}\")\n\n# Run DIAMOND with blastx\n# Output format 6 produces a standard BLAST tab-delimited file\n${diamond} blastx \\\n--db ${dmnd} \\\n--query \"${fasta}\" \\\n--out \"${no_ext}\".blastx.outfmt6 \\\n--outfmt 6 \\\n--evalue 1e-4 \\\n--max-target-seqs 1 \\\n--block-size 15.0 \\\n--index-chunks 4\n\n\nRESULTS\nAs usual, runtime was ridiculously fast: 12 seconds\n\n\n\ndiamond blastx runtime\n\n\nOutput folder:\n\n20200519_cbai_diamond_blastx_transcriptome_v1.6/\n\nBLASTx output (outfmt6; text; 1.9MB):\n\n20200519_cbai_diamond_blastx_transcriptome_v1.6/cbai_transcriptome_v1.6.blastx.outfmt6"
  },
  {
    "objectID": "posts/2020/2020-06-05-Transcriptome-Assessment---BUSCO-Metazoa-on-C.bairdi-Transcriptome-v2.1/index.html",
    "href": "posts/2020/2020-06-05-Transcriptome-Assessment---BUSCO-Metazoa-on-C.bairdi-Transcriptome-v2.1/index.html",
    "title": "Transcriptome Assessment - BUSCO Metazoa on C.bairdi Transcriptome v2.1",
    "section": "",
    "text": "Continuing to try to identify the best C.bairdi transcriptome, we decided to extract all non-dinoflagellate sequences from cbai_transcriptome_v2.0 (RNAseq shorthand: 2018, 2019, 2020-GW, 2020-UW) and cbai_transcriptome_v3.0 (RNAseq shorthand: 2018, 2019, 2020-UW).\nNow, want to assess cbai_transcriptome_v2.1 “completeness” using BUSCO and the metazoa_odb9 database.\nBUSCO was run with the --mode transcriptome option on Mox.\nSBATCH script (GitHub):\n\n20200605_cbai_busco_transcriptome_v2.1.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_busco_v2.1_transcriptome\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=1-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200605_cbai_busco_transcriptome_v2.1\n\n### C.bairdi transcriptome assembly completeness assessment using BUSCO.\n### This is checking cbai_transcriptome_v1.7.fasta\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Load Open MPI module for parallel, multi-node processing\nmodule load icc_19-ompi_3.1.2\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\n## Input files and settings\nbusco_db=/gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9\ntranscriptome_fasta=/gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v2.1.fasta\naugustus_species=fly\nthreads=28\n\n## Save working directory\nwd=$(pwd)\n\n# Extract FastA filename\nfasta_name=${transcriptome_fasta##*/}\n\n## Set program paths\naugustus_bin=/gscratch/srlab/programs/Augustus-3.3.2/bin\naugustus_scripts=/gscratch/srlab/programs/Augustus-3.3.2/scripts\nblast_dir=/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin/\nbusco=/gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py\nhmm_dir=/gscratch/srlab/programs/hmmer-3.2.1/src/\n\n## Augustus configs\naugustus_dir=${wd}/augustus\naugustus_config_dir=${augustus_dir}/config\naugustus_orig_config_dir=/gscratch/srlab/programs/Augustus-3.3.2/config\n\n## BUSCO configs\nbusco_config_default=/gscratch/srlab/programs/busco-v3/config/config.ini.default\nbusco_config_ini=${wd}/config.ini\n\n# Export BUSCO config file location\nexport BUSCO_CONFIG_FILE=\"${busco_config_ini}\"\n\n# Export Augustus variable\nexport PATH=\"${augustus_bin}:$PATH\"\nexport PATH=\"${augustus_scripts}:$PATH\"\nexport AUGUSTUS_CONFIG_PATH=\"${augustus_config_dir}\"\n\n\n# Copy BUSCO config file\ncp ${busco_config_default} \"${busco_config_ini}\"\n\n# Make Augustus directory if it doesn't exist\nif [ ! -d \"${augustus_dir}\" ]; then\n  mkdir --parents \"${augustus_dir}\"\nfi\n\n# Copy Augustus config directory\ncp --preserve -r ${augustus_orig_config_dir} \"${augustus_dir}\"\n\n# Edit BUSCO config file\n## Set paths to various programs\n### The use of the % symbol sets the delimiter sed uses for arguments.\n### Normally, the delimiter that most examples use is a slash \"/\".\n### But, we need to expand the variables into a full path with slashes, which screws up sed.\n### Thus, the use of % symbol instead (it could be any character that is NOT present in the expanded variable; doesn't have to be \"%\").\nsed -i \"/^;cpu/ s/1/${threads}/\" \"${busco_config_ini}\"\nsed -i \"/^tblastn_path/ s%tblastn_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^makeblastdb_path/ s%makeblastdb_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^augustus_path/ s%augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^etraining_path/ s%etraining_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^gff2gbSmallDNA_path/ s%gff2gbSmallDNA_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^new_species_path/ s%new_species_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^optimize_augustus_path/ s%optimize_augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^hmmsearch_path/ s%hmmsearch_path = /home/osboxes/BUSCOVM/hmmer/hmmer-3.1b2-linux-intel-ia32/binaries/%path = ${hmm_dir}%\" \"${busco_config_ini}\"\n\n\n# Run BUSCO/Augustus training\n${busco} \\\n--in ${transcriptome_fasta} \\\n--out ${fasta_name} \\\n--lineage_path ${busco_db} \\\n--mode transcriptome \\\n--cpu ${threads} \\\n--long \\\n--species ${augustus_species} \\\n--tarzip \\\n--augustus_parameters='--progress=true'\n\n# Create checksum for potential verification\nmd5sum \"${transcriptome_fasta}\" >> \"${fasta_name}\".checksum.md5\n\n\nRESULTS\nAs always, very quick; ~6.5mins:\n\n\n\ncbai v2.1 BUSCO runtime\n\n\nOutput folder:\n\n20200605_cbai_busco_transcriptome_v2.1/\n\nShort summary file (text):\n\n20200605_cbai_busco_transcriptome_v2.1/run_cbai_transcriptome_v2.1.fasta/short_summary_cbai_transcriptome_v2.1.fasta.txt\n\n# BUSCO version is: 3.0.2\n# The lineage dataset is: metazoa_odb9 (Creation date: 2016-02-13, number of species: 65, number of BUSCOs: 978)\n# To reproduce this run: python /gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py -i /gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v2.1.fasta -o cbai_transcriptome_v2.1.fasta -l /gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9/ -m transcriptome -c 28 --long -z\n#\n# Summarized benchmarking in BUSCO notation for file /gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v2.1.fasta\n# BUSCO was run in mode: transcriptome\n\n    C:98.3%[S:25.2%,D:73.1%],F:1.4%,M:0.3%,n:978\n\n    961 Complete BUSCOs (C)\n    246 Complete and single-copy BUSCOs (S)\n    715 Complete and duplicated BUSCOs (D)\n    14  Fragmented BUSCOs (F)\n    3   Missing BUSCOs (M)\n    978 Total BUSCO groups searched\nWill add scores to Genomic Resources wiki. Also, after running BUSCO on the cbai_transcriptome_v3.1 transcriptome, I will update my BUSCO comparision notebook entry from 20200528."
  },
  {
    "objectID": "posts/2020/2020-08-26-Transcriptome-Annotation---Trinotate-Hematodinium-v3.1-on-Mox/index.html",
    "href": "posts/2020/2020-08-26-Transcriptome-Annotation---Trinotate-Hematodinium-v3.1-on-Mox/index.html",
    "title": "Transcriptome Annotation - Trinotate Hematodinium v3.1 on Mox",
    "section": "",
    "text": "To continue annotation of our Hematodinium v3.1 transcriptome assembly, I wanted to run Trinotate.\nInfo for each transcriptome version (library composition, assembly dates, BUSCO, etc) can be found in this table:\n\nhemat_transcriptome_comp\n\nThis was run on Mox.\nSBATCH script (GitHub):\n\n20200826_hemat_trinotate_transcriptome-v3.1.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=hemat_trinotate_transcriptome-v3.1\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=7-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200826_hemat_trinotate_transcriptome-v3.1\n\n\n# Script to run Trinotate on Hematodinium transcriptome:\n# v3.1\n\n###################################################################################\n# These variables need to be set by user\n\n# Input files\n## BLASTx\nblastx_out=\"/gscratch/scrubbed/samwhite/outputs/20200814_hemat_diamond_blastx_v1.6_v1.7_v2.1_v3.1/hemat_transcriptome_v3.1.fasta.blastx.outfmt6\"\n\n## TransDecoder\ntransdecoder_dir=\"/gscratch/scrubbed/samwhite/outputs/20200817_hemat_transdecoder_transcriptomes_v1.6_v1.7_v2.1_v.3.1/20200817_hemat_transcriptome_v3.1.fasta.transdecoder\"\nblastp_out=\"${transdecoder_dir}/20200817_hemat_transcriptome_v3.1.fasta.blastp_out/20200817_hemat_transcriptome_v3.1.fasta.blastp.outfmt6\"\npfam_out=\"${transdecoder_dir}/20200817_hemat_transcriptome_v3.1.fasta.pfam_out/20200817_hemat_transcriptome_v3.1.fasta.pfam.domtblout\"\nlORFs_pep=\"${transdecoder_dir}/hemat_transcriptome_v3.1.fasta.transdecoder_dir/longest_orfs.pep\"\n\n## Transcriptomics\ntranscriptomes_dir=\"/gscratch/srlab/sam/data/Hematodinium/transcriptomes\"\ntrinity_fasta=\"${transcriptomes_dir}/hemat_transcriptome_v3.1.fasta\"\ntrinity_gene_map=\"${transcriptomes_dir}/hemat_transcriptome_v3.1.fasta.gene_trans_map\"\n\n###################################################################################\n\nwd=\"$(pwd)\"\ntimestamp=$(date +%Y%m%d)\n\n\n## Paths to input/output files\n\n## New folders for working directory\nrnammer_out_dir=\"${wd}/RNAmmer_out\"\nsignalp_out_dir=\"${wd}/signalp_out\"\ntmhmm_out_dir=\"${wd}/tmhmm_out\"\n\n\nrnammer_prefix=${trinity_fasta##*/}\nprefix=\"${timestamp}.${rnammer_prefix}.trinotate\"\n\n# Output files\nrnammer_out=\"${rnammer_out_dir}/${rnammer_prefix}.rnammer.gff\"\nsignalp_out=\"${signalp_out_dir}/${prefix}.signalp.out\"\ntmhmm_out=\"${tmhmm_out_dir}/${prefix}.tmhmm.out\"\ntrinotate_report=\"${wd}/${prefix}_annotation_report.txt\"\n\n# Paths to programs\nrnammer_dir=\"/gscratch/srlab/programs/RNAMMER-1.2\"\nrnammer=\"${rnammer_dir}/rnammer\"\nsignalp_dir=\"/gscratch/srlab/programs/signalp-4.1\"\nsignalp=\"${signalp_dir}/signalp\"\ntmhmm_dir=\"/gscratch/srlab/programs/tmhmm-2.0c/bin\"\ntmhmm=\"${tmhmm_dir}/tmhmm\"\ntrinotate_dir=\"/gscratch/srlab/programs/Trinotate-v3.1.1\"\ntrinotate=\"${trinotate_dir}/Trinotate\"\ntrinotate_rnammer=\"${trinotate_dir}/util/rnammer_support/RnammerTranscriptome.pl\"\ntrinotate_GO=\"${trinotate_dir}/util/extract_GO_assignments_from_Trinotate_xls.pl\"\ntrinotate_features=\"${trinotate_dir}/util/Trinotate_get_feature_name_encoding_attributes.pl\"\ntrinotate_sqlite_db=\"Trinotate.sqlite\"\n\n# Generate FastA checksum, for reference if needed.\nmd5sum ${trinity_fasta} > fasta.checksum.md5\n\n# Make output directories\nmkdir \"${rnammer_out_dir}\" \"${signalp_out_dir}\" \"${tmhmm_out_dir}\"\n\n# Copy sqlite database template\n\ncp ${trinotate_dir}/admin/Trinotate.sqlite .\n\n# Run signalp\n${signalp} \\\n-f short \\\n-n \"${signalp_out}\" \\\n${lORFs_pep}\n\n# Run tmHMM\n${tmhmm} \\\n--short \\\n< ${lORFs_pep} \\\n> \"${tmhmm_out}\"\n\n# Run RNAmmer\ncd \"${rnammer_out_dir}\" || exit\n${trinotate_rnammer} \\\n--transcriptome ${trinity_fasta} \\\n--path_to_rnammer ${rnammer}\ncd \"${wd}\" || exit\n\n# Run Trinotate\n## Load transcripts and coding regions into database\n${trinotate} \\\n${trinotate_sqlite_db} \\\ninit \\\n--gene_trans_map \"${trinity_gene_map}\" \\\n--transcript_fasta \"${trinity_fasta}\" \\\n--transdecoder_pep \"${lORFs_pep}\"\n\n## Load BLAST homologies\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_swissprot_blastp \\\n\"${blastp_out}\"\n\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_swissprot_blastx \\\n\"${blastx_out}\"\n\n## Load Pfam\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_pfam \\\n\"${pfam_out}\"\n\n## Load transmembrane domains\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_tmhmm \\\n\"${tmhmm_out}\"\n\n## Load signal peptides\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_signalp \\\n\"${signalp_out}\"\n\n## Load RNAmmer\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_rnammer \\\n\"${rnammer_out}\"\n\n## Creat annotation report\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nreport \\\n> \"${trinotate_report}\"\n\n# Extract GO terms from annotation report\n\"${trinotate_GO}\" \\\n--Trinotate_xls \"${trinotate_report}\" \\\n-G \\\n--include_ancestral_terms \\\n> \"${prefix}\".go_annotations.txt\n\n# Make transcript features annotation map\n\"${trinotate_features}\" \\\n\"${trinotate_report}\" \\\n> \"${prefix}\".annotation_feature_map.txt\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nRESULTS\nTook ~1.5hrs to run:\n\n\n\nRuntime for Hemat v3.1 Trinotate job\n\n\nOutput folder:\n\n20200826_hemat_trinotate_transcriptome-v3.1/\n\nAnnotation feature map (2.6MB; TXT):\n\n20200826.hemat_transcriptome_v3.1.fasta.trinotate.annotation_feature_map.txt\n\nThis can be used to update Trinity-based gene expression matrices like so:\n\n${TRINITY_HOME}/Analysis/DifferentialExpression/rename_matrix_feature_identifiers.pl Trinity_trans.counts.matrix annot_feature_map.txt > Trinity_trans.counts.wAnnot.matrix\n\n\n\nGene ontology (GO) annotations (2.8MB; TXT):\n\n20200826.hemat_transcriptome_v3.1.fasta.trinotate.go_annotations.txt\n\nAnnotation report (35MB; CSV):\n\n20200826.hemat_transcriptome_v3.1.fasta.trinotate_annotation_report.txt\n\nSQlite database (543MB; SQLITE):\n\nTrinotate.sqlite"
  },
  {
    "objectID": "posts/2020/2020-12-08-Alignment---C.gigas-RNAseq-to-GCF_000297895.1_oyster_v9-Genome-Using-STAR-on-Mox/index.html",
    "href": "posts/2020/2020-12-08-Alignment---C.gigas-RNAseq-to-GCF_000297895.1_oyster_v9-Genome-Using-STAR-on-Mox/index.html",
    "title": "Alignment - C.gigas RNAseq to GCF_000297895.1_oyster_v9 Genome Using STAR on Mox",
    "section": "",
    "text": "Mac was getting some weird results when mapping some single cell RNAseq data to the C.gigas mitochondrial (mt) genome that she had, so she asked for some help mapping other C.gigas RNAseq data (GitHub Issue) to the C.gigas mt genome to see if someone else would get similar results.\nPer Mac’s suggestion, I used STAR to perform an RNAseq alignment.\nI used a genome FastA and transcriptome GTF file that she had previously provided in this GitHub Issue, so I don’t know much about their origination/history.\nFor RNAseq data, I used the only Roberts Lab C.gigas data I could find (see Nightingales (Google Sheet) for more info), which was surprisingly limited. I didn’t realize that we’ve performed so few RNAseq experiments with C.gigas.\nI used the following files for the alignment:\nRNAseq (FastQ):\n\n2M_AGTCAA_L001_R1_001.fastq.gz (2.4GB)\n2M-HS_CCGTCC_L001_R1_001.fastq.gz (1.9GB)\n4M_AGTTCC_L001_R1_001.fastq.gz (2.0GB)\nhttp://owl.fish.washington.edu/nightingales/C_gigas/4M-HS_GTCCGC_L001_R1_001.fastq.gz (1.5GB)\nhttp://owl.fish.washington.edu/nightingales/C_gigas/6M_ATGTCA_L001_R1_001.fastq.gz (2.0GB)\nhttp://owl.fish.washington.edu/nightingales/C_gigas/6M-HS_GTGAAA_L001_R1_001.fastq.gz (1.5GB)\n\nGenome FastA (540MB):\n\nGCF_000297895.1_oyster_v9/GCF_000297895.1_oyster_v9_genomic.fasta\n\nTranscriptome GTF (380MB):\n\nGCF_000297895.1_oyster_v9_genomic.gtf.wl_keep_mito_v7.sorted.gtf\n\nThis was run on Mox.\nSBATCH script (GitHub):\n\n20201208_cgig_STAR_RNAseq-to-NCBI-GCF_000297895.1_oyster_v9.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=20201208_cgig_STAR_RNAseq-to-NCBI-GCF_000297895.1_oyster_v9\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20201208_cgig_STAR_RNAseq-to-NCBI-GCF_000297895.1_oyster_v9\n\n\n### C.gigas RNAseq alignment to NCBI genome FastA file from Mac GCF_000297895.1_oyster_v9_genomic.fasta.\n### Mackenzie Gavery asked for help to evaluate RNAseq read mappings to mt genome.\n\n\n###################################################################################\n# These variables need to be set by user\n\n# Working directory\nwd=$(pwd)\n\n# Set number of CPUs to use\nthreads=28\n\n# Initialize arrays\nfastq_array=()\n\n# Input/output files\nfastq_checksums=fastq_checksums.md5\ngenome_fasta_checksum=genome_fasta_checksum.md5\ngtf_checksum=gtf_checksum.md5\nrnaseq_reads_dir=/gscratch/srlab/sam/data/C_gigas/RNAseq\ngtf=/gscratch/srlab/sam/data/C_gigas/transcriptomes/GCF_000297895.1_oyster_v9_genomic.gtf.wl_keep_mito_v7.sorted.gtf\ngenome_dir=${wd}/genome_dir\ngenome_fasta=/gscratch/srlab/sam/data/C_gigas/genomes/GCF_000297895.1_oyster_v9_genomic.fasta\n\n# Paths to programs\nmultiqc=/gscratch/srlab/programs/anaconda3/bin/multiqc\nsamtools=\"/gscratch/srlab/programs/samtools-1.10/samtools\"\nstar=/gscratch/srlab/programs/STAR-2.7.6a/bin/Linux_x86_64_static/STAR\n\n\n# Programs associative array\ndeclare -A programs_array\nprograms_array=(\n[multiqc]=\"${multiqc}\" \\\n[samtools_index]=\"${samtools} index\" \\\n[samtools_sort]=\"${samtools} sort\" \\\n[samtools_view]=\"${samtools} view\" \\\n[star]=\"${star}\"\n)\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Load GCC OMP compiler. Might/not be needed for STAR\nmodule load gcc_8.2.1-ompi_4.0.2\n\n\n# Make STAR genome directory\nmkdir --parents ${genome_dir}\n\n# Populate RNAseq array\nfastq_array=(${rnaseq_reads_dir}/*.fastq)\n\n# Comma separated list required for STAR mapping\n# Uses tr to change spaces between elements to commas\nfastq_list=$(tr ' ' ',' <<< \"${fastq_array[@]}\")\n\n\n\n# Create STAR genome indexes\n# Overhang value is set to \"generic\" 100bp -\n# this value is unknown and is the suggested default in\n# STAR documentation.\n${programs_array[star]} \\\n--runThreadN ${threads} \\\n--runMode genomeGenerate \\\n--genomeDir ${genome_dir} \\\n--genomeFastaFiles ${genome_fasta} \\\n--sjdbGTFfile ${gtf} \\\n--sjdbOverhang 100 \\\n--genomeSAindexNbases 13\n\n# Run STAR mapping\n# Sets output to sorted BAM file\n${programs_array[star]} \\\n--runThreadN ${threads} \\\n--genomeDir ${genome_dir} \\\n--outSAMtype BAM SortedByCoordinate \\\n--readFilesIn ${fastq_list}\n\n# Index BAM output file\n${programs_array[samtools_index]} \\\nAligned.sortedByCoord.out.bam\n\n# Extract mt alignments\n# -h: includes header\n${programs_array[samtools_view]} \\\n--threads ${threads} \\\n--write-index \\\n-h \\\nAligned.sortedByCoord.out.bam NC_001276.1 \\\n-o Aligned.sortedByCoord.out.NC_001276.1.bam\n\n# Generate checksums for reference\n# Uses bash string substitution to replace commas with spaces\n# NOTE: do NOT quote string substitution command\nfor fastq in ${fastq_list//,/ }\ndo\n\n    # Generate MD5 checksums for each input FastQ file\n    echo \"Generating MD5 checksum for ${fastq}.\"\n    md5sum \"${fastq}\" >> \"${fastq_checksums}\"\n    echo \"Completed: MD5 checksum for ${fastq}.\"\n    echo \"\"\ndone\n\n# Run MultiQC\n${programs_array[multiqc]} .\n\n# Generate checksums for genome FastA and GTF\necho \"Generating MD5 checksum for ${genome_fasta}.\"\nmd5sum \"${genome_fasta}\" > \"${genome_fasta_checksum}\"\necho \"Completed: MD5 checksum for ${genome_fasta}.\"\necho \"\"\n\necho \"Generating MD5 hecksum for ${gtf}.\"\nmd5sum \"${gtf}\" > \"${gtf_checksum}\"\necho \"Completed: MD5 checksum for ${gtf}.\"\necho \"\"\n\n\n# Capture program options\necho \"Logging program options...\"\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n  # Handle samtools help menus\n  if [[ \"${program}\" == \"samtools_index\" ]] \\\n  || [[ \"${program}\" == \"samtools_sort\" ]] \\\n  || [[ \"${program}\" == \"samtools_view\" ]]\n  then\n    ${programs_array[$program]}\n  fi\n    ${programs_array[$program]} -h\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\n\n  # If MultiQC is in programs_array, copy the config file to this directory.\n  if [[ \"${program}\" == \"multiqc\" ]]; then\n    cp --preserve ~/.multiqc_config.yaml multiqc_config.yaml\n  fi\ndone\n\necho \"\"\necho \"Finished logging program options.\"\necho \"\"\n\necho \"\"\necho \"Logging system PATH.\"\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\necho \"Finished logging system PATH\"\n\n\nRESULTS\nThis was pretty quick, but wasn’t really sure what to expect. Only 20mins:\n\n\n\nSTAR runtime on Mox\n\n\nA quick comparison of my alignment with what Mac saw previously show very similar results:\nSAM’S ALIGNMENT:\n\n\n\nSam’s C.gigas RNAseq STAR alignment to mt genome in IGV\n\n\nMAC’S ALIGNMENT:\n\n\n\nMac’s C.gigas single-cell RNAseq alignment to mt genome in IGV\n\n\nHer primary concern is the fact that a majority of the reads appear to align to non-coding regions of the C.gigas mt genome. My alignment shows the same. I suspect that is likely related to poor annotation of the C.gigas mt genome/transcriptome. Also, I believe the mitochondrial translation codons differ from that of nuclear translation codons. On top of that, I think invertebrates might also have a slightly altered set of translation codons. Zooming in on the IGV alignment seems to show that the standard (mammalian) codons were used to identify coding regions.\nNotice that the stop codon from this alignment shown below uses TGA as termination. In invertebrate mt genomes, this codon actually encodes for tryptophan (Trp/W). This suggests that the GTF file was generated with a standard (i.e. vertebrate, non-mitochondrial) codon table, instead of a mt codon table (and almost certainly not an invertebrate mt codon table).\n\n\n\nIGV screencap showing standard stop codon usage instead of invertebrate mt tryptophan codon\n\n\nIn any case, I’ve posted my thoughts/results in that GitHub Issue. Links to files are below.\nOutput folder:\n\n20201208_cgig_STAR_RNAseq-to-NCBI-GCF_000297895.1_oyster_v9/\n\nBAM files:\n\nMitochondrial BAM and index:\n\nAligned.sortedByCoord.out.NC_001276.1.bam\nAligned.sortedByCoord.out.NC_001276.1.bam.csi\n\nFull BAM and index:\n\nAligned.sortedByCoord.out.bam\nAligned.sortedByCoord.out.bam.bai\n\n\nMD5 checksums (TEXT):\n\nfastq_checksums.md5\ngenome_fasta_checksum.md5\ngtf_checksum.md5"
  },
  {
    "objectID": "posts/2020/2020-04-13-Data-Wrangling---Arthropoda-and-Alveolata-Day-and-Treatment-Taxonomic-RNAseq-FastQ-Extractions/index.html",
    "href": "posts/2020/2020-04-13-Data-Wrangling---Arthropoda-and-Alveolata-Day-and-Treatment-Taxonomic-RNAseq-FastQ-Extractions/index.html",
    "title": "Data Wrangling - Arthropoda and Alveolata Day and Treatment Taxonomic RNAseq FastQ Extractions",
    "section": "",
    "text": "After using MEGAN6 to extract Arthropoda and Alveolata reads from our RNAseq data on 20200330, I had then extracted taxonomic-specific reads and aggregated each into basic Read 1 and Read 2 FastQs to simplify transcriptome assembly for C.bairdi and for Hematodinium. That was fine and all, but wasn’t fully thought through.\nFor gene expression analysis, I need the FastQs based on infection status and sample days. So, I need to modify the read extraction procedure to parse reads based on those conditions. I could’ve/should’ve done this originally, as I could’ve just assembled the transcriptome from the FastQs I’m going to generate now. Oh well.\nAs a reminder, the reason I’m doing this is that I realized that the FastA headers were incomplete and did not distinguish between paired reads. Here’s an example:\nR1 FastQ header:\n@A00147:37:HG2WLDMXX:1:1101:5303:1000 1:N:0:AGGCGAAG+AGGCGAAG\nR2 FastQ header:\n@A00147:37:HG2WLDMXX:1:1101:5303:1000 2:N:0:AGGCGAAG+AGGCGAAG\nHowever, the reads extracted via MEGAN have FastA headers like this:\n>A00147:37:HG2WLDMXX:1:1101:5303:1000\nSEQUENCE1\n>A00147:37:HG2WLDMXX:1:1101:5303:1000\nSEQUENCE2\nThose are a set of paired reads, but there’s no way to distinguish between R1/R2. This may not be an issue, but I’m not sure how downstream programs (i.e. Trinity) will handle duplicate FastA IDs as inputs. To avoid any headaches, I’ve decided to parse out the corresponding FastQ reads which have the full header info.\nAnyway, here’s a brief rundown of the approach:\n\nCreate list of unique read headers from MEGAN6 FastA files.\nUse list with seqtk program to pull out corresponding FastQ reads from the trimmed FastQ R1 and R2 files.\n\nThe entire procedure is documented in a Jupyter Notebook below.\nJupyter notebook (GitHub):\n\n20200413_swoose_cbai_megan_day-treatment_read_extractions.ipynb\n\n\n\nRESULTS\nOutput folders:\n\n20200413_C_bairdi_megan_reads/\n20200413_Hematodinium_megan_reads/\n\nWe now have two distinct sets of RNAseq reads from C.bairdi (Arhtropoda) and Hematodinium (Alveolata), split by infection status and sample day! Will get some gene expression analysis going."
  },
  {
    "objectID": "posts/2020/2020-10-14-Read-Mapping---C.bairdi-201002558-2729-Q7-and-6129-403-26-Q7-Taxa-Specific-NanoPore-Reads-to-cbai_genome_v1.01.fasta-Using-Minimap2-on-Mox/index.html",
    "href": "posts/2020/2020-10-14-Read-Mapping---C.bairdi-201002558-2729-Q7-and-6129-403-26-Q7-Taxa-Specific-NanoPore-Reads-to-cbai_genome_v1.01.fasta-Using-Minimap2-on-Mox/index.html",
    "title": "Read Mapping - C.bairdi 201002558-2729-Q7 and 6129-403-26-Q7 Taxa-Specific NanoPore Reads to cbai_genome_v1.01.fasta Using Minimap2 on Mox",
    "section": "",
    "text": "After extracting FastQ reads using seqtk on 20201013 from the various taxa I had been interested in, the next thing needed doing was mapping reads to the cbai_genome_v1.01 “genome” assembly from 20200917. I found that Minimap2 will map long reads (e.g. NanoPore), in addition to short reads, so I decided to give that a rip.\nMinimap2 was run on Mox.\nSBATCH script (GitHub):\n\n20201014_cbai_minimap_nanopore-megan6-taxa-reads.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=20201014__cbai_minimap_nanopore-megan6-taxa-reads\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=15-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20201014_cbai_minimap_nanopore-megan6-taxa-reads\n\n\n###################################################################################\n# These variables need to be set by user\n\n## Assign Variables\n\n# CPU threads to use\nthreads=27\n\n# Genome FastA path\ngenome_fasta=/gscratch/srlab/sam/data/C_bairdi/genomes/cbai_genome_v1.01.fasta\n\n\n# Paths to programs\nminimap2=\"/gscratch/srlab/programs/minimap2-2.17_x64-linux/minimap2\"\nsamtools=\"/gscratch/srlab/programs/samtools-1.10/samtools\"\n\n\n\n# Programs array\ndeclare -A programs_array\nprograms_array=(\n[minimap2]=\"${minimap2}\" \\\n[samtools_sort]=\"${samtools} sort\" \\\n[samtools_view]=\"${samtools} view\"\n)\n\n\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Capture date\ntimestamp=$(date +%Y%m%d)\n\n# Loop through each FastQ\nfor fastq in *.fq\ndo\n\n  # Parse out sample name\n  sample=$(echo \"${fastq}\" | awk -F\"_\" '{print $2}')\n\n  # Caputure taxa\n  taxa=$(echo \"${fastq}\" | awk -F\"_\" '{print $3}')\n\n  # Capture filename prefix\n  prefix=\"${timestamp}_${sample}_${taxa}\"\n\n  # Run Minimap2 with Oxford NanoPore Technologies (ONT) option\n  # Using SAM output format (-a option)\n  ${programs_array[minimap2]} \\\n  -ax map-ont \\\n  ${genome_fasta} \\\n  ${fastq} \\\n  | ${programs_array[samtools_sort]} --threads ${threads} \\\n  -O sam \\\n  > \"${prefix}\".sorted.sam\n\n\n  # Capture FastA checksums for verification ()\n  echo \"Generating checksum for ${fastq}\"\n  md5sum \"${fastq}\" > fastq_checksums.md5\n  echo \"Finished generating checksum for ${fastq}\"\n  echo \"\"\n\n\ndone\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# Capture program options\n## Note: Trinity util/support scripts don't have options/help menus\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n    ${programs_array[$program]} --help\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n\nRESULTS\nAlthough there aren’t that many total number of sequences to map, I was still surprised at how quick this was; ~5mins:\n\n\n\nMinimap2 runtime on Mox for all taxa read mapping\n\n\nOutput folder and files:\n\n20201014_cbai_minimap_nanopore-megan6-taxa-reads/\n\n20201014_201002558-2729-Q7_Aquifex.sorted.sam (1.5M)\n20201014_201002558-2729-Q7_Arthropoda.sorted.sam (11M)\n20201014_201002558-2729-Q7_Enterospora.sorted.sam (8.3M)\n20201014_201002558-2729-Q7_Sar.sorted.sam (104K)\n20201014_6129-403-26-Q7_Alveolata.sorted.sam (5.6M)\n20201014_6129-403-26-Q7_Aquifex.sorted.sam (68M)\n20201014_6129-403-26-Q7_Arthropoda.sorted.sam (491M)\n20201014_6129-403-26-Q7_Enterospora.sorted.sam (261M)\n\n\nI left the output files as SAM files (instead of compressing them to the standard BAM format) so that they would be human readable. I haven’t actually explored SAM/BAM manipulation too much in the past and felt that this was a good excuse and being able to view the SAM files without the need to use samtools seemed easier. Also, I knew these would be relatively small files, so compressing them wasn’t a huge priority.\nNext up, messing around with these SAM files and identifying contigs/scaffolds where these various reads map."
  },
  {
    "objectID": "posts/2020/2020-03-06-RNA-Isolation-and-Quantification---C.bairdi-RNA-from-Hemolymph-Pellets-in-RNAlater/index.html",
    "href": "posts/2020/2020-03-06-RNA-Isolation-and-Quantification---C.bairdi-RNA-from-Hemolymph-Pellets-in-RNAlater/index.html",
    "title": "RNA Isolation and Quantification - C.bairdi RNA from Hemolymph Pellets in RNAlater",
    "section": "",
    "text": "Based on qPCR results testing for residual gDNA from 20200225, a set of 24 samples were identified that required DNase treatment and/or additional RNA. I opted to just isolate more RNA from all samples, since the kit includes a DNase step and avoids diluting the existing RNA using the Turbo DNA-free Kit that we usully use. Isolated RNA using the Quick DNA/RNA Microprep Kit (ZymoResearch; PDF) according to the manufacturer’s protocol for liquids/cells in RNAlater.\n\nUsed 35uL from each RNAlater/hemocyte slurry.\nMixed with equal volume of H2O (35uL).\nRetained DNA on the Zymo-Spin IC-XM columns for isolation after RNA isolation.\nPerformed on-column DNase step.\nRNA was eluted in 15uL H2O\n\nRNA was quantified on the Roberts Lab Qubit 3.0 using the RNA High Sensitivity Assay (Invitrogen), using 2uL of each sample.\n\n\nRESULTS\nQubit results (Google Sheet):\n\n20200306_qubit_crab_RNA\n\nMost samples have good yields. Only a few are a bit low. Will check all samples for residual gDNA."
  },
  {
    "objectID": "posts/2020/2020-07-31-FastQ-Read-Alignment-and-Quantification---P.generosa-Water-Metagenomic-Libraries-to-MetaGeneMark-Assembly-with-Hisat2-on-Mox/index.html",
    "href": "posts/2020/2020-07-31-FastQ-Read-Alignment-and-Quantification---P.generosa-Water-Metagenomic-Libraries-to-MetaGeneMark-Assembly-with-Hisat2-on-Mox/index.html",
    "title": "FastQ Read Alignment and Quantification - P.generosa Water Metagenomic Libraries to MetaGeneMark Assembly with Hisat2 on Mox",
    "section": "",
    "text": "Continuing working on the manuscript for this data, Emma wanted the number of reads aligned to each gene. I previously created and assembly with genes/proteins using MetaGeneMark on 20190103, but the assemby process didn’t output any sort of stastics on read counts.\nSo, to get this data, I used Hisat2 to align reads (creating a BAM file) and then used samtools idxstats to generate a file with read counts aligned to each gene.\nThis was all done on Mox.\nHere’s how the sample names breakdown:\n\n\n\nSample\nDevelomental Stage (days post-fertilization)\npH Treatment\n\n\n\n\nMG1\n13\n8.2\n\n\nMG2\n17\n8.2\n\n\nMG3\n6\n7.1\n\n\nMG5\n10\n8.2\n\n\nMG6\n13\n7.1\n\n\nMG7\n17\n7.1\n\n\n\nSBATCH script (GitHub):\n\n20200731_metagenome_hisat2_alignments.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=metagenome_hisat2_alignments\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=7-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200731_metagenome_hisat2_alignments\n\n\n###################################################################################\n# These variables need to be set by user\n\n# Assign Variables\nreads_dir=/gscratch/srlab/sam/data/metagenomics/P_generosa/sequencing\nassembly=/gscratch/srlab/sam/data/metagenomics/P_generosa/assemblies/20190103-mgm-nucleotides.fa\nthreads=28\n# Set hisat2 basename\nhisat2_basename=20190103-mgm\n\n# Array of the various comparisons to evaluate\nlibraries_array=(\nMG_1 \\\nMG_2 \\\nMG_3 \\\nMG_5 \\\nMG_6 \\\nMG_7\n)\n\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n## Hisat2 requires Python2. Fails with syntax error if using Python3\n#module load intel-python3_2017\nmodule load intel-python2_2017\n\n# Program directories\nhisat2_dir=\"/gscratch/srlab/programs/hisat2-2.2.0/\"\nsamtools_dir=\"/gscratch/srlab/programs/samtools-1.10/samtools\"\n\n# Programs array\ndeclare -A programs_array\nprograms_array=(\n[hisat2]=\"${hisat2_dir}hisat2\" \\\n[hisat2_build]=\"${hisat2_dir}hisat2-build\" \\\n[samtools_view]=\"${samtools_dir} view\" \\\n[samtools_sort]=\"${samtools_dir} sort\" \\\n[samtools_index]=\"${samtools_dir} index\"\n[samtools_idxstats]=\"${samtools_dir} idxstats\"\n)\n\n# Capture FastA checksums for verification\necho \"Generating checksum for ${assembly}\"\nmd5sum \"${assembly}\" >> fasta.checksums.md5\necho \"Finished generating checksum for ${assembly}\"\necho \"\"\n\n# Build hisat2 index\n${programs_array[hisat2_build]} \\\n-f \"${assembly}\" \\\n\"${hisat2_basename}\" \\\n-p ${threads}\n\n# Loop through each library\nfor library in \"${libraries_array[@]}\"\ndo\n\n  ## Inititalize arrays\n  R1_array=()\n  R2_array=()\n  reads_array=()\n\n  # Variables\n  R1_list=\"\"\n  R2_list=\"\"\n\n\n  if [[ \"${library}\" == \"MG_1\" ]]; then\n\n    reads_array=(\"${reads_dir}\"/*MG_1*fastq.gz)\n\n    # Create array of fastq R1 files\n    R1_array=(\"${reads_dir}\"/*MG_1*R1*fastq.gz)\n\n    # Create array of fastq R2 files\n    R2_array=(\"${reads_dir}\"/*MG_1*R2*fastq.gz)\n\n\n\n  elif [[ \"${library}\" == \"MG_2\" ]]; then\n\n    reads_array=(\"${reads_dir}\"/*MG_2*fastq.gz)\n\n    # Create array of fastq R1 files\n    R1_array=(\"${reads_dir}\"/*MG_2*R1*fastq.gz)\n\n    # Create array of fastq R2 files\n    R2_array=(\"${reads_dir}\"/*MG_2*R2*fastq.gz)\n\n  elif [[ \"${library}\" == \"MG_3\" ]]; then\n\n    reads_array=(\"${reads_dir}\"/*MG_3*fastq.gz)\n\n    # Create array of fastq R1 files\n    R1_array=(\"${reads_dir}\"/*MG_3*R1*fastq.gz)\n\n    # Create array of fastq R2 files\n    R2_array=(\"${reads_dir}\"/*MG_3*R2*fastq.gz)\n\n  elif [[ \"${library}\" == \"MG_5\" ]]; then\n\n    reads_array=(\"${reads_dir}\"/*MG_5*fastq.gz)\n\n    # Create array of fastq R1 files\n    R1_array=(\"${reads_dir}\"/*MG_5*R1*fastq.gz)\n\n    # Create array of fastq R2 files\n    R2_array=(\"${reads_dir}\"/*MG_5*R2*fastq.gz)\n\n  elif [[ \"${library}\" == \"MG_6\" ]]; then\n\n    reads_array=(\"${reads_dir}\"/*MG_6*fastq.gz)\n\n    # Create array of fastq R1 files\n    R1_array=(\"${reads_dir}\"/*MG_6*R1*fastq.gz)\n\n    # Create array of fastq R2 files\n    R2_array=(\"${reads_dir}\"/*MG_6*R2*fastq.gz)\n\n  elif [[ \"${library}\" == \"MG_7\" ]]; then\n\n    reads_array=(\"${reads_dir}\"/*MG_7*fastq.gz)\n\n    # Create array of fastq R1 files\n    R1_array=(\"${reads_dir}\"/*MG_7*R1*fastq.gz)\n\n    # Create array of fastq R2 files\n    R2_array=(\"${reads_dir}\"/*MG_7*R2*fastq.gz)\n\n\n  fi\n\n  # Create list of fastq files used in analysis\n  ## Uses parameter substitution to strip leading path from filename\n  printf \"%s\\n\" \"${reads_array[@]##*/}\" >> \"${library}\".fastq.list.txt\n\n  # Create comma-separated lists of FastQ reads\n  R1_list=$(echo \"${R1_array[@]}\" | tr \" \" \",\")\n  R2_list=$(echo \"${R2_array[@]}\" | tr \" \" \",\")\n\n  # Align reads to metagenome assembly\n  ${programs_array[hisat2]} \\\n  --threads ${threads} \\\n  -x \"${hisat2_basename}\" \\\n  -q \\\n  -1 \"${R1_list}\" \\\n  -2 \"${R2_list}\" \\\n  -S \"${library}\".sam \\\n  2>&1 | tee \"${library}\".alignment_stats.txt\n\n  # Convert SAM file to BAM\n  ${programs_array[samtools_view]} \\\n  --threads ${threads} \\\n  -b \"${library}\".sam \\\n  > \"${library}\".bam\n\n  # Sort BAM\n  ${programs_array[samtools_sort]} \\\n  --threads ${threads} \\\n  \"${library}\".bam \\\n  -o \"${library}\".sorted.bam\n\n  # Index for use in IGV\n  ##-@ specifies thread count; --thread option not available in samtools index\n  ${programs_array[samtools_index]} \\\n  -@ ${threads} \\\n  \"${library}\".sorted.bam\n\n  # Get index stats from sorted bam\n  # Third column is number of reads\n  ${programs_array[samtools_idxstats]} \\\n  --threads ${threads} \\\n  \"${library}\".sorted.bam \\\n  > \"${library}\".sorted.bam.stats.txt\n\n  # Remove original SAM and unsorted BAM\n  rm \"${library}\".bam \"${library}\".sam\n\n\ndone\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n    ${programs_array[$program]} --help\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n  } &>> program_options.log || true\ndone\n\n\n\nRESULTS\nRuntime: Took about 5hrs:\n\n\n\nRuntime\n\n\nOutput folder:\n\n20200731_metagenome_hisat2_alignments/\n\nSamtools idxstats output files. They are tab-delimited.\nFormat:\n<sequence name> <sequence length> <# mapped read-segments> <# unmapped read-segments>\nNOTE: The last line of each file begins with an asterisk and seems to have a total read count? It’s not clear what this line is, as it is not described in the samtools idxstats documentation.\n\nMG_1.sorted.bam.stats.txt\nMG_2.sorted.bam.stats.txt\nMG_3.sorted.bam.stats.txt\nMG_5.sorted.bam.stats.txt\nMG_6.sorted.bam.stats.txt\nMG_7.sorted.bam.stats.txt"
  },
  {
    "objectID": "posts/2020/2020-08-20-Samples-Submitted---Ronits-C.gigas-Diploid-and-Triploid-Ctenidia-to-ZymoResearch-for-WGBS/index.html",
    "href": "posts/2020/2020-08-20-Samples-Submitted---Ronits-C.gigas-Diploid-and-Triploid-Ctenidia-to-ZymoResearch-for-WGBS/index.html",
    "title": "Samples Submitted - Ronits C.gigas Diploid and Triploid Ctenidia to ZymoResearch for WGBS",
    "section": "",
    "text": "Submitted 1.75ug of gDNA from 10 Crassostrea gigas ctenidia samples from Ronit’s dessication/temp/ploidy experiment to ZymoResearch for whole genome bisulfite sequencing (BSseq). They will sequence to ~30x coverage, using 150bp PE reads.\n\nRonit Samples (Google Sheet)\n\nThe samples sent for sequencing are marked in the sheet above, but here’s a list of the samples:\n\n\n\nSample_ID\nConcentration(ng/uL)\nVolume_for_1.75ug(uL)\n\n\n\n\nD11-C\n181\n9.7\n\n\nD12-C\n192\n9.1\n\n\nD13-C\n288\n6.1\n\n\nD19-C\n173\n28\n\n\nD20-C\n109\n14.2\n\n\nT11-C\n130\n13.5\n\n\nT12-C\n262\n6.7\n\n\nT13-C\n250\n7\n\n\nT19-C\n173\n10.1\n\n\nT20-C\n109\n16.1\n\n\n\nSamples were shipped on dry, FedEx standard overnight: 147801693220"
  },
  {
    "objectID": "posts/2020/2020-11-10-Transcriptome-Assessment---Crustacean-Transcripome-Completeness-Evaluation-Using-BUSCO-on-Mox/index.html",
    "href": "posts/2020/2020-11-10-Transcriptome-Assessment---Crustacean-Transcripome-Completeness-Evaluation-Using-BUSCO-on-Mox/index.html",
    "title": "Transcriptome Assessment - Crustacean Transcripome Completeness Evaluation Using BUSCO on Mox",
    "section": "",
    "text": "Grace was recently working on writing up a manuscript which did a basic comparison of our C.bairdi transcriptome (cbai_transcriptome_v3.1) (see the Genomic Resources wiki for more deets) to two other species’ transcriptome assemblies. We wanted BUSCO evaluations as part of this comparison, but the two other species did not have BUSCO scores in their respective publications. As such, I decided to generate them myself, as BUSCO runs very quickly. The job was run on Mox.\nInfo on the other two species’ transcriptomes:\n\nCarcinus maenas (green crab) transcriptome: NCBI TSA\n\nPublication: Verbruggen, Bas, Lisa K. Bickley, Eduarda M. Santos, Charles R. Tyler, Grant D. Stentiford, Kelly S. Bateman, and Ronny van Aerle. 2015. “De Novo Assembly of the Carcinus Maenas Transcriptome and Characterization of Innate Immune System Pathways.” BMC Genomics 16 (June): 458.\n\nLitopenaeus vannamei (whiteleg shrimp) transcriptome: OAKTrust\n\nPublication: Novel transcriptome assembly and improved annotation of the whiteleg shrimp (Litopenaeus vannamei), a dominant crustacean in global seafood mariculture\n\n\nSBATCH script (GitHub):\n\n20201110_crustacean-transcriptomes_busco.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=20201110_crustacean-transcriptomes_busco\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=3-00:00:00\n## Memory per node\n#SBATCH --mem=200G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20201110_crustacean-transcriptomes_busco\n###################################################################################\n\n\n\n\n\n# These variables need to be set by user\n\n## Save working directory\nwd=$(pwd)\n\n# Transcriptomes array\ntranscriptomes_array=(\n/gscratch/srlab/sam/data/C_maenas/transcriptomes/GBXE01.1.fsa_nt \\\n/gscratch/srlab/sam/data/L_vannamei/transcriptomes/Trinity_Trimmed_Whiteleg_Shrimp_Transcrimptome_Assmbled_Supplemental_Data_1.fasta\n)\n\n\n\n## Input files and settings\nbusco_db=/gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9\naugustus_species=fly\nthreads=28\n\n# Programs associative array\ndeclare -A programs_array\nprograms_array=(\n[busco]=\"/gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py\"\n)\n\n\n## Set program paths\naugustus_bin=/gscratch/srlab/programs/Augustus-3.3.2/bin\naugustus_orig_config_dir=/gscratch/srlab/programs/Augustus-3.3.2/config\naugustus_scripts=/gscratch/srlab/programs/Augustus-3.3.2/scripts\nblast_dir=/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin/\nhmm_dir=/gscratch/srlab/programs/hmmer-3.2.1/src/\n\n# Export Augustus variable\nexport PATH=\"${augustus_bin}:$PATH\"\nexport PATH=\"${augustus_scripts}:$PATH\"\n\n## BUSCO configs\nbusco_config_default=/gscratch/srlab/programs/busco-v3/config/config.ini.default\nbusco_config_ini=${wd}/config.ini\n\n# Export BUSCO config file location\nexport BUSCO_CONFIG_FILE=\"${busco_config_ini}\"\n\n# Copy BUSCO config file\ncp ${busco_config_default} \"${busco_config_ini}\"\n\n# Edit BUSCO config file\n## Set paths to various programs\n### The use of the % symbol sets the delimiter sed uses for arguments.\n### Normally, the delimiter that most examples use is a slash \"/\".\n### But, we need to expand the variables into a full path with slashes, which screws up sed.\n### Thus, the use of % symbol instead (it could be any character that is NOT present in the expanded variable; doesn't have to be \"%\").\nsed -i \"/^;cpu/ s/1/${threads}/\" \"${busco_config_ini}\"\nsed -i \"/^tblastn_path/ s%tblastn_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^makeblastdb_path/ s%makeblastdb_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^augustus_path/ s%augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^etraining_path/ s%etraining_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^gff2gbSmallDNA_path/ s%gff2gbSmallDNA_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^new_species_path/ s%new_species_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^optimize_augustus_path/ s%optimize_augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^hmmsearch_path/ s%hmmsearch_path = /home/osboxes/BUSCOVM/hmmer/hmmer-3.1b2-linux-intel-ia32/binaries/%path = ${hmm_dir}%\" \"${busco_config_ini}\"\n\n###################################################################################\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Load Open MPI module for parallel, multi-node processing\nmodule load icc_19-ompi_3.1.2\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\nfor transcriptome in \"${!transcriptomes_array[@]}\"\ndo\n\n  # Remove path from transcriptome using parameter substitution\n  transcriptome_name=\"${transcriptomes_array[$transcriptome]##*/}\"\n\n  ## Augustus config directories\n  augustus_dir=${wd}/${transcriptome_name}_augustus\n  augustus_config_dir=${augustus_dir}/config\n\n\n  export AUGUSTUS_CONFIG_PATH=\"${augustus_config_dir}\"\n\n\n  # Make Augustus directory if it doesn't exist\n  if [ ! -d \"${augustus_dir}\" ]; then\n    mkdir --parents \"${augustus_dir}\"\n  fi\n\n  # Copy Augustus config directory\n  cp --preserve -r ${augustus_orig_config_dir} \"${augustus_dir}\"\n\n\n  # Run BUSCO/Augustus training\n  ${programs_array[busco]} \\\n  --in ${transcriptomes_array[$transcriptome]} \\\n  --out ${transcriptome_name} \\\n  --lineage_path ${busco_db} \\\n  --mode transcriptome \\\n  --cpu ${threads} \\\n  --long \\\n  --species ${augustus_species} \\\n  --tarzip \\\n  --augustus_parameters='--progress=true'\n\n  # Capture FastA checksums for verification\n  echo \"\"\n  echo \"Generating checksum for ${transcriptome_name}\"\n  md5sum \"${transcriptomes_array[$transcriptome]}\" > \"${transcriptome_name}\".checksum.md5\n  echo \"Finished generating checksum for ${transcriptome_name}\"\n  echo \"\"\n\ndone\n\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n    ${programs_array[$program]} --help\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n\nRESULTS\nAs usual, runtime was very quick ~8mins:\n\n\n\nCumulative runtime for BUSCO evaluation of L.vannamei and C.maenas transcriptomes on Mox\n\n\nOutput folder:\n\n20201110_crustacean-transcriptomes_busco/\n\n\nC.maenas\n\n20201110_crustacean-transcriptomes_busco/run_GBXE01.1.fsa_nt/short_summary_GBXE01.1.fsa_nt.txt\n\n# BUSCO version is: 3.0.2\n# The lineage dataset is: metazoa_odb9 (Creation date: 2016-02-13, number of species: 65, number of BUSCOs: 978)\n# To reproduce this run: python /gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py -i /gscratch/srlab/sam/data/C_maenas/transcriptomes/GBXE01.1.fsa_nt -o GBXE01.1.fsa_nt -l /gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9/ -m transcriptome -c 28 --long -z\n#\n# Summarized benchmarking in BUSCO notation for file /gscratch/srlab/sam/data/C_maenas/transcriptomes/GBXE01.1.fsa_nt\n# BUSCO was run in mode: transcriptome\n\n    C:95.7%[S:57.0%,D:38.7%],F:3.6%,M:0.7%,n:978\n\n    935 Complete BUSCOs (C)\n    557 Complete and single-copy BUSCOs (S)\n    378 Complete and duplicated BUSCOs (D)\n    35  Fragmented BUSCOs (F)\n    8   Missing BUSCOs (M)\n    978 Total BUSCO groups searched\n\n\nL.vannamei\n\n20201110_crustacean-transcriptomes_busco/run_Trinity_Trimmed_Whiteleg_Shrimp_Transcrimptome_Assmbled_Supplemental_Data_1.fasta/short_summary_Trinity_Trimmed_Whiteleg_Shrimp_Transcrimptome_Assmbled_Supplemental_Data_1.fasta.txt\n\n# BUSCO version is: 3.0.2\n# The lineage dataset is: metazoa_odb9 (Creation date: 2016-02-13, number of species: 65, number of BUSCOs: 978)\n# To reproduce this run: python /gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py -i /gscratch/srlab/sam/data/L_vannamei/transcriptomes/Trinity_Trimmed_Whiteleg_Shrimp_Transcrimptome_Assmbled_Supplemental_Data_1.fasta -o Trinity_Trimmed_Whiteleg_Shrimp_Transcrimptome_Assmbled_Supplemental_Data_1.fasta -l /gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9/ -m transcriptome -c 28 --long -z\n#\n# Summarized benchmarking in BUSCO notation for file /gscratch/srlab/sam/data/L_vannamei/transcriptomes/Trinity_Trimmed_Whiteleg_Shrimp_Transcrimptome_Assmbled_Supplemental_Data_1.fasta\n# BUSCO was run in mode: transcriptome\n\n    C:98.1%[S:72.7%,D:25.4%],F:0.9%,M:1.0%,n:978\n\n    959 Complete BUSCOs (C)\n    711 Complete and single-copy BUSCOs (S)\n    248 Complete and duplicated BUSCOs (D)\n    9   Fragmented BUSCOs (F)\n    10  Missing BUSCOs (M)\n    978 Total BUSCO groups searched"
  },
  {
    "objectID": "posts/2020/2020-04-27-GO-to-GOslim---C.bairdi-Enriched-GO-Terms-from-20200422-DEGs/index.html",
    "href": "posts/2020/2020-04-27-GO-to-GOslim---C.bairdi-Enriched-GO-Terms-from-20200422-DEGs/index.html",
    "title": "GO to GOslim - C.bairdi Enriched GO Terms from 20200422 DEGs",
    "section": "",
    "text": "After running pairwise comparisons and identify differentially expressed genes (DEGs) on 20200422 and finding enriched gene ontology terms, I decided to map the GO terms to Biological Process GOslims. Additionally, I decided to try another level of comparison (I’m not sure how valid it is), whereby I will count the number of GO terms assigned to each GOslim and then calculate the percentage of GOterms that get assigned to each of the GOslim categories. The idea being that it might help identify Biological Processes that are “favored” in a given set of DEGs. I decided to set up “fancy” pyramid plots to view a given set of GO-GOslims for each DEG comparison.\nAll work was done in R. The initial counting/percentage calculations were done with the following R script (note: all of the followin R code are part of an R Project - link is in the RESULTS section of notebook). The R script uses a “flattened” set of the enriched GO terms identified by Trinity/GOseq, where flattened means one GO term per row. So, a gene may be represented multiple times, in multiple rows if there were multiple GO terms assigned to it by Trinity/GOseq.\nThe script then relies on the GSEABase package (Bioconductor) and the GO Consortium’s “Generic GO subset”:\n\ngoslim_generic.obo\n\nAfter that, I plotted the outputs.\nGO to GOslim R script:\n\nGO_to_GOslim.R\n\nlibrary(GSEABase)\nlibrary(tidyverse)\n\n#########################################################################\n# Scipt to map C.bairdi DEG enriched GO terms to GOslims\n# and identify the GO terms contributing to each GOslim\n#########################################################################\n\n### Download files and specify destination directory\ndownload.file(url = \"https://gannet.fish.washington.edu/Atumefaciens/20200422_cbai_DEG_basic_comparisons/D9-D12/edgeR.169728.dir/salmon.gene.counts.matrix.D12_vs_D9.edgeR.DE_results.P0.05_C1.D12-UP.subset.GOseq.enriched.flattened\",\n              destfile = \"./data/D9-D12/salmon.gene.counts.matrix.D12_vs_D9.edgeR.DE_results.P0.05_C1.D12-UP.subset.GOseq.enriched.flattened\")\n\ndownload.file(url = \"https://gannet.fish.washington.edu/Atumefaciens/20200422_cbai_DEG_basic_comparisons/D9-D12/edgeR.169728.dir/salmon.gene.counts.matrix.D12_vs_D9.edgeR.DE_results.P0.05_C1.D9-UP.subset.GOseq.enriched.flattened\",\n              destfile = \"./data/D9-D12/salmon.gene.counts.matrix.D12_vs_D9.edgeR.DE_results.P0.05_C1.D9-UP.subset.GOseq.enriched.flattened\")\n\ndownload.file(url = \"https://gannet.fish.washington.edu/Atumefaciens/20200422_cbai_DEG_basic_comparisons/D9-D26/edgeR.200352.dir/salmon.gene.counts.matrix.D26_vs_D9.edgeR.DE_results.P0.05_C1.D9-UP.subset.GOseq.enriched.flattened\",\n              destfile = \"./data/D9-D26/salmon.gene.counts.matrix.D26_vs_D9.edgeR.DE_results.P0.05_C1.D9-UP.subset.GOseq.enriched.flattened\")\n\ndownload.file(url = \"https://gannet.fish.washington.edu/Atumefaciens/20200422_cbai_DEG_basic_comparisons/D9-D26/edgeR.200352.dir/salmon.gene.counts.matrix.D26_vs_D9.edgeR.DE_results.P0.05_C1.D26-UP.subset.GOseq.enriched.flattened\",\n              destfile = \"./data/D9-D26/salmon.gene.counts.matrix.D26_vs_D9.edgeR.DE_results.P0.05_C1.D26-UP.subset.GOseq.enriched.flattened\")\n\ndownload.file(url = \"https://gannet.fish.washington.edu/Atumefaciens/20200422_cbai_DEG_basic_comparisons/D12-D26/edgeR.230922.dir/salmon.gene.counts.matrix.D12_vs_D26.edgeR.DE_results.P0.05_C1.D26-UP.subset.GOseq.enriched.flattened\",\n              destfile = \"./data/D12-D26/salmon.gene.counts.matrix.D12_vs_D26.edgeR.DE_results.P0.05_C1.D26-UP.subset.GOseq.enriched.flattened\")\n\ndownload.file(url = \"https://gannet.fish.washington.edu/Atumefaciens/20200422_cbai_DEG_basic_comparisons/ambient-cold/edgeR.267393.dir/salmon.gene.counts.matrix.ambient_vs_cold.edgeR.DE_results.P0.05_C1.ambient-UP.subset.GOseq.enriched.flattened\",\n              destfile = \"./data/ambient-cold/salmon.gene.counts.matrix.ambient_vs_cold.edgeR.DE_results.P0.05_C1.ambient-UP.subset.GOseq.enriched.flattened\")\n\ndownload.file(url = \"https://gannet.fish.washington.edu/Atumefaciens/20200422_cbai_DEG_basic_comparisons/ambient-cold/edgeR.267393.dir/salmon.gene.counts.matrix.ambient_vs_cold.edgeR.DE_results.P0.05_C1.cold-UP.subset.GOseq.enriched.flattened\",\n              destfile = \"./data/ambient-cold/salmon.gene.counts.matrix.ambient_vs_cold.edgeR.DE_results.P0.05_C1.cold-UP.subset.GOseq.enriched.flattened\")\n\ndownload.file(url = \"https://gannet.fish.washington.edu/Atumefaciens/20200422_cbai_DEG_basic_comparisons/ambient-warm/edgeR.297991.dir/salmon.gene.counts.matrix.ambient_vs_warm.edgeR.DE_results.P0.05_C1.warm-UP.subset.GOseq.enriched.flattened\",\n              destfile = \"./data/ambient-warm/salmon.gene.counts.matrix.ambient_vs_warm.edgeR.DE_results.P0.05_C1.warm-UP.subset.GOseq.enriched.flattened\")\n\ndownload.file(url = \"https://gannet.fish.washington.edu/Atumefaciens/20200422_cbai_DEG_basic_comparisons/ambient-warm/edgeR.297991.dir/salmon.gene.counts.matrix.ambient_vs_warm.edgeR.DE_results.P0.05_C1.ambient-UP.subset.GOseq.enriched.flattened\",\n              destfile = \"./data/ambient-warm/salmon.gene.counts.matrix.ambient_vs_warm.edgeR.DE_results.P0.05_C1.ambient-UP.subset.GOseq.enriched.flattened\")\n\ndownload.file(url = \"https://gannet.fish.washington.edu/Atumefaciens/20200422_cbai_DEG_basic_comparisons/cold-warm/edgeR.328585.dir/salmon.gene.counts.matrix.cold_vs_warm.edgeR.DE_results.P0.05_C1.warm-UP.subset.GOseq.enriched.flattened\",\n              destfile = \"./data/cold-warm/salmon.gene.counts.matrix.cold_vs_warm.edgeR.DE_results.P0.05_C1.warm-UP.subset.GOseq.enriched.flattened\")\n\ndownload.file(url = \"https://gannet.fish.washington.edu/Atumefaciens/20200422_cbai_DEG_basic_comparisons/cold-warm/edgeR.328585.dir/salmon.gene.counts.matrix.cold_vs_warm.edgeR.DE_results.P0.05_C1.cold-UP.subset.GOseq.enriched.flattened\",\n              destfile = \"./data/cold-warm/salmon.gene.counts.matrix.cold_vs_warm.edgeR.DE_results.P0.05_C1.cold-UP.subset.GOseq.enriched.flattened\")\n\ndownload.file(url = \"https://gannet.fish.washington.edu/Atumefaciens/20200422_cbai_DEG_basic_comparisons/infected-uninfected/edgeR.132470.dir/salmon.gene.counts.matrix.infected_vs_uninfected.edgeR.DE_results.P0.05_C1.infected-UP.subset.GOseq.enriched.flattened\",\n              destfile = \"./data/infected-uninfected/salmon.gene.counts.matrix.infected_vs_uninfected.edgeR.DE_results.P0.05_C1.infected-UP.subset.GOseq.enriched.flattened\")\n\ndownload.file(url = \"https://gannet.fish.washington.edu/Atumefaciens/20200422_cbai_DEG_basic_comparisons/infected-uninfected/edgeR.132470.dir/salmon.gene.counts.matrix.infected_vs_uninfected.edgeR.DE_results.P0.05_C1.uninfected-UP.subset.GOseq.enriched.flattened\",\n              destfile = \"./data/infected-uninfected/salmon.gene.counts.matrix.infected_vs_uninfected.edgeR.DE_results.P0.05_C1.uninfected-UP.subset.GOseq.enriched.flattened\")\n\n\n### Set false discovery rate (FDR) filter, if desired\nfdr <- as.character(\"1.0\")\n\n### Create list of files\ngoseq_files <- list.files(path = \"./data\",\n                          pattern = \"\\\\.GOseq.[de]\",\n                          recursive = TRUE,\n                          full.names = TRUE)\n\n### Set output filename suffix\noutput_suffix=(\"GOslims.csv\")\n\n### Strip path from goseq files\ngoseq_filename <- basename(goseq_files)\n\n### Vector of GOslim ontologies (e.g. Biological Process = BP, Molecular Function = MF, Cellular Component = CC)\nontologies <- c(\"BP\", \"CC\", \"MF\")\n\nfor (slim_ontology in ontologies) {\n\n  ### Set GOOFFSPRING database, based on ontology group set above\n  go_offspring <- paste(\"GO\", slim_ontology, \"OFFSPRING\", sep = \"\")\n\n  for (item in goseq_files) {\n\n    ## Get max number of fields\n    # Needed to handle reading in file with different number of columns in each row\n    # as there may be multiple\n    max_fields <- max(count.fields(item, sep = \"\\t\"), na.rm = TRUE)\n\n    ## Read in tab-delimited GOseq file\n    # Use \"max_fields\" to populate all columns with a sequentially numbered header\n    go_seqs <- read.delim(item,\n                          col.names = paste0(\"V\",seq_len(max_fields)))\n\n    ## Filter enriched GOterms with false discovery rate\n    goseqs_fdr <- filter(go_seqs, V8 <= as.numeric(fdr))\n\n    ## Grab just the individual GO terms from the \"category\" column)\n    goterms <- as.character(goseqs_fdr$V1)\n\n    ### Use GSEA to map GO terms to GOslims\n\n    ## Store goterms as GSEA object\n    myCollection <- GOCollection(goterms)\n\n    ## Use generic GOslim file to create a GOslim collection\n\n    # I downloaded goslim_generic.obo from http://geneontology.org/docs/go-subset-guide/\n    # then i moved it to the R library for GSEABase in the extdata folder\n    # in addition to using the command here - I think they're both required.\n    slim <- getOBOCollection(\"./data/goslim_generic.obo\")\n\n    ## Map GO terms to GOslims and select Biological Processes group\n    slimsdf <- goSlim(myCollection, slim, slim_ontology)\n\n    ## Need to know the 'offspring' of each term in the ontology, and this is given by the data in:\n    # GO.db::getFromNamespace(go_offspring, \"GO.db\")\n\n    ## Create function to parse out GO terms assigned to each GOslim\n    ## Courtesy Bioconductor Support: https://support.bioconductor.org/p/128407/\n    mappedIds <-\n      function(df, collection, OFFSPRING)\n      {\n        map <- as.list(OFFSPRING[rownames(df)])\n        mapped <- lapply(map, intersect, ids(collection))\n        df[[\"go_terms\"]] <- vapply(unname(mapped), paste, collapse = \";\", character(1L))\n        df\n      }\n\n    ## Run the function\n    slimsdf <- mappedIds(slimsdf, myCollection, getFromNamespace(go_offspring, \"GO.db\"))\n\n    ## Provide column name for first column\n    slimsdf <- cbind(GOslim = rownames(slimsdf), slimsdf)\n    rownames(slimsdf) <- NULL\n\n    ### Prep output file naming structure\n\n    ## Split filenames on periods\n    ## Creates a list\n    split_filename <- strsplit(item, \".\", fixed = TRUE)\n\n    ## Split filename on directories\n    ## Creates a list\n    split_dirs <- strsplit(item, \"/\", fixed = TRUE)\n\n    ## Slice split_filename list from position 9 to the last position of the list\n    ## Paste these together using a period\n    goseq_filename_split <-paste(split_filename[[1]][9:lengths(split_filename)], collapse = \".\")\n\n    ## Slice split_dirs list at position\n\n    ## Paste elements together to form output filename\n    fdr_file_out <- paste(\"FDR\", fdr, sep = \"_\")\n    outfilename <- paste(goseq_filename_split, fdr_file_out, slim_ontology ,output_suffix, collapse = \".\", sep = \".\")\n\n    ## Set output file destination and name\n    ## Adds proper subdirectory from split_dirs list\n    outfile_dest <- file.path(\"./analyses\", split_dirs[[1]][3], outfilename)\n\n    ## Write output file\n    write.csv(slimsdf, file = outfile_dest, quote = FALSE, row.names = FALSE)\n\n\n  }\n}\nSince I got “lazy” and didn’t want to try to figure out how to properly loop through all of the output files from the above script, I just made individual scripts to plot each set of comparison GO terms percentages assigned to GOslims. Here’s an example:\n\ninfected-uninfected_GOslim_pyramid_plotting.R\n\n# Script to generate a \"pyramid\" plot\n# comparing the percentages of enriched GO terms assinged\n# to each category of Biological Process GOslims\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\n\n#####################################################\n# Set the following variables for the appropriate comparisons/files\n#####################################################\n# Comparison\ncomparison <- \"infected-uninfected\"\n\n# Treatments\ntreatment_01 <- \"infected\"\ntreatment_02 <- \"uninfected\"\n\n# Read in first comparsion files\ndf1 <- read.csv(\"analyses/infected-uninfected/P0.05_C1.infected-UP.subset.GOseq.enriched.flattened.FDR_1.0.BP.GOslims.csv\")\n\n# Read in second comparison file\ndf2 <- read.csv(\"analyses/infected-uninfected/P0.05_C1.uninfected-UP.subset.GOseq.enriched.flattened.FDR_1.0.BP.GOslims.csv\")\n\n\n######################################################\n# CHANGES BELOW HERE ARE PROBABLY NOT NECESSARY\n######################################################\n\n# GOslim categories\nontologies <- c(\"BP\", \"CC\", \"MF\")\n\n# Remove generic \"biological_process\" category\ndf1 <- df1[df1$GOslim != \"GO:0008150\",]\ndf2 <- df2[df2$GOslim != \"GO:0008150\",]\n\n# Remove generic \"cellular_component\"  category\ndf1 <- df1[df1$GOslim != \"GO:0005575\",]\ndf2 <- df2[df2$GOslim != \"GO:0005575\",]\n\n\n# Remove generic \"molecular_function\"  category\ndf1 <- df1[df1$GOslim != \"GO:0003674\",]\ndf2 <- df2[df2$GOslim != \"GO:0003674\",]\n\n# Select columns\ndf1 <- df1 %>% select(Term, Percent)\ndf2 <- df2 %>% select(Term, Percent)\n\n# Create treatment column and assign term to all rows\ndf1$treatment <- treatment_01\ndf2$treatment <- treatment_02\n\n# Concatenate dataframes\ndf3 <- rbind(df1, df2)\n\n# Filename for plot\npyramid <- paste(comparison, \"GOslims\", \"BP\", \"png\", sep = \".\")\npyramid_path <- paste(comparison, pyramid, sep = \"/\")\npyramid_dest <- file.path(\"./analyses\", pyramid_path)\n\n# \"Open\" PNG file for saving subsequent plot\npng(pyramid_dest, width = 600, height = 1200, units = \"px\", pointsize = 12)\n\n# Create \"pyramid\" plot\nggplot(df3, aes(x = Term, fill = treatment,\n                y = ifelse(test = treatment == treatment_01,\n                           yes = -Percent,\n                           no = Percent))) +\n  geom_bar(stat = \"identity\") +\n  scale_y_continuous(labels = abs, limits = max(df3$Percent) * c(-1,1)) +\n  labs(title = \"Percentages of GO terms assigned to BP GOslims\", x = \"GOslim\", y = \"Percent GO terms in GOslim\") +\n  scale_x_discrete(expand = c(-1,0)) +\n  coord_flip()\n\n# Close PNG file\ndev.off()\n\n\nRESULTS\nOutput folder (GitHub; R Project):\n\n20200427_cbai_deg_go-goslims\n\nImages of each of the plots are below. Larger versions of the images can be viewed by clicking on the image. All images are 1200x600 pixels, so should be a reasonable size for viewing.\nAlso, it should be noted that the GOslim term “biological_process” was omitted from the plotting. This GOslim category is a “catchall” for any GO terms that do not fall into a GOslim category. As such, “biological_process” almost always makes up the bulk of the GOslim and this effectively compresses the plots, making it difficult to see any differences between the remaining GOslim categories. Knowing this explains why the percentages in each comparison never add up to 100%!\n\n\nD9-D12\n\n\n\nD9 vs D12 GO-GOslim pyramid plot\n\n\n\n\n\nD9-D26\n\n\n\nD9 vs D26 GO-GOslim pyramid plot\n\n\n\n\n\nD12-D26\n\n\n\nD12 vs D26 GO-GOslim pyramid plot\n\n\n\n\n\nambient-cold\n\n\n\nambient vs vold GO-GOslim pyramid plot\n\n\n\n\n\nambient-warm\n\n\n\nambient vs warm GO-GOslim pyramid plot\n\n\n\n\n\ncold-warm\n\n\n\ncold vs warm GO-GOslim pyramid plot\n\n\n\n\n\ninfected-uninfected\n\n\n\ninfected vs uninfected GO-GOslim pyramid plot"
  },
  {
    "objectID": "posts/2020/2020-03-31-Transcriptome-Assembly---Hematodinium-with-MEGAN6-Taxonomy-specific-Reads-with-Trinity-on-Mox/index.html",
    "href": "posts/2020/2020-03-31-Transcriptome-Assembly---Hematodinium-with-MEGAN6-Taxonomy-specific-Reads-with-Trinity-on-Mox/index.html",
    "title": "Transcriptome Assembly - Hematodinium with MEGAN6 Taxonomy-specific Reads with Trinity on Mox",
    "section": "",
    "text": "Ran a de novo assembly using the extracted reads classified under Alveolata from:\n\n20200122\n20200330\n\nThe assembly was performed with Trinity on Mox. It’s important to note that this assembly was not performed using the “stranded” option in Trinity. The previous Trinity assembly from 20200122 was performed using the “stranded” setting. The reason for this difference is that the most recent RNAseq libraries from 20200318 were not stranded libraries. As such, I think it might be best to use the “lowest common denominator” approach.\nSBATCH script (GitHub):\n\n20200330_hemat_trinity_megan_RNAseq.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=trinity_hemat\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200330_hemat_trinity_megan_RNAseq\n\n# Exit script if a command fails\nset -e\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# User-defined variables\nreads_dir=/gscratch/srlab/sam/data/Hematodinium/RNAseq\ntranscriptome_dir=/gscratch/srlab/sam/data/Hematodinium/transcriptomes\nthreads=27\nassembly_stats=assembly_stats.txt\ntimestamp=$(date +%Y%m%d)\nfasta_name=\"${timestamp}.hemat.megan.Trinity.fasta\"\n\n# Paths to programs\ntrinity_dir=\"/gscratch/srlab/programs/trinityrnaseq-v2.9.0\"\nsamtools=\"/gscratch/srlab/programs/samtools-1.10/samtools\"\n\n\n## Inititalize arrays\nR1_array=()\nR2_array=()\n\n# Variables for R1/R2 lists\nR1_list=\"\"\nR2_list=\"\"\n\n# Create array of fastq R1 files\nR1_array=(\"${reads_dir}\"/*_R1.fq)\n\n# Create array of fastq R2 files\nR2_array=(\"${reads_dir}\"/*_R2.fq)\n\n# Create list of fastq files used in analysis\n## Uses parameter substitution to strip leading path from filename\nfor fastq in \"${reads_dir}\"/*.fq\ndo\n  echo \"${fastq##*/}\" >> fastq.list.txt\ndone\n\n# Create comma-separated lists of FastQ reads\nR1_list=$(echo \"${R1_array[@]}\" | tr \" \" \",\")\nR2_list=$(echo \"${R2_array[@]}\" | tr \" \" \",\")\n\n\n# Run Trinity using \"stranded\" setting (--SS_lib_type)\n${trinity_dir}/Trinity \\\n--seqType fq \\\n--max_memory 120G \\\n--CPU ${threads} \\\n--left \"${R1_list}\" \\\n--right \"${R2_list}\"\n\n# Rename generic assembly FastA\nmv trinity_out_dir/Trinity.fasta trinity_out_dir/\"${fasta_name}\"\n\n# Assembly stats\n${trinity_dir}/util/TrinityStats.pl trinity_out_dir/\"${fasta_name}\" \\\n> ${assembly_stats}\n\n# Create gene map files\n${trinity_dir}/util/support_scripts/get_Trinity_gene_to_trans_map.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n> trinity_out_dir/\"${fasta_name}\".gene_trans_map\n\n# Create sequence lengths file (used for differential gene expression)\n${trinity_dir}/util/misc/fasta_seq_length.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n> trinity_out_dir/\"${fasta_name}\".seq_lens\n\n# Create FastA index\n${samtools} faidx \\\ntrinity_out_dir/\"${fasta_name}\"\n\n# Copy files to transcriptome directory\nrsync -av \\\ntrinity_out_dir/\"${fasta_name}\"* \\\n${transcriptome_dir}\n\n\nRESULTS\nThis was remarkably fast! I think was likely due to not using the “stranded” setting in Trinity.\n\nOutput folder:\n\n20200330_hemat_trinity_megan_RNAseq/\n\nAssembly (FastA; 4.5MB):\n\n20200330_hemat_trinity_megan_RNAseq/trinity_out_dir/20200408.hemat.megan.Trinity.fasta\n\nFastA Index (FAI):\n\n20200330_hemat_trinity_megan_RNAseq/trinity_out_dir/20200408.hemat.megan.Trinity.fasta.fai\n\nTrinity Gene Trans Map (txt):\n\n20200330_hemat_trinity_megan_RNAseq/trinity_out_dir/20200408.hemat.megan.Trinity.fasta.gene_trans_map\n\nAssembly Stats (txt):\n\n20200330_hemat_trinity_megan_RNAseq/assembly_stats.txt\n\n################################\n## Counts of transcripts, etc.\n################################\nTotal trinity 'genes':  5632\nTotal trinity transcripts:  6348\nPercent GC: 50.37\n\n########################################\nStats based on ALL transcript contigs:\n########################################\n\n    Contig N10: 1805\n    Contig N20: 1406\n    Contig N30: 1152\n    Contig N40: 961\n    Contig N50: 817\n\n    Median contig length: 530\n    Average contig: 656.83\n    Total assembled bases: 4169557\n\n\n#####################################################\n## Stats based on ONLY LONGEST ISOFORM per 'GENE':\n#####################################################\n\n    Contig N10: 1770\n    Contig N20: 1386\n    Contig N30: 1131\n    Contig N40: 941\n    Contig N50: 797\n\n    Median contig length: 511\n    Average contig: 636.72\n    Total assembled bases: 3586009\nInterestingly, this assembly may actually be worse than the previous Trinity assembly from 20200122. Although it has marginally greater numbers of trinity genes and trinity transcripts, virtually all other metrics have decreased (albeit, not by much). Will assess transcriptome completeness with BUSCO and see if there’s any noticeable improvement on that front."
  },
  {
    "objectID": "posts/2020/2020-03-10-qPCR---C.bairdi-RNA-Check-for-Residual-gDNA/index.html",
    "href": "posts/2020/2020-03-10-qPCR---C.bairdi-RNA-Check-for-Residual-gDNA/index.html",
    "title": "qPCR - C.bairdi RNA Check for Residual gDNA",
    "section": "",
    "text": "Previuosly checked existing crab RNA for residual gDNA on 20200226 and identified samples with yields that were likely too low, as well as samples with residual gDNA. For those samples, was faster/easier to just isolate more RNA and perform the in-column DNase treatment in the ZymoResearch Quick DNA/RNA Microprep Plus Kit; this keeps samples concentrated. So, I isolated more RNA on 20200306 and now need to check for residual gDNA.\nUsed 2ng of RNA (1uL) in each reaction. A 5uL dilution of each sample was made to a concentration of 2ng/uL. The decision for this quantity was based on the amount of RNA we might use in a reverse transcription reaction (50ng/25uL) and the volume of the resulting cDNA we’d run in a qPCR reaction (1uL). Calculations and the qPCR results (Cq values) are below (Google Sheet).\n\n20200310_cbai_RNA_calcs_qPCR_results\n\nAll reactions were run with 2x SsoFast EVA Green qPCR Master Mix (BioRad) on the Roberts Lab CFX Connect qPCR machine.\nAll samples were run in duplicate. See the qPCR Report (in Results section below) for plate layout, cycling params, etc.\nMaster mix calcs are here (Google Sheet):\n\n20200310_qPCR_cbai_RNA_checks_master_mix_calcs\n\n\n\nRESULTS\nqPCR data file (CFX):\n\nsam_2020-03-10%2016-09-06_BR006896.pcrd\n\nqPCR Report (PDF):\n\nsam_2020-03-10%2016-09-06_BR006896.pdf.pdf\n\nqPCR results file (CSV):\n\nsam_2020-03-10%2016-09-06_BR006896-QuantificationCqResults.csv.csv\n\nPositive control amplified.\nNo template controls (NTCs) did not amplify.\nNo amplification in any samples.\nThings look good. Will evaluate which samples will be used for reverse transcription and subsequent qPCRs.\n\n\n\nAmplification Plots\nBlue: RNA samples\nGreen: Positive control gDNA\nRed: No template controls\n\n\n\nqPCR amplification plots\n\n\n\n\n\nMelt curve plots\nSame color scheme as amplification plots\n\n\n\nqPCR melt curve plots"
  },
  {
    "objectID": "posts/2020/2020-04-19-RNAseq-Reads-Extractions---C.bairdi-Taxonomic-Reads-Extractions-with-MEGAN6-on-swoose/index.html",
    "href": "posts/2020/2020-04-19-RNAseq-Reads-Extractions---C.bairdi-Taxonomic-Reads-Extractions-with-MEGAN6-on-swoose/index.html",
    "title": "RNAseq Reads Extractions - C.bairdi Taxonomic Reads Extractions with MEGAN6 on swoose",
    "section": "",
    "text": "I previously annotated reads and converted them to the MEGAN6 format RMA6 on 20200414.\nI’ll use the MEGAN6 GUI to “Open” the RMA6 file. Once the file loads, you get a nice looking taxonomic tree! From here, you can select any part of the taxonomic tree by right-clicking on the desired taxonomy and “Extract reads…”. Here, you have the option to include “Summarized reads”. This option allows you to extract just the reads that are part of the exact classification you’ve selected or all those within and “below” the classification you’ve selected (i.e. summarized reads).\nExtracted reads will be generated as FastA files.\nExample:\nIf you select Arthropoda and do not check the box for “Summarized Reads” you will only get reads classified as Arthropoda! You will not get any reads with more specific taxonomies. However, if you select Arthropoda and you do check the box for “Summarized Reads”, you will get all reads classified as Arthropoda AND all reads in more specific taxonomic classifications, down to the species level.\nI will extract reads from two phyla:\n\nArthropoda (for crabs)\nAlveolata (for Hematodinium)\n\nAfter read extractions using MEGAN6, I’ll need to extract the actual reads from the trimmed FastQ files from 20200414.\nIt’s a bit convoluted, but I realized that the FastA headers were incomplete and did not distinguish between paired reads. Here’s an example:\nR1 FastQ header:\n@A00147:37:HG2WLDMXX:1:1101:5303:1000 1:N:0:AGGCGAAG+AGGCGAAG\nR2 FastQ header:\n@A00147:37:HG2WLDMXX:1:1101:5303:1000 2:N:0:AGGCGAAG+AGGCGAAG\nHowever, the reads extracted via MEGAN have FastA headers like this:\n>A00147:37:HG2WLDMXX:1:1101:5303:1000\nSEQUENCE1\n>A00147:37:HG2WLDMXX:1:1101:5303:1000\nSEQUENCE2\nThose are a set of paired reads, but there’s no way to distinguish between R1/R2. This may not be an issue, but I’m not sure how downstream programs (i.e. Trinity) will handle duplicate FastA IDs as inputs. To avoid any headaches, I’ve decided to parse out the corresponding FastQ reads which have the full header info.\nHere’s a brief rundown of the approach:\n\nCreate list of unique read headers from MEGAN6 FastA files.\nUse list with seqtk program to pull out corresponding FastQ reads from the trimmed FastQ R1 and R2 files.\n\nThis aspect of read extractions/concatenations is documented in the following Jupyter notebook (GitHub):\n\n20200419_swoose_cbai_megan_day-treatment-temp_read_extractions.ipynb\n\n\n\nRESULTS\nOUTPUT FOLDERS\nInitial reads extracted as FastAs:\n\n20200419_cbai_MEGAN_read_extractions/\n\nFastQ C.bairdi read extractions:\n\n20200419_C_bairdi_megan_reads\n\nFastQ Hematodinium read extractions:\n\n20200419_Hematodinium_megan_reads\n\n\n\n\nTaxonomic Trees\n\n\n\n(MEGAN taxonomic tree for 380820\n\n\n\n\n\n\n(MEGAN taxonomic tree for 380821\n\n\n\n\n\n\n(MEGAN taxonomic tree for 380822\n\n\n\n\n\n\n(MEGAN taxonomic tree for 380823\n\n\n\n\n\n\n(MEGAN taxonomic tree for 380824\n\n\n\n\n\n\n(MEGAN taxonomic tree for 380825"
  },
  {
    "objectID": "posts/2020/2020-05-29-Transcriptome-Comparison---C.bairdi-Transcriptomes-Compared-with-DETONATE-on-Mox/index.html",
    "href": "posts/2020/2020-05-29-Transcriptome-Comparison---C.bairdi-Transcriptomes-Compared-with-DETONATE-on-Mox/index.html",
    "title": "Transcriptome Comparison - C.bairdi Transcriptomes Compared with DETONATE on Mox",
    "section": "",
    "text": "We’ve produced a number of C.bairdi transcriptomes and we’re interested in doing some comparisons to try to determine which one might be “best”. I previously compared the BUSCO scores of each of these transcriptomes and now will be using the DETONATE software package to perform two different types of comparisons: compared to a reference (REF-EVAL) and determine an overall quality “score” (RSEM-EVAL). I’ll be running REF-EVAL in this notebook.\nA link to the paper is here and explains both:\n\nEvaluation of de novo transcriptome assemblies from RNA-Seq data\n\nI opted to just “quickly” run through REF-EVAL, as it only requires (minimally) transcriptome FastAs for performing assembly comparisons; although it probably provides more accurate comparisons if you generate a “true assembly” first. However, this can’t always be done if using a publicly available transcriptome which doesn’t have the corresponding FastQ files used for the assembly.\nSince this is designed to compare a transcriptome assembly to a “reference” transcriptome of a related species, I did a couple of things:\n\nDownloaded Japanese blue crab (Portunus trituberculatus) transcriptome from NCBI (accession: GFFJ01.1).\nDownloaded green crab (Carcinus maenas) transcriptome from NCBI (accession: GBXE01.1).\nDownloaded and [assembled Portunus trituberculatus NCBI SRA RNAseq data](https://robertslab.github.io/sams-notebook/2020/05/23/Transcriptome-Assembly-P.trituberculatus-(Japanese-blue-crab)-NCBI-SRA-BioProject-PRJNA597187-Data-with-Trinity-on-Mox.html).\n\nI then compared all of our assemblies to each other, to the three “reference” sequences, and the three “reference” sequences to our C.bairdi assemblies (i.e. using our assemblies as the “reference” in the comparison).\nThis job was run on Mox.\nSBATCH script (GitHub):\n\n20200529_cbai_detonate_transcriptome_comparisons.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_detonate_transcriptome_comparisons\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=8-00:00:00\n## Memory per node\n#SBATCH --mem=500G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200529_cbai_detonate_transcriptome_comparisons\n\n\n###################################################################################\n# These variables need to be set by user\n\n# Array of the various comparisons to evaluate\n# Each condition in each comparison should be separated by a \"-\"\ntranscriptomes_array=(\ncbai_transcriptome_v1.0.fa \\\ncbai_transcriptome_v1.5.fa \\\ncbai_transcriptome_v1.6.fa \\\ncbai_transcriptome_v1.7.fa \\\ncbai_transcriptome_v2.0.fa \\\ncbai_transcriptome_v3.0.fa \\\n20200526.P_trituberculatus.Trinity.fa \\\nGFFJ01.1.fa \\\nGBXE01.1.fa\n)\n\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nthreads=28\n\n#programs\npblat=\"/gscratch/srlab/programs/pblat-2.1/pblat\"\ndetonate=\"/gscratch/srlab/programs/detonate-1.11/ref-eval/ref-eval\"\n\n\n# Determine length of transcriptomes array\ntranscriptomes_array_length=${#transcriptomes_array[@]}\n\n# Loop through each comparison\nfor (( i=0; i < transcriptomes_array_length; i++ ))\ndo\n  transcriptome1=\"${transcriptomes_array[$i]}\"\n\n  # Capture FastA checksums for verification\n  echo \"Generating checksum for ${transcriptome1}\"\n  md5sum \"${transcriptome1}\" >> fasta.checksums.md5\n  echo \"Finished generating checksum for ${transcriptome1}\"\n  echo \"\"\n\n  for (( j=0; j < transcriptomes_array_length; j++ ))\n  do\n    # Don't run comparison of the same transcriptome\n    if [[ \"${transcriptomes_array[$j]}\" != \"${transcriptomes_array[$i]}\" ]]; then\n      transcriptome2=\"${transcriptomes_array[$j]}\"\n      comparison1=\"${transcriptome1}-vs-${transcriptome2}\"\n      comparison2=\"${transcriptome2}-vs-${transcriptome1}\"\n\n      # Check if pblat output files are not present\n      if [[ ! -f \"${comparison1}.psl\" ]] && [[  -f \"${comparison2}\".psl ]]; then\n        # Run pblat\n        echo \"Starting pblat: ${comparison1}\"\n        ${pblat} -minIdentity=80 -threads=${threads} \"${transcriptome2}\" \"${transcriptome1}\" \"${comparison1}\".psl\n        echo \"Finished pblat: ${comparison1}\"\n        echo \"\"\n\n        echo \"Starting pblat: ${comparison2}\"\n        ${pblat} -minIdentity=80 -threads=${threads} \"${transcriptome1}\" \"${transcriptome2}\" \"${comparison2}\".psl\n        echo \"Finished pblat: ${comparison2}\"\n        echo \"\"\n      fi\n\n      # Check if DETONATE output file exists\n      if [[ ! -f \"${comparison1}.scores.txt\" ]]; then\n        # Run ref-eval, unweighted scores only\n        echo \"Running DETONATE with ${transcriptome1} and ${transcriptome2}.\"\n        ${detonate} \\\n        --scores=nucl,pair,contig \\\n        --weighted=no \\\n        --A-seqs \"${transcriptome1}\" \\\n        --B-seqs \"${transcriptome2}\" \\\n        --A-to-B \"${comparison1}\".psl \\\n        --B-to-A \"${comparison2}\".psl \\\n        | tee \"${comparison1}.scores.txt\"\n        echo \"Finished DETONATE with ${transcriptome1} and ${transcriptome2}.\"\n        echo \"\"\n      fi\n    fi\n\n\n  done\ndone\n\n\nRESULTS\nTook a bit over 3 days to complete:\n\n\n\ncbai transcriptome comparisons runtime\n\n\nNOTE: There are two jobs associated with this because I had to modify SBATCH script after initial run to account for missed reference comparisons.\nWell, I ran this and I am completely unsure what it all means. Hah! And, ugh! It was easy enough to setup and run, so it didn’t require too much effort. However, even after reading the paper, it’s still not clear if this has any real value; particularly since the paper focuses on evaluating de novo assemblies. The evaluation to a reference transcriptome seems like it’s an aside. However, the two sets of software are packaged together as DETONATE, so I figured I’d run them both.\nAll the files are linked below for anyone curious enough to spend time trying to figure out if these results mean anything…\nOutput folder:\n\n20200529_cbai_detonate_transcriptome_comparisons/\n\n\n\nReference: cbai_transcriptome_v1.0\n\nGBXE01.1.fa-vs-cbai_transcriptome_v1.0.fa.scores.txt\nGFFJ01.1.fa-vs-cbai_transcriptome_v1.0.fa.scores.txt\ncbai_transcriptome_v1.5.fa-vs-cbai_transcriptome_v1.0.fa.scores.txt\ncbai_transcriptome_v1.6.fa-vs-cbai_transcriptome_v1.0.fa.scores.txt\ncbai_transcriptome_v1.7.fa-vs-cbai_transcriptome_v1.0.fa.scores.txt\ncbai_transcriptome_v2.0.fa-vs-cbai_transcriptome_v1.0.fa.scores.txt\ncbai_transcriptome_v3.0.fa-vs-cbai_transcriptome_v1.0.fa.scores.txt\n\n\n\n\nReference: cbai_transcriptome_v1.5\n\nGBXE01.1.fa-vs-cbai_transcriptome_v1.5.fa.scores.txt\nGFFJ01.1.fa-vs-cbai_transcriptome_v1.5.fa.scores.txt\ncbai_transcriptome_v1.0.fa-vs-cbai_transcriptome_v1.5.fa.scores.txt\ncbai_transcriptome_v1.6.fa-vs-cbai_transcriptome_v1.5.fa.scores.txt\ncbai_transcriptome_v1.7.fa-vs-cbai_transcriptome_v1.5.fa.scores.txt\ncbai_transcriptome_v2.0.fa-vs-cbai_transcriptome_v1.5.fa.scores.txt\ncbai_transcriptome_v3.0.fa-vs-cbai_transcriptome_v1.5.fa.scores.txt\n\n\n\n\nReference: cbai_transcriptome_v1.6\n\nGBXE01.1.fa-vs-cbai_transcriptome_v1.6.fa.scores.txt\nGFFJ01.1.fa-vs-cbai_transcriptome_v1.6.fa.scores.txt\ncbai_transcriptome_v1.0.fa-vs-cbai_transcriptome_v1.6.fa.scores.txt\ncbai_transcriptome_v1.5.fa-vs-cbai_transcriptome_v1.6.fa.scores.txt\ncbai_transcriptome_v1.7.fa-vs-cbai_transcriptome_v1.6.fa.scores.txt\ncbai_transcriptome_v2.0.fa-vs-cbai_transcriptome_v1.6.fa.scores.txt\ncbai_transcriptome_v3.0.fa-vs-cbai_transcriptome_v1.6.fa.scores.txt\n\n\n\n\nReference: cbai_transcriptome_v1.7\n\nGBXE01.1.fa-vs-cbai_transcriptome_v1.7.fa.scores.txt\nGFFJ01.1.fa-vs-cbai_transcriptome_v1.7.fa.scores.txt\ncbai_transcriptome_v1.0.fa-vs-cbai_transcriptome_v1.7.fa.scores.txt\ncbai_transcriptome_v1.5.fa-vs-cbai_transcriptome_v1.7.fa.scores.txt\ncbai_transcriptome_v1.6.fa-vs-cbai_transcriptome_v1.7.fa.scores.txt\ncbai_transcriptome_v2.0.fa-vs-cbai_transcriptome_v1.7.fa.scores.txt\ncbai_transcriptome_v3.0.fa-vs-cbai_transcriptome_v1.7.fa.scores.txt\n\n\n\n\nReference: cbai_transcriptome_v2.0\n\nGBXE01.1.fa-vs-cbai_transcriptome_v2.0.fa.scores.txt\nGFFJ01.1.fa-vs-cbai_transcriptome_v2.0.fa.scores.txt\ncbai_transcriptome_v1.0.fa-vs-cbai_transcriptome_v2.0.fa.scores.txt\ncbai_transcriptome_v1.5.fa-vs-cbai_transcriptome_v2.0.fa.scores.txt\ncbai_transcriptome_v1.6.fa-vs-cbai_transcriptome_v2.0.fa.scores.txt\ncbai_transcriptome_v1.7.fa-vs-cbai_transcriptome_v2.0.fa.scores.txt\ncbai_transcriptome_v3.0.fa-vs-cbai_transcriptome_v2.0.fa.scores.txt\n\n\n\n\nReference: cbai_transcriptome_v3.0\n\nGBXE01.1.fa-vs-cbai_transcriptome_v3.0.fa.scores.txt\nGFFJ01.1.fa-vs-cbai_transcriptome_v3.0.fa.scores.txt\ncbai_transcriptome_v1.0.fa-vs-cbai_transcriptome_v3.0.fa.scores.txt\ncbai_transcriptome_v1.5.fa-vs-cbai_transcriptome_v3.0.fa.scores.txt\ncbai_transcriptome_v1.6.fa-vs-cbai_transcriptome_v3.0.fa.scores.txt\ncbai_transcriptome_v1.7.fa-vs-cbai_transcriptome_v3.0.fa.scores.txt\ncbai_transcriptome_v2.0.fa-vs-cbai_transcriptome_v3.0.fa.scores.txt\n\n\n\n\nReference: 20200526.P_trituberculatus\n\nGBXE01.1.fa-vs-20200526.P_trituberculatus.Trinity.fa.scores.txt\nGFFJ01.1.fa-vs-20200526.P_trituberculatus.Trinity.fa.scores.txt\ncbai_transcriptome_v1.0.fa-vs-20200526.P_trituberculatus.Trinity.fa.scores.txt\ncbai_transcriptome_v1.5.fa-vs-20200526.P_trituberculatus.Trinity.fa.scores.txt\ncbai_transcriptome_v1.6.fa-vs-20200526.P_trituberculatus.Trinity.fa.scores.txt\ncbai_transcriptome_v1.7.fa-vs-20200526.P_trituberculatus.Trinity.fa.scores.txt\ncbai_transcriptome_v2.0.fa-vs-20200526.P_trituberculatus.Trinity.fa.scores.txt\ncbai_transcriptome_v3.0.fa-vs-20200526.P_trituberculatus.Trinity.fa.scores.txt\n\n\n\n\nReference: GBXE01.1\n\nGFFJ01.1.fa-vs-GBXE01.1.fa.scores.txt\ncbai_transcriptome_v1.0.fa-vs-GBXE01.1.fa.scores.txt\ncbai_transcriptome_v1.5.fa-vs-GBXE01.1.fa.scores.txt\ncbai_transcriptome_v1.6.fa-vs-GBXE01.1.fa.scores.txt\ncbai_transcriptome_v1.7.fa-vs-GBXE01.1.fa.scores.txt\ncbai_transcriptome_v2.0.fa-vs-GBXE01.1.fa.scores.txt\ncbai_transcriptome_v3.0.fa-vs-GBXE01.1.fa.scores.txt\n\n\n\n\nReference: GFFJ01.1\n\nGBXE01.1.fa-vs-GFFJ01.1.fa.scores.txt\ncbai_transcriptome_v1.0.fa-vs-GFFJ01.1.fa.scores.txt\ncbai_transcriptome_v1.5.fa-vs-GFFJ01.1.fa.scores.txt\ncbai_transcriptome_v1.6.fa-vs-GFFJ01.1.fa.scores.txt\ncbai_transcriptome_v1.7.fa-vs-GFFJ01.1.fa.scores.txt\ncbai_transcriptome_v2.0.fa-vs-GFFJ01.1.fa.scores.txt\ncbai_transcriptome_v3.0.fa-vs-GFFJ01.1.fa.scores.txt"
  },
  {
    "objectID": "posts/2020/2020-05-08-Transcriptome-Annotation---C.bairdi-Transcriptome-v2.0-Using-DIAMOND-BLASTx-on-Mox/index.html",
    "href": "posts/2020/2020-05-08-Transcriptome-Annotation---C.bairdi-Transcriptome-v2.0-Using-DIAMOND-BLASTx-on-Mox/index.html",
    "title": "Transcriptome Annotation - C.bairdi Transcriptome v2.0 Using DIAMOND BLASTx on Mox",
    "section": "",
    "text": "As part of annotating the C.bairdi v2.0 transcriptome assembly from 20200502, I need to run DIAMOND BLASTx to use with Trinotate.\nRan DIAMOND BLASTx against the UniProt/SwissProt database (downloaded 20200123) on Mox.\nSBATCH script (GitHub):\n\n20200508_cbai_diamond_blastx_transcriptome-v2.0.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_blastx_DIAMOND\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200508_cbai_diamond_blastx_transcriptome-v2.0\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\n# Program paths\ndiamond=/gscratch/srlab/programs/diamond-0.9.29/diamond\n\n# DIAMOND UniProt database\ndmnd=/gscratch/srlab/blastdbs/uniprot_sprot_20200123/uniprot_sprot.dmnd\n\n\n# Trinity assembly (FastA)\nfasta=/gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200507.C_bairdi.Trinity.fasta\n\n# Strip leading path and extensions\nno_path=$(echo \"${fasta##*/}\")\nno_ext=$(echo \"${no_path%.*}\")\n\n# Run DIAMOND with blastx\n# Output format 6 produces a standard BLAST tab-delimited file\n${diamond} blastx \\\n--db ${dmnd} \\\n--query \"${fasta}\" \\\n--out \"${no_ext}\".blastx.outfmt6 \\\n--outfmt 6 \\\n--evalue 1e-4 \\\n--max-target-seqs 1 \\\n--block-size 15.0 \\\n--index-chunks 4\n\n\nRESULTS\nI’ll never not be amazed at how fast this runs! 51 seconds!\n\n\n\ndiamond blastx runtime\n\n\nOutput folder:\n\n20200508_cbai_diamond_blastx_transcriptome-v2.0/\n\nBLASTx output - BLAST format 6 (tab):\n\n20200508_cbai_diamond_blastx_transcriptome-v2.0/20200507.C_bairdi.Trinity.blastx.outfmt6\n\nWill proceed with Trinotate."
  },
  {
    "objectID": "posts/2020/2020-08-25-qPCR---P.generosa-RPL5-and-TIF3s6b-v2-and-v3-Normalizing-Gene-Assessment/index.html",
    "href": "posts/2020/2020-08-25-qPCR---P.generosa-RPL5-and-TIF3s6b-v2-and-v3-Normalizing-Gene-Assessment/index.html",
    "title": "qPCR - P.generosa RPL5 and TIF3s6b v2 and v3 Normalizing Gene Assessment",
    "section": "",
    "text": "After testing out the RPL5 and TIF3s6b v2 and v3 primers yesterday on pooled cDNA, we determined the primers looked good, so will go forward testing them on a set of P.generosa hemolymph cDNA made by Kaitlyn on 20200212. This will evaluate whether or not these can be utilized as normalizing genes for subsequent gene expression analyses.\nPrimers used:\n\n\n\nSRID\nPrimer_Name\n\n\n\n\n1787\nRPL5_v2_FWD\n\n\n1786\nRPL5_v2_REV\n\n\n1785\nRPL5_v3_FWD\n\n\n1784\nRPL5_v3_REV\n\n\n1783\nTIF3s6b_v2_FWD\n\n\n1782\nTIF3s6b_v2_REV\n\n\n1781\nTIF3s6b_v3_FWD\n\n\n1780\nTIF3s6b_v3_REV\n\n\n\nI used geoduck gDNA (162ng/uL; from 20170105) as a positive control.\nMaster mix calcs are here:\n\n200200825_qPCR_geoduck_RPL5-v2-v3_TIF2s6b-v2-v3 (Google Sheet)\n\nAll qPCR reactions were run in duplicate. See qPCR Report (Results section below) for plate layout, cycling params, etc.\nNOTE: These qPCRs used the remainder of all the samples.\n\n\nRESULTS\nThese primers are not going to be useful as normalizing genes:\n\nRPL5 spread is way too wide for use as a normalizing gene (~10 Cqs)\nTIF3s6b doesn’t amplify in most samples (however, it is very consistent in those that it does amplify…)\n\nData files and amplification/melt plots are below.\nRPL5 qPCR Report (PDF):\n\nsam_2020-08-25_05-22-37_BR006896.pdf\n\nRPL5 CFX Data File (PCRD):\n\nsam_2020-08-25%2005-22-37_BR006896.pcrd\n\nRPL5 CFX Results File (CSV):\n\nsam_2020-08-25_05-22-37_BR006896-Quantification-Cq-Results.csv\n\nTIF3s6b qPCR Report (PDF):\n\nsam_2020-08-25_06-59-18_BR006896.pdf\n\nTIF3s6b CFX Data File (PCRD):\n\nsam_2020-08-25%2006-59-18_BR006896.pcrd\n\nTIF3s6b CFX Results File (CSV):\n\nsam_2020-08-25_06-59-18_BR006896-Quantification-Cq-Results.csv\n\n\nRPL5 v2\nAMPLIFICATION PLOTS\n\n\n\nRPL5 v2 amplification plots\n\n\nMELT PLOTS\n\n\n\nRPL5 v2 melt plots\n\n\n\n\nRPL5 v3\n\n\n\nRPL5 v3 amplification plots\n\n\n\n\n\nRPL5 v3 melt plots\n\n\n\n\nTIF3s6b v2\n\n\n\nTIF3s6b v2 amplification plots\n\n\n\n\n\nTIF3s6b v2 melt plots\n\n\n\n\nTIF3s6b v3\n\n\n\nTIF3s6b v3 amplification plots\n\n\n\n\n\nTIF3s6b v3 melt plots"
  },
  {
    "objectID": "posts/2020/2020-12-29-Transcriptome-Comparisons---C.bairdi-Transcriptomes-Evaluations-with-DETONATE-rsem-eval-on-Mox/index.html",
    "href": "posts/2020/2020-12-29-Transcriptome-Comparisons---C.bairdi-Transcriptomes-Evaluations-with-DETONATE-rsem-eval-on-Mox/index.html",
    "title": "Transcriptome Comparisons - C.bairdi Transcriptomes Evaluations with DETONATE rsem-eval on Mox",
    "section": "",
    "text": "UPDATE: I’ll lead in with the fact that this failed with an error message that I can’t figure out. This will save the reader some time. I’ve posted the problem as an Issue on the DETONATE GitHub repo, however it’s clear that this software is no longer maintained, as the repo hasn’t been updated in >3yrs; even lacking responses to Issues that are that old.\nHere’s the error message and some other details that could be useful for troubleshooting (which are beyond my knowledge - although I suspect that the XM tag is the culprit and the first entry in the BAM file has XM:i:2 and the error message might suggest that 2 is not an acceptable value e.g. Assertion val == 0 || val == 1 || val == 5' failed.):\nrsem-synthesis-reference-transcripts cbai_transcriptome_v3.1.fasta.temp/cbai_transcriptome_v3.1.fasta 0 0 0 /gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v3.1.fasta\nTranscript Information File is generated!\nGroup File is generated!\nExtracted Sequences File is generated!\n\nrsem-preref cbai_transcriptome_v3.1.fasta.temp/cbai_transcriptome_v3.1.fasta.transcripts.fa 1 cbai_transcriptome_v3.1.fasta.temp/cbai_transcriptome_v3.1.fasta\nRefs.makeRefs finished!\nRefs.saveRefs finished!\ncbai_transcriptome_v3.1.fasta.temp/cbai_transcriptome_v3.1.fasta.idx.fa is generated!\ncbai_transcriptome_v3.1.fasta.temp/cbai_transcriptome_v3.1.fasta.n2g.idx.fa is generated!\n\nrsem-parse-alignments cbai_transcriptome_v3.1.fasta.temp/cbai_transcriptome_v3.1.fasta cbai_transcriptome_v3.1.fasta.temp/cbai_transcriptome_v3.1.fasta cbai_transcriptome_v3.1.fasta.stat/cbai_transcriptome_v3.1.fasta b /gscratch/scrubbed/samwhite/outputs/20201224_cbai_bowtie2_transcriptomes_alignments/cbai_transcriptome_v3.1.fasta.sorted.bam -t 3 -tag XM\nrsem-parse-alignments: parseIt.cpp:92: void parseIt(SamParser*) [with ReadType = PairedEndReadQ; HitType = PairedEndHit]: Assertion `val == 0 || val == 1 || val == 5' failed.\n\"rsem-parse-alignments cbai_transcriptome_v3.1.fasta.temp/cbai_transcriptome_v3.1.fasta cbai_transcriptome_v3.1.fasta.temp/cbai_transcriptome_v3.1.fasta cbai_transcriptome_v3.1.fasta.stat/cbai_transcriptome_v3.1.fasta b /gscratch/scrubbed/samwhite/outputs/20201224_cbai_bowtie2_transcriptomes_alignments/cbai_transcriptome_v3.1.fasta.sorted.bam -t 3 -tag XM\" failed! Plase check if you provide correct parameters/options for the pipeline!\nHere’s what the head of the BAM file looks like:\n[samwhite@n2233 20201224_cbai_bowtie2_transcriptomes_alignments]$ /gscratch/srlab/programs/samtools-1.10/samtools view cbai_transcriptome_v3.1.fasta.sorted.bam | head\nA00147:108:HLLJFDMXX:1:1369:3893:6637   163 TRINITY_DN5604_c0_g2_i1 1   42  101M    =   81  181 GAAAGAAAAACCGACAGGAGGAATTTCTTTGTTACCAACAAAAACTAATATATTTCGCATACCTGACAGACATGGTGACAGCGCCTCTGATGTTCGCCGAA   :FFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFF:FFFFFFFFFFFF:FFF:FFFFFFFFFFFFFFFFFFFFFFFF   AS:i:-2 XN:i:0  XM:i:2  XO:i:0  XG:i:0  NM:i:2  MD:Z:2G31A66    YS:i:0  YT:Z:CP\nA00147:121:HLLVMDMXX:1:2159:5674:25786  163 TRINITY_DN5604_c0_g2_i1 4   42  101M    =   72  169 AGAAAAACCGACAGGAGGAATTTCTTTGTTAACAACAAAAACTAATATATTTCGCATACCTGACAGACATGGTGACAGCGCCTCTGATGTTCGCCGAATTA   FFFFFF:FFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF   AS:i:0  XN:i:0  XM:i:0  XO:i:0  XG:i:0  NM:i:0  MD:Z:101    YS:i:0  YT:Z:CP\nA00147:108:HLLJFDMXX:2:1420:13702:14920 163 TRINITY_DN5604_c0_g2_i1 5   42  101M    =   197 293 GAAAAACCGACAGGAGGAATTTCTTTGTTAACAACAAAAACTAATATATTTCGCATACCTGACAGACATGGTGACAGCGCCTCTGATGTTCGCCGAATTAA   FFFFFFFFFFFFFFFFFF:FFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF,FFFFFFFFFFF   AS:i:0  XN:i:0  XM:i:0  XO:i:0  XG:i:0  NM:i:0  MD:Z:101    YS:i:0  YT:Z:CP\nA00147:108:HLLJFDMXX:2:1420:13431:15796 163 TRINITY_DN5604_c0_g2_i1 5   42  101M    =   197 293 GAAAAACCGACAGGAGGAATTTCTTTGTTAACAACAAAAACTAATATATTTCGCATACCTGACAGACATGGTGACAGCGCCTCTGATGTTCGCCGAATTAA   FFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF   AS:i:0  XN:i:0  XM:i:0  XO:i:0  XG:i:0  NM:i:0  MD:Z:101    YS:i:0  YT:Z:CP\nA00147:121:HLLVMDMXX:1:1258:5141:32377  163 TRINITY_DN5604_c0_g2_i1 5   42  101M    =   107 203 GAAAAACCGACAGGAGGAATTTCTTTGTTACCAACAAAAACTAATATATTTCGCATACCTGACAGACATGGTGACAGCGCCTCTGATGTTCGCCGAATTAA   FFFFF,FFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFF:F:FFFFFFFF   AS:i:-1 XN:i:0  XM:i:1  XO:i:0  XG:i:0  NM:i:1  MD:Z:30A70  YS:i:0  YT:Z:CP\nA00147:121:HLLVMDMXX:1:1259:7645:5838   163 TRINITY_DN5604_c0_g2_i1 5   42  101M    =   107 203 GAAAAACCGACAGGAGGAATTTCTTTGTTACCAACAAAAACTAATATATTTCGCATACCTGACAGACATGGTGACAGCGCCTCTGATGTTCGCCGAATTAA   FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFF   AS:i:-1 XN:i:0  XM:i:1  XO:i:0  XG:i:0  NM:i:1  MD:Z:30A70  YS:i:0  YT:Z:CP\nA00147:108:HLLJFDMXX:1:1351:27082:1705  163 TRINITY_DN5604_c0_g2_i1 6   42  101M    =   158 253 AAAAACCGACAGGAGGAATTTCTTTGTTAACAACAAAAACTAATATATTTCGCATACCTGACAGACATGGTGACAGCGCCTCTGATGTTCGCCGAATTAAA   FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:   AS:i:0  XN:i:0  XM:i:0  XO:i:0  XG:i:0  NM:i:0  MD:Z:101    YS:i:0  YT:Z:CP\nA00147:108:HLLJFDMXX:1:1475:28926:32706 163 TRINITY_DN5604_c0_g2_i1 6   42  101M    =   158 253 AAAAACCGACAGGAGGAATTTCTTTGTTAACAACAAAAACTAATATATTTCGCATACCTGACAGACATGGTGACAGCGCCTCTGATGTTCGCCGAATTAAA   FFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF   AS:i:0  XN:i:0  XM:i:0  XO:i:0  XG:i:0  NM:i:0  MD:Z:101    YS:i:0  YT:Z:CP\nA00147:121:HLLVMDMXX:1:2162:31385:26381 163 TRINITY_DN5604_c0_g2_i1 6   42  101M    =   158 253 AAAAACCGACAGGAGGAANTTCTTTGTTAACAACAAAAACTAATATATTTCGCATACCTGACAGACATGGTGACAGCGCCTCTGATGTTCGCCGAATTAAA   FFFFFFFFFFFFFFFFFF#FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFF:   AS:i:-1 XN:i:0  XM:i:1  XO:i:0  XG:i:0  NM:i:1  MD:Z:18T82  YS:i:0  YT:Z:CP\nA00147:121:HLLVMDMXX:2:1425:28745:30639 163 TRINITY_DN5604_c0_g2_i1 7   42  101M    =   169 263 AAAACCGACAGGAGGAATTTCTTTGTTAACAACAAAAACTAATATATTTCGCATACCTGACAGACATGGTGACAGCGCCTCTGATGTTCGCCGAATTAAAG   FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:   AS:i:0  XN:i:0  XM:i:0  XO:i:0  XG:i:0  NM:i:0  MD:Z:101    YS:i:0  YT:Z:CP\n\nbowtie2 commands to generate the BAM file:\n  # Use bowtie2 and paired-end options\n  # Uses settings specified for use with DETONATE\n  # and for paired end reads when using DETONATE.\n  ${programs_array[bowtie2]} \\\n  -x ${transcriptome_name} \\\n  -S ${transcriptome_name}.sam \\\n  --threads ${threads} \\\n  -1 ${R1_list} \\\n  -2 ${R2_list} \\\n  --sensitive \\\n  --dpad 0 \\\n  --gbar 99999999 \\\n  --mp 1,1 \\\n  --np 1 \\\n  --score-min L,0,-0.1 \\\n  --no-mixed \\\n  --no-discordant\n\n  # Convert SAM to sorted BAM\n  #\n  ${programs_array[samtools_view]} \\\n  -b \\\n  ${transcriptome_name}.sam \\\n  | ${programs_array[samtools_sort]} \\\n  -m ${mem_per_thread} \\\n  --threads ${threads} \\\n  -o ${transcriptome_name}.sorted.bam \\\n  -\nWith all of that out of the way, you can find the original post below.\n\nUsing bowtie2, I generated transcriptome alignments on 20201224 to provide as input to the program DETONATE (rsem-eval) which should be able to generate a score to allow for an assessment of which transcriptome assembly is most accurate. My previous attempt to compare all of our C.bairdi transcriptome assemblies using DETONATE on 20200601 consistently failed due to hitting time limits on Mox and that is why I created the bowtie2 alignments in a separate job; it was significantly faster than doing so within the DETONATE (rsem-eval) software.\nThe job was run on Mox.\nSBATCH script (GitHub):\n\n20201229_cbai_detonate_transcriptome_evaluations.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=20201229_cbai_detonate_transcriptome_evaluations\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=500G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20201229_cbai_detonate_transcriptome_evaluations\n\n# Script runs DETONATE on each of the C.bairdi transcriptomes\n# using Bowtie2 BAM alignments generated on 20201224.\n# DETONATE will generate a corresponding \"score\" for each transcriptome,\n# providing another metric by which to compare each assembly.\n\n# Requires Bash >=4.0, as script uses associative arrays.\n\n\n###################################################################################\n# These variables need to be set by user\n\n# Assign Variables\n## frag_size is guesstimate of library fragment sizes\nfrag_size=500\nbams_dir=/gscratch/scrubbed/samwhite/outputs/20201224_cbai_bowtie2_transcriptomes_alignments\ntranscriptomes_dir=/gscratch/srlab/sam/data/C_bairdi/transcriptomes\nthreads=28\n\n# Associative array of the transcriptomes and corresponding BAM file\ndeclare -A transcriptomes_array\ntranscriptomes_array=(\n[\"${transcriptomes_dir}/cbai_transcriptome_v1.5.fasta\"]=\"${bams_dir}/cbai_transcriptome_v1.5.fasta.sorted.bam\" \\\n[\"${transcriptomes_dir}/cbai_transcriptome_v1.6.fasta\"]=\"${bams_dir}/cbai_transcriptome_v1.6.fasta.sorted.bam\" \\\n[\"${transcriptomes_dir}/cbai_transcriptome_v1.7.fasta\"]=\"${bams_dir}/cbai_transcriptome_v1.7.fasta.sorted.bam\" \\\n[\"${transcriptomes_dir}/cbai_transcriptome_v2.0.fasta\"]=\"${bams_dir}/cbai_transcriptome_v2.0.fasta.sorted.bam\" \\\n[\"${transcriptomes_dir}/cbai_transcriptome_v2.1.fasta\"]=\"${bams_dir}/cbai_transcriptome_v2.1.fasta.sorted.bam\" \\\n[\"${transcriptomes_dir}/cbai_transcriptome_v3.0.fasta\"]=\"${bams_dir}/cbai_transcriptome_v3.0.fasta.sorted.bam\" \\\n[\"${transcriptomes_dir}/cbai_transcriptome_v3.1.fasta\"]=\"${bams_dir}/cbai_transcriptome_v3.1.fasta.sorted.bam\"\n)\n\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n\n# Programs array\n\ndeclare -A programs_array\nprograms_array=(\n[detonate_trans_length]=\"/gscratch/srlab/programs/detonate-1.11/rsem-eval/rsem-eval-estimate-transcript-length-distribution\" \\\n[detonate]=\"/gscratch/srlab/programs/detonate-1.11/rsem-eval/rsem-eval-calculate-score\"\n)\n\n\n\n\n# Loop through each comparison\nfor transcriptome in \"${!transcriptomes_array[@]}\"\ndo\n\n  # Remove path from transcriptome\n  transcriptome_name=\"${transcriptome##*/}\"\n\n  # Set RSEM distance output filename\n  rsem_eval_dist_mean_sd=\"${transcriptome_name}_true_length_dis_mean_sd.txt\"\n\n\n  # Determine transcript length\n  # Needed for subsequent rsem-eval command.\n  ${programs_array[detonate_trans_length]} \\\n  \"${transcriptome}\" \\\n  \"${rsem_eval_dist_mean_sd}\"\n\n\n  # Run rsem-eval\n  # Use paired-end options\n  ${programs_array[detonate]} \\\n  --transcript-length-parameters \"${rsem_eval_dist_mean_sd}\" \\\n  --bam \\\n  --paired-end \\\n  \"${transcriptomes_array[$transcriptome]}\" \\\n  \"${transcriptome}\" \\\n  \"${transcriptome_name}\" \\\n  ${frag_size}\n\n  # Capture FastA checksums for verification\n  echo \"Generating checksum for ${transcriptome_name}\"\n  md5sum \"${transcriptome}\" >> fasta.checksums.md5\n  echo \"Finished generating checksum for ${transcriptome_name}\"\n  echo \"\"\n\n  # Capture BAM checksums for verification\n  echo \"Generating checksum for ${transcriptomes_array[$transcriptome]}\"\n  md5sum \"${transcriptomes_array[$transcriptome]}\" >> bam.checksums.md5\n  echo \"Finished generating checksum for ${transcriptomes_array[$transcriptome]}\"\n  echo \"\"\n\ndone\n\n# Capture program options\necho \"Logging program options...\"\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n  # Handle samtools help menus\n  if [[ \"${program}\" == \"samtools_index\" ]] \\\n  || [[ \"${program}\" == \"samtools_sort\" ]] \\\n  || [[ \"${program}\" == \"samtools_view\" ]]\n  then\n    ${programs_array[$program]}\n  fi\n    ${programs_array[$program]} -h\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\n\n  # If MultiQC is in programs_array, copy the config file to this directory.\n  if [[ \"${program}\" == \"multiqc\" ]]; then\n    cp --preserve ~/.multiqc_config.yaml multiqc_config.yaml\n  fi\ndone\n\necho \"\"\necho \"Finished logging program options.\"\necho \"\"\n\necho \"\"\necho \"Logging system PATH.\"\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\necho \"Finished logging system PATH\"\n\n\nRESULTS\nThe job failed (virtually instantly) with this message:\nrsem-synthesis-reference-transcripts cbai_transcriptome_v3.1.fasta.temp/cbai_transcriptome_v3.1.fasta 0 0 0 /gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v3.1.fasta\nTranscript Information File is generated!\nGroup File is generated!\nExtracted Sequences File is generated!\n\nrsem-preref cbai_transcriptome_v3.1.fasta.temp/cbai_transcriptome_v3.1.fasta.transcripts.fa 1 cbai_transcriptome_v3.1.fasta.temp/cbai_transcriptome_v3.1.fasta\nRefs.makeRefs finished!\nRefs.saveRefs finished!\ncbai_transcriptome_v3.1.fasta.temp/cbai_transcriptome_v3.1.fasta.idx.fa is generated!\ncbai_transcriptome_v3.1.fasta.temp/cbai_transcriptome_v3.1.fasta.n2g.idx.fa is generated!\n\nrsem-parse-alignments cbai_transcriptome_v3.1.fasta.temp/cbai_transcriptome_v3.1.fasta cbai_transcriptome_v3.1.fasta.temp/cbai_transcriptome_v3.1.fasta cbai_transcriptome_v3.1.fasta.stat/cbai_transcriptome_v3.1.fasta b /gscratch/scrubbed/samwhite/outputs/20201224_cbai_bowtie2_transcriptomes_alignments/cbai_transcriptome_v3.1.fasta.sorted.bam -t 3 -tag XM\nrsem-parse-alignments: parseIt.cpp:92: void parseIt(SamParser*) [with ReadType = PairedEndReadQ; HitType = PairedEndHit]: Assertion `val == 0 || val == 1 || val == 5' failed.\n\"rsem-parse-alignments cbai_transcriptome_v3.1.fasta.temp/cbai_transcriptome_v3.1.fasta cbai_transcriptome_v3.1.fasta.temp/cbai_transcriptome_v3.1.fasta cbai_transcriptome_v3.1.fasta.stat/cbai_transcriptome_v3.1.fasta b /gscratch/scrubbed/samwhite/outputs/20201224_cbai_bowtie2_transcriptomes_alignments/cbai_transcriptome_v3.1.fasta.sorted.bam -t 3 -tag XM\" failed! Plase check if you provide correct parameters/options for the pipeline!"
  },
  {
    "objectID": "posts/2020/2020-01-23-Transcriptome-Annotation---Hematodinium-MEGAN-Trinity-Assembly-Using-DIAMOND-BLASTx-on-Mox/index.html",
    "href": "posts/2020/2020-01-23-Transcriptome-Annotation---Hematodinium-MEGAN-Trinity-Assembly-Using-DIAMOND-BLASTx-on-Mox/index.html",
    "title": "Transcriptome Annotation - Hematodinium MEGAN Trinity Assembly Using DIAMOND BLASTx on Mox",
    "section": "",
    "text": "As part of annotating the transcriptome assembly from the MEGAN6 Hematodinium taxonomic-specific reads, I need to run DIAMOND BLASTx to use with Trinotate.\nRan DIAMOND BLASTx against the UniProt/SwissProt database (downloaded today) on Mox.\nSBATCH script (GitHub):\n\n20200123_hemat_diamond_blastx_megan.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=hemat_blastx_DIAMOND\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200123_hemat_diamond_blastx_megan\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\n# Program paths\ndiamond=/gscratch/srlab/programs/diamond-0.9.29/diamond\n\n# DIAMOND UniProt database\ndmnd=/gscratch/srlab/blastdbs/uniprot_sprot_20200123/uniprot_sprot.dmnd\n\n\n# Trinity assembly (FastA)\nfasta=/gscratch/srlab/sam/data/Hematodinium/transcriptomes/20200122.hemat.megan.Trinity.fasta\n\n# Strip leading path and extensions\nno_path=$(echo \"${fasta##*/}\")\nno_ext=$(echo \"${no_path%.*}\")\n\n# Run DIAMOND with blastx\n# Output format 6 produces a standard BLAST tab-delimited file\n${diamond} blastx \\\n--db ${dmnd} \\\n--query \"${fasta}\" \\\n--out \"${no_ext}\".blastx.outfmt6 \\\n--outfmt 6 \\\n--evalue 1e-4 \\\n--max-target-seqs 1 \\\n--block-size 15.0 \\\n--index-chunks 4\n\n\nRESULTS\nWell, this ran in a ridiculous 3 seconds!\n\n\n\nhemat DIAMOND runtime\n\n\nOutput folder:\n\n20200123_hemat_diamond_blastx_megan/\n\nBLASTx output - BLAST format 6 (tab):\n\n20200123_hemat_diamond_blastx_megan/20200122.hemat.megan.Trinity.blastx.outfmt6\n\nWill proceed with Trinotate."
  },
  {
    "objectID": "posts/2020/2020-12-02-Sample-Submission---M.magister-MBD-BSseq-Libraries-for-MiSeq-at-NOAA/index.html",
    "href": "posts/2020/2020-12-02-Sample-Submission---M.magister-MBD-BSseq-Libraries-for-MiSeq-at-NOAA/index.html",
    "title": "Sample Submission - M.magister MBD BSseq Libraries for MiSeq at NOAA",
    "section": "",
    "text": "Earlier today I quantified the libraries with the Qubit in preparation for sample pooling and sequencing. Before performing a full sequencing run, Mac wanted to select a subset of the libraries based on the experimental treatments to have an equal representation of samples. She also wanted to do a quick run on the MiSeq at NOAA to evaluate how well libraries map and to make sure libraries appear to be sequencing at relatively equal levels.\nI created 4nM aliquots of all samples, using the average fragment length calculated by the Bioanalyzer region setting I created. The formula for determining molarity from concentration is:\nSample_Nameconcentration(ng/uL) * (660(g/mole/bp) * frag_len(bp))-1 * 1000000(uL/L) = molarity(nM)\nAfter creating 4nM aliquots, I combined 1uL from each aliquot (per Mac’s typical procedure) and gave the pooled libraries to Mac to sequence at NOAA.\nThe following samples are those that were not used in the library pool:\n\nCH05-26\nCH09-11\nCH09-29\nCH10-19\n\nAll these library calculations are in the principal spreadsheet for this project:\n\nOA Crab Sample Collection 071119 (Google Sheet)\nSpecific columns:\n\nqubit_concentration(ng/uL)\nqubit_molarity(nM)\nlibrary_4nM_Vi(uL): Library volume needed for 4nM in 25uL aliquot.\nlibrary_4nM_Vf(uL): Final volume of library aliquot (25uL).\nlibrary_4nM_Cf(nM): Final concentration of library aliquot (4nM).\nlibrary_4nM_H2O(uL): Water needed to bring aliquot to 25uL.\n\n\nAdditional details are available in this GitHub repo:\n\nproject-dungeness-crab"
  },
  {
    "objectID": "posts/2020/2020-01-22-Data-Wrangling---Arthropoda-and-Alveolata-Taxonomic-RNAseq-FastQ-Extractions/index.html",
    "href": "posts/2020/2020-01-22-Data-Wrangling---Arthropoda-and-Alveolata-Taxonomic-RNAseq-FastQ-Extractions/index.html",
    "title": "Data Wrangling - Arthropoda and Alveolata Taxonomic RNAseq FastQ Extractions",
    "section": "",
    "text": "After using MEGAN6 to extract Arthropoda and Alveolata reads from our RNAseq data on 20200114 (for reference, these include RNAseq data using a newly established “shorthand”: 2018, 2019), I realized that the FastA headers were incomplete and did not distinguish between paired reads. Here’s an example:\nR1 FastQ header:\n@A00147:37:HG2WLDMXX:1:1101:5303:1000 1:N:0:AGGCGAAG+AGGCGAAG\nR2 FastQ header:\n@A00147:37:HG2WLDMXX:1:1101:5303:1000 2:N:0:AGGCGAAG+AGGCGAAG\nHowever, the reads extracted via MEGAN have FastA headers like this:\n>A00147:37:HG2WLDMXX:1:1101:5303:1000\nSEQUENCE1\n>A00147:37:HG2WLDMXX:1:1101:5303:1000\nSEQUENCE2\nThose are a set of paired reads, but there’s no way to distinguish between R1/R2. This may not be an issue, but I’m not sure how downstream programs (i.e. Trinity) will handle duplicate FastA IDs as inputs. To avoid any headaches, I’ve decided to parse out the corresponding FastQ reads which have the full header info.\nHere’s a brief rundown of the approach:\n\nCreate list of unique read headers from MEGAN6 FastA files.\nUse list with seqtk program to pull out corresponding FastQ reads from the trimmed FastQ R1 and R2 files.\n\nThe entire procedure is documented in a Jupyter Notebook below.\nJupyter notebook (GitHub):\n\n20200122_swoose_cbai_megan_read_extractions.ipynb\n\n\n\nRESULTS\nOutput folders:\n\n20200122.C_bairdi_megan_reads\n20200122.Hematodinium_megan_reads/\n\nWe now have to distinct sets of RNAseq reads to create separate transcriptome assemblies from C.bairdi (Arhtropoda) and Hematodinium (Alveolata)! Will get de novo assemblies with Trinity going on Mox."
  },
  {
    "objectID": "posts/2020/2020-05-21-Tutorial---SRA-Toolkit-for-Data-Retrieval-and-Conversion-to-FastQ/index.html",
    "href": "posts/2020/2020-05-21-Tutorial---SRA-Toolkit-for-Data-Retrieval-and-Conversion-to-FastQ/index.html",
    "title": "Tutorial - SRA Toolkit for Data Retrieval and Conversion to FastQ",
    "section": "",
    "text": "I was looking for some crab transcriptomic data today and, unable to find any previously assembled transcriptomes, turned to the good ol’ NCBI SRA. In order to simplify retrieval and conversion of SRA data, need to use the SRA Toolkit software suite. Since I haven’t used this in many years, I figured I might as well put together a brief guide/tutorial so I can refer back to it in the future.\nIt should be noted that this is written to describe usage of the SRA Toolkit on our Mox account (UW HPC). If setting this up elsewhere, you’ll want (need?) to configure the default storage location that the SRA Toolkit will use on your specific computer.\nAs a side note, I found this helpful page which tracks arthropod genome data present on NCBI:\n\ni5k\n\nStart by visiting the SRA BioProject page for a particular SRA.\n\nBioProject Page:\n\n\n\n\nsra_tools_tutorial_bioproject\n\n\n\n\nClick on the “Number of Links” in “SRA Experiments” row:\n\n\n\n\nsra_tools_tutorial_sra-experiments\n\n\n\n\nClick on “All runs” link:\n\n\n\n\nsra_tools_tutorial_sra-accession\n\n\n\n\nClick on “Accesion List” (circled) to download text file of all associated SRR accessions:\n\n\n\n\nsra_tools_tutorial_all-runs\n\n\n\nThat file will look like this:\n$ head SRR_Acc_List.txt\nSRR10757136\nSRR10757128\nSRR10757129\nSRR10757130\nSRR10757131\nSRR10757132\nSRR10757133\nSRR10757134\nSRR10757135\nSRR10757137\nUse that file to download the actual SRA files.\n /gscratch/srlab/programs/sratoolkit.2.10.6-centos_linux64/bin/prefetch.2.10.6 --output-directory . --option-file SRR_Acc_List.txt\n\nIf running on Mox, you’ll need to use a build node, as the processing will be more than allowed with the default login node and you need internet access (which is not avaiable on an interactive/execute node).\nIf no output directory is specified, the files will end up in: /gscratch/srlab/data/ncbi/sra/\n\nGet FastQ files from the SRA file(s). This can be run on a build node, an interactive node, or via an execute node using an SBATCH script. The settings used in the example below will produce a set of paired FastQ files for each SRA file (assuming the SRA consists of paired-end reads).\nfor file in *.sra\ndo\n  /gscratch/srlab/programs/sratoolkit.2.10.6-centos_linux64/bin/fasterq-dump.2.10.6 \\\n  --outdir . \\\n  --split-files \\\n  --threads 27 \\\n  --mem 100GB \\\n  --progres \\\n  ${file}\ndone"
  },
  {
    "objectID": "posts/2020/2020-10-22-DNA-Shearing---M.magister-CH05-21-gDNA-Full-Shearing-Test-and-Bioanalyzer/index.html",
    "href": "posts/2020/2020-10-22-DNA-Shearing---M.magister-CH05-21-gDNA-Full-Shearing-Test-and-Bioanalyzer/index.html",
    "title": "DNA Shearing - M.magister CH05-21 gDNA Full Shearing Test and Bioanalyzer",
    "section": "",
    "text": "Yesterday, I did some shearing of Metacarcinus magister gill gDNA on a test sample (CH05-21) to determine how many cycles to run on the sonicator (Bioruptor 300; Diagenode) to achieve an average fragment length of ~350 - 500bp in preparation for MBD-BSseq. The determination from yesterday was 70 cycles (30s ON, 30s OFF; low intensity). That determination was made by first sonicating for 35 cycles, followed by successive rounds of 5 cycles each. I decided to repeat this, except by doing it in a single round of sonication.\nI used 1ug of DNA in a volume of 50uL, using 0.65mL prelubricated snap cap tubes (Costar; Cat# 3206).\nIt turns out the Bioruptor has a maximum cycle setting of 60 cycles, so I decided to do 35 cycles, immediately followed by another 35 cycles.\nPost-sonication/shearing, samples were run on High Sensitivity DNA Assay chips in the Bioanalyzer 2100 (Agilent).\n\n\nRESULTS\nOutput folder:\n\n20201021_mmag_bioanalyzer/\n\nBioanalyzer files (XAD; require 2100 Expert software to open):\n  - [2100 expert_High Sensitivity DNA Assay_DE72902486_2020-10-22_07-27-24.xad](https://gannet.fish.washington.edu/Atumefaciens/20201021_mmag_bioanalyzer/2100 expert_High Sensitivity DNA Assay_DE72902486_2020-10-22_07-27-24.xad)\n\n  - [2100 expert_High Sensitivity DNA Assay_DE72902486_2020-10-22_08-47-27.xad](https://gannet.fish.washington.edu/Atumefaciens/20201021_mmag_bioanalyzer/2100 expert_High Sensitivity DNA Assay_DE72902486_2020-10-22_08-47-27.xad)\n\n\nElectropherograms are beneath the discussion that follows.\nAs it turns out, the initial 35 cycles + 35 cycles (total of 70) that didn’t produce the results I was expecting (see RESULTS below for more info). The electropherogram had a similar profile to the sample after 35 cycles that I did yesterday. So, I performed runs of 5 cycles each, for a total of 35 additional cycles. My thinking: Electropherogram looked similar to only 35 cycles, so an additional cumulative 35 cycles would repeat what I did yesterday (despite the fact that the sample had already been through two consecutive runs of 35 cycles each).\nAdmittedly, this is annoying, surprising, and concerning.\n\nAnnoying: Suggests that I’ll have to do this when sonicating the remaining samples - it’s tedious to monitor and eliminates the “set it and forget it” approach.\nSurprising: Wouldn’t expect differences in outcome between 35 cycles in one shot vs. 35 cycles comprised of seven rounds of 5 cycles.\nConcerning: Makes me wonder if I actually initiated the second round of 35 cycles in the first place… I’m confident that I did, but these results suggest otherwise.\n\nLo and behold, the subsequent incremental runs of 5 cycles each, ended up yielding the expected fragmentation length profile!\nStrange. I guess I’ll just take this approach when I sonicate the remainder of the samples.\n\nInitial 35 + 35 cycles:\n\n\n\nBioanalyzer electropherogram of CH05-21 after two successive 35 cycle shearing\n\n\n\n\nSubsequent 35 cycles, by 5 cycle increments (total of 105 cycles):\n\n\n\nBioanalyzer electropherogram of CH05-21 after seven successive rounds of 5 cycles each (total of 105 cycles)"
  },
  {
    "objectID": "posts/2020/2020-04-14-TrimmingFastQCMultiQC---C.bairdi-RNAseq-FastQ-with-fastp-on-Mox/index.html",
    "href": "posts/2020/2020-04-14-TrimmingFastQCMultiQC---C.bairdi-RNAseq-FastQ-with-fastp-on-Mox/index.html",
    "title": "TrimmingFastQCMultiQC—C.bairdi-RNAseq-FastQ-with-fastp-on-Mox",
    "section": "",
    "text": "After receiving our RNAseq data from Genewiz earlier today, needed to trim and check trimmed reads with FastQC.\nfastp trimming was run on Mox, followed by MultiQC.\nFastQC on trimmed reads were run locally, followed by MultiQC.\nSBATCH script (GitHub):\n\n20200414_cbai_RNAseq_fastp_trimming.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_fastp_trimming_RNAseq\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200414_cbai_RNAseq_fastp_trimming\n\n\n### C.bairdi RNAseq trimming using fastp.\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# Set number of CPUs to use\nthreads=27\n\n# Input/output files\ntrimmed_checksums=trimmed_fastq_checksums.md5\nraw_reads_dir=/gscratch/srlab/sam/data/C_bairdi/RNAseq/\n\n# Paths to programs\nfastp=/gscratch/srlab/programs/fastp-0.20.0/fastp\nfastqc=/gscratch/srlab/programs/fastqc_v0.11.8/fastqc\nmultiqc=/gscratch/srlab/programs/anaconda3/bin/multiqc\n\n## Inititalize arrays\nfastq_array_R1=()\nfastq_array_R2=()\nprograms_array=()\nR1_names_array=()\nR2_names_array=()\n\n# Programs array\nprograms_array=(\"${fastp}\" \"${multiqc}\" \"${fastqc}\")\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${programs_array[program]}: \"\n    echo \"\"\n    ${programs_array[program]} -h\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n# Sync raw FastQ files to working directory\nrsync --archive --verbose \\\n\"${raw_reads_dir}\"[3][8]*.fastq.gz .\n\n# Sync checkums file\nrsync --archive --verbose \\\n\"${raw_reads_dir}\"20200413_cbai_checkums.md5 .\n\n# Check md5 checksums\nmd5sum --check 20200413_cbai_checkums.md5\n\n# Create array of fastq R1 files\nfor fastq in *R1*.gz\ndo\n  fastq_array_R1+=(\"${fastq}\")\ndone\n\n# Create array of fastq R2 files\nfor fastq in *R2*.gz\ndo\n  fastq_array_R2+=(\"${fastq}\")\ndone\n\n\n# Create array of sample names\n## Uses awk to parse out sample name from filename\nfor R1_fastq in *R1*.gz\ndo\n  R1_names_array+=($(echo \"${R1_fastq}\" | awk -F\".\" '{print $1}'))\ndone\n\n# Create array of sample names\n## Uses awk to parse out sample name from filename\nfor R2_fastq in *R2*.gz\ndo\n  R2_names_array+=($(echo \"${R2_fastq}\" | awk -F\".\" '{print $1}'))\ndone\n\n# Create list of fastq files used in analysis\nfor fastq in *.gz\ndo\n  echo \"${fastq}\" >> fastq.list.txt\ndone\n\n# Run fastp on files\nfor index in \"${!fastq_array_R1[@]}\"\ndo\n    timestamp=$(date +%Y%m%d%M%S)\n  R1_sample_name=$(echo \"${R1_names_array[index]}\")\n    R2_sample_name=$(echo \"${R2_names_array[index]}\")\n    ${fastp} \\\n    --in1 \"${fastq_array_R1[index]}\" \\\n    --in2 \"${fastq_array_R2[index]}\" \\\n    --detect_adapter_for_pe \\\n    --thread ${threads} \\\n    --html \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".report.html \\\n    --json \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".report.json \\\n    --out1 \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz \\\n    --out2 \"${R2_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz\n\n    # Generate md5 checksums for newly trimmed files\n    {\n        md5sum \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz\n        md5sum \"${R2_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz\n    } >> \"${trimmed_checksums}\"\n\n    # Run FastQC\n    ${fastqc} --threads ${threads} \\\n    \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz \\\n    \"${R2_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz\n\n    # Remove original FastQ files\n    rm \"${fastq_array_R1[index]}\" \"${fastq_array_R2[index]}\"\ndone\n\n\n\n# Run MultiQC\n${multiqc} .\n\n\nRESULTS\nRun time was just under 31mins:\n\n\n\nfastp runtime screencap\n\n\nOutput folder:\n\n20200414_cbai_RNAseq_fastp_trimming/\n\nMultiQC report summarizes fastp and FastQC analyses (HTML):\n\n20200414_cbai_RNAseq_fastp_trimming/multiqc_report.html\n\nIndividual fastp reports are also available (HTML). An example is below:\nhttps://gannet.fish.washington.edu/Atumefaciens/20200414_cbai_RNAseq_fastp_trimming/380820_S1_L001_R1_001.fastp-trim.202004143431.report.html\nDownstream stuff entails:\n\nBLASTx\ntaxonomic read assignment using MEGAN6"
  },
  {
    "objectID": "posts/2020/2020-05-19-Transcriptome-Assessment---BUSCO-Metazoa-on-C.bairdi-Transcriptome-v1.6/index.html",
    "href": "posts/2020/2020-05-19-Transcriptome-Assessment---BUSCO-Metazoa-on-C.bairdi-Transcriptome-v1.6/index.html",
    "title": "Transcriptome Assessment - BUSCO Metazoa on C.bairdi Transcriptome v1.6",
    "section": "",
    "text": "I previously created a C.bairdi de novo transcriptome assembly v1.6 with Trinity from all our C.bairdi taxonomically filtered RNAseq on 20200518 and decided to assess its “completeness” using BUSCO and the metazoa_odb9 database.\nBUSCO was run with the --mode transcriptome option on Mox.\nSBATCH script (GitHub):\n\n20200519_cbai_busco_transcriptome_v1.6.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_busco_v2.0_transcriptome\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=5-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=${USER}@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200519_cbai_busco_transcriptome_v1.6\n\n### C.bairdi transcriptome assembly completeness assessment using BUSCO.\n### Transcriptome consists of all RNAseq data, Arthropoda only - shorthand: 2018, 2019, 2020-GW, 2020-UW\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Load Open MPI module for parallel, multi-node processing\nmodule load icc_19-ompi_3.1.2\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\n# Establish variables for more readable code\ntimestamp=$(date +%Y%m%d)\nspecies=\"cbai\"\nprefix=\"${timestamp}.${species}\"\n\n## Input files and settings\nbase_name=\"${prefix}\"\nbusco_db=/gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9\ntranscriptome_fasta=/gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v1.6.fasta\naugustus_species=fly\nthreads=28\n\n## Save working directory\nwd=$(pwd)\n\n## Set program paths\naugustus_bin=/gscratch/srlab/programs/Augustus-3.3.2/bin\naugustus_scripts=/gscratch/srlab/programs/Augustus-3.3.2/scripts\nblast_dir=/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin/\nbusco=/gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py\nhmm_dir=/gscratch/srlab/programs/hmmer-3.2.1/src/\n\n## Augustus configs\naugustus_dir=${wd}/augustus\naugustus_config_dir=${augustus_dir}/config\naugustus_orig_config_dir=/gscratch/srlab/programs/Augustus-3.3.2/config\n\n## BUSCO configs\nbusco_config_default=/gscratch/srlab/programs/busco-v3/config/config.ini.default\nbusco_config_ini=${wd}/config.ini\n\n# Export BUSCO config file location\nexport BUSCO_CONFIG_FILE=\"${busco_config_ini}\"\n\n# Export Augustus variable\nexport PATH=\"${augustus_bin}:$PATH\"\nexport PATH=\"${augustus_scripts}:$PATH\"\nexport AUGUSTUS_CONFIG_PATH=\"${augustus_config_dir}\"\n\n\n# Copy BUSCO config file\ncp ${busco_config_default} \"${busco_config_ini}\"\n\n# Make Augustus directory if it doesn't exist\nif [ ! -d \"${augustus_dir}\" ]; then\n  mkdir --parents \"${augustus_dir}\"\nfi\n\n# Copy Augustus config directory\ncp --preserve -r ${augustus_orig_config_dir} \"${augustus_dir}\"\n\n# Edit BUSCO config file\n## Set paths to various programs\n### The use of the % symbol sets the delimiter sed uses for arguments.\n### Normally, the delimiter that most examples use is a slash \"/\".\n### But, we need to expand the variables into a full path with slashes, which screws up sed.\n### Thus, the use of % symbol instead (it could be any character that is NOT present in the expanded variable; doesn't have to be \"%\").\nsed -i \"/^;cpu/ s/1/${threads}/\" \"${busco_config_ini}\"\nsed -i \"/^tblastn_path/ s%tblastn_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^makeblastdb_path/ s%makeblastdb_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^augustus_path/ s%augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^etraining_path/ s%etraining_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^gff2gbSmallDNA_path/ s%gff2gbSmallDNA_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^new_species_path/ s%new_species_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^optimize_augustus_path/ s%optimize_augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^hmmsearch_path/ s%hmmsearch_path = /home/osboxes/BUSCOVM/hmmer/hmmer-3.1b2-linux-intel-ia32/binaries/%path = ${hmm_dir}%\" \"${busco_config_ini}\"\n\n\n# Run BUSCO/Augustus training\n${busco} \\\n--in ${transcriptome_fasta} \\\n--out ${base_name} \\\n--lineage_path ${busco_db} \\\n--mode transcriptome \\\n--cpu ${threads} \\\n--long \\\n--species ${augustus_species} \\\n--tarzip \\\n--augustus_parameters='--progress=true'\n\n\nRESULTS\nRun time was quick, ~1min (no screencap due to use of ${USER} in email of SBATCH script. Whoops.)\nOutput folder:\n\n20200519_cbai_busco_transcriptome_v1.6/\n\nBUSCO short summary (text):\n\n20200519_cbai_busco_transcriptome_v1.6/run_20200519.cbai/short_summary_20200519.cbai.txt\n\n# BUSCO version is: 3.0.2\n# The lineage dataset is: metazoa_odb9 (Creation date: 2016-02-13, number of species: 65, number of BUSCOs: 978)\n# To reproduce this run: python /gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py -i /gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v1.6.fasta -o 20200615.cbai -l /gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9/ -m transcriptome -c 28 --long -z\n#\n# Summarized benchmarking in BUSCO notation for file /gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v1.6.fasta\n# BUSCO was run in mode: transcriptome\n\n    C:91.7%[S:62.6%,D:29.1%],F:6.2%,M:2.1%,n:978\n\n    897 Complete BUSCOs (C)\n    612 Complete and single-copy BUSCOs (S)\n    285 Complete and duplicated BUSCOs (D)\n    61  Fragmented BUSCOs (F)\n    20  Missing BUSCOs (M)\n    978 Total BUSCO groups searched"
  },
  {
    "objectID": "posts/2020/2020-01-02-Reagent-Prep---RNA-Pico-Ladder-Aliquoting-and-Testing/index.html",
    "href": "posts/2020/2020-01-02-Reagent-Prep---RNA-Pico-Ladder-Aliquoting-and-Testing/index.html",
    "title": "Reagent Prep - RNA Pico Ladder Aliquoting and Testing",
    "section": "",
    "text": "Created aliquots of RNA Pico Ladder received on 20191101, per the manufacturer’s instructions. Created single-use aliquots of 1.5uL and stored at -80oC:\n\nRack 2, Column 3, Row 4\n\nI verified that the ladder looks good by running a blank RNA Pico 6000 chip on the 2100 Bioanalyzer (Agilent) in the Seeb Lab.\n\n\nRESULTS\n\n\n\nRNA Pico 6000 ladder electropherogram"
  },
  {
    "objectID": "posts/2020/2020-12-07-SRA-Submission---Haws-Lab-C.gigas-Ploidy-pH-WGBS/index.html",
    "href": "posts/2020/2020-12-07-SRA-Submission---Haws-Lab-C.gigas-Ploidy-pH-WGBS/index.html",
    "title": "SRA Submission - Haws Lab C.gigas Ploidy pH WGBS",
    "section": "",
    "text": "I submitted the 24 C.gigas diploid/triploid pH-treated WGBS sequence data we received 20201205 to the NCBI Sequence Read Archive (SRA).\nThe samples were registered as part of the following BioProject:\n\nPRJNA682817\n\nThis accession number is what should be referenced for any publications with these samples. This has been added to Nightingales (Google Sheet), the Roberts Lab NGS database.\nHere is a table which contains individual sample accession numbers, in case they’re needed:\n\n\n\nSample_ID\nBioSample\nBioProject\n\n\n\n\n2N_HI_05\nSAMN17011249\nPRJNA682817\n\n\n2N_HI_08\nSAMN17011255\nPRJNA682817\n\n\n2N_HI_09\nSAMN17011256\nPRJNA682817\n\n\n2N_HI_10\nSAMN17011257\nPRJNA682817\n\n\n2N_HI_11\nSAMN17011258\nPRJNA682817\n\n\n2N_HI_12\nSAMN17011259\nPRJNA682817\n\n\n2N_LOW_01\nSAMN17011260\nPRJNA682817\n\n\n2N_LOW_02\nSAMN17011261\nPRJNA682817\n\n\n2N_LOW_03\nSAMN17011262\nPRJNA682817\n\n\n2N_LOW_04\nSAMN17011239\nPRJNA682817\n\n\n2N_LOW_05\nSAMN17011240\nPRJNA682817\n\n\n2N_LOW_06\nSAMN17011241\nPRJNA682817\n\n\n3N_HI_02\nSAMN17011242\nPRJNA682817\n\n\n3N_HI_03\nSAMN17011243\nPRJNA682817\n\n\n3N_HI_05\nSAMN17011244\nPRJNA682817\n\n\n3N_HI_08\nSAMN17011245\nPRJNA682817\n\n\n3N_HI_10\nSAMN17011246\nPRJNA682817\n\n\n3N_HI_11\nSAMN17011247\nPRJNA682817\n\n\n3N_LOW_06\nSAMN17011248\nPRJNA682817\n\n\n3N_LOW_07\nSAMN17011250\nPRJNA682817\n\n\n3N_LOW_08\nSAMN17011251\nPRJNA682817\n\n\n3N_LOW_10\nSAMN17011252\nPRJNA682817\n\n\n3N_LOW_11\nSAMN17011253\nPRJNA682817\n\n\n3N_LOW_12\nSAMN17011254\nPRJNA682817"
  },
  {
    "objectID": "posts/2020/2020-09-01-DNA-Quantification---Re-quant-Ronits-C.gigas-Diploid-Triploid-Ctenidia-gDNA-Submitted-to-ZymoResearch/index.html",
    "href": "posts/2020/2020-09-01-DNA-Quantification---Re-quant-Ronits-C.gigas-Diploid-Triploid-Ctenidia-gDNA-Submitted-to-ZymoResearch/index.html",
    "title": "DNA Quantification - Re-quant Ronits C.gigas Diploid-Triploid Ctenidia gDNA Submitted to ZymoResearch",
    "section": "",
    "text": "I received notice from ZymoResearch yesterday afternoon that the DNA we sent on 20200820 for this project (Quote 3534) had insufficient DNA for sequencing for most of the samples. This was, honestly, shocking. I had even submitted well over the minimum amount of DNA required (submitted 1.75ug - only needed 1ug). So, I’m not entirely sure what happened here.\nI went ahead and re-quantified these samples with the intent of sending them more DNA. Samples were fully thawed, mixed thoroughly by finger flicking, spun down, and quantified using the Roberts Lab Qubit 3.0 and the dsDNA BR Assay (Invitrogen). Used 2uL of each sample.\n\n\nRESULTS\nQubit results (Google Sheet):\n\n20200901_qubit_DNA_gigas_ronit_ploidy\n\nComparison table below shows the initial sample quantification (which can be found in the Ronit’s Samples Google Sheet), as well as the concentrations determiend by Zymo, and today’s quantification. The table also lists the volume needed to send an additional 1ug of DNA from each sample, based on today’s quantifications.\n\n\n\nSample_ID\ninitial\nZymo\n20200901\nVol_for_1ug(uL)\n\n\n\n\nD11-C\n181\n85.20\n269\n3.72\n\n\nD12-C\n192\n46.16\n289\n3.46\n\n\nD13-C\n288\n606.23\n332\n3.01\n\n\nD19-C\n63.6\n11.14\n51.3\n19.49\n\n\nD20-C\n123\n9.40\n77\n12.99\n\n\nT11-C\n130\n41.52\n88\n11.36\n\n\nT12-C\n262\n9.96\n139\n7.19\n\n\nT13-C\n250\n130.14\n148\n6.76\n\n\nT19-C\n173\n35.58\n92.9\n10.76\n\n\nT20-C\n109\n132.10\n78.4\n12.76\n\n\n\nI’m not going to think too hard about what’s going on here, but I am surprised at the concentration differences between all three measurements. It should also be noted that I believe the ZymoResearch concentrations provided were from the Agilent TapeStation, not a Qubit. The TapeStation is less accurate/sensitive than a dye-based quantification methodology like the Qubit.\nWill send off 1ug of each sample, based on today’s quants…"
  },
  {
    "objectID": "posts/2020/2020-08-28-Transcriptome-Annotation---Trinotate-C.bairdi-v3.1-on-Mox/index.html",
    "href": "posts/2020/2020-08-28-Transcriptome-Annotation---Trinotate-C.bairdi-v3.1-on-Mox/index.html",
    "title": "Transcriptome Annotation - Trinotate C.bairdi v3.1 on Mox",
    "section": "",
    "text": "To continue annotation of our C.bairdi v3.1 transcriptome assembly], I wanted to run Trinotate.\nInfo for each transcriptome version (library composition, assembly dates, BUSCO, etc) can be found in this table:\n\ncbai_transcriptome_comp\n\nThis was run on Mox.\nSBATCH script (GitHub):\n\n20200828_cbai_trinotate_transcriptome-v3.1.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_trinotate_transcriptome-v3.1\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=7-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200828_cbai_trinotate_transcriptome-v3.1\n\n\n# Script to run Trinotate on C.bairdi transcriptome:\n# v3.1\n\n###################################################################################\n# These variables need to be set by user\n\n# Input files\n## BLASTx\nblastx_out=\"/gscratch/scrubbed/samwhite/outputs/20200608_cbai_diamond_blastx_v2.1_v3.1/cbai_transcriptome_v3.1.blastx.outfmt6\"\n\n## TransDecoder\ntransdecoder_dir=\"/gscratch/scrubbed/samwhite/outputs/20200826_cbai_transdecoder_transcriptomes_v2.1_v.3.1/20200826_cbai_transcriptome_v3.1.fasta.transdecoder\"\nblastp_out=\"${transdecoder_dir}/20200826_cbai_transcriptome_v3.1.fasta.blastp_out/20200826_cbai_transcriptome_v3.1.fasta.blastp.outfmt6\"\npfam_out=\"${transdecoder_dir}/20200826_cbai_transcriptome_v3.1.fasta.pfam_out/20200826_cbai_transcriptome_v3.1.fasta.pfam.domtblout\"\nlORFs_pep=\"${transdecoder_dir}/cbai_transcriptome_v3.1.fasta.transdecoder_dir/longest_orfs.pep\"\n\n## Transcriptomics\ntranscriptomes_dir=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes\"\ntrinity_fasta=\"${transcriptomes_dir}/cbai_transcriptome_v3.1.fasta\"\ntrinity_gene_map=\"${transcriptomes_dir}/cbai_transcriptome_v3.1.fasta.gene_trans_map\"\n\n###################################################################################\n\nwd=\"$(pwd)\"\ntimestamp=$(date +%Y%m%d)\n\n\n## Paths to input/output files\n\n## New folders for working directory\nrnammer_out_dir=\"${wd}/RNAmmer_out\"\nsignalp_out_dir=\"${wd}/signalp_out\"\ntmhmm_out_dir=\"${wd}/tmhmm_out\"\n\n\nrnammer_prefix=${trinity_fasta##*/}\nprefix=\"${timestamp}.${rnammer_prefix}.trinotate\"\n\n# Output files\nrnammer_out=\"${rnammer_out_dir}/${rnammer_prefix}.rnammer.gff\"\nsignalp_out=\"${signalp_out_dir}/${prefix}.signalp.out\"\ntmhmm_out=\"${tmhmm_out_dir}/${prefix}.tmhmm.out\"\ntrinotate_report=\"${wd}/${prefix}_annotation_report.txt\"\n\n# Paths to programs\nrnammer_dir=\"/gscratch/srlab/programs/RNAMMER-1.2\"\nrnammer=\"${rnammer_dir}/rnammer\"\nsignalp_dir=\"/gscratch/srlab/programs/signalp-4.1\"\nsignalp=\"${signalp_dir}/signalp\"\ntmhmm_dir=\"/gscratch/srlab/programs/tmhmm-2.0c/bin\"\ntmhmm=\"${tmhmm_dir}/tmhmm\"\ntrinotate_dir=\"/gscratch/srlab/programs/Trinotate-v3.1.1\"\ntrinotate=\"${trinotate_dir}/Trinotate\"\ntrinotate_rnammer=\"${trinotate_dir}/util/rnammer_support/RnammerTranscriptome.pl\"\ntrinotate_GO=\"${trinotate_dir}/util/extract_GO_assignments_from_Trinotate_xls.pl\"\ntrinotate_features=\"${trinotate_dir}/util/Trinotate_get_feature_name_encoding_attributes.pl\"\ntrinotate_sqlite_db=\"Trinotate.sqlite\"\n\n# Generate FastA checksum, for reference if needed.\nmd5sum ${trinity_fasta} > fasta.checksum.md5\n\n# Make output directories\nmkdir \"${rnammer_out_dir}\" \"${signalp_out_dir}\" \"${tmhmm_out_dir}\"\n\n# Copy sqlite database template\n\ncp ${trinotate_dir}/admin/Trinotate.sqlite .\n\n# Run signalp\n${signalp} \\\n-f short \\\n-n \"${signalp_out}\" \\\n${lORFs_pep}\n\n# Run tmHMM\n${tmhmm} \\\n--short \\\n< ${lORFs_pep} \\\n> \"${tmhmm_out}\"\n\n# Run RNAmmer\ncd \"${rnammer_out_dir}\" || exit\n${trinotate_rnammer} \\\n--transcriptome ${trinity_fasta} \\\n--path_to_rnammer ${rnammer}\ncd \"${wd}\" || exit\n\n# Run Trinotate\n## Load transcripts and coding regions into database\n${trinotate} \\\n${trinotate_sqlite_db} \\\ninit \\\n--gene_trans_map \"${trinity_gene_map}\" \\\n--transcript_fasta \"${trinity_fasta}\" \\\n--transdecoder_pep \"${lORFs_pep}\"\n\n## Load BLAST homologies\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_swissprot_blastp \\\n\"${blastp_out}\"\n\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_swissprot_blastx \\\n\"${blastx_out}\"\n\n## Load Pfam\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_pfam \\\n\"${pfam_out}\"\n\n## Load transmembrane domains\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_tmhmm \\\n\"${tmhmm_out}\"\n\n## Load signal peptides\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_signalp \\\n\"${signalp_out}\"\n\n## Load RNAmmer\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_rnammer \\\n\"${rnammer_out}\"\n\n## Creat annotation report\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nreport \\\n> \"${trinotate_report}\"\n\n# Extract GO terms from annotation report\n\"${trinotate_GO}\" \\\n--Trinotate_xls \"${trinotate_report}\" \\\n-G \\\n--include_ancestral_terms \\\n> \"${prefix}\".go_annotations.txt\n\n# Make transcript features annotation map\n\"${trinotate_features}\" \\\n\"${trinotate_report}\" \\\n> \"${prefix}\".annotation_feature_map.txt\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nRESULTS\nRuntime was ~2.5hrs:\n\n\n\ncbai v3.1 Trinotate runtime\n\n\nOutput folder:\n\n20200828_cbai_trinotate_transcriptome-v3.1\n\nAnnotation feature map (7.0MB; text):\n\n20200828.cbai_transcriptome_v3.1.fasta.trinotate.annotation_feature_map.txt\n\nThis can be used to update Trinity-based gene expression matrices like so:\n\n${TRINITY_HOME}/Analysis/DifferentialExpression/rename_matrix_feature_identifiers.pl Trinity_trans.counts.matrix annot_feature_map.txt > Trinity_trans.counts.wAnnot.matrix\n\n\n\nAnnotation report (92MB; CSV)\n\n20200828.cbai_transcriptome_v3.1.fasta.trinotate_annotation_report.txt\n\nGene ontology (GO) annotations (12MB; text)\n\n20200828.cbai_transcriptome_v3.1.fasta.trinotate.go_annotations.txt\n\nSQlite database (788MB; SQLITE):\n\nTrinotate.sqlite"
  },
  {
    "objectID": "posts/2020/2020-06-04-Transcriptome-Annotation---C.bairdi-Transcriptomes-v2.0-and-v3.0-with-DIAMOND-BLASTx-on-Mox/index.html",
    "href": "posts/2020/2020-06-04-Transcriptome-Annotation---C.bairdi-Transcriptomes-v2.0-and-v3.0-with-DIAMOND-BLASTx-on-Mox/index.html",
    "title": "Transcriptome Annotation - C.bairdi Transcriptomes v2.0 and v3.0 with DIAMOND BLASTx on Mox",
    "section": "",
    "text": "Continuing to try to identify the best C.bairdi transcriptome, we decided to extract all non-dinoflagellate sequences from cbai_transcriptome_v2.0 (RNAseq shorthand: 2018, 2019, 2020-GW, 2020-UW) and cbai_transcriptome_v3.0 (RNAseq shorthand: 2018, 2019, 2020-UW). Both of these transcriptomes were assembled without any taxonomic filter applied.\nWe’ll do this by:\n\nRunning BLASTx on the transcriptomes (this notebook).\nConverting BLASTx output to MEGAN6 RMA6 format (this notebook).\nUse MEGAN6 to extract all non-dinoflagellate sequences (different notebook).\n\nInitial DIAMOND BLASTx was run on Mox.\nDue to usage of X11, the subsequent conversion of the DIAMOND BLASTx output to RMA6 can’t be performed on Mox, so was performed on my computer, swoose. Scripts for both jobs are below.\nSBATCH script (GitHub):\n\n20200604_cbai_v2.0_v3.0_diamond_blastx.sh (commit 9f61124)\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_blastx_DIAMOND\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=1-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200604_cbai_v2.0_v3.0_diamond_blastx\n\n## Perform DIAMOND BLASTx on Chionoecetes bairdi (Tanner crab) transcriptome assemblies:\n## v2.0 and v3.0 for subsequent taxonomic filtering with MEGAN6.\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\n\n# Program paths\ndiamond=/gscratch/srlab/programs/diamond-0.9.29/diamond\n\n# DIAMOND NCBI nr database\ndmnd=/gscratch/srlab/blastdbs/ncbi-nr-20190925/nr.dmnd\n\n# Capture program options\n{\necho \"Program options for DIAMOND: \"\necho \"\"\n\"${diamond}\" help\necho \"\"\necho \"\"\necho \"----------------------------------------------\"\necho \"\"\necho \"\"\n} &>> program_options.log || true\n\n# Transcriptomes directory\ntranscriptome_dir=/gscratch/srlab/sam/data/C_bairdi/transcriptomes/\n\n\n# Loop through transcriptome FastA files, log filenames to fasta_list.txt.\n# Run DIAMOND on each FastA\nfor fasta in ${transcriptome_dir}cbai_transcriptome_v[23]*.fasta\ndo\n    # Record md5 checksums\n    md5sum \"${fasta}\" >> transcriptomes_checkums.md5\n\n    # Strip leading path and extensions\n    no_path=$(echo \"${fasta##*/}\")\n\n    # Run DIAMOND with blastx\n    # Output format 100 produces a DAA binary file for use with MEGAN\n    ${diamond} blastx \\\n    --db ${dmnd} \\\n    --query \"${fasta}\" \\\n    --out \"${no_path}\".blastx.daa \\\n    --outfmt 100 \\\n    --top 5 \\\n    --block-size 15.0 \\\n    --index-chunks 4\ndone\n\n\nRESULTS\nTook a little over 2hrs:\n\n\n\ncbai transcritpomes 2.0 and 3.0 diamond blastx runtime\n\n\nOutput folder:\n\n20200604_cbai_v2.0_v3.0_diamond_blastx\n\nMEGAN6 RMA6 files:\n\n20200604_cbai_v2.0_v3.0_diamond_blastx/cbai_transcriptome_v3.0.daa2rma.rma6 (168MB)\n20200604_cbai_v2.0_v3.0_diamond_blastx/cbai_transcriptome_v2.0.daa2rma.rma6 (328MB)\n\nWill import the RMA6 files into MEGAN6 and extract sequences."
  },
  {
    "objectID": "posts/2020/2020-05-08-Transcriptome-Assessment---BUSCO-Metazoa-on-C.bairdi-v2.0-Transcriptome/index.html",
    "href": "posts/2020/2020-05-08-Transcriptome-Assessment---BUSCO-Metazoa-on-C.bairdi-v2.0-Transcriptome/index.html",
    "title": "Transcriptome Assessment - BUSCO Metazoa on C.bairdi v2.0 Transcriptome",
    "section": "",
    "text": "I previously created a C.bairdi de novo transcriptome assembly with Trinity using all existing, unfiltered (i.e. no taxonomic selection) RNAseq data on 20200502 and decided to assess its “completeness” using BUSCO and the metazoa_odb9 database.\nBUSCO was run with the --mode transcriptome option on Mox.\nSBATCH script (GitHub):\n\n20200508_cbai_busco_transcriptome_v2.0.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_busco_v2.0_transcriptome\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=1-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=${USER}@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200508_cbai_busco_transcriptome_v2.0\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Load Open MPI module for parallel, multi-node processing\nmodule load icc_19-ompi_3.1.2\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\n# Establish variables for more readable code\ntimestamp=$(date +%Y%m%d)\nspecies=\"cbai\"\nprefix=\"${timestamp}.${species}\"\n\n## Input files and settings\nbase_name=\"${prefix}\"\nbusco_db=/gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9\ntranscriptome_fasta=/gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200507.C_bairdi.Trinity.fasta\naugustus_species=fly\nthreads=28\n\n## Save working directory\nwd=$(pwd)\n\n## Set program paths\naugustus_bin=/gscratch/srlab/programs/Augustus-3.3.2/bin\naugustus_scripts=/gscratch/srlab/programs/Augustus-3.3.2/scripts\nblast_dir=/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin/\nbusco=/gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py\nhmm_dir=/gscratch/srlab/programs/hmmer-3.2.1/src/\n\n## Augustus configs\naugustus_dir=${wd}/augustus\naugustus_config_dir=${augustus_dir}/config\naugustus_orig_config_dir=/gscratch/srlab/programs/Augustus-3.3.2/config\n\n## BUSCO configs\nbusco_config_default=/gscratch/srlab/programs/busco-v3/config/config.ini.default\nbusco_config_ini=${wd}/config.ini\n\n# Export BUSCO config file location\nexport BUSCO_CONFIG_FILE=\"${busco_config_ini}\"\n\n# Export Augustus variable\nexport PATH=\"${augustus_bin}:$PATH\"\nexport PATH=\"${augustus_scripts}:$PATH\"\nexport AUGUSTUS_CONFIG_PATH=\"${augustus_config_dir}\"\n\n\n# Copy BUSCO config file\ncp ${busco_config_default} \"${busco_config_ini}\"\n\n# Make Augustus directory if it doesn't exist\nif [ ! -d \"${augustus_dir}\" ]; then\n  mkdir --parents \"${augustus_dir}\"\nfi\n\n# Copy Augustus config directory\ncp --preserve -r ${augustus_orig_config_dir} \"${augustus_dir}\"\n\n# Edit BUSCO config file\n## Set paths to various programs\n### The use of the % symbol sets the delimiter sed uses for arguments.\n### Normally, the delimiter that most examples use is a slash \"/\".\n### But, we need to expand the variables into a full path with slashes, which screws up sed.\n### Thus, the use of % symbol instead (it could be any character that is NOT present in the expanded variable; doesn't have to be \"%\").\nsed -i \"/^;cpu/ s/1/${threads}/\" \"${busco_config_ini}\"\nsed -i \"/^tblastn_path/ s%tblastn_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^makeblastdb_path/ s%makeblastdb_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^augustus_path/ s%augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^etraining_path/ s%etraining_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^gff2gbSmallDNA_path/ s%gff2gbSmallDNA_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^new_species_path/ s%new_species_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^optimize_augustus_path/ s%optimize_augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^hmmsearch_path/ s%hmmsearch_path = /home/osboxes/BUSCOVM/hmmer/hmmer-3.1b2-linux-intel-ia32/binaries/%path = ${hmm_dir}%\" \"${busco_config_ini}\"\n\n\n# Run BUSCO/Augustus training\n${busco} \\\n--in ${transcriptome_fasta} \\\n--out ${base_name} \\\n--lineage_path ${busco_db} \\\n--mode transcriptome \\\n--cpu ${threads} \\\n--long \\\n--species ${augustus_species} \\\n--tarzip \\\n--augustus_parameters='--progress=true'\n\n\nRESULTS\nPretty quick, ~18 minutes:\nOutput folder:\n\n20200508_cbai_busco_transcriptome_v2.0/\n\nBUSCO short summary (text):\n\n20200508_cbai_busco_transcriptome_v2.0/run_20200508.cbai/short_summary_20200508.cbai.txt)\n\n# BUSCO version is: 3.0.2\n# The lineage dataset is: metazoa_odb9 (Creation date: 2016-02-13, number of species: 65, number of BUSCOs: 978)\n# To reproduce this run: python /gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py -i /gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200507.C_bairdi.Trinity.fasta -o 20200508.cbai -l /gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9/ -m transcriptome -c 28 --long -z\n#\n# Summarized benchmarking in BUSCO notation for file /gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200507.C_bairdi.Trinity.fasta\n# BUSCO was run in mode: transcriptome\n\n    C:98.8%[S:24.9%,D:73.9%],F:0.9%,M:0.3%,n:978\n\n    967 Complete BUSCOs (C)\n    244 Complete and single-copy BUSCOs (S)\n    723 Complete and duplicated BUSCOs (D)\n    9   Fragmented BUSCOs (F)\n    2   Missing BUSCOs (M)\n    978 Total BUSCO groups searched"
  },
  {
    "objectID": "posts/2020/2020-02-07-Transcriptome-Assessment---BUSCO-Metazoa-on-Hematodinium-MEGAN-Transcriptome/index.html",
    "href": "posts/2020/2020-02-07-Transcriptome-Assessment---BUSCO-Metazoa-on-Hematodinium-MEGAN-Transcriptome/index.html",
    "title": "Transcriptome Assessment - BUSCO Metazoa on Hematodinium MEGAN Transcriptome",
    "section": "",
    "text": "I previously created a Hematodinium de novo transcriptome assembly with Trinity from the MEGAN6 taxonomic-specific reads for Alveolata on 20200122 and decided to assess its “completeness” using BUSCO and the metazoa_odb9 database.\nBUSCO was run with the --mode transcriptome option on Mox.\nSBATCH script (GitHub):\n\n20200207_hemat_busco_megan.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_busco_megan_transcriptome\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=3-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200207_hemat_busco_megan\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Load Open MPI module for parallel, multi-node processing\nmodule load icc_19-ompi_3.1.2\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\n# Establish variables for more readable code\ntimestamp=$(date +%Y%m%d)\nspecies=\"hemat\"\nprefix=\"${timestamp}.${species}\"\n\n## Input files and settings\nbase_name=\"${prefix}.megan\"\nbusco_db=/gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9\ntranscriptome_fasta=/gscratch/srlab/sam/data/Hematodinium/transcriptomes/20200122.hemat.megan.Trinity.fasta\naugustus_species=fly\nthreads=28\n\n## Save working directory\nwd=$(pwd)\n\n## Set program paths\naugustus_bin=/gscratch/srlab/programs/Augustus-3.3.2/bin\naugustus_scripts=/gscratch/srlab/programs/Augustus-3.3.2/scripts\nblast_dir=/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin/\nbusco=/gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py\nhmm_dir=/gscratch/srlab/programs/hmmer-3.2.1/src/\n\n## Augustus configs\naugustus_dir=${wd}/augustus\naugustus_config_dir=${augustus_dir}/config\naugustus_orig_config_dir=/gscratch/srlab/programs/Augustus-3.3.2/config\n\n## BUSCO configs\nbusco_config_default=/gscratch/srlab/programs/busco-v3/config/config.ini.default\nbusco_config_ini=${wd}/config.ini\n\n# Export BUSCO config file location\nexport BUSCO_CONFIG_FILE=\"${busco_config_ini}\"\n\n# Export Augustus variable\nexport PATH=\"${augustus_bin}:$PATH\"\nexport PATH=\"${augustus_scripts}:$PATH\"\nexport AUGUSTUS_CONFIG_PATH=\"${augustus_config_dir}\"\n\n\n# Copy BUSCO config file\ncp ${busco_config_default} \"${busco_config_ini}\"\n\n# Make Augustus directory if it doesn't exist\nif [ ! -d \"${augustus_dir}\" ]; then\n  mkdir --parents \"${augustus_dir}\"\nfi\n\n# Copy Augustus config directory\ncp --preserve -r ${augustus_orig_config_dir} \"${augustus_dir}\"\n\n# Edit BUSCO config file\n## Set paths to various programs\n### The use of the % symbol sets the delimiter sed uses for arguments.\n### Normally, the delimiter that most examples use is a slash \"/\".\n### But, we need to expand the variables into a full path with slashes, which screws up sed.\n### Thus, the use of % symbol instead (it could be any character that is NOT present in the expanded variable; doesn't have to be \"%\").\nsed -i \"/^;cpu/ s/1/${threads}/\" \"${busco_config_ini}\"\nsed -i \"/^tblastn_path/ s%tblastn_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^makeblastdb_path/ s%makeblastdb_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^augustus_path/ s%augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^etraining_path/ s%etraining_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^gff2gbSmallDNA_path/ s%gff2gbSmallDNA_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^new_species_path/ s%new_species_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^optimize_augustus_path/ s%optimize_augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^hmmsearch_path/ s%hmmsearch_path = /home/osboxes/BUSCOVM/hmmer/hmmer-3.1b2-linux-intel-ia32/binaries/%path = ${hmm_dir}%\" \"${busco_config_ini}\"\n\n\n# Run BUSCO/Augustus training\n${busco} \\\n--in ${transcriptome_fasta} \\\n--out ${base_name} \\\n--lineage_path ${busco_db} \\\n--mode transcriptome \\\n--cpu ${threads} \\\n--long \\\n--species ${augustus_species} \\\n--tarzip \\\n--augustus_parameters='--progress=true'\n\n\nRESULTS\nThis was very quick - 33s (ignore the mislaballed job name!):\n\n\n\nBUSCO runtime\n\n\nOutput folder:\n\n20200207_hemat_busco_megan/\n\nBUSCO short summary (text):\n\n20200207_hemat_busco_megan/run_20200207.hemat.megan/short_summary_20200207.hemat.megan.txt\n\n# BUSCO version is: 3.0.2\n# The lineage dataset is: metazoa_odb9 (Creation date: 2016-02-13, number of species: 65, number of BUSCOs: 978)\n# To reproduce this run: python /gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py -i /gscratch/srlab/sam/data/Hematodinium/transcriptomes/20200122.hemat.megan.Trinity.fasta -o 20200331.hemat.megan -l /gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9/ -m transcriptome -c 28 --long -z\n#\n# Summarized benchmarking in BUSCO notation for file /gscratch/srlab/sam/data/Hematodinium/transcriptomes/20200122.hemat.megan.Trinity.fasta\n# BUSCO was run in mode: transcriptome\n\n    C:25.1%[S:19.2%,D:5.9%],F:9.5%,M:65.4%,n:978\n\n    246 Complete BUSCOs (C)\n    188 Complete and single-copy BUSCOs (S)\n    58  Complete and duplicated BUSCOs (D)\n    93  Fragmented BUSCOs (F)\n    639 Missing BUSCOs (M)\n    978 Total BUSCO groups searched"
  },
  {
    "objectID": "posts/2020/2020-09-04-Data-Wrangling---NanoPore-Fast5-Conversion-to-FastQ-of-C.bairdi-20102558-2729-Run-01-on-Mox-with-GPU-Node/index.html",
    "href": "posts/2020/2020-09-04-Data-Wrangling---NanoPore-Fast5-Conversion-to-FastQ-of-C.bairdi-20102558-2729-Run-01-on-Mox-with-GPU-Node/index.html",
    "title": "Data Wrangling - NanoPore Fast5 Conversion to FastQ of C.bairdi 20102558-2729 Run-01 on Mox with GPU Node",
    "section": "",
    "text": "Time to start working with the NanoPore data that I generated back in January(???!!!). In order to proceed, I first need to convert the raw Fast5 files to FastQ. To do so, I’ll use the NanoPore program guppy.\nPrior to running this, I did some quick test runs on Mox using different settings for --num_callers and --cpu_threads_per_caller to gauge how long the job might take. Using a small (~45MB) Fast5 file, conversion ranged from ~1 - 1.5hrs! Considering there are 26 files in this set, this might take a while. Poking around a bit to see how I could leverage multiple nodes in an high performance computing (HPC) environment like Mox, I came across the fact that using a GPU instead of a CPU could cut the runtime by a factor of 10!\nI decided to see if we could access a GPU node on Mox and it turns out that we can! A quick test with the GPU node confirmed a massive time reduction! The same Fast5 used in the CPU threads/callers test converted in <10 seconds!! Amazing! The only rub is that since we don’t own a GPU node, any jobs we submit are:\n\nlowest priority in any queue\ncan get interrupted at any time by jobs submitted by the node owner\n\nI’ll be submitting these very early in the morning and with runtimes this fast, I shouldn’t encounter any issues. Exciting!\nSBATCH script (GitHub):\n\n20200110_cbai_guppy_nanopore_20102558-2729.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_guppy_nanopore_20102558-2729\n## Allocation Definition\n#SBATCH --account=srlab-ckpt\n#SBATCH --partition=ckpt\n## Resources\n## GPU\n#SBATCH --gres=gpu:P100:1\n#SBATCH --constraint=gpu_default\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=0-01:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200110_cbai_guppy_nanopore_20102558-2729\n\n## Script for running ONT guppy to perform\n## basecalling (i.e. convert raw ONT Fast5 to FastQ) of NanaPore data generated\n## on 20200109 from C.bairdi 20102558-2729 gDNA.\n\n## This script utilizes a GPU node. These nodes are only available as part of the checkpoint\n## partition/account. Since we don't own a GPU node, our GPU jobs are lowest priority and\n## can be interrupted at any time if the node owner submits a new job.\n\n###################################################################################\n# These variables need to be set by user\n\nwd=$(pwd)\n\n# Programs array\ndeclare -A programs_array\nprograms_array=(\n[guppy_basecaller]=\"/gscratch/srlab/programs/ont-guppy_4.0.15_linux64/bin/guppy_basecaller\"\n)\n\n# Establish variables for more readable code\n\n# Input files directory\nfast5_dir=/gscratch/srlab/sam/data/C_bairdi/DNAseq/ont_FAL58500_94244ffd_20102558-2729\n\n# Output directory\nout_dir=${wd}\n\n# CPU threads\nthreads=28\n\n# Flowcell type\nflowcell=\"FLO-MIN106\"\n\n# Sequencing kit used\nkit=\"SQK-RAD004\"\n\n# GPU devices setting\nGPU_devices=auto\n\n# Set number of FastQ sequences written per file (0 means all in one file)\nrecords_per_fastq=0\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Load CUDA GPU module\nmodule load cuda/10.1.105_418.39\n\n\n${programs_array[guppy_basecaller]} \\\n--input_path ${fast5_dir} \\\n--save_path ${out_dir} \\\n--flowcell ${flowcell} \\\n--kit ${kit} \\\n--device ${GPU_devices} \\\n--records_per_fastq ${records_per_fastq} \\\n--num_callers ${threads}\n\n###################################################################################\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : n\n} >> system_path.log\n\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n    ${programs_array[$program]} --help\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n\nRESULTS\nTook 11mins to convert 26 Fast5 files to FastQ with the Mox GPU node:\n\n\n\nFast5 to FastQ conversion runtime for 26 Fast5 files using Mox GPU node\n\n\nOutput folder:\n\n20200110_cbai_guppy_nanopore_20102558-2729/\n\nSequencing Summary (17MB; TXT)\n\n20200110_cbai_guppy_nanopore_20102558-2729/sequencing_summary.txt\n\nUseful with downstream analysis tools, like NanoPlot.\n\n\nAll the resulting FastQ files can be accessed in the output folder linked above with this pattern:\n\n*.fastq\n\nUnbeknownst to me, I misinterpreted the behavior of the program. I thought the FastQs from all of the Fast5 would be concatenated into a single FastQ. However, that’s not the case. Each Fast5 got converted to its own FastQ. So, I now have 26 FastQ files instead of just one. Not a big deal as I can concatenate these at a later date.\nNow, I’ll get these run through some QC software (FastQC, NanoPlot) to get an idea of how things look before processing them further."
  },
  {
    "objectID": "posts/2020/2020-05-19-TransDecoder---C.bairdi-Transcriptome-v1.6-on-Mox/index.html",
    "href": "posts/2020/2020-05-19-TransDecoder---C.bairdi-Transcriptome-v1.6-on-Mox/index.html",
    "title": "TransDecoder - C.bairdi Transcriptome v1.6 on Mox",
    "section": "",
    "text": "Need to run TransDecoder on Mox on the C.bairdi transcriptome v1.6 from 20200518.\nSBATCH script (GitHub):\n\n20200519_cbai_transdecoder_transcriptome-v1.6.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=transdecoder_cbai\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200519_cbai_transdecoder_transcriptome-v1.6\n\n\n# Exit script if a command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# Set workind directory as current directory\nwd=\"$(pwd)\"\n\n# Capture date as YYYYMMDD\ntimestamp=$(date +%Y%m%d)\n\n# Set input file locations and species designation\ntrinity_fasta=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v1.6.fasta\"\ntrinity_gene_map=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v1.6.fasta.gene_trans_map\"\nspecies=\"cbai\"\n\n# Capture trinity file name\ntrinity_fasta_name=${trinity_fasta##*/}\n\n\n\n# Paths to input/output files\nblastp_out_dir=\"${wd}/blastp_out\"\ntransdecoder_out_dir=\"${wd}/${trinity_fasta_name}.transdecoder_dir\"\npfam_out_dir=\"${wd}/pfam_out\"\nblastp_out=\"${blastp_out_dir}/${timestamp}.${species}.blastp.outfmt6\"\npfam_out=\"${pfam_out_dir}/${timestamp}.${species}.pfam.domtblout\"\nlORFs_pep=\"${transdecoder_out_dir}/longest_orfs.pep\"\npfam_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/Pfam-A.hmm\"\nsp_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/uniprot_sprot.pep\"\n\n\n\n# Paths to programs\nblast_dir=\"/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin\"\nblastp=\"${blast_dir}/blastp\"\nhmmer_dir=\"/gscratch/srlab/programs/hmmer-3.2.1/src\"\nhmmscan=\"${hmmer_dir}/hmmscan\"\ntransdecoder_dir=\"/gscratch/srlab/programs/TransDecoder-v5.5.0\"\ntransdecoder_lORFs=\"${transdecoder_dir}/TransDecoder.LongOrfs\"\ntransdecoder_predict=\"${transdecoder_dir}/TransDecoder.Predict\"\n\n# Capture FastA MD5 checksum for future reference\nmd5sum \"${trinity_fasta}\" >> fasta.checksum.md5\n\n# Make output directories\nmkdir \"${blastp_out_dir}\"\nmkdir \"${pfam_out_dir}\"\n\n# Extract long open reading frames\n\"${transdecoder_lORFs}\" \\\n--gene_trans_map \"${trinity_gene_map}\" \\\n-t \"${trinity_fasta}\"\n\n# Run blastp on long ORFs\n\"${blastp}\" \\\n-query \"${lORFs_pep}\" \\\n-db \"${sp_db}\" \\\n-max_target_seqs 1 \\\n-outfmt 6 \\\n-evalue 1e-5 \\\n-num_threads 28 \\\n> \"${blastp_out}\"\n\n# Run pfam search\n\"${hmmscan}\" \\\n--cpu 28 \\\n--domtblout \"${pfam_out}\" \\\n\"${pfam_db}\" \\\n\"${lORFs_pep}\"\n\n# Run Transdecoder with blastp and Pfam results\n\"${transdecoder_predict}\" \\\n-t \"${trinity_fasta}\" \\\n--retain_pfam_hits \"${pfam_out}\" \\\n--retain_blastp_hits \"${blastp_out}\"\n\n\nRESULTS\nTook about 8hrs:\n\n\n\ncbai v1.6 transdecoder runtime\n\n\nOutput folder:\n\n20200519_cbai_transdecoder_transcriptome-v1.6/\n\nCoding Sequences (FastA):\n\ncbai_transcriptome_v1.6.fasta.transdecoder.cds\n\nPeptide Sequences (FastA):\n\ncbai_transcriptome_v1.6.fasta.transdecoder.pep\n\nBLASTp output (tab):\n\n20200519_cbai_transdecoder_transcriptome-v1.6/blastp_out/20200519.cbai.blastp.outfmt6\n\nPfam output:\n\n20200519_cbai_transdecoder_transcriptome-v1.6/pfam_out/20200519.cbai.pfam.domtblout\n\nWill get ready to run Trinotate with these output files."
  },
  {
    "objectID": "posts/2020/2020-01-22-Transcriptome-Assembly---C.bairdi-with-MEGAN6-Taxonomy-specific-Reads-with-Trinity-on-Mox/index.html",
    "href": "posts/2020/2020-01-22-Transcriptome-Assembly---C.bairdi-with-MEGAN6-Taxonomy-specific-Reads-with-Trinity-on-Mox/index.html",
    "title": "Transcriptome Assembly - C.bairdi with MEGAN6 Taxonomy-specific Reads with Trinity on Mox",
    "section": "",
    "text": "Ran a de novo assembly using the extracted reads classified under Arthropoda from 20200122 (for reference, these include RNAseq data using a newly established “shorthand”: 2018, 2019). The assembly was performed with Trinity on Mox.\nSBATCH Script (GitHub):"
  },
  {
    "objectID": "posts/2020/2020-01-22-Transcriptome-Assembly---C.bairdi-with-MEGAN6-Taxonomy-specific-Reads-with-Trinity-on-Mox/index.html#stats-based-on-only-longest-isoform-per-gene",
    "href": "posts/2020/2020-01-22-Transcriptome-Assembly---C.bairdi-with-MEGAN6-Taxonomy-specific-Reads-with-Trinity-on-Mox/index.html#stats-based-on-only-longest-isoform-per-gene",
    "title": "Transcriptome Assembly - C.bairdi with MEGAN6 Taxonomy-specific Reads with Trinity on Mox",
    "section": "Stats based on ONLY LONGEST ISOFORM per ‘GENE’:",
    "text": "Stats based on ONLY LONGEST ISOFORM per ‘GENE’:\n\n\nContig N10: 3186\nContig N20: 2340\nContig N30: 1889\nContig N40: 1584\nContig N50: 1312\n\nMedian contig length: 635\nAverage contig: 899.22\nTotal assembled bases: 12411973\n```"
  },
  {
    "objectID": "posts/2020/2020-01-08-DNA-Isolation-and-Quantification---C.bairdi-gDNA-from-EtOH-Preserved-Tissue/index.html",
    "href": "posts/2020/2020-01-08-DNA-Isolation-and-Quantification---C.bairdi-gDNA-from-EtOH-Preserved-Tissue/index.html",
    "title": "DNA Isolation and Quantification - C.bairdi gDNA from EtOH Preserved Tissue",
    "section": "",
    "text": "I isolated gDNA from ethanol-preserved C.bairdi muscle tissue from sample 20102558-2729 (SPNO-ReferenceNO). This sample was chosen as it had 0 in the SMEAR_result and BCS_PCR_results columns, indicating it should be free of Hematodinium. See the sample spreadsheet linked below for more info.\nC.bairdi ethanol-preserved sample sheet from Pam Jensen (GoogleSheets):\n\nSample info 4 Steven etal 112719\n\nI performed four separate isolations using 50mg of tissue. Samples were “ground” * in liquid nitrogen (LN2) with ceramic mortar/pestle and then processed using the E.Z.N.A. Mollusc DNA Kit according to the manufacturer’s protocol, with the following notes/changes:\n\nUsed ThermoFisher Proteinase K (18mg/mL) instead of that supplied by kit. Kit Proteinase K was moldy (!); the kit is nearly four years old…\nLysed tissue for 1hr.\nEluted with 200uL for each sample and pooled for final total volume of ~800uL.\n\nSample was quantified on the Robert Lab Qubit 3.0 using the DNA Broad Range assay, using 1uL of sample.\n* The tissue did not powder as one would expect when grinding in liquid nitrogen. Instead, despite all utensils being pre-chilled with LN2 and tissue being actively ground under LN2, the tissue became a frozen paste that adhered to the pestle. I’ve never experienced this before, but I also have not attempted to grind ethanol-preserved tissue in LN2 before.\n\n\nRESULTS\nQubit data (Google Sheet):\n\n20200108_qubit_crab_gDNA\n\nYield is very good: ~51ng/uL * 800uL = 40ug\nWill run sample on gel and NanoDrop to evalute gDNA integrity/quality.\nSample was stored at -80oC in:\nRack 6, 4, 1 in C.bairdi gDNA Box #1"
  },
  {
    "objectID": "posts/2020/2020-09-21-SRA-Submissions---NanoPore-C.bairdi-20102558-2729-and-6129_403_26/index.html",
    "href": "posts/2020/2020-09-21-SRA-Submissions---NanoPore-C.bairdi-20102558-2729-and-6129_403_26/index.html",
    "title": "SRA Submissions - NanoPore C.bairdi 20102558-2729 and 6129_403_26",
    "section": "",
    "text": "Submitted our C.bairdi NanoPore sequencing data from 20200109 (Sample 20102558-2729 - uninfected EtOH-preserved muscle) and from 20200311 (Sample 6129_403_26 - RNAlater-preserved Hematodinium-infected hemolymph) to the NCBI Sequencing Read Archive(SRA).\nI submitted the FastQ files instead of the raw Fast5 files (20102558-2729-Run-01 conversion on 20200904, 20102558-2729-Run-02 conversion on 20200904, and 6129_403_26 conversion on 20200904) because NCBI SRA requires NanoPore Fast5 files to be basecalled; I did not perform basecalling during the original sequencing runs - only during FastQ conversion.\nAll samples were submitted to NCBI SRA BioProject PRJNA625480. NCBI indicates this is what should be referenced in publications. However, here are the SRA “Run” accessions:\n\n\n\nSample\nRun\n\n\n\n\n20102558-2729\nSRR12683090\n\n\n6129_403_26\nSRR12689542)\n\n\n\nWill add info to Nightingales (Google Sheet)."
  },
  {
    "objectID": "posts/2020/2020-11-19-RNA-Isolation-and-Quantification---P.generosa-Hemocytes-from-Shelly/index.html",
    "href": "posts/2020/2020-11-19-RNA-Isolation-and-Quantification---P.generosa-Hemocytes-from-Shelly/index.html",
    "title": "RNA Isolation and Quantification - P.generosa Hemocytes from Shelly",
    "section": "",
    "text": "Shelly asked me to isolate RNA from some P.generosa hemocytes (GitHub Issue) that she had.\nRNA was isolated using the Quick DNA-RNA Microprep Plus Kit (ZymoResearch), according to the “Cells” protocol with the following notes/changes:\n\nAll samples were lysed with 400uL of DNA/RNA Lysis buffer\nAll samples were DNased using DNase aliquots from 20200127 (prepped by Kaitlyn Mitchell).\n\nSamples were quantified using 1uL of sample with the Qubit RNA HS Assay (Invitrogen) on the Roberts Lab Qubit 3.0.\nTwo samples (022H and 044H) were too concentrated, so a 1:10 dilution was prepared and the two samples were re-quantified.\nSee the RESULTS section below for Qubit data and summary table of sample concentrations/yields.\n\n\nRESULTS\nAll samples were stored in the -80oC in Shellfish RNA Box #8, slots E7 - F3.\nQubit results:\n\n20201119_qubit_pgen_hemo_RNA (Google Sheet)\n\n\n\n\nSample\nConcentration(ng/uL)\nElution_vol(uL)\nYield(ng)\n\n\n\n\n021 H\n176\n15\n2640\n\n\n022 H\n382\n15\n5730\n\n\n041 H\n102\n15\n1530\n\n\n044 H\n580\n15\n8700\n\n\n14 H\n194\n15\n2910\n\n\n15 H\n124\n15\n1860"
  },
  {
    "objectID": "posts/2020/2020-05-28-Transcriptome-Comparisons---C.bairdi-BUSCO-Scores/index.html",
    "href": "posts/2020/2020-05-28-Transcriptome-Comparisons---C.bairdi-BUSCO-Scores/index.html",
    "title": "Transcriptome Comparisons - C.bairdi BUSCO Scores",
    "section": "",
    "text": "Since we’ve generated a number of versions of the C.bairdi transcriptome, we’ve decided to compare them using various metrics. Here, I’ve compared the BUSCO scores generated for each transcriptome using BUSCO’s built-in plotting script. The script generates a stacked bar plot of all BUSCO short summary files that it is provided with, as well as the R code used to generate the plot.\nThis was run on Mox with the following script (GitHub):\n\nbusco_comparison_plotting.sh\n\n\n\nRESULTS\nOutput folder:\n\n20200528_cbai_transcriptome_busco_comparisons\n\n\n\n\nbusco comparison stacked bar plot\n\n\nHere’s a table to help see which libraries contribute to each of the transcriptomes:\n\n\n\n\n\n\n\n\n\n\n\nassembly_name\narthropoda_only(y/n)\nlibrary_01\nlibrary_02\nlibrary_03\nlibrary_04\n\n\n\n\ncbai_transcriptome_v1.0.fasta\ny\n2018\n2019\nNA\nNA\n\n\ncbai_transcriptome_v1.5.fasta\ny\n2018\n2019\n2020-GW\nNA\n\n\ncbai_transcriptome_v1.6.fasta\ny\n2018\n2019\n2020-GW\n2020-UW\n\n\ncbai_transcriptome_v1.7.fasta\ny\n2018\n2019\n2020-UW\nNA\n\n\ncbai_transcriptome_v2.0.fasta\nn\n2018\n2019\n2020-GW\n2020-UW\n\n\ncbai_transcriptome_v3.0.fasta\nn\n2018\n2019\n2020-UW\nNA\n\n\n\nUnsurprisingly, we see a high amount of duplicated BUSCOs in these results. Why is this unsurprising? This is not surprising because we looked at BUSCO results using the full Trinty transcriptome FastAs. These FastAs include all isoforms for any given gene. As such, the presence of the isoforms will lead to a large increase in duplicated (and fragmented) BUSCOs.\nAlso, we see that transcriptomes v2.0 & v3.0 show the highest amounts of duplicated BUSCOs, compared with the other three. This is likely due to the fact that these two assemblies have not been subjected to taxonomic filtering, so BUSCOs are likely being identified from multiple organisms (e.g. Hematodinium sp.) that would be present.\nI’ll extract just the genes from each of the assemblies and re-run BUSCO and subsequent comparisons to see how they look."
  },
  {
    "objectID": "posts/2020/2020-05-13-Transcriptome-Annotation---Trinotate-C.bairdi-Transcriptome-v2.0-from-20200502-on-Mox/index.html",
    "href": "posts/2020/2020-05-13-Transcriptome-Annotation---Trinotate-C.bairdi-Transcriptome-v2.0-from-20200502-on-Mox/index.html",
    "title": "Transcriptome Annotation - Trinotate C.bairdi Transcriptome v2.0 from 20200502 on Mox",
    "section": "",
    "text": "After performing de novo assembly on all of our Tanner crab RNAseq data (no taxonomic filter applied, either) on 20200502 and performing BLASTx annotation on 20200508, I continued the annotation process by running Trinotate.\nTrinotate will perform functional annotation of the transcriptome assembly, including GO terms and an annotation feature map that can be used in subsequent Trinity-based differential gene expression analysis so that functional annotations are carried downstream through that process.\nSBATCH script (GitHub):\n\n20200513_cbai_trinotate_transcriptome-v2.0.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=trinotate_cbai\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=20-00:00:00\n## Memory per node\n#SBATCH --mem=500G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200513_cbai_trinotate_transcriptome-v2.0\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nwd=\"$(pwd)\"\ntimestamp=$(date +%Y%m%d)\nspecies=\"cbai\"\n\nprefix=\"${timestamp}.${species}.trinotate\"\n\n\n## Paths to input/output files\n\n## New folders for working directory\nrnammer_out_dir=\"${wd}/RNAmmer_out\"\nsignalp_out_dir=\"${wd}/signalp_out\"\ntmhmm_out_dir=\"${wd}/tmhmm_out\"\n\n# Input files\n## BLASTx\nblastx_out=\"/gscratch/scrubbed/samwhite/outputs/20200508_cbai_diamond_blastx_transcriptome-v2.0/20200507.C_bairdi.Trinity.blastx.outfmt6\"\n\n## TransDecoder\nblastp_out=\"/gscratch/scrubbed/samwhite/outputs/20200508_cbai_transdecoder_transcriptome-v2.0/blastp_out/20200508.cbai.blastp.outfmt6\"\npfam_out=\"/gscratch/scrubbed/samwhite/outputs/20200508_cbai_transdecoder_transcriptome-v2.0/pfam_out/20200508.cbai.pfam.domtblout\"\nlORFs_pep=\"/gscratch/scrubbed/samwhite/outputs/20200508_cbai_transdecoder_transcriptome-v2.0/20200507.C_bairdi.Trinity.fasta.transdecoder_dir/longest_orfs.pep\"\n\n## Transcriptomics\ntrinity_fasta=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200507.C_bairdi.Trinity.fasta\"\ntrinity_gene_map=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200507.C_bairdi.Trinity.fasta.gene_trans_map\"\n\nrnammer_prefix=${trinity_fasta##*/}\n\n# Output files\nrnammer_out=\"${rnammer_out_dir}/${rnammer_prefix}.rnammer.gff\"\nsignalp_out=\"${signalp_out_dir}/${prefix}.signalp.out\"\ntmhmm_out=\"${tmhmm_out_dir}/${prefix}.tmhmm.out\"\ntrinotate_report=\"${wd}/${prefix}_annotation_report.txt\"\n\n# Paths to programs\nrnammer_dir=\"/gscratch/srlab/programs/RNAMMER-1.2\"\nrnammer=\"${rnammer_dir}/rnammer\"\nsignalp_dir=\"/gscratch/srlab/programs/signalp-4.1\"\nsignalp=\"${signalp_dir}/signalp\"\ntmhmm_dir=\"/gscratch/srlab/programs/tmhmm-2.0c/bin\"\ntmhmm=\"${tmhmm_dir}/tmhmm\"\ntrinotate_dir=\"/gscratch/srlab/programs/Trinotate-v3.1.1\"\ntrinotate=\"${trinotate_dir}/Trinotate\"\ntrinotate_rnammer=\"${trinotate_dir}/util/rnammer_support/RnammerTranscriptome.pl\"\ntrinotate_GO=\"${trinotate_dir}/util/extract_GO_assignments_from_Trinotate_xls.pl\"\ntrinotate_features=\"${trinotate_dir}/util/Trinotate_get_feature_name_encoding_attributes.pl\"\ntrinotate_sqlite_db=\"Trinotate.sqlite\"\n\n# Make output directories\nmkdir \"${rnammer_out_dir}\" \"${signalp_out_dir}\" \"${tmhmm_out_dir}\"\n\n# Copy sqlite database template\n\ncp ${trinotate_dir}/admin/Trinotate.sqlite .\n\n# Run signalp\n${signalp} \\\n-f short \\\n-n \"${signalp_out}\" \\\n${lORFs_pep}\n\n# Run tmHMM\n${tmhmm} \\\n--short \\\n< ${lORFs_pep} \\\n> \"${tmhmm_out}\"\n\n# Run RNAmmer\ncd \"${rnammer_out_dir}\" || exit\n${trinotate_rnammer} \\\n--transcriptome ${trinity_fasta} \\\n--path_to_rnammer ${rnammer}\ncd \"${wd}\" || exit\n\n# Run Trinotate\n## Load transcripts and coding regions into database\n${trinotate} \\\n${trinotate_sqlite_db} \\\ninit \\\n--gene_trans_map \"${trinity_gene_map}\" \\\n--transcript_fasta \"${trinity_fasta}\" \\\n--transdecoder_pep \"${lORFs_pep}\"\n\n## Load BLAST homologies\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_swissprot_blastp \\\n\"${blastp_out}\"\n\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_swissprot_blastx \\\n\"${blastx_out}\"\n\n## Load Pfam\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_pfam \\\n\"${pfam_out}\"\n\n## Load transmembrane domains\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_tmhmm \\\n\"${tmhmm_out}\"\n\n## Load signal peptides\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_signalp \\\n\"${signalp_out}\"\n\n## Load RNAmmer\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_rnammer \\\n\"${rnammer_out}\"\n\n## Creat annotation report\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nreport \\\n> \"${trinotate_report}\"\n\n# Extract GO terms from annotation report\n\"${trinotate_GO}\" \\\n--Trinotate_xls \"${trinotate_report}\" \\\n-G \\\n--include_ancestral_terms \\\n> \"${prefix}\".go_annotations.txt\n\n# Make transcript features annotation map\n\"${trinotate_features}\" \\\n\"${trinotate_report}\" \\\n> \"${prefix}\".annotation_feature_map.txt\n\n\nRESULTS\nTook ~ 13.5hrs:\n\n\n\nTrinotate runtime\n\n\nOutput folder:\n\n20200513_cbai_trinotate_transcriptome-v2.0/\n\nAnnotation feature map. This can be used to update Trinity-based gene expression matrices like so:\n\n${TRINITY_HOME}/Analysis/DifferentialExpression/rename_matrix_feature_identifiers.pl Trinity_trans.counts.matrix annot_feature_map.txt > Trinity_trans.counts.wAnnot.matrix\n20200513.cbai.trinotate.annotation_feature_map.txt\n\nAnnotation report (CSV):\n\n20200513.cbai.trinotate_annotation_report.txt\n\nGene ontology (GO) annotations (TXT):\n\n20200513.cbai.trinotate.go_annotations.txt\n\nSQlite database:\n\nTrinotate.sqlite"
  },
  {
    "objectID": "posts/2020/2020-11-05-Hard-Drive-Upgrade---Gannet-Synology-Server/index.html",
    "href": "posts/2020/2020-11-05-Hard-Drive-Upgrade---Gannet-Synology-Server/index.html",
    "title": "Hard Drive Upgrade - Gannet Synology Server",
    "section": "",
    "text": "Completed upgrading the 12 x 8TB HDDs in our server, Gannet (Synology RS3618XS), to 12 x 16TB HDDs. The process was simple, but the repair process took ~20hrs for each new drive. So, the entire process required 12 separate days of pulling out one old HDD, replacing with a new HDD, and initiating the repair process in the Synology web interface.\nBut, it’s done and we now have a total of 145 TB (!!!), with ~72TB remaining to use up!\n\n\n\nScreencap of Gannet storage space after upgrading all 12 HDDs."
  },
  {
    "objectID": "posts/2020/2020-03-30-Transcriptome-Assembly---C.bairdi-with-MEGAN6-Taxonomy-specific-Reads-with-Trinity-on-Mox/index.html",
    "href": "posts/2020/2020-03-30-Transcriptome-Assembly---C.bairdi-with-MEGAN6-Taxonomy-specific-Reads-with-Trinity-on-Mox/index.html",
    "title": "Transcriptome Assembly - C.bairdi with MEGAN6 Taxonomy-specific Reads with Trinity on Mox",
    "section": "",
    "text": "Ran a de novo assembly using the extracted reads classified under Arthropoda from:\n\n20200122\n20200330\n\nThe assembly was performed with Trinity on Mox. It’s important to note that this assembly was not performed using the “stranded” option in Trinity. The previous Trinity assembly from 20200122 was performed using the “stranded” setting. The reason for this difference is that the most recent RNAseq libraries from 20200318 were not stranded libraries. As such, I think it might be best to use the “lowest common denominator” approach.\nSBATCH script (GitHub):\n\n20200330_cbai_trinity_megan_RNAseq.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=trinity_cbai\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=6-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200330_cbai_trinity_megan_RNAseq\n\n# Exit script if a command fails\nset -e\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# User-defined variables\nreads_dir=/gscratch/srlab/sam/data/C_bairdi/RNAseq\ntranscriptome_dir=/gscratch/srlab/sam/data/C_bairdi/transcriptomes\nthreads=27\nassembly_stats=assembly_stats.txt\ntimestamp=$(date +%Y%m%d)\nfasta_name=\"${timestamp}.C_bairdi.megan.Trinity.fasta\"\n\n# Paths to programs\ntrinity_dir=\"/gscratch/srlab/programs/trinityrnaseq-v2.9.0\"\nsamtools=\"/gscratch/srlab/programs/samtools-1.10/samtools\"\n\n\n## Inititalize arrays\nR1_array=()\nR2_array=()\n\n# Variables for R1/R2 lists\nR1_list=\"\"\nR2_list=\"\"\n\n# Create array of fastq R1 files\nR1_array=(\"${reads_dir}\"/*_R1.fq)\n\n# Create array of fastq R2 files\nR2_array=(\"${reads_dir}\"/*_R2.fq)\n\n# Create list of fastq files used in analysis\n## Uses parameter substitution to strip leading path from filename\nfor fastq in \"${reads_dir}\"/*.fq\ndo\n  echo \"${fastq##*/}\" >> fastq.list.txt\ndone\n\n# Create comma-separated lists of FastQ reads\nR1_list=$(echo \"${R1_array[@]}\" | tr \" \" \",\")\nR2_list=$(echo \"${R2_array[@]}\" | tr \" \" \",\")\n\n\n# Run Trinity\n## Not running as \"stranded\", due to mix of library types\n${trinity_dir}/Trinity \\\n--seqType fq \\\n--max_memory 120G \\\n--CPU ${threads} \\\n--left \"${R1_list}\" \\\n--right \"${R2_list}\"\n\n# Rename generic assembly FastA\nmv trinity_out_dir/Trinity.fasta trinity_out_dir/\"${fasta_name}\"\n\n# Assembly stats\n${trinity_dir}/util/TrinityStats.pl trinity_out_dir/\"${fasta_name}\" \\\n> ${assembly_stats}\n\n# Create gene map files\n${trinity_dir}/util/support_scripts/get_Trinity_gene_to_trans_map.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n> trinity_out_dir/\"${fasta_name}\".gene_trans_map\n\n# Create sequence lengths file (used for differential gene expression)\n${trinity_dir}/util/misc/fasta_seq_length.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n> trinity_out_dir/\"${fasta_name}\".seq_lens\n\n# Create FastA index\n${samtools} faidx \\\ntrinity_out_dir/\"${fasta_name}\"\n\n# Copy files to transcriptome directory\nrsync -av \\\ntrinity_out_dir/\"${fasta_name}\"* \\\n${transcriptome_dir}\n\n\nRESULTS\nTook ~4hrs to run:\n\n\n\nTrinity Mox runtime\n\n\nOutput folder:\n\n20200330_cbai_trinity_megan_RNAseq/\n\nAssembly (FastA; 36MB):\n\n20200330_cbai_trinity_megan_RNAseq/trinity_out_dir/20200408.C_bairdi.megan.Trinity.fasta\n\nFastA Index (FAI):\n\n20200330_cbai_trinity_megan_RNAseq/trinity_out_dir/20200408.C_bairdi.megan.Trinity.fasta.fai\n\nTrinity Gene Trans Map (txt):\n\n20200330_cbai_trinity_megan_RNAseq/trinity_out_dir/Trinity.fasta.gene_trans_map\n\nAssembly Stats (txt):\n\n20200330_cbai_trinity_megan_RNAseq/assembly_stats.txt\n\n################################\n## Counts of transcripts, etc.\n################################\nTotal trinity 'genes':  24727\nTotal trinity transcripts:  40435\nPercent GC: 53.17\n\n########################################\nStats based on ALL transcript contigs:\n########################################\n\n    Contig N10: 3497\n    Contig N20: 2502\n    Contig N30: 1977\n    Contig N40: 1611\n    Contig N50: 1322\n\n    Median contig length: 488\n    Average contig: 824.28\n    Total assembled bases: 33329770\n\n\n#####################################################\n## Stats based on ONLY LONGEST ISOFORM per 'GENE':\n#####################################################\n\n    Contig N10: 3196\n    Contig N20: 2364\n    Contig N30: 1885\n    Contig N40: 1534\n    Contig N50: 1239\n\n    Median contig length: 403\n    Average contig: 741.81\n    Total assembled bases: 18342751\n\nWhen compared to the previous assembly, this certainly has more genes (24,727 vs 12,803), more transcripts (40,435 vs 19,670), and more assembled bases. However, the median length, average length and N50 values are all lower."
  },
  {
    "objectID": "posts/2020/2020-07-09-SRA-Submission---Geoduck-Epigenetic-Ocean-Acidification-RNAseq/index.html",
    "href": "posts/2020/2020-07-09-SRA-Submission---Geoduck-Epigenetic-Ocean-Acidification-RNAseq/index.html",
    "title": "SRA Submission - Geoduck Epigenetic Ocean Acidification RNAseq",
    "section": "",
    "text": "Can’t remember where it was discussed (probably lab meeting), but I created a GitHub Issue to add all of geoduck RNAseq data to NCBI Short Read Archive (SRA). Anyway, got all the remaining RNAseq data uploaded to the NCBI SRA and organized into the correct BioSamples and BioProjects.\nThe table below has links to each corresponding NCBI BioSample and BioProject. NCBI indicates that references should point to a particular BioProject; not individual Short Read References (SRR).\nI’ve added the corresponding links to the NCBI BioProjects to our sequencing database, Nightingales (Google Sheet).\nBelow is a table sorted by BioProject that also includes links to each BioSample for each “SeqID” (the SeqID is a unique identifier, usually the FastQ filename prefix) used in Nightingales (Google Sheet).\n\n\n\n\nSeqID\nBioSample\nTissue\nBioProject\n\n\n\n\nGeoduck-larvae-day5-RNA-EPI-99-1_S8_L001_001\n11259647\nlarvae\nPRJNA529226\n\n\nGeoduck-larvae-day5-RNA-EPI-99-2_S16_L002_001\n11259647\nlarvae\nPRJNA529226\n\n\nGeoduck-larvae-day5-RNA-EPI-99-3_S24_L003_001\n11259647\nlarvae\nPRJNA529226\n\n\nGeoduck-larvae-day5-RNA-EPI-99-4_S32_L004_001\n11259647\nlarvae\nPRJNA529226\n\n\nGeoduck-larvae-day5-RNA-EPI-99-5_S40_L005_001\n11259647\nlarvae\nPRJNA529226\n\n\nGeoduck-larvae-day5-RNA-EPI-99-6_S48_L006_001\n11259647\nlarvae\nPRJNA529226\n\n\nGeoduck-larvae-day5-RNA-EPI-99-7_S56_L007_001\n11259647\nlarvae\nPRJNA529226\n\n\nGeoduck-larvae-day5-RNA-EPI-99-8_S64_L008_001\n11259647\nlarvae\nPRJNA529226\n\n\nGeoduck-juvenile-ambient-exposure-RNA-EPI-123-1_S6_L001_001\n15517238\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-ambient-exposure-RNA-EPI-123-2_S14_L002_001\n15517238\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-ambient-exposure-RNA-EPI-123-3_S22_L003_001\n15517238\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-ambient-exposure-RNA-EPI-123-4_S30_L004_001\n15517238\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-ambient-exposure-RNA-EPI-123-5_S38_L005_001\n15517238\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-ambient-exposure-RNA-EPI-123-6_S46_L006_001\n15517238\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-ambient-exposure-RNA-EPI-123-7_S54_L007_001\n15517238\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-ambient-exposure-RNA-EPI-123-8_S62_L008_001\n15517238\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-ambient-exposure-RNA-EPI-124-1_S7_L001_001\n15517239\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-ambient-exposure-RNA-EPI-124-2_S15_L002_001\n15517239\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-ambient-exposure-RNA-EPI-124-3_S23_L003_001\n15517239\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-ambient-exposure-RNA-EPI-124-4_S31_L004_001\n15517239\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-ambient-exposure-RNA-EPI-124-5_S39_L005_001\n15517239\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-ambient-exposure-RNA-EPI-124-6_S47_L006_001\n15517239\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-ambient-exposure-RNA-EPI-124-7_S55_L007_001\n15517239\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-ambient-exposure-RNA-EPI-124-8_S63_L008_001\n15517239\njuvenile\nPRJNA566166\n\n\nNR005_S4_L001_001\n15517237\njuvenile\nPRJNA566166\n\n\nNR005_S4_L002_001\n15517237\njuvenile\nPRJNA566166\n\n\nNR019_S7_L001_001\n15517239\njuvenile\nPRJNA566166\n\n\nNR019_S7_L002_001\n15517239\njuvenile\nPRJNA566166\n\n\nTrueseq-stranded-mRNA-libraries-GeoRNA5-E1-NR005_S3_L001\n15517237\njuvenile\nPRJNA566166\n\n\nTrueseq-stranded-mRNA-libraries-GeoRNA5-E1-NR005_S3_L002\n15517237\njuvenile\nPRJNA566166\n\n\nTrueseq-stranded-mRNA-libraries-GeoRNA7-G1-NR019_S4_L001\n15517239\njuvenile\nPRJNA566166\n\n\nTrueseq-stranded-mRNA-libraries-GeoRNA7-G1-NR019_S4_L002\n15517239\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-OA-exposure-RNA-EPI-115-1_S4_L001_001\n15517236\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-OA-exposure-RNA-EPI-115-2_S12_L002_001\n15517236\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-OA-exposure-RNA-EPI-115-3_S20_L003_001\n15517236\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-OA-exposure-RNA-EPI-115-4_S28_L004_001\n15517236\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-OA-exposure-RNA-EPI-115-5_S36_L005_001\n15517236\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-OA-exposure-RNA-EPI-115-6_S44_L006_001\n15517236\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-OA-exposure-RNA-EPI-115-7_S52_L007_001\n15517236\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-OA-exposure-RNA-EPI-115-8_S60_L008_001\n15517236\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-OA-exposure-RNA-EPI-116-1_S5_L001_001\n15517237\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-OA-exposure-RNA-EPI-116-2_S13_L002_001\n15517237\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-OA-exposure-RNA-EPI-116-3_S21_L003_001\n15517237\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-OA-exposure-RNA-EPI-116-4_S29_L004_001\n15517237\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-OA-exposure-RNA-EPI-116-5_S37_L005_001\n15517237\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-OA-exposure-RNA-EPI-116-6_S45_L006_001\n15517237\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-OA-exposure-RNA-EPI-116-7_S53_L007_001\n15517237\njuvenile\nPRJNA566166\n\n\nGeoduck-juvenile-OA-exposure-RNA-EPI-116-8_S61_L008_001\n15517237\njuvenile\nPRJNA566166\n\n\nGeoduck-ctenidia-RNA-1_S3_L001_001\n15524251\nctenidia\nPRJNA646071\n\n\nGeoduck-ctenidia-RNA-2_S11_L002_001\n15524251\nctenidia\nPRJNA646071\n\n\nGeoduck-ctenidia-RNA-3_S19_L003_001\n15524251\nctenidia\nPRJNA646071\n\n\nGeoduck-ctenidia-RNA-4_S27_L004_001\n15524251\nctenidia\nPRJNA646071\n\n\nGeoduck-ctenidia-RNA-5_S35_L005_001\n15524251\nctenidia\nPRJNA646071\n\n\nGeoduck-ctenidia-RNA-6_S43_L006_001\n15524251\nctenidia\nPRJNA646071\n\n\nGeoduck-ctenidia-RNA-7_S51_L007_001\n15524251\nctenidia\nPRJNA646071\n\n\nGeoduck-ctenidia-RNA-8_S59_L008_001\n15524251\nctenidia\nPRJNA646071\n\n\nGeoduck-gonad-RNA-1_S1_L001_001\n15524260\ngonad\nPRJNA646071\n\n\nGeoduck-gonad-RNA-2_S9_L002_001\n15524260\ngonad\nPRJNA646071\n\n\nGeoduck-gonad-RNA-3_S17_L003_001\n15524260\ngonad\nPRJNA646071\n\n\nGeoduck-gonad-RNA-4_S25_L004_001\n15524260\ngonad\nPRJNA646071\n\n\nGeoduck-gonad-RNA-5_S33_L005_001\n15524260\ngonad\nPRJNA646071\n\n\nGeoduck-gonad-RNA-6_S41_L006_001\n15524260\ngonad\nPRJNA646071\n\n\nGeoduck-gonad-RNA-7_S49_L007_001\n15524260\ngonad\nPRJNA646071\n\n\nGeoduck-gonad-RNA-8_S57_L008_001\n15524260\ngonad\nPRJNA646071\n\n\nGeoduck-heart-RNA-1_S2_L001_001\n15524261\nheart\nPRJNA646071\n\n\nGeoduck-heart-RNA-2_S10_L002_001\n15524261\nheart\nPRJNA646071\n\n\nGeoduck-heart-RNA-3_S18_L003_001\n15524261\nheart\nPRJNA646071\n\n\nGeoduck-heart-RNA-4_S26_L004_001\n15524261\nheart\nPRJNA646071\n\n\nGeoduck-heart-RNA-5_S34_L005_001\n15524261\nheart\nPRJNA646071\n\n\nGeoduck-heart-RNA-6_S42_L006_001\n15524261\nheart\nPRJNA646071\n\n\nGeoduck-heart-RNA-7_S50_L007_001\n15524261\nheart\nPRJNA646071\n\n\nGeoduck-heart-RNA-8_S58_L008_001\n15524261\nheart\nPRJNA646071\n\n\nNR006_S3_L001_001\n15524260\ngonad\nPRJNA646071\n\n\nNR006_S3_L002_001\n15524260\ngonad\nPRJNA646071\n\n\nNR012_S1_L001_001\n15524251\nctenidia\nPRJNA646071\n\n\nNR012_S1_L002_001\n15524251\nctenidia\nPRJNA646071\n\n\nTrueseq-stranded-mRNA-libraries-GeoRNA1-A1-NR006_S1_L001\n15524260\ngonad\nPRJNA646071\n\n\nTrueseq-stranded-mRNA-libraries-GeoRNA1-A1-NR006_S1_L002\n15524260\ngonad\nPRJNA646071\n\n\nTrueseq-stranded-mRNA-libraries-GeoRNA3-C1-NR012_S2_L001\n15524251\nctenidia\nPRJNA646071\n\n\nTrueseq-stranded-mRNA-libraries-GeoRNA3-C1-NR012_S2_L002\n15524251\nctenidia\nPRJNA646071"
  },
  {
    "objectID": "posts/2020/2020-03-11-DNA-Isolation-and-Quantification---C.bairdi-Hemocyte-Pellets-in-RNAlater/index.html",
    "href": "posts/2020/2020-03-11-DNA-Isolation-and-Quantification---C.bairdi-Hemocyte-Pellets-in-RNAlater/index.html",
    "title": "DNA Isolation and Quantification - C.bairdi Hemocyte Pellets in RNAlater",
    "section": "",
    "text": "Isolated DNA from 22 samples (see Qubit spreadsheet in “Results” below for sample IDs) using the Quick DNA/RNA Microprep Kit (ZymoResearch; PDF) according to the manufacturer’s protocol for liquids/cells in RNAlater.\nThese samples were from an RNA isolation on the following date:\n\n20200306\n\nBrief rundown of method:\n\nUsed 35uL from each RNAlater/hemocyte slurry.\nMixed with equal volume of H2O (35uL).\nRetained DNA on the Zymo-Spin IC-XM columns at 4oC for isolation after RNA isolation.\nDNA was eluted in 15uL H2O\n\nDNA was quantified on the Roberts Lab Qubit 3.0 using the 1x DNA High Sensitivity Assay (Invitrogen), using 1uL of each sample.\n\n\nRESULTS\nQubit results (Google Sheet):\n\n20200311_qubit_crab_DNA\n\nOverall, the yields aren’t particularly great and are significantly lower than when I previously “co-isolated” RNA/DNA using this kit on 20200117. The primary difference between today and 20200117 is that today’s samples had been stored on the column for multiple days, whereas the samples from 20200117 were isolated immediately after the RNA isolation procedure was completed. Interesting…\nSamples were stored at -80oC in:\nRack 15, 4, 5 in C.bairdi gDNA Box #2"
  },
  {
    "objectID": "posts/2020/2020-05-21-SRA-Library-Assessment---Determine-RNAseq-Library-Strandedness-from-P.trituberculatus-SRA-BioProject-PRJNA597187/index.html",
    "href": "posts/2020/2020-05-21-SRA-Library-Assessment---Determine-RNAseq-Library-Strandedness-from-P.trituberculatus-SRA-BioProject-PRJNA597187/index.html",
    "title": "SRA Library Assessment - Determine RNAseq Library Strandedness from P.trituberculatus SRA BioProject PRJNA597187",
    "section": "",
    "text": "We’ve produced a number of C.bairid transcriptomes utilizing different assembly approaches (e.g. Arthropoda reads only, stranded libraries only, mixed strandedness libraries, etc) and we want to determine which of them is “best”. Trinity has a nice list of tools to assess the quality of transcriptome assemblies, but most of the tools rely on comparison to a transcriptome of a related species.\nI was unable to readily find a crab transcriptome assembly anywhere, so decided to make our own assembly using RNAseq data from NCBI SRA BioProject PRJNA597187. This is from the Japanese blue crab, Portunus trituberculatus and has a fair amount of sequencing data, which should result in a pretty comprehensive transcriptome.\nBefore assembling, however, I want to determine if the libraries in this particular project were stranded or not, as Trinity has an option to indicate stranded libraries for use in the assembly. Trinity also offers a script to determine library strandedness which produces a set of violin plots to help discern the type of library one is working with.\nBasically, you have to create a transcriptome assembly and then map the reads back to the assembly. Then, the Trinity script examine_strand_specificity.pl will generate the violin plots. I ran the Trinity script on just a single set of paired-end reads FastQs to make this happen relatively quickly. This was run on Mox.\nSBATCH script (GitHub):\n\n20200521_ptri_trinity_strandedness_check.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=trinity_ptri_strand_check\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=9-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200521_ptri_trinity_strandedness_check\n\n### De novo transcriptome assembly of Portunus trituberculatus (Japanese blue crab)\n### RNAseq data from  NCBI BioProject PRJNA597187.\n### Use single set of FastQ reads to determine library standedness.\n\n# Exit script if a command fails\nset -e\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# User-defined variables\nreads_dir=/gscratch/srlab/sam/data/P_trituberculatus/RNAseq\nthreads=28\nassembly_stats=assembly_stats.txt\n\n# Paths to programs\ntrinity_dir=\"/gscratch/srlab/programs/trinityrnaseq-v2.9.0\"\nsamtools=\"/gscratch/srlab/programs/samtools-1.10/samtools\"\ntrinity_bowtie=\"${trinity_dir}/util/misc/run_bowtie2.pl\"\ntrinity_strand=\"${trinity_dir}/util/misc/examine_strand_specificity.pl\"\n\n\n## Inititalize arrays\nR1_array=()\nR2_array=()\n\n# Variables for R1/R2 lists\nR1_list=\"\"\nR2_list=\"\"\n\n# Create array of fastq R1 files\nR1_array=(\"${reads_dir}\"/SRR10757128.sra_1.fastq)\n\n# Create array of fastq R2 files\nR2_array=(\"${reads_dir}\"/SRR10757128.sra_2.fastq)\n\n# Create list of fastq files used in analysis\n## Uses parameter substitution to strip leading path from filename\nfor fastq in \"${!R1_array[@]}\"\ndo\n  {\n    echo \"${R1_array[${fastq}]##*/}\"\n    echo \"${R2_array[${fastq}]##*/}\"\n  } >> fastq.list.txt\ndone\n\n# Create comma-separated lists of FastQ reads\nR1_list=$(echo \"${R1_array[@]}\" | tr \" \" \",\")\nR2_list=$(echo \"${R2_array[@]}\" | tr \" \" \",\")\n\n\n# Run Trinity\n## Not running as \"stranded\", due to mix of library types\n${trinity_dir}/Trinity \\\n--seqType fq \\\n--max_memory 100G \\\n--CPU ${threads} \\\n--left \"${R1_list}\" \\\n--right \"${R2_list}\"\n\n# Assembly stats\n${trinity_dir}/util/TrinityStats.pl trinity_out_dir/Trinity.fasta \\\n> ${assembly_stats}\n\n# Create FastA index\n${samtools} faidx \\\ntrinity_out_dir/Trinity.fasta\n\n# Align reads to assembly\n${trinity_bowtie} \\\n--target trinity_out_dir/Trinity.fasta \\\n--left \"${R1_list}\" \\\n--right \"${R2_list}\" \\\n| ${samtools} view \\\n--threads ${threads} \\\n-Sb - \\\n| ${samtools} sort \\\n--threads ${threads} \\\n- -o bowtie2.coordSorted.bam\n\n# Examine strand specificity\n${trinity_strand} bowtie2.coordSorted.bam\n\n\nRESULTS\nThis took a surprisingly long time to run, considering I was only using a single set of paired-end reads; ~15hrs (note: failure shown below was due to a missin R package (vioplot) needed for plotting)\n\n\n\nstrandedness runtime\n\n\nOutput folder:\n\n20200521_ptri_trinity_strandedness_check\n\nViolin plots (PDF):\n\nss_analysis.dat.vioplot.pdf\n\n\n\n\nptri strandedness violin plots\n\n\n\nTrinity Example:\n\n\n\nTrinity example of stranded library aligned to non-stranded assembly\n\n\n\nThe shape of my violin plots (“barbell”) match the Trinity example of stranded libraries aligned to an assembly created with the non-stranded setting, indicating that the libraries for these RNAseq reads are stranded. I will create a transcriptome assembly from all of the reads using the stranded setting in Trinity."
  },
  {
    "objectID": "posts/2020/2020-08-26-Transcriptome-Annotation---Trinotate-Hematodinium-v2.1-on-Mox/index.html",
    "href": "posts/2020/2020-08-26-Transcriptome-Annotation---Trinotate-Hematodinium-v2.1-on-Mox/index.html",
    "title": "Transcriptome Annotation - Trinotate Hematodinium v2.1 on Mox",
    "section": "",
    "text": "To continue annotation of our Hematodinium v1.6 transcriptome assembly, I wanted to run Trinotate.\nInfo for each transcriptome version (library composition, assembly dates, BUSCO, etc) can be found in this table:\n\nhemat_transcriptome_comp\n\nThis was run on Mox.\nSBATCH script (GitHub):\n\n20200826_hemat_trinotate_transcriptome-v1.6.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=hemat_trinotate_transcriptome-v2.1\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=7-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200826_hemat_trinotate_transcriptome-v2.1\n\n\n# Script to run Trinotate on Hematodinium transcriptome:\n# v2.1\n\n###################################################################################\n# These variables need to be set by user\n\n# Input files\n## BLASTx\nblastx_out=\"/gscratch/scrubbed/samwhite/outputs/20200814_hemat_diamond_blastx_v1.6_v1.7_v2.1_v3.1/hemat_transcriptome_v2.1.fasta.blastx.outfmt6\"\n\n## TransDecoder\ntransdecoder_dir=\"/gscratch/scrubbed/samwhite/outputs/20200817_hemat_transdecoder_transcriptomes_v1.6_v1.7_v2.1_v.3.1/20200817_hemat_transcriptome_v2.1.fasta.transdecoder\"\nblastp_out=\"${transdecoder_dir}/20200817_hemat_transcriptome_v2.1.fasta.blastp_out/20200817_hemat_transcriptome_v2.1.fasta.blastp.outfmt6\"\npfam_out=\"${transdecoder_dir}/20200817_hemat_transcriptome_v2.1.fasta.pfam_out/20200817_hemat_transcriptome_v2.1.fasta.pfam.domtblout\"\nlORFs_pep=\"${transdecoder_dir}/hemat_transcriptome_v2.1.fasta.transdecoder_dir/longest_orfs.pep\"\n\n## Transcriptomics\ntranscriptomes_dir=\"/gscratch/srlab/sam/data/Hematodinium/transcriptomes\"\ntrinity_fasta=\"${transcriptomes_dir}/hemat_transcriptome_v2.1.fasta\"\ntrinity_gene_map=\"${transcriptomes_dir}/hemat_transcriptome_v2.1.fasta.gene_trans_map\"\n\n###################################################################################\n\nwd=\"$(pwd)\"\ntimestamp=$(date +%Y%m%d)\n\n\n## Paths to input/output files\n\n## New folders for working directory\nrnammer_out_dir=\"${wd}/RNAmmer_out\"\nsignalp_out_dir=\"${wd}/signalp_out\"\ntmhmm_out_dir=\"${wd}/tmhmm_out\"\n\n\nrnammer_prefix=${trinity_fasta##*/}\nprefix=\"${timestamp}.${rnammer_prefix}.trinotate\"\n\n# Output files\nrnammer_out=\"${rnammer_out_dir}/${rnammer_prefix}.rnammer.gff\"\nsignalp_out=\"${signalp_out_dir}/${prefix}.signalp.out\"\ntmhmm_out=\"${tmhmm_out_dir}/${prefix}.tmhmm.out\"\ntrinotate_report=\"${wd}/${prefix}_annotation_report.txt\"\n\n# Paths to programs\nrnammer_dir=\"/gscratch/srlab/programs/RNAMMER-1.2\"\nrnammer=\"${rnammer_dir}/rnammer\"\nsignalp_dir=\"/gscratch/srlab/programs/signalp-4.1\"\nsignalp=\"${signalp_dir}/signalp\"\ntmhmm_dir=\"/gscratch/srlab/programs/tmhmm-2.0c/bin\"\ntmhmm=\"${tmhmm_dir}/tmhmm\"\ntrinotate_dir=\"/gscratch/srlab/programs/Trinotate-v3.1.1\"\ntrinotate=\"${trinotate_dir}/Trinotate\"\ntrinotate_rnammer=\"${trinotate_dir}/util/rnammer_support/RnammerTranscriptome.pl\"\ntrinotate_GO=\"${trinotate_dir}/util/extract_GO_assignments_from_Trinotate_xls.pl\"\ntrinotate_features=\"${trinotate_dir}/util/Trinotate_get_feature_name_encoding_attributes.pl\"\ntrinotate_sqlite_db=\"Trinotate.sqlite\"\n\n# Generate FastA checksum, for reference if needed.\nmd5sum ${trinity_fasta} > fasta.checksum.md5\n\n# Make output directories\nmkdir \"${rnammer_out_dir}\" \"${signalp_out_dir}\" \"${tmhmm_out_dir}\"\n\n# Copy sqlite database template\n\ncp ${trinotate_dir}/admin/Trinotate.sqlite .\n\n# Run signalp\n${signalp} \\\n-f short \\\n-n \"${signalp_out}\" \\\n${lORFs_pep}\n\n# Run tmHMM\n${tmhmm} \\\n--short \\\n< ${lORFs_pep} \\\n> \"${tmhmm_out}\"\n\n# Run RNAmmer\ncd \"${rnammer_out_dir}\" || exit\n${trinotate_rnammer} \\\n--transcriptome ${trinity_fasta} \\\n--path_to_rnammer ${rnammer}\ncd \"${wd}\" || exit\n\n# Run Trinotate\n## Load transcripts and coding regions into database\n${trinotate} \\\n${trinotate_sqlite_db} \\\ninit \\\n--gene_trans_map \"${trinity_gene_map}\" \\\n--transcript_fasta \"${trinity_fasta}\" \\\n--transdecoder_pep \"${lORFs_pep}\"\n\n## Load BLAST homologies\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_swissprot_blastp \\\n\"${blastp_out}\"\n\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_swissprot_blastx \\\n\"${blastx_out}\"\n\n## Load Pfam\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_pfam \\\n\"${pfam_out}\"\n\n## Load transmembrane domains\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_tmhmm \\\n\"${tmhmm_out}\"\n\n## Load signal peptides\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_signalp \\\n\"${signalp_out}\"\n\n## Load RNAmmer\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_rnammer \\\n\"${rnammer_out}\"\n\n## Creat annotation report\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nreport \\\n> \"${trinotate_report}\"\n\n# Extract GO terms from annotation report\n\"${trinotate_GO}\" \\\n--Trinotate_xls \"${trinotate_report}\" \\\n-G \\\n--include_ancestral_terms \\\n> \"${prefix}\".go_annotations.txt\n\n# Make transcript features annotation map\n\"${trinotate_features}\" \\\n\"${trinotate_report}\" \\\n> \"${prefix}\".annotation_feature_map.txt\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nRESULTS\nTook ~37mins to run:\n\n\n\nRuntime for Hemat v2.1 Trinotate job\n\n\nOutput folder:\n\n20200826_hemat_trinotate_transcriptome-v2.1/\n\nAnnotation feature map (2.6MB; TXT):\n\n20200826.hemat_transcriptome_v2.1.fasta.trinotate.annotation_feature_map.txt\n\nThis can be used to update Trinity-based gene expression matrices like so:\n\n${TRINITY_HOME}/Analysis/DifferentialExpression/rename_matrix_feature_identifiers.pl Trinity_trans.counts.matrix annot_feature_map.txt > Trinity_trans.counts.wAnnot.matrix\n\n\n\nGene ontology (GO) annotations (2.8MB; TXT):\n\n20200826.hemat_transcriptome_v2.1.fasta.trinotate.go_annotations.txt\n\nAnnotation report (35MB; CSV):\n\n20200826.hemat_transcriptome_v2.1.fasta.trinotate_annotation_report.txt\n\nSQlite database (546MB; SQLITE):\n\nTrinotate.sqlite"
  },
  {
    "objectID": "posts/2020/2020-04-15-SRA-Submission---C.bairdi-RNAseq-Data/index.html",
    "href": "posts/2020/2020-04-15-SRA-Submission---C.bairdi-RNAseq-Data/index.html",
    "title": "SRA Submission - C.bairdi RNAseq Data",
    "section": "",
    "text": "Since we received the last of our RNAseq data for this project on 20200413, I submitted all of it to the NCBI Sequencing Read Archive (SRA). Data was released today and all accession numbers can be found in the table below:\n\n\n\n\n\n\n\n\n\n\nAccession\nTitle\nBioProject\nSRA\nBioSample.name\n\n\n\n\nSAMN14600889\nD12_infected_cold\nPRJNA625480\nSRR11548643\n254\n\n\nSAMN14600897\nD12_uninfected_cold\nPRJNA625480\nSRR11548644\n222\n\n\nSAMN14600896\nD12_uninfected_cold\nPRJNA625480\nSRR11548645\n221\n\n\nSAMN14600915\nD9_infected\nPRJNA625480\nSRR11548646\n178\n\n\nSAMN14600914\nD9_infected\nPRJNA625480\nSRR11548647\n173\n\n\nSAMN14600913\nD9_infected\nPRJNA625480\nSRR11548648\n151\n\n\nSAMN14600917\nD9_uninfected\nPRJNA625480\nSRR11548649\n73\n\n\nSAMN14600909\nD9_infected\nPRJNA625480\nSRR11548650\n72\n\n\nSAMN14600903\nD26_infected_ambient\nPRJNA625480\nSRR11548651\n485\n\n\nSAMN14600902\nD26_infected_ambient\nPRJNA625480\nSRR11548652\n481\n\n\nSAMN14600901\nD26_infected_ambient\nPRJNA625480\nSRR11548653\n463\n\n\nSAMN14600912\nD9_infected\nPRJNA625480\nSRR11548654\n132\n\n\nSAMN14600904\nD26_infected_cold\nPRJNA625480\nSRR11548655\n445\n\n\nSAMN14600908\nD26_uninfected_cold\nPRJNA625480\nSRR11548656\n427\n\n\nSAMN14600907\nD26_uninfected_cold\nPRJNA625480\nSRR11548657\n425\n\n\nSAMN14600894\nD12_infected_warm\nPRJNA625480\nSRR11548658\n380825\n\n\nSAMN14600899\nD12_uninfected_warm\nPRJNA625480\nSRR11548659\n380824\n\n\nSAMN14600890\nD12_infected_cold\nPRJNA625480\nSRR11548660\n380823\n\n\nSAMN14600898\nD12_uninfected_cold\nPRJNA625480\nSRR11548661\n380822\n\n\nSAMN14600916\nD9_infected\nPRJNA625480\nSRR11548662\n380821\n\n\nSAMN14600919\nD9_uninfected\nPRJNA625480\nSRR11548663\n380820\n\n\nSAMN14600888\nD12_infected_ambient\nPRJNA625480\nSRR11548664\n359\n\n\nSAMN14600911\nD9_infected\nPRJNA625480\nSRR11548665\n127\n\n\nSAMN14600887\nD12_infected_ambient\nPRJNA625480\nSRR11548666\n349\n\n\nSAMN14600886\nD12_infected_ambient\nPRJNA625480\nSRR11548667\n334\n\n\nSAMN14600906\nD26_uninfected\nPRJNA625480\nSRR11548668\n329777\n\n\nSAMN14600900\nD26_infected\nPRJNA625480\nSRR11548669\n329776\n\n\nSAMN14600895\nD12_uninfected\nPRJNA625480\nSRR11548670\n329775\n\n\nSAMN14600885\nD12_infected\nPRJNA625480\nSRR11548671\n329774\n\n\nSAMN14600905\nD26_pool\nPRJNA625480\nSRR11548672\n304428\n\n\nSAMN14600893\nD12_infected_warm\nPRJNA625480\nSRR11548673\n294\n\n\nSAMN14600892\nD12_infected_warm\nPRJNA625480\nSRR11548674\n280\n\n\nSAMN14600891\nD12_infected_warm\nPRJNA625480\nSRR11548675\n272\n\n\nSAMN14600910\nD9_infected\nPRJNA625480\nSRR11548676\n118\n\n\nSAMN14600918\nD9_uninfected\nPRJNA625480\nSRR11548677\n113"
  },
  {
    "objectID": "posts/2020/2020-02-07-Gene-Expression---Hematodinium-MEGAN6-with-Trinity-and-EdgeR/index.html",
    "href": "posts/2020/2020-02-07-Gene-Expression---Hematodinium-MEGAN6-with-Trinity-and-EdgeR/index.html",
    "title": "Gene Expression - Hematodinium MEGAN6 with Trinity and EdgeR",
    "section": "",
    "text": "After completing annotation of the Hematodinium MEGAN6 taxonomic-specific Trinity assembly using Trinotate on 20200126, I performed differential gene expression analysis and gene ontology (GO) term enrichment analysis using Trinity’s scripts to run EdgeR and GOseq, respectively. The comparison listed below is the only comparison possible, as there were no reads present in the uninfected Hematodinium extractions.\nIt should be noted that this comparison does not have any replicate samples. I made a weak attempt to coerce some results from these by setting a dispersion value in the edgeR command. However, I’m not expecting much, nor am I certain I would really trust the results from those particular comparisons.\nSBATCH script (GitHub):\n\nD12-vs-D26\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=DEG_hemat_D12-vs-D26\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=01-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200207_hemat_DEG/D12-vs-D26\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nwd=\"$(pwd)\"\ntimestamp=$(date +%Y%m%d)\nspecies=\"hemat\"\nthreads=28\ncomparison=\"${wd##*/}\"\n\n\nfasta_prefix=\"20200122.hemat.megan.Trinity\"\n\n\n## Set input file locations\ntrimmed_reads_dir=\"/gscratch/srlab/sam/data/Hematodinium/RNAseq\"\nsalmon_out_dir=\"${wd}\"\ntranscriptome_dir=\"/gscratch/srlab/sam/data/Hematodinium/transcriptomes\"\ntranscriptome=\"${transcriptome_dir}/${fasta_prefix}.fasta\"\nfasta_seq_lengths=\"${transcriptome_dir}/${fasta_prefix}.fasta.seq_lens\"\nsamples=\"${wd}/${comparison}.samples.txt\"\n\ntrinotate_feature_map=\"/gscratch/scrubbed/samwhite/outputs/20200126_hemat_trinotate_megan/20200126.hemat.trinotate.annotation_feature_map.txt\"\ngene_map=\"${transcriptome_dir}/${fasta_prefix}.fasta.gene_trans_map\"\nsalmon_gene_matrix=\"${salmon_out_dir}/salmon.gene.TMM.EXPR.matrix\"\nsalmon_iso_matrix=\"${salmon_out_dir}/salmon.isoform.TMM.EXPR.matrix\"\ngo_annotations=\"${transcriptome_dir}/20200126.hemat.trinotate.go_annotations.txt\"\n\n\n# Standard output/error files\ndiff_expr_stdout=\"diff_expr_stdout.txt\"\ndiff_expr_stderr=\"diff_expr_stderr.txt\"\nmatrix_stdout=\"matrix_stdout.txt\"\nmatrix_stderr=\"matrix_stderr.txt\"\nsalmon_stdout=\"salmon_stdout.txt\"\nsalmon_stderr=\"salmon_stderr.txt\"\ntpm_length_stdout=\"tpm_length_stdout.txt\"\ntpm_length_stderr=\"tpm_length_stderr.txt\"\ntrinity_DE_stdout=\"trinity_DE_stdout.txt\"\ntrinity_DE_stderr=\"trinity_DE_stderr.txt\"\n\nedgeR_dir=\"\"\n\n#programs\ntrinity_home=/gscratch/srlab/programs/trinityrnaseq-v2.9.0\ntrinity_annotate_matrix=\"${trinity_home}/Analysis/DifferentialExpression/rename_matrix_feature_identifiers.pl\"\ntrinity_abundance=${trinity_home}/util/align_and_estimate_abundance.pl\ntrinity_matrix=${trinity_home}/util/abundance_estimates_to_matrix.pl\ntrinity_DE=${trinity_home}/Analysis/DifferentialExpression/run_DE_analysis.pl\ndiff_expr=${trinity_home}/Analysis/DifferentialExpression/analyze_diff_expr.pl\ntrinity_tpm_length=${trinity_home}/util/misc/TPM_weighted_gene_length.py\n\n# Create directory/sample list for ${trinity_matrix} command\ntrin_matrix_list=$(awk '{printf \"%s%s\", $2, \"/quant.sf \" }' \"${samples}\")\n\ncd ${trimmed_reads_dir}\ntime ${trinity_abundance} \\\n--output_dir \"${salmon_out_dir}\" \\\n--transcripts ${transcriptome} \\\n--seqType fq \\\n--samples_file \"${samples}\" \\\n--SS_lib_type RF \\\n--est_method salmon \\\n--aln_method bowtie2 \\\n--gene_trans_map \"${gene_map}\" \\\n--prep_reference \\\n--thread_count \"${threads}\" \\\n1> \"${salmon_out_dir}\"/${salmon_stdout} \\\n2> \"${salmon_out_dir}\"/${salmon_stderr}\n\n# Move output folders\nmv ${trimmed_reads_dir}/D* \\\n\"${salmon_out_dir}\"\n\ncd \"${salmon_out_dir}\"\n\n# Convert abundance estimates to matrix\n${trinity_matrix} \\\n--est_method salmon \\\n--gene_trans_map ${gene_map} \\\n--out_prefix salmon \\\n--name_sample_by_basedir \\\n${trin_matrix_list}\n1> ${matrix_stdout} \\\n2> ${matrix_stderr}\n\n# Integrate functional Trinotate functional annotations\n\"${trinity_annotate_matrix}\" \\\n\"${trinotate_feature_map}\" \\\nsalmon.gene.counts.matrix \\\n> salmon.gene.counts.annotated.matrix\n\n\n# Generate weighted gene lengths\n\"${trinity_tpm_length}\" \\\n--gene_trans_map \"${gene_map}\" \\\n--trans_lengths \"${fasta_seq_lengths}\" \\\n--TPM_matrix \"${salmon_iso_matrix}\" \\\n> Trinity.gene_lengths.txt \\\n2> ${tpm_length_stderr}\n\n# Differential expression analysis\ncd ${transcriptome_dir}\n${trinity_DE} \\\n--matrix \"${salmon_out_dir}\"/salmon.gene.counts.matrix \\\n--method edgeR \\\n--samples_file \"${samples}\" \\\n1> ${trinity_DE_stdout} \\\n2> ${trinity_DE_stderr}\n\nmv edgeR* \"${salmon_out_dir}\"\n\n\n# Run differential expression on edgeR output matrix\n# Set fold difference to 2-fold (ie. -C 1 = 2^1)\n# P value <= 0.05\n# Has to run from edgeR output directory\n\n# Pulls edgeR directory name and removes leading ./ in find output\ncd \"${salmon_out_dir}\"\nedgeR_dir=$(find . -type d -name \"edgeR*\" | sed 's%./%%')\ncd \"${edgeR_dir}\"\nmv \"${transcriptome_dir}/${trinity_DE_stdout}\" .\nmv \"${transcriptome_dir}/${trinity_DE_stderr}\" .\n${diff_expr} \\\n--matrix \"${salmon_gene_matrix}\" \\\n--samples \"${samples}\" \\\n--examine_GO_enrichment \\\n--GO_annots \"${go_annotations}\" \\\n--include_GOplot \\\n--gene_lengths \"${salmon_out_dir}\"/Trinity.gene_lengths.txt \\\n-C 1 \\\n-P 0.05 \\\n1> ${diff_expr_stdout} \\\n2> ${diff_expr_stderr}\n\n\nRESULTS\nOutput folder:\n\n20200207_hemat_DEG/\n\nD12-vs-D26\nTook ~17mins to run:\n\n\n\nD12 vs D26 runtime\n\n\n\nD12-vs-D26/\n\nNo differentially expressed genes between these two groups.\nNOTE: Since no DEGs, that’s why this run shows as FAILED in the above runtime screencap. This log file captures the error message that kills the job and generates the FAILED indicator:\n\n20200207_hemat_DEG/D12-vs-D26/edgeR.28118.dir/diff_expr_stderr.txt\n\nError, no differentially expressed transcripts identified at cuttoffs: P:0.05, C:1 at /gscratch/srlab/programs/trinityrnaseq-v2.9.0/Analysis/DifferentialExpression/analyze_diff_expr.pl line 203."
  },
  {
    "objectID": "posts/2020/2020-01-28-DNA-Isolation-and-Quantification---C.bairdi-Hemocyte-Pellets-in-RNAlater/index.html",
    "href": "posts/2020/2020-01-28-DNA-Isolation-and-Quantification---C.bairdi-Hemocyte-Pellets-in-RNAlater/index.html",
    "title": "DNA Isolation and Quantification - C.bairdi Hemocyte Pellets in RNAlater",
    "section": "",
    "text": "Isolated DNA from 56 samples (see Qubit spreadsheet in “Results” below for sample IDs) using the Quick DNA/RNA Microprep Kit (ZymoResearch; PDF) according to the manufacturer’s protocol for liquids/cells in RNAlater.\nThese samples were from RNA isolations on the following dates:\n\n20200126\n20200124\n20200123\n\nBrief rundown of method:\n\nUsed 35uL from each RNAlater/hemocyte slurry.\nMixed with equal volume of H2O (35uL).\nRetained DNA on the Zymo-Spin IC-XM columns at 4oC for isolation after RNA isolation.\nDNA was eluted in 15uL H2O\n\nDNA was quantified on the Roberts Lab Qubit 3.0 using the 1x DNA High Sensitivity Assay (Invitrogen), using 1uL of each sample.\n\n\nRESULTS\nQubit results (Google Sheet):\n\n20200128_qubit_cbai_DNA\n\nOverall, the yields aren’t particularly great and are significantly lower than when I previously “co-isolated” RNA/DNA using this kit on 20200117 (~6.6ng/uL vs. ~32.6ng/uL). The primary difference between today and 20200117 is that today’s samples had been stored on the column for multiple days, whereas the samples from 20200117 were isolated immediately after the RNA isolation procedure was completed. Interesting…\nSamples were stored at -80oC in:\nRack 6, 4, 1 in C.bairdi gDNA Box #1\nand\nRack 15, 4, 5 in C.bairdi gDNA Box #2"
  },
  {
    "objectID": "posts/2020/2020-08-14-Transcriptome-Annotation---Hematodinium-Transcriptomes-v1.6-v1.7-v2.1-v3.1-with-DIAMOND-BLASTx-on-Mox/index.html",
    "href": "posts/2020/2020-08-14-Transcriptome-Annotation---Hematodinium-Transcriptomes-v1.6-v1.7-v2.1-v3.1-with-DIAMOND-BLASTx-on-Mox/index.html",
    "title": "Transcriptome Annotation - Hematodinium Transcriptomes v1.6 v1.7 v2.1 v3.1 with DIAMOND BLASTx on Mox",
    "section": "",
    "text": "Needed to annotate the Hematodinium sp. transcriptomes that I’ve assembled using DIAMOND BLASTx. This will also be used for additional downstream annotation (TransDecoder, Trinotate):\n\nhemat_transcriptome_v1.6.fasta (4.5MB; from 20210308)\nhemat_transcriptome_v1.7.fasta (1.9MB; from 20210308)\nhemat_transcriptome_v2.1.fasta (65MB; from 20200605)\nhemat_transcriptome_v3.1.fasta (65MB; from 20200605)\n\nAll of the above transcriptomes were assembled with different combinations of the crab RNAseq data we generated. Here’s a link to an overview of the various assemblies:\n\nhemat_transcriptome_comp (Google Sheet)\n\nDIAMOND BLASTx was run on Mox.\nSBATCH script (GitHub):\n\n20200814_hemat_diamond_blastx_v1.6_v1.7_v2.1_v3.1.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=hemat_diamond_blastx_v1.6_v1.7_v2.1_v3.1\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=0-08:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200814_hemat_diamond_blastx_v1.6_v1.7_v2.1_v3.1\n\n\n## Script for running BLASTx (using DIAMOND) to annotate\n## Hematodinium transcriptomes v1.6, v1.7, v2.1 and v3.1 against SwissProt database.\n## Output will be in standard BLAST output format 6.\n\n###################################################################################\n# These variables need to be set by user\n\n# Programs array\ndeclare -A programs_array\nprograms_array=(\n[diamond]=\"/gscratch/srlab/programs/diamond-0.9.29/diamond\"\n)\n\n# Establish variables for more readable code\ntranscriptomes_dir=/gscratch/srlab/sam/data/Hematodinium/transcriptomes\n\n# Array of the various comparisons to evaluate\n# Each condition in each comparison should be separated by a \"-\"\ntranscriptomes_array=(\n\"${transcriptomes_dir}\"/hemat_transcriptome_v1.6.fasta \\\n\"${transcriptomes_dir}\"/hemat_transcriptome_v1.7.fasta \\\n\"${transcriptomes_dir}\"/hemat_transcriptome_v2.1.fasta \\\n\"${transcriptomes_dir}\"/hemat_transcriptome_v3.1.fasta\n)\n\n# DIAMOND UniProt database\ndmnd=/gscratch/srlab/blastdbs/uniprot_sprot_20200123/uniprot_sprot.dmnd\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n\nfor fasta in \"${!transcriptomes_array[@]}\"\ndo\n\n  # Remove path from transcriptome using parameter substitution\n  transcriptome_name=\"${transcriptomes_array[$fasta]##*/}\"\n\n  # Generate checksums for reference\n  md5sum \"${transcriptomes_array[$fasta]}\">> fasta.checksums.md5\n\n  # Run DIAMOND with blastx\n  # Output format 6 produces a standard BLAST tab-delimited file\n  ${programs_array[diamond]} blastx \\\n  --db ${dmnd} \\\n  --query \"${transcriptomes_array[$fasta]}\" \\\n  --out \"${transcriptome_name}\".blastx.outfmt6 \\\n  --outfmt 6 \\\n  --evalue 1e-4 \\\n  --max-target-seqs 1 \\\n  --block-size 15.0 \\\n  --index-chunks 4\ndone\n\n\n###################################################################################\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : n\n} >> system_path.log\n\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n    ${programs_array[$program]} --help\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n\nRESULTS\nJust under 40 seconds (!!) to annotate the four transcriptomes:\n\n\n\nDIAMOND BLASTx cumulative runtime\n\n\nOutput folder:\n\n20200814_hemat_diamond_blastx_v1.6_v1.7_v2.1_v3.1/\n\n\nhemat_transcriptome_v1.6.fasta.blastx.outfmt6\n\n20200814_hemat_diamond_blastx_v1.6_v1.7_v2.1_v3.1/hemat_transcriptome_v1.6.fasta.blastx.outfmt6 (text; 2.0MB)\n\n\n\nhemat_transcriptome_v1.7.fasta.blastx.outfmt6\n\n20200814_hemat_diamond_blastx_v1.6_v1.7_v2.1_v3.1/hemat_transcriptome_v1.7.fasta.blastx.outfmt6 (text; 1.3MB)\n\n\n\nhemat_transcriptome_v2.1.fasta.blastx.outfmt6\n\n20200814_hemat_diamond_blastx_v1.6_v1.7_v2.1_v3.1/hemat_transcriptome_v2.1.fasta.blastx.outfmt6 (text; 1.5MB)\n\n\n\nhemat_transcriptome_v3.1.fasta.blastx.outfmt6\n\n20200814_hemat_diamond_blastx_v1.6_v1.7_v2.1_v3.1/hemat_transcriptome_v3.1.fasta.blastx.outfmt6 (text; 1.4MB)"
  },
  {
    "objectID": "posts/2020/2020-08-19-Assembly-Stats---C.bairdi-Transcriptomes-v2.1-and-v3.1-Trinity-Stats-on-Mox/index.html",
    "href": "posts/2020/2020-08-19-Assembly-Stats---C.bairdi-Transcriptomes-v2.1-and-v3.1-Trinity-Stats-on-Mox/index.html",
    "title": "Assembly Stats - C.bairdi Transcriptomes v2.1 and v3.1 Trinity Stats on Mox",
    "section": "",
    "text": "Realized that transcriptomes v2.1 and v3.1 (extracted from BLASTx-annotated FastAs from 20200605) didn’t have any associated stats.\nUsed built-in Trinity scripts to generate assembly stats on Mox.\nSBATCH script (GitHub):\n\n20200819_cbai_trinity_stats_v2.1_3.1.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_trinity_stats_v2.1_v3.1\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=15-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200819_cbai_trinity_stats_v2.1_v3.1\n\n\n# Script to generate C.bairdi transcriptome v2.1 and v3.1 Trinity stats.\n\n###################################################################################\n# These variables need to be set by user\n\n# Assign Variables\ntranscriptomes_dir=/gscratch/srlab/sam/data/C_bairdi/transcriptomes\n\n\n# Paths to programs\ntrinity_dir=\"/gscratch/srlab/programs/trinityrnaseq-v2.9.0\"\nsamtools=\"/gscratch/srlab/programs/samtools-1.10/samtools\"\n\n\n# Array of the various comparisons to evaluate\n# Each condition in each comparison should be separated by a \"-\"\ntranscriptomes_array=(\n\"${transcriptomes_dir}\"/cbai_transcriptome_v2.1.fasta \\\n\"${transcriptomes_dir}\"/cbai_transcriptome_v3.1.fasta\n)\n\n\n\n\n# Programs array\ndeclare -A programs_array\nprograms_array=(\n[samtools_faidx]=\"${samtools} faidx\" \\\n[trinity_stats]=\"${trinity_dir}/util/TrinityStats.pl\" \\\n[trinity_gene_trans_map]=\"${trinity_dir}/util/support_scripts/get_Trinity_gene_to_trans_map.pl\" \\\n[trinity_fasta_seq_length]=\"${trinity_dir}/util/misc/fasta_seq_length.pl\"\n)\n\n\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n\n# Loop through each transcriptome\nfor transcriptome in \"${!transcriptomes_array[@]}\"\ndo\n\n\n  # Variables\n  transcriptome_name=\"${transcriptomes_array[$transcriptome]##*/}\"\n  assembly_stats=\"${transcriptome_name}_assembly_stats.txt\"\n\n\n  # Assembly stats\n  ${programs_array[trinity_stats]} \"${transcriptomes_array[$transcriptome]}\" \\\n  > \"${assembly_stats}\"\n\n  # Create gene map files\n  ${programs_array[trinity_gene_trans_map]} \\\n  \"${transcriptomes_array[$transcriptome]}\" \\\n  > \"${transcriptome_name}\".gene_trans_map\n\n  # Create sequence lengths file (used for differential gene expression)\n  ${programs_array[trinity_fasta_seq_length]} \\\n  \"${transcriptomes_array[$transcriptome]}\" \\\n  > \"${transcriptome_name}\".seq_lens\n\n  # Create FastA index\n  ${programs_array[samtools_faidx]} \\\n  \"${transcriptomes_array[$transcriptome]}\" \\\n  > \"${transcriptome_name}\".fai\n\n  # Copy files to transcriptomes directory\n  rsync -av \\\n  \"${transcriptome_name}\"* \\\n  ${transcriptomes_dir}\n\n  # Capture FastA checksums for verification\n    echo \"\"\n  echo \"Generating checksum for ${transcriptome_name}\"\n  md5sum \"${transcriptomes_array[$transcriptome]}\" > \"${transcriptome_name}\".checksum.md5\n  echo \"Finished generating checksum for ${transcriptome_name}\"\n  echo \"\"\n\n\ndone\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# Capture program options\n## Note: Trinity util/support scripts don't have options/help menus\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n    ${programs_array[$program]} --help\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n\nRESULTS\nOutput folder:"
  },
  {
    "objectID": "posts/2020/2020-03-18-Transcriptome-Annotation---C.bairdi-Using-DIAMOND-BLASTx-on-Mox-and-MEGAN6-Meganizer-on-swoose/index.html",
    "href": "posts/2020/2020-03-18-Transcriptome-Annotation---C.bairdi-Using-DIAMOND-BLASTx-on-Mox-and-MEGAN6-Meganizer-on-swoose/index.html",
    "title": "Transcriptome Annotation - C.bairdi Using DIAMOND BLASTx on Mox and MEGAN6 Meganizer on swoose",
    "section": "",
    "text": "After receiving/trimming the latest round of C.bairdi RNAseq data on 20200318, need to get the data ready to perform taxonomic selection of sequencing reads. To do this, I first need to run DIAMOND BLASTx, then “meganize” the output files in preparation for loading into MEGAN6, which will allow for taxonomic-specific read separation.\nDIAMOND BLASTx will be run on Mox. Meganization will be run on my computer (swoose), due to MEGAN6’s reliance on Java X11 window (this is not available on Mox - throws an error when trying to run it).\nI fully anticipate this process to take a week or two (DIAMOND BLASTx will likely take a few days and read extraction will definitely take many days…)\nSBATCH script (GitHub):\n\n20200318_cbai_diamond_blastx.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_blastx_DIAMOND\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=20-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200318_cbai_diamond_blastx\n\n## Perform DIAMOND BLASTx on trimmed Chionoecetes bairdi (Tanner crab) FastQ files.\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\n\n# Program paths\ndiamond=/gscratch/srlab/programs/diamond-0.9.29/diamond\n\n# DIAMOND NCBI nr database\ndmnd=/gscratch/srlab/blastdbs/ncbi-nr-20190925/nr.dmnd\n\n# Capture program options\n{\necho \"Program options for DIAMOND: \"\necho \"\"\n\"${diamond}\" help\necho \"\"\necho \"\"\necho \"----------------------------------------------\"\necho \"\"\necho \"\"\n} &>> program_options.log || true\n\n# Trimmed FastQ files directory\nfastq_dir=/gscratch/scrubbed/samwhite/outputs/20200318_cbai_RNAseq_fastp_trimming/\n\n\n# Loop through FastQ files, log filenames to fastq_list.txt.\n# Run DIAMOND on each FastQ\nfor fastq in ${fastq_dir}*fastp-trim*.fq.gz\ndo\n    # Log input FastQs\n    echo \"${fastq}\" >> fastq_list.txt\n\n    # Strip leading path and extensions\n    no_path=$(echo \"${fastq##*/}\")\n    no_ext=$(echo \"${no_path%%.*}\")\n\n    # Run DIAMOND with blastx\n    # Output format 100 produces a DAA binary file for use with MEGAN\n    ${diamond} blastx \\\n    --db ${dmnd} \\\n    --query \"${fastq}\" \\\n    --out \"${no_ext}\".blastx.daa \\\n    --outfmt 100 \\\n    --top 5 \\\n    --block-size 15.0 \\\n    --index-chunks 4\ndone\n\nMEGANIZER script (GitHub):\n\n20200323_cbai_diamond_blastx_meganizer.sh\n\n#!/bin/bash\n\n# Script to run MEGAN6 meganizer on DIAMOND DAA files from\n# 20200318_cbai_diamond_blastx Mox job.\n\n# Requires MEGAN mapping files from:\n# http://ab.inf.uni-tuebingen.de/data/software/megan6/download/\n\n# Exit script if any command fails\nset -e\n\n# Program path\nmeganizer=/home/sam/programs/megan/tools/daa2rma\n\n# MEGAN mapping files\nprot_acc2tax=/home/sam/data/databases/MEGAN/prot_acc2tax-Jul2019X1.abin\nacc2interpro=/home/sam/data/databases/MEGAN/acc2interpro-Jul2019X.abin\nacc2eggnog=/home/sam/data/databases/MEGAN/acc2eggnog-Jul2019X.abin\n\n\n## Inititalize arrays\ndaa_array_R1=()\ndaa_array_R2=()\n\n# Create array of DAA R1 files\nfor daa in *R1*.daa\ndo\n  daa_array_R1+=(\"${daa}\")\ndone\n\n# Create array of DAA R2 files\nfor daa in *R2*.daa\ndo\n  daa_array_R2+=(\"${daa}\")\ndone\n\n## Run MEGANIZER\n\n# Capture start \"time\"\n# Uses builtin bash variable called ${SECONDS}\nstart=${SECONDS}\n\nfor index in \"${!daa_array_R1[@]}\"\ndo\n  start_loop=${SECONDS}\n  sample_name=$(echo \"${daa_array_R1[index]}\" | awk -F \"_\" '{print $1}')\n\n  echo \"Now processing ${sample_name}.daa2rma.rma6\"\n  echo \"\"\n\n  # Run daa2rma with paired option\n  ${meganizer} \\\n  --paired \\\n  --in \"${daa_array_R1[index]}\" \"${daa_array_R2[index]}\" \\\n    --acc2taxa ${prot_acc2tax} \\\n    --acc2interpro2go ${acc2interpro} \\\n    --acc2eggnog ${acc2eggnog} \\\n  --out \"${sample_name}\".daa2rma.rma6 \\\n  2>&1 | tee --append daa2rma_log.txt\n\n  end_loop=${SECONDS}\n  loop_runtime=$((end_loop-start_loop))\n\n\n  echo \"Finished processing ${sample_name}.daa2rma.rma6 in ${loop_runtime} seconds.\"\n  echo \"\"\n\ndone\n\n# Caputure end \"time\"\nend=${SECONDS}\n\nruntime=$((end-start))\n\n# Print MEGANIZER runtime, in seconds\n\n{\n  echo \"\"\n  echo \"---------------------\"\n  echo \"\"\n  echo \"Total runtime was: ${runtime} seconds\"\n} >> daa2rma_log.txt\n\n\nRESULTS\nDIAMOND BLASTx took ~4.5 days:\n\nDIAMOND BLASTx runtime\n\nThe subsequent conversion from DAA to RMA6 files to ~5.6 days.\nOutput folder:\n\n20200318_cbai_diamond_blastx/\n\nThe RMA6 files can now be loaded into MEGAN6 to extract reads based on taxonomy."
  },
  {
    "objectID": "posts/2020/2020-06-05-Sequence-Extractions---C.bairdi-Transcriptomes-v2.0-and-v3.0-Excluding-Alveolata-with-MEGAN6-on-Swoose/index.html",
    "href": "posts/2020/2020-06-05-Sequence-Extractions---C.bairdi-Transcriptomes-v2.0-and-v3.0-Excluding-Alveolata-with-MEGAN6-on-Swoose/index.html",
    "title": "Sequence Extractions - C.bairdi Transcriptomes v2.0 and v3.0 Excluding Alveolata with MEGAN6 on Swoose",
    "section": "",
    "text": "Continuing to try to identify the best C.bairdi transcriptome, we decided to extract all non-dinoflagellate sequences from cbai_transcriptome_v2.0 (RNAseq shorthand: 2018, 2019, 2020-GW, 2020-UW) and cbai_transcriptome_v3.0 (RNAseq shorthand: 2018, 2019, 2020-UW). Both of these transcriptomes were assembled without any taxonomic filter applied. DIAMOND BLASTx and conversion to MEGAN6 RMA6 files was performed yesterday (20200604).\nWill import RMA6 files into MEGAN6 and extract all non_Alveolata (dinoflagellates) sequences to create new transcriptomes. The new transcriptomes will be named cbai_transcriptome_v2.1 and cbai_transcriptome_v3.1. I’ll also extract only Alveolata sequences to generate a Hematodinium sp. transcriptome.\n\n\nRESULTS\nOutput folder:\n\n20200605_cbai_v2.0_v3.0_megan_seq_extractions\n20200605_cbai_v2.0_v3.0_megan_seq_extractions/megan_log.txt\n\n\n\nC.bairdi Transcritpomes:\n\ncbai_transcriptome_v2.1.fasta (241MB)\ncbai_transcriptome_v3.1.fasta (139MB)\n\n\n\n\nHematodinium sp. Transcriptomes:\n\nhemat_transcriptome_v2.1.fasta (65MB)\nhemat_transcriptome_v3.1.fasta (65MB)\n\n\nScreenshots of taxonomic trees in MEGAN6 used to extract sequences for each new transcriptome:\n\n\n\ncbai_transcriptome_v2.0 MEGAN non-Alveolota taxonomic tree\n\n\n\ncbai_transcriptome_v2.0 MEGAN non-alveolota taxonomic tree\n\n\n\n\n\ncbai_transcriptome_v3.0 MEGAN non-Alveolota taxonomic tree\n\n\n\ncbai_transcriptome_v3.0 MEGAN non-alveolota taxonomic tree\n\n\n\n\n\nhemat_transcriptome_v2.0 MEGAN Alveolata only taxonomic tree\n\n\n\nhemat_transcriptome_v2.0 MEGAN Alveolata only taxonomic tree\n\n\n\n\n\nhemat_transcriptome_v3.0 MEGAN Alveolata only taxonomic tree\n\n\n\nhemat_transcriptome_v3.0 MEGAN Alveolata only taxonomic tree\n\n\nThe transcriptomes will be added to our Genomic Resources wiki. Next up is to run BUSCO and generate BUSCO comparisons to previous transcriptome assemblies."
  },
  {
    "objectID": "posts/2020/2020-01-10-Lab-Maintenance---Cluster-UPS-Battery-Replacement/index.html",
    "href": "posts/2020/2020-01-10-Lab-Maintenance---Cluster-UPS-Battery-Replacement/index.html",
    "title": "Lab Maintenance - Cluster UPS Battery Replacement",
    "section": "",
    "text": "Replaced the batteries on one of the APC uninterruptable power supplies (UPS) on our local server cabinet.\nBad battery indicator light:\n\n\n\nAPC UPS bad battery indicator light\n\n\n\nBattery module drawer removed and opened:\n\n\n\nopened battery module\n\n\n\nNew batteries are in:\n\n\n\nnew batteries installed\n\n\n\nUPS powered back on, indicating good batteries:\n\n\n\nUPS showing good batteries"
  },
  {
    "objectID": "posts/2020/2020-10-29-Trimming---Shelly-S.salar-RNAseq-Using-fastp-and-MultiQC-on-Mox/index.html",
    "href": "posts/2020/2020-10-29-Trimming---Shelly-S.salar-RNAseq-Using-fastp-and-MultiQC-on-Mox/index.html",
    "title": "Trimming - Shelly S.salar RNAseq Using fastp and MultiQC on Mox",
    "section": "",
    "text": "Shelly asked that I trim, align to a genome, and perform transcriptome alignment counts in this GitHub issue with some Salmo salar RNAseq data she had and, using a subset of the NCBI Salmo salar RefSeq genome, GCF_000233375.1. She created a subset of this genome using only sequences designated as “chromosomes.” A link to the FastA (and a link to her notebook on creating this file) are in that GitHub issue link above. The transcriptome she has provided has not been subsetted in a similar fashion; maybe I’ll do that prior to alignment.\nHere, I performed adapter trimming using fastp. I opt for this trimmer as:\n\nIt’s fast (duh).\nIt automatically generates trimming reports similar to FastQC without the need for FastQC.\nThe results can be read by MultiQC.\n\nI’ll run fastp, followed by MultiQC on Mox.\nSBATCH script (GitHub):\n\n20201029_ssal_RNAseq_fastp_trimming.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=202001029_ssal_RNAseq_fastp_trimming\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=200G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20201029_ssal_RNAseq_fastp_trimming\n\n\n### S.salar RNAseq trimming using fastp, and MultiQC.\n\n### FastQ files provided by Shelly Trigg. See this GitHub issue for deets:\n### https://github.com/RobertsLab/resources/issues/1016#issuecomment-718812876\n\n### Expects input FastQ files to be in format: Pool26_16_P_31_1.fastq.gz\n\n\n\n###################################################################################\n# These variables need to be set by user\n\n## Assign Variables\n\n# Set number of CPUs to use\nthreads=27\n\n# Input/output files\ntrimmed_checksums=trimmed_fastq_checksums.md5\nraw_reads_dir=/gscratch/srlab/sam/data/S_salar/RNAseq/\nfastq_checksums=raw_fastq_checksums.md5\n\n# Paths to programs\nfastp=/gscratch/srlab/programs/fastp-0.20.0/fastp\nmultiqc=/gscratch/srlab/programs/anaconda3/bin/multiqc\n\n## Inititalize arrays\nfastq_array_R1=()\nfastq_array_R2=()\nR1_names_array=()\nR2_names_array=()\n\n\n# Programs associative array\ndeclare -A programs_array\nprograms_array=(\n[fastp]=\"${fastp}\" \\\n[multiqc]=\"${multiqc}\"\n)\n\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Capture date\ntimestamp=$(date +%Y%m%d)\n\n# Sync raw FastQ files to working directory\nrsync --archive --verbose \\\n\"${raw_reads_dir}\"*.gz .\n\n# Create arrays of fastq R1 files and sample names\nfor fastq in *_1.fastq.gz\ndo\n  fastq_array_R1+=(\"${fastq}\")\n    R1_names_array+=(\"$(echo \"${fastq}\" | awk 'BEGIN {FS = \"[._]\";OFS = \"_\"} {print $1, $2, $3, $4, $5}')\")\ndone\n\n# Create array of fastq R2 files\nfor fastq in *_2.fastq.gz\ndo\n  fastq_array_R2+=(\"${fastq}\")\n    R2_names_array+=(\"$(echo \"${fastq}\" |awk 'BEGIN {FS = \"[._]\";OFS = \"_\"} {print $1, $2, $3, $4, $5}')\")\ndone\n\n# Create list of fastq files used in analysis\n# Create MD5 checksum for reference\nfor fastq in *.gz\ndo\n  echo \"${fastq}\" >> input.fastq.list.txt\n    md5sum >> ${fastq_checksums}\ndone\n\n# Run fastp on files\n# Adds JSON report output for downstream usage by MultiQC\nfor index in \"${!fastq_array_R1[@]}\"\ndo\n  R1_sample_name=$(echo \"${R1_names_array[index]}\")\n    R2_sample_name=$(echo \"${R2_names_array[index]}\")\n    ${fastp} \\\n    --in1 ${fastq_array_R1[index]} \\\n    --in2 ${fastq_array_R2[index]} \\\n    --detect_adapter_for_pe \\\n    --thread ${threads} \\\n    --html \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".report.html \\\n    --json \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".report.json \\\n    --out1 \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz \\\n    --out2 \"${R2_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz\n\n    # Generate md5 checksums for newly trimmed files\n    {\n        md5sum \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz\n        md5sum \"${R2_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz\n    } >> \"${trimmed_checksums}\"\n    # Remove original FastQ files\n    rm \"${fastq_array_R1[index]}\" \"${fastq_array_R2[index]}\"\ndone\n\n# Run MultiQC\n${multiqc} .\n\n\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n    ${programs_array[$program]} -h\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\n\n  # If MultiQC is in programs_array, copy the config file to this directory.\n  if [[ \"${program}\" == \"multiqc\" ]]; then\n    cp --preserve ~/.multiqc_config.yaml \"${timestamp}_multiqc_config.yaml\"\n  fi\ndone\n\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# Remove raw FastQ file\nwhile read -r line\ndo\n    echo \"\"\n    echo \"Removing ${line}\"\n    rm \"${line}\"\ndone < input.fastq.list.txt\n\n\nRESULTS\nCumulative runtime for fastp and MultiQC was very fast; ~18mins:\n\n\n\nCumulative runtime for fastp and MultiQC\n\n\nNOTE: Despite the “FAILED” indication, the script ran to completion. The last command in the script is a redundant file removal step, which triggered the script “failure”. Left the command in the SBATCH script above for reproducibility.\nOverall, the results look good to me. Will proceed with Hisat2 alignment to the custome genome provided by Shelly.\nOutput folder:\n\n20201029_ssal_RNAseq_fastp_trimming/\n\nMultiQC Report (HTML; can open link in browser):\n\nNOTE: Sample names listed in the report are inaccurate and reflect a filename parsing issue, however, the data/results are fine.\nmultiqc_report.html\n\n\nTrimmed FastQ files and corresponding fastp HTML reportj:\n\nNOTE: The same naming issue applies here for the fastp reports. The report name is only named after the first of the two samples, but the report encompasses the two pairs of FastQ files.\nPool26_16_P_31_1.fastp-trim.20201029.fq.gz\nPool26_16_P_31_2.fastp-trim.20201029.fq.gz\n\nPool26_16_P_31_1.fastp-trim.20201029.report.html\n\nPool26_8_P_31_1.fastp-trim.20201029.fq.gz\nPool26_8_P_31_2.fastp-trim.20201029.fq.gz\n\nPool26_8_P_31_1.fastp-trim.20201029.report.html\n\nPool32_16_P_31_1.fastp-trim.20201029.fq.gz\nPool32_16_P_31_2.fastp-trim.20201029.fq.gz\n\nPool32_16_P_31_1.fastp-trim.20201029.report.html\n\nPool32_8_P_31_1.fastp-trim.20201029.fq.gz\nPool32_8_P_31_2.fastp-trim.20201029.fq.gz\n\nPool32_8_P_31_1.fastp-trim.20201029.report.html"
  },
  {
    "objectID": "posts/2020/2020-03-31-Transcriptome-Assessment---BUSCO-Metazoa-on-Hematodinium-MEGAN-Transcriptome/index.html",
    "href": "posts/2020/2020-03-31-Transcriptome-Assessment---BUSCO-Metazoa-on-Hematodinium-MEGAN-Transcriptome/index.html",
    "title": "Transcriptome Assessment - BUSCO Metazoa on Hematodinium MEGAN Transcriptome",
    "section": "",
    "text": "I previously created a C.bairdi de novo transcriptome assembly with Trinity from the MEGAN6 taxonomic-specific reads for Alveolata on 20200331 and decided to assess its “completeness” using BUSCO and the metazoa_odb9 database.\nBUSCO was run with the --mode transcriptome option on Mox.\nSBATCH script (GitHub):\n\n20200331_hemat_busco_megan.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=hemat_busco_megan_transcriptome\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=3-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200331_hemat_busco_megan\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Load Open MPI module for parallel, multi-node processing\nmodule load icc_19-ompi_3.1.2\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\n# Establish variables for more readable code\ntimestamp=$(date +%Y%m%d)\nspecies=\"hemat\"\nprefix=\"${timestamp}.${species}\"\n\n## Input files and settings\nbase_name=\"${prefix}.megan\"\nbusco_db=/gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9\ntranscriptome_fasta=/gscratch/srlab/sam/data/Hematodinium/transcriptomes/20200408.hemat.megan.Trinity.fasta\naugustus_species=fly\nthreads=28\n\n## Save working directory\nwd=$(pwd)\n\n## Set program paths\naugustus_bin=/gscratch/srlab/programs/Augustus-3.3.2/bin\naugustus_scripts=/gscratch/srlab/programs/Augustus-3.3.2/scripts\nblast_dir=/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin/\nbusco=/gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py\nhmm_dir=/gscratch/srlab/programs/hmmer-3.2.1/src/\n\n## Augustus configs\naugustus_dir=${wd}/augustus\naugustus_config_dir=${augustus_dir}/config\naugustus_orig_config_dir=/gscratch/srlab/programs/Augustus-3.3.2/config\n\n## BUSCO configs\nbusco_config_default=/gscratch/srlab/programs/busco-v3/config/config.ini.default\nbusco_config_ini=${wd}/config.ini\n\n# Export BUSCO config file location\nexport BUSCO_CONFIG_FILE=\"${busco_config_ini}\"\n\n# Export Augustus variable\nexport PATH=\"${augustus_bin}:$PATH\"\nexport PATH=\"${augustus_scripts}:$PATH\"\nexport AUGUSTUS_CONFIG_PATH=\"${augustus_config_dir}\"\n\n\n# Copy BUSCO config file\ncp ${busco_config_default} \"${busco_config_ini}\"\n\n# Make Augustus directory if it doesn't exist\nif [ ! -d \"${augustus_dir}\" ]; then\n  mkdir --parents \"${augustus_dir}\"\nfi\n\n# Copy Augustus config directory\ncp --preserve -r ${augustus_orig_config_dir} \"${augustus_dir}\"\n\n# Edit BUSCO config file\n## Set paths to various programs\n### The use of the % symbol sets the delimiter sed uses for arguments.\n### Normally, the delimiter that most examples use is a slash \"/\".\n### But, we need to expand the variables into a full path with slashes, which screws up sed.\n### Thus, the use of % symbol instead (it could be any character that is NOT present in the expanded variable; doesn't have to be \"%\").\nsed -i \"/^;cpu/ s/1/${threads}/\" \"${busco_config_ini}\"\nsed -i \"/^tblastn_path/ s%tblastn_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^makeblastdb_path/ s%makeblastdb_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^augustus_path/ s%augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^etraining_path/ s%etraining_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^gff2gbSmallDNA_path/ s%gff2gbSmallDNA_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^new_species_path/ s%new_species_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^optimize_augustus_path/ s%optimize_augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^hmmsearch_path/ s%hmmsearch_path = /home/osboxes/BUSCOVM/hmmer/hmmer-3.1b2-linux-intel-ia32/binaries/%path = ${hmm_dir}%\" \"${busco_config_ini}\"\n\n\n# Run BUSCO/Augustus training\n${busco} \\\n--in ${transcriptome_fasta} \\\n--out ${base_name} \\\n--lineage_path ${busco_db} \\\n--mode transcriptome \\\n--cpu ${threads} \\\n--long \\\n--species ${augustus_species} \\\n--tarzip \\\n--augustus_parameters='--progress=true'\n\n\nRESULTS\nVery fast! 49 seconds:\n\n\n\nHemat BUSCO runtime\n\n\nOutput folder:\n\n20200331_hemat_busco_megan\n\nBUSCO short summary (text):\n\n20200331_hemat_busco_megan/run_20200331.hemat.megan/short_summary_20200331.hemat.megan.txt\n\n# BUSCO version is: 3.0.2\n# The lineage dataset is: metazoa_odb9 (Creation date: 2016-02-13, number of species: 65, number of BUSCOs: 978)\n# To reproduce this run: python /gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py -i /gscratch/srlab/sam/data/Hematodinium/transcriptomes/20200408.hemat.megan.Trinity.fasta -o 20200408.hemat.megan -l /gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9/ -m transcriptome -c 28 --long -z\n#\n# Summarized benchmarking in BUSCO notation for file /gscratch/srlab/sam/data/Hematodinium/transcriptomes/20200408.hemat.megan.Trinity.fasta\n# BUSCO was run in mode: transcriptome\n\n    C:25.6%[S:20.7%,D:4.9%],F:11.7%,M:62.7%,n:978\n\n    250 Complete BUSCOs (C)\n    202 Complete and single-copy BUSCOs (S)\n    48  Complete and duplicated BUSCOs (D)\n    114 Fragmented BUSCOs (F)\n    614 Missing BUSCOs (M)\n    978 Total BUSCO groups searched\n\nThis current assembly shows only a slight increase in completeness (25.6% complete BUSCOS), compared to the initial transcriptome assembly from 20200123 (25.1%)."
  },
  {
    "objectID": "posts/2020/2020-10-28-MBD-Selection---M.magister-Sheared-Gill-gDNA-8-of-24-Samples-Set-1-of-3/index.html",
    "href": "posts/2020/2020-10-28-MBD-Selection---M.magister-Sheared-Gill-gDNA-8-of-24-Samples-Set-1-of-3/index.html",
    "title": "MBD Selection - M.magister Sheared Gill gDNA 8 of 24 Samples Set 1 of 3",
    "section": "",
    "text": "M.magister (Dungeness crab) gill gDNA provided by Mackenzie Gavery was previously sheared on 20201026 and three samples were subjected to additional rounds of shearing on 20201027, in preparation for methyl bidning domain (MBD) selection using the MethylMiner Kit (Invitrogen).\nFollowed the manufacturer’s protocol for using <= 1ug of DNA (I’m using 1ug) with the following notes/changes:\n\nPrepared beads for all 8 samples in single prep. Combined the amount of beads/protein needed for 8, 1ug reactions. Protein calculations and wash volumes were based off of 8ug of input DNA. Prepared beads were resuspended in 80uL (instead of 100uL) and 10uL were distributed to each of 8 tubes. Volume was then brought up to 100uL with 1x binding/wash buffer.\nDNA capture incubation was performed overnight (~20hrs).\nNon-captured DNA and wash volumes were combined in a single tube for each sample. These were stored at 4oC, but were not precipitated.\nEthanol precipitations were incubated at -80oC overnight (~20hrs).\nPrecipitated DNA was resuspended in 21uL of H2O (this allows the usage of 1uL for Qubit and leave 20uL as the maximum input volume for the subsequent PicoMethylSeq Kit (ZymoResearch)).\n\nSamples were quantified using the Roberts Lab Qubit 3.0 with the Qubit 1x dsDNA HS Assay (Invitrogen), using 1uL of sample.\nAll samples were stored temporarily at 4oC.\nFor reference, all sample info for this project is here (Google Sheet):\n\nOA Crab Sample Collection 071119\n\n\n\nRESULTS\nQubit results (Google Sheet):\n\n20201030_qubit_DNA_mmag_MBD\n\n\n\n\n\n\n\n\n\n\nSample_ID\nResuspension_vol(uL)\nTotal_recovery(ng)\nPercent_recovery\n\n\n\n\nCH01-06\n21\n2.90\n0.29\n\n\nCH01-14\n21\n2.98\n0.30\n\n\nCH01-22\n21\n3.40\n0.34\n\n\nCH01-38\n21\n6.05\n0.60\n\n\nCH03-04\n21\n25.20\n2.52\n\n\nCH03-15\n21\n2.69\n0.27\n\n\nCH03-33\n21\n3.53\n0.35\n\n\nCH05-01\n21\n14.62\n1.46\n\n\n\nYields are much lower than expected, as Mac indicated that the M.magister genome was ~7% methylated. However, there is more than enough DNA for the subsequent library prep with the Pico MethylSeq Kit (Zymo)."
  },
  {
    "objectID": "posts/2020/2020-12-17-Samples-Received---Cockle-Clam-Gonad-H-and-E-Slides/index.html",
    "href": "posts/2020/2020-12-17-Samples-Received---Cockle-Clam-Gonad-H-and-E-Slides/index.html",
    "title": "Samples Received - Cockle Clam Gonad H and E Slides",
    "section": "",
    "text": "Today we received the H & E-stained slides from the cockle clam gonad tissue blocks/cassettes we submitted on 20201201. Slides were added to Slide Case #5 - Rows 13 - 37 (Google Sheet).\nAll info has been added to:\n\nRoberts Lab histology database (Google Sheet)."
  },
  {
    "objectID": "posts/2020/2020-05-19-Transcriptome-Assessment---BUSCO-Metazoa-on-C.bairdi-Transcriptome-v3.0/index.html",
    "href": "posts/2020/2020-05-19-Transcriptome-Assessment---BUSCO-Metazoa-on-C.bairdi-Transcriptome-v3.0/index.html",
    "title": "Transcriptome Assessment - BUSCO Metazoa on C.bairdi Transcriptome v3.0",
    "section": "",
    "text": "I previously created a C.bairdi de novo transcriptome assembly with Trinity from all our C.bairdi pooled RNAseq (not taxonomically filtered) on 20200518 and decided to assess its “completeness” using BUSCO and the metazoa_odb9 database.\nBUSCO was run with the --mode transcriptome option on Mox.\nSBATCH script (GitHub):\n\n20200519_cbai_busco_transcriptome_v3.0.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_busco_v2.0_transcriptome\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=5-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=${USER}@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200519_cbai_busco_transcriptome_v3.0\n\n### C.bairdi transcriptome assembly completeness assessment using BUSCO.\n### This is checking cbai_transcriptome_v3.0.fasta (orginal name, used below, is 20200518.C_bairdi.Trinity.fasta)\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Load Open MPI module for parallel, multi-node processing\nmodule load icc_19-ompi_3.1.2\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\n# Establish variables for more readable code\ntimestamp=$(date +%Y%m%d)\nspecies=\"cbai\"\nprefix=\"${timestamp}.${species}\"\n\n## Input files and settings\nbase_name=\"${prefix}\"\nbusco_db=/gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9\ntranscriptome_fasta=/gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200518.C_bairdi.Trinity.fasta\naugustus_species=fly\nthreads=28\n\n## Save working directory\nwd=$(pwd)\n\n## Set program paths\naugustus_bin=/gscratch/srlab/programs/Augustus-3.3.2/bin\naugustus_scripts=/gscratch/srlab/programs/Augustus-3.3.2/scripts\nblast_dir=/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin/\nbusco=/gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py\nhmm_dir=/gscratch/srlab/programs/hmmer-3.2.1/src/\n\n## Augustus configs\naugustus_dir=${wd}/augustus\naugustus_config_dir=${augustus_dir}/config\naugustus_orig_config_dir=/gscratch/srlab/programs/Augustus-3.3.2/config\n\n## BUSCO configs\nbusco_config_default=/gscratch/srlab/programs/busco-v3/config/config.ini.default\nbusco_config_ini=${wd}/config.ini\n\n# Export BUSCO config file location\nexport BUSCO_CONFIG_FILE=\"${busco_config_ini}\"\n\n# Export Augustus variable\nexport PATH=\"${augustus_bin}:$PATH\"\nexport PATH=\"${augustus_scripts}:$PATH\"\nexport AUGUSTUS_CONFIG_PATH=\"${augustus_config_dir}\"\n\n\n# Copy BUSCO config file\ncp ${busco_config_default} \"${busco_config_ini}\"\n\n# Make Augustus directory if it doesn't exist\nif [ ! -d \"${augustus_dir}\" ]; then\n  mkdir --parents \"${augustus_dir}\"\nfi\n\n# Copy Augustus config directory\ncp --preserve -r ${augustus_orig_config_dir} \"${augustus_dir}\"\n\n# Edit BUSCO config file\n## Set paths to various programs\n### The use of the % symbol sets the delimiter sed uses for arguments.\n### Normally, the delimiter that most examples use is a slash \"/\".\n### But, we need to expand the variables into a full path with slashes, which screws up sed.\n### Thus, the use of % symbol instead (it could be any character that is NOT present in the expanded variable; doesn't have to be \"%\").\nsed -i \"/^;cpu/ s/1/${threads}/\" \"${busco_config_ini}\"\nsed -i \"/^tblastn_path/ s%tblastn_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^makeblastdb_path/ s%makeblastdb_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^augustus_path/ s%augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^etraining_path/ s%etraining_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^gff2gbSmallDNA_path/ s%gff2gbSmallDNA_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^new_species_path/ s%new_species_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^optimize_augustus_path/ s%optimize_augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^hmmsearch_path/ s%hmmsearch_path = /home/osboxes/BUSCOVM/hmmer/hmmer-3.1b2-linux-intel-ia32/binaries/%path = ${hmm_dir}%\" \"${busco_config_ini}\"\n\n\n# Run BUSCO/Augustus training\n${busco} \\\n--in ${transcriptome_fasta} \\\n--out ${base_name} \\\n--lineage_path ${busco_db} \\\n--mode transcriptome \\\n--cpu ${threads} \\\n--long \\\n--species ${augustus_species} \\\n--tarzip \\\n--augustus_parameters='--progress=true'\n\n\nRESULTS\nRun time was quick, ~9mins (no screencap due to use of ${USER} in email of SBATCH script. Whoops.)\nOutput folder:\n\n20200519_cbai_busco_transcriptome_v3.0/\n\nBUSCO short summary (text):\n\n20200519_cbai_busco_transcriptome_v3.0/run_20200519.cbai/short_summary_20200519.cbai.txt\n\n# BUSCO version is: 3.0.2\n# The lineage dataset is: metazoa_odb9 (Creation date: 2016-02-13, number of species: 65, number of BUSCOs: 978)\n# To reproduce this run: python /gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py -i /gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200518.C_bairdi.Trinity.fasta -o 20200519.cbai -l /gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9/ -m transcriptome -c 28 --long -z\n#\n# Summarized benchmarking in BUSCO notation for file /gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200518.C_bairdi.Trinity.fasta\n# BUSCO was run in mode: transcriptome\n\n    C:97.6%[S:39.1%,D:58.5%],F:1.6%,M:0.8%,n:978\n\n    954 Complete BUSCOs (C)\n    382 Complete and single-copy BUSCOs (S)\n    572 Complete and duplicated BUSCOs (D)\n    16  Fragmented BUSCOs (F)\n    8   Missing BUSCOs (M)\n    978 Total BUSCO groups searched"
  },
  {
    "objectID": "posts/2020/2020-09-16-qPCR---Geoduck-Normalizing-Gene-Primers-28s-v4-and-EF1a-v1-Tests/index.html",
    "href": "posts/2020/2020-09-16-qPCR---Geoduck-Normalizing-Gene-Primers-28s-v4-and-EF1a-v1-Tests/index.html",
    "title": "qPCR - Geoduck Normalizing Gene Primers 28s-v4 and EF1a-v1 Tests",
    "section": "",
    "text": "On Monday (20200914), I checked a set of 28s and EF1a primer sets and determined that 28s-v4 and EF1a-v1 were probably the best of the bunch, although they all looked great. So, I needed to test these out on some individual cDNA samples to see if they might be useful as normalizing genes - should have consistent Cq values across all samples/treatments.\nPrimers tested:\n\n\n\nSRID\nPrimer_Name\n\n\n\n\n1797\n28s_v4_FWD\n\n\n1796\n28s_v4_REV\n\n\n1795\nEF1a_v1_FWD\n\n\n1794\nEF1a_v1_REV\n\n\n\nI tested them on a set of P.generosa hemolymph cDNA made by Kaitlyn on 20200212.\nI also used a 1:10 dilution of geoduck gDNA (162ng/uL; from 20170105) as a positive control, as gDNA was amplified by all the primer sets on Monday.\nMaster mix calcs are here:\n\n200200916_qPCR_geoduck_28s-4_EF1a-v1 (Google Sheet)\n\nAll qPCR reactions were run in duplicate. See qPCR Report (Results section below) for plate layout, cycling params, etc.\n\n\nRESULTS\nqPCR Report (PDF):\n\nsam_2020-09-16_04-57-06_BR006896.pdf\n\nCFX Data File (PCRD):\n\nsam_2020-09-16_04-57-06_BR006896.pcrd\n\nCFX Results File (CSV):\n\nsam_2020-09-16_04-57-06_BR006896-Quantification-Cq-Results.csv\n\n28s-v4 melt plots aren’t great and might even possibly have a slight shoulder, suggesting a secondary product. Not great. Additionally, the samples have a fairly large Cq range; not good for a normalizing gene.\nEF1a-v1 melt plots look great, but the amplification also exhibits a Cq range that’s too large for a normalizing gene.\nWith all of that said, I’m starting to think it would be best to re-quant the source RNA and remake cDNA.\nAmplifcation and melt plots for each primer set are below. Color coding:\n\nRED: No Template Control (NTC)\nCHARTREUSE: gDNA\nOTHER: cDNA\n\n\n28s v4\nAMPLIFICATION PLOTS\n\n\n\n28s-v4 amp plots.png\n\n\nMELT PLOTS\n\n\n\n28s-v4 melt plots.png\n\n\n\n\nEF1a v1\nAMPLIFICATION PLOTS\n\n\n\nEF1a-v1 amp plots.png\n\n\nMELT PLOTS\n\n\n\nEF1a-v1 melt plots.png"
  },
  {
    "objectID": "posts/2020/2020-12-11-FastQC-MultiQC---M.magister-MBD-BSseq-Pool-Test-MiSeq-Run-on-Mox/index.html",
    "href": "posts/2020/2020-12-11-FastQC-MultiQC---M.magister-MBD-BSseq-Pool-Test-MiSeq-Run-on-Mox/index.html",
    "title": "FastQC-MultiQC - M.magister MBD-BSseq Pool Test MiSeq Run on Mox",
    "section": "",
    "text": "Earlier today we received the M.magister (C.magister; Dungeness crab) MiSeq data from Mac.\nI ran FastQC and MultiQC on Mox.\nSBATCH script (GitHub):\n\n20201211_mmag_fastqc_multiqc_mbd-bsseq_miseq.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=20201211_mmag_fastqc_multiqc_mbd-bsseq_miseq\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20201211_mmag_fastqc_multiqc_mbd-bsseq_miseq\n\n\n### FastQC assessment of raw MiSeq sequencing test run for\n### MBD-BSseq pool of M.magister samples from 20201202.\n\n\n###################################################################################\n# These variables need to be set by user\n\n# FastQC output directory\noutput_dir=$(pwd)\n\n# Set number of CPUs to use\nthreads=28\n\n# Input/output files\nchecksums=fastq_checksums.md5\nfastq_list=fastq_list.txt\nraw_reads_dir=/gscratch/srlab/sam/data/C_magister/MBD-BSseq/\n\n# Paths to programs\nfastqc=/gscratch/srlab/programs/fastqc_v0.11.9/fastqc\nmultiqc=/gscratch/srlab/programs/anaconda3/bin/multiqc\n\n\n# Programs associative array\ndeclare -A programs_array\nprograms_array=(\n[fastqc]=\"${fastqc}\" \\\n[multiqc]=\"${multiqc}\"\n)\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Sync raw FastQ files to working directory\nrsync --archive --verbose \\\n\"${raw_reads_dir}\"CH*.fastq.gz .\n\n# Populate array with FastQ files\nfastq_array=(CH*.fastq.gz)\n\n# Pass array contents to new variable\nfastqc_list=$(echo \"${fastq_array[*]}\")\n\n# Run FastQC\n# NOTE: Do NOT quote ${fastqc_list}\n${programs_array[fastqc]} \\\n--threads ${threads} \\\n--outdir ${output_dir} \\\n${fastqc_list}\n\n\n# Create list of fastq files used in analysis\necho \"${fastqc_list}\" | tr \" \" \"\\n\" >> ${fastq_list}\n\n# Generate checksums for reference\nwhile read -r line\ndo\n\n    # Generate MD5 checksums for each input FastQ file\n    echo \"Generating MD5 checksum for ${line}.\"\n    md5sum \"${line}\" >> \"${checksums}\"\n    echo \"Completed: MD5 checksum for ${line}.\"\n    echo \"\"\n\n    # Remove fastq files from working directory\n    echo \"Removing ${line} from directory\"\n    rm \"${line}\"\n    echo \"Removed ${line} from directory\"\n    echo \"\"\ndone < ${fastq_list}\n\n# Run MultiQC\n${programs_array[multiqc]} .\n\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n  # Handle samtools help menus\n  if [[ \"${program}\" == \"samtools_index\" ]] \\\n  || [[ \"${program}\" == \"samtools_sort\" ]] \\\n  || [[ \"${program}\" == \"samtools_view\" ]]\n  then\n    ${programs_array[$program]}\n  fi\n    ${programs_array[$program]} -h\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\n\n  # If MultiQC is in programs_array, copy the config file to this directory.\n  if [[ \"${program}\" == \"multiqc\" ]]; then\n    cp --preserve ~/.multiqc_config.yaml multiqc_config.yaml\n  fi\ndone\n\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nRESULTS\nRuntime was fast, ~3.5mins:\n\n\n\nCumulative runtime for FastQC and MultiQC on C.magister MiSeq data\n\n\nWill add FastQC report links to Nightingales spreadsheet (Google Sheet) for those that did not fail.\nNOTE: This post was updated on 20201217 using a newly transferred set of FastQs that Mac set up. See the previous commit of this post for more info.\nOutput folder:\n\n20201211_mmag_fastqc_multiqc_mbd-bsseq_miseq/\n\nMultiQC Report (HTML; open with web browser):\n\n20201211_mmag_fastqc_multiqc_mbd-bsseq_miseq/multiqc_report.html\n\nIndividual FastQC reports can be found by browsing the output folder linked above and/or by clicking through the MultiQC report that’s linked above.\nThis test run was to help evaluate evenness of the sample pooling, as well as identify any other possible issues. Evenness appears OK (not great), but I’m not entirely sure how this would be addressed, as an aliquot of each library was created at a concentration of 4nM and then 1uL of each of these aliquots was combined. Is it safe to assume that any sequencing biases leading to preferential library sequencing is due to the individual libraries? And, that this can be adjusted for when making the final pooling that gets sent off for a full sequencing run? Also, I’m a bit surprised at the high levels of adapter content. I’m curious how these data will look after trimming. Anyway, at this point, I’ll let Laura Spencer and Mac make decisions about going forward with a full sequencing run, as it’s really their project anyway."
  },
  {
    "objectID": "posts/2020/2020-02-20-Primer-Design---C.bairdi-Primers-for-Checking-RNA-for-Residual-gDNA/index.html",
    "href": "posts/2020/2020-02-20-Primer-Design---C.bairdi-Primers-for-Checking-RNA-for-Residual-gDNA/index.html",
    "title": "Primer Design - C.bairdi Primers for Checking RNA for Residual gDNA",
    "section": "",
    "text": "Getting ready to run some qPCRs and first we need to confirm that our RNA is actually DNA-free. Before we can do that, we need some primers to use, so I decided to semi-arbitrarily select three different gene targets from our MEGAN6 taxonomic-specific Trinity assembly from 20200122.\nI used our recent differential gene expression analysis to identify those genes which were highly differentially expressed in infected vs. uninfected samples.\nOverall, the process went something like this:\n\nSort upregulated genes in infected group by logFC (fold change) to find Trinity transcript IDs of highly expressed genes:\n\nawk 'NR>1' salmon.gene.counts.matrix.infected_vs_uninfected.edgeR.DE_results.P0.05_C1.infected-UP.subset \\\n| sort -n -k4,4\n\nSearch for some of the highly expressed Trinity IDs in the Trinotate annotations to find SwissProt IDs:\n\ngrep \"TRINITY_DN6549_c0_g1\" \\\n20200126.cbai.trinotate_annotation_report.txt\n\nCopy SwissProt ID (if available) and see what it is on the UniProtKB website.\nIf interesting (somewhat), search Trinity de novo assembly for transcript sequence.\nUse sequence to generate primers on the Primer3 website.\n\n\n\nRESULTS\nHere are the targets and primers designed and ordered.\n\n\n40s rRNA S30\nPRIMER PICKING RESULTS FOR cbai_TRINITY_DN6411_c0_g2_i1\n\nNo mispriming library specified\nUsing 1-based sequence positions\nOLIGO            start  len      tm     gc%   any    3' seq\nLEFT PRIMER         80   20   59.94   45.00  4.00  0.00 TGCCGGTAAGGTGAAAAATC\nRIGHT PRIMER       261   20   59.97   45.00  2.00  2.00 AAATCCGCAACCAATACAGC\nSEQUENCE SIZE: 334\nINCLUDED REGION SIZE: 334\n\nPRODUCT SIZE: 182, PAIR ANY COMPL: 3.00, PAIR 3' COMPL: 0.00\n\n    1 GTTTTTTCCTTTTTCGTTTTCTACATATATTAACCCCCCTTTATTAAACAATGGGTAAAG\n\n\n   61 TCCACGGTTCCTTGGCTCGTGCCGGTAAGGTGAAAAATCAGACCCCGAAAGTTGCCAAGA\n                         >>>>>>>>>>>>>>>>>>>>                     \n\n  121 TGGAGAAGAAGAAGTCTCTCACGGGCCGCGCCAAGAAACGCATGCAGTACAACCGTCGTT\n\n\n  181 TCGTGAACATCGTGCGGGCAGGTGGCCCCAAGCGCGGCCCTAATTCCAACCAGAAGTAAA\n\n\n  241 GGCTGTATTGGTTGCGGATTTTAGGTGTTAACGATGCGCTGGACTTCCTCCTCTATATGA\n       <<<<<<<<<<<<<<<<<<<<                                       \n\n  301 GTATCATGGGATGGATGCAACGAACTTGATGGAC\n\n\n\nallantoicase\n    PRIMER PICKING RESULTS FOR cbai_TRINITY_DN13073_c0_g1_i1\n\nNo mispriming library specified\nUsing 1-based sequence positions\nOLIGO            start  len      tm     gc%   any    3' seq\nLEFT PRIMER         65   20   60.29   50.00  4.00  0.00 CGAGTGTTTCCAAGCCTGTT\nRIGHT PRIMER       215   20   60.07   50.00  4.00  0.00 GTGAATACGCCTTCCTTCCA\nSEQUENCE SIZE: 237\nINCLUDED REGION SIZE: 237\n\nPRODUCT SIZE: 151, PAIR ANY COMPL: 3.00, PAIR 3' COMPL: 1.00\n\n    1 GTAGTATTCTGGAATCGGCGTTTTTTGTTTGTGTAATCCGTGGAAATGGACATATCTCAA\n\n\n   61 CCCGCGAGTGTTTCCAAGCCTGTTTTTACACGCTTGACCGACCTCGCGAGCGAACTGCTC\n          >>>>>>>>>>>>>>>>>>>>                                    \n\n  121 GGCTCGAAGGTGCTTTTTGCCACCGATCAGTGGTTTGCCGAAGCTTCAAATTTACTCAAG\n\n\n  181 AGTGAAGAGCCGGTATGGAAGGAAGGCGTATTCACCGAACATGGAAAATGGATGGAC\n                     <<<<<<<<<<<<<<<<<<<<                      \n\n\n\nubiqutin thioesterase\nPRIMER PICKING RESULTS FOR cbai_TRINITY_DN6549_c0_g1_i1\n\nNo mispriming library specified\nUsing 1-based sequence positions\nOLIGO            start  len      tm     gc%   any    3' seq\nLEFT PRIMER        297   20   60.00   45.00  4.00  2.00 CGGTTTGTTTGAACGGCTAT\nRIGHT PRIMER       577   20   59.95   50.00  4.00  3.00 GATAAAGCTCGGCATTCTGC\nSEQUENCE SIZE: 647\nINCLUDED REGION SIZE: 647\n\nPRODUCT SIZE: 281, PAIR ANY COMPL: 3.00, PAIR 3' COMPL: 0.00\n\n    1 TGCGGGAATATCTTTAAATACTATATACTCGGGTAGCGTCTTGGAATGTCATGTGAGGGA\n\n\n   61 AATTCAGACCCGCACCATGATTATCAGGCATCCCTGAACCAGCAAGATGCGATCCGGCAG\n\n\n  121 GAAGCGTCCGTCGATCACCCGTTGATGAAGAAGCGCGAGCCCGTAGGGGCATCGCTGAAC\n\n\n  181 GAGCAGTTCGCGGAGAATAAGAACTTCCTACAGAAGGTCGCTTCAATCGCGGCCAAGTAT\n\n\n  241 GAGTTCATTCGACGGGCGAGACCGGACGGCAATTGCTTTTACCGCACGTATCTGTTCGGT\n                                                              >>>>\n\n  301 TTGTTTGAACGGCTATTGGGCATGTCCCGCGAGGAGCGGGACAAATTTGTCGTGTTTCTC\n      >>>>>>>>>>>>>>>>                                            \n\n  361 AAGAAATCACTGGATGATGTGCTTTGCCAAGGGTATGAGCGATTTGCGGTAGAAGAAATG\n\n\n  421 CACGAAGATATCCTTGAAGAGTTTGAGAAACTCGCTCAGAATGACAATGCAACCGTCGGC\n\n\n  481 GATATCGAGACGATATTCGACGAGGAAAGGCATTACCATATTTGCTACTTGAGGTGCCTA\n\n\n  541 GCGTCGGCGTACCTCAAGCAGAATGCCGAGCTTTATCAATCGTTCCTCGAAGGCTATGCG\n                       <<<<<<<<<<<<<<<<<<<<                       \n\n  601 ACTATAGCAGAGTTCTGCGCTCATGAAGTGGATCCTATGTGGCGCGG"
  },
  {
    "objectID": "posts/2020/2020-04-15-Transcript-Abundance---C.bairdi-Alignment-free-with-Salmon-on-Mox-for-Grace/index.html",
    "href": "posts/2020/2020-04-15-Transcript-Abundance---C.bairdi-Alignment-free-with-Salmon-on-Mox-for-Grace/index.html",
    "title": "Transcript Abundance - C.bairdi Alignment-free with Salmon on Mox for Grace",
    "section": "",
    "text": "Per this GitHub Issue, Grace and Steven asked if I could help by generating a transcript abundance file for Grace to use with EdgeR. To do so, I used Salmon for alignment-free transcript abundance estimates due to its speed and its incorporation into Trinity with the following files:\n\nTrimmed FastQs from 20191025\nC.bairdi transcriptome from 20200409 (NOTE: Due to delays in running the initial assembly, FastA file is dated 20200408, despite notebook dated 20200330).\nTrinotate annotations from 20200409\n\nSBATCH script (GitHub):\n\n20200415_cbai_salmon_abundance.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_salmon_abundance_estimates\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=04-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200415_cbai_salmon_abundance\n\n## Script to get gene abundance estimates via salmon alignment-free\n## Specifically for Grace, per this GitHub issue: https://github.com/RobertsLab/resources/issues/902\n\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\nwd=\"$(pwd)\"\nthreads=28\n\nsamples=samples.txt\n\nfasta_prefix=\"20200408.C_bairdi.megan.Trinity\"\n\n\n## Set input file locations\ntrimmed_reads_dir=\"/gscratch/srlab/sam/data/C_bairdi/RNAseq\"\ntranscriptome_dir=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes\"\ntranscriptome=\"${transcriptome_dir}/${fasta_prefix}.fasta\"\n\ntrinotate_feature_map=\"${transcriptome_dir}/20200409.cbai.trinotate.annotation_feature_map.txt\"\ngene_map=\"${transcriptome_dir}/${fasta_prefix}.fasta.gene_trans_map\"\n\n# Standard output/error files\nmatrix_stdout=\"matrix_stdout.txt\"\nmatrix_stderr=\"matrix_stderr.txt\"\nsalmon_stdout=\"salmon_stdout.txt\"\nsalmon_stderr=\"salmon_stderr.txt\"\n\n\n#programs\ntrinity_home=/gscratch/srlab/programs/trinityrnaseq-v2.9.0\ntrinity_annotate_matrix=\"${trinity_home}/Analysis/DifferentialExpression/rename_matrix_feature_identifiers.pl\"\ntrinity_abundance=${trinity_home}/util/align_and_estimate_abundance.pl\ntrinity_matrix=${trinity_home}/util/abundance_estimates_to_matrix.pl\n\n# Create salmon index of Trinity FastA\n# Useful for saving time if needed in future for\n# additional runs.\n${trinity_abundance} \\\n--transcripts ${transcriptome} \\\n--est_method salmon \\\n--prep_reference \\\n--thread_count \"${threads}\" \\\n--output_dir \"${wd}\"\n\n\n# Rsync trimmed reads\nrsync \\\n--archive \\\n--verbose \\\n${trimmed_reads_dir}/3297*trim*.gz .\n\n# Populate array with unique sample names\n## NOTE: Requires Bash >=v4.0\nmapfile -t samples_array < <( for fastq in 3297*.gz; do echo \"${fastq}\" | awk -F\"_\" '{print $1}'; done | sort -u )\n\n# Loop to concatenate same sample R1 and R2 reads\n# Also create sample list file\nfor sample in \"${!samples_array[@]}\"\ndo\n  # Concatenate R1 reads for each sample\n  for fastq in *R1*.gz\n  do\n    fastq_sample=$(echo \"${fastq}\" | awk -F\"_\" '{print $1}')\n    if [ \"${samples_array[sample]}\" == \"${fastq_sample}\" ]; then\n      echo \"${fastq}\" >> fastq.list.txt\n      reads_1=${samples_array[sample]}_reads_1.fq\n      gunzip --to-stdout \"${fastq}\" >> \"${reads_1}\"\n    fi\n  done\n\n  # Concatenate R2 reads for each sample\n  for fastq in *R2*.gz\n  do\n    fastq_sample=$(echo \"${fastq}\" | awk -F\"_\" '{print $1}')\n    if [ \"${samples_array[sample]}\" == \"${fastq_sample}\" ]; then\n      echo \"${fastq}\" >> fastq.list.txt\n      reads_2=${samples_array[sample]}_reads_2.fq\n      gunzip --to-stdout \"${fastq}\" >> \"${reads_2}\"\n    fi\n  done\n\n  # Create tab-delimited samples file.\n  printf \"%s\\t%s\\t%s\\t%s\\n\" \"${samples_array[sample]}\" \"${samples_array[sample]}_01\" \"${reads_1}\" \"${reads_2}\" \\\n  >> ${samples}\ndone\n\n# Create directory/sample list for ${trinity_matrix} command\ntrin_matrix_list=$(awk '{printf \"./%s%s\", $2, \"/quant.sf \" }' \"${samples}\")\n\n\n# Runs salmon and stranded library option\n${trinity_abundance} \\\n--transcripts ${transcriptome} \\\n--seqType fq \\\n--left reads_1.fq \\\n--right reads_2.fq \\\n--SS_lib_type RF \\\n--est_method salmon \\\n--samples_file \"${samples}\" \\\n--gene_trans_map \"${gene_map}\" \\\n--thread_count \"${threads}\" \\\n--output_dir \"${wd}\" \\\n1> ${salmon_stdout} \\\n2> ${salmon_stderr}\n\n\n# Convert abundance estimates to matrix\n${trinity_matrix} \\\n--est_method salmon \\\n--gene_trans_map ${gene_map} \\\n--out_prefix salmon \\\n--name_sample_by_basedir \\\n${trin_matrix_list} \\\n1> ${matrix_stdout} \\\n2> ${matrix_stderr}\n\n# Integrate functional Trinotate functional annotations\n\"${trinity_annotate_matrix}\" \\\n\"${trinotate_feature_map}\" \\\nsalmon.gene.counts.matrix \\\n> salmon.gene.counts.annotated.matrix\n\n# Clean up\nrm ./*trim*.gz\nrm ./*.fq\n\n\nRESULTS\nPretty quick, ~46mins:\n\n\n\nruntime salmon abundance estimates\n\n\nOutput folder:\n\n20200415_cbai_salmon_abundance/\n\nTranscript counts matrix (text):\n\n20200415_cbai_salmon_abundance/salmon.isoform.counts.matrix\n\nGene counts matrix (text):\n\n20200415_cbai_salmon_abundance/salmon.gene.counts.matrix\n\nAnnotated (Trinotate) gene counts matrix (text):\n\n20200415_cbai_salmon_abundance/salmon.gene.counts.annotated.matrix"
  },
  {
    "objectID": "posts/2020/2020-02-10-RNA-Isolation-and-Quantification---C.bairdi-RNA-from-Sample-6129_403_26/index.html",
    "href": "posts/2020/2020-02-10-RNA-Isolation-and-Quantification---C.bairdi-RNA-from-Sample-6129_403_26/index.html",
    "title": "RNA Isolation & Quantification - C.bairdi RNA from Sample 6129_403_26",
    "section": "",
    "text": "Since I was isolating gDNA from C.bairdi 6129_403_26 hemolymph, I figured I might as well co-isolate RNA since I was using the Quick DNA/RNA Microprep Plus Kit (ZymoResearch).\nFollowed the manufacturer’s protocol with the following notes/changes:\n\nUsed 480uL of sample, combined with 1:1 H2O (480uL), with 4:1 Lysis Buffer (3840uL) and mixed in 15mL conical\nFlow-through was retained in a 15mL conical for RNA isolation\nColumn began to clog during loading of the initial flow-through + EtOH mixture\nEluted with 15uL\n\nQuantified on the Roberts Lab Qubit 3.0 using the high-sensitivity RNA Assay (Invitrogen) and 1uL of sample.\n\n\nRESULTS\nQubit results (Google Sheet):\n\n20200210_qubit_crab_RNA\n\n[RNA] = 7.86ng/uL in 15uL\nYield = ~118ng\nYield is very, very low, considering the amount of starting material. Yield is likely due to clogging of column, due to overloading.\nSample was stored at -80oC in:\nRack 2, 3, 5 in Shellfish Box #8"
  },
  {
    "objectID": "posts/2020/2020-09-17-Data-Wrangling---C.bairdi-NanoPore-Quality-Filtering-Using-NanoFilt-on-Mox/index.html",
    "href": "posts/2020/2020-09-17-Data-Wrangling---C.bairdi-NanoPore-Quality-Filtering-Using-NanoFilt-on-Mox/index.html",
    "title": "Data Wrangling - C.bairdi NanoPore Quality Filtering Using NanoFilt on Mox",
    "section": "",
    "text": "I previously converting our C.bairdi NanoPre sequencing data from the raw Fast5 format to FastQ format for our three sets of data:\n\nC.bairdi-20102558-2729-Run-01\nC.bairdi-20102558-2729-Run-02\nC.bairdi-6129_403_26\n\nI visualized the data with NanoPlot on 20200914.\nIn preparation for an attempt at a de novo assembly, I decided to quality filter the sequencing data using NanoFilt. I semi-arbitrarily selected a quality score of 7 as the cutoff. This is primarily based on the fact that this value is the default used by ONT when you allow their software to automatically make basecalls and quality selections. Additionally, some of the visualizations of the raw sequencing reads show a bit of a bifurcation in quality above/below this quality score.\nThe job was run on Mox.\nSBATCH script (GitHub):\n\n20200917_cbai_nanofilt_nanopore-data.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_nanofilt_Q7_nanopore-data\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200917_cbai_nanofilt_Q7_nanopore-data\n\n\n\n\n###################################################################################\n# These variables need to be set by user\n\n# Load Anaconda\n# Uknown why this is needed, but Anaconda will not run if this line is not included.\n. \"/gscratch/srlab/programs/anaconda3/etc/profile.d/conda.sh\"\n\n\n# Activate the NanoPlot Anaconda environment\nconda activate nanofilt_2.6.0_env\n\n\n# Declare array\nraw_reads_dir_array=()\n\n# Paths to reads\nraw_reads_dir_array=(\n\"/gscratch/srlab/sam/data/C_bairdi/DNAseq/ont_FAL58500_04bb4d86_20102558-2729\" \\\n\"/gscratch/srlab/sam/data/C_bairdi/DNAseq/ont_FAL58500_94244ffd_20102558-2729\" \\\n\"/gscratch/srlab/sam/data/C_bairdi/DNAseq/ont_FAL86873_d8db260e_cbai_6129_403_26\"\n)\n\n# FastQ concatenation filename\nfastq_cat=20200917_cbai_nanopore_all.fastq\n\nfastq_filtered=20200917_cbai_nanopore_all_quality-7.fastq\n\n# Paths to programs\nnanofilt=NanoFilt\n\n# Set mean quality filter (integer)\nquality=7\n\n###################################################################################\n\n\n# Exit script if any command fails\nset -e\n\n# Inititalize array\nprograms_array=()\n\n# Programs array\nprograms_array=(\"${nanofilt}\")\n\n\n# Loop through NanoPore data directories\n# to run NanoPlot, FastQC, and MultiQC\nfor directory in \"${raw_reads_dir_array[@]}\"\ndo\n\n  # Find all FastQ files and concatenate into singel file\n  while IFS= read -r -d '' filename\n  do\n    # Concatenate all FastQ files into single file\n    # for NanoFilt and generate MD5 checksums\n    echo \"Now concatenating ${filename} to ${fastq_cat}...\"\n    cat \"${filename}\" >> ${fastq_cat}\n\n    # Create checksums file\n    echo \"Now generating checksum for ${filename}...\"\n    echo \"\"\n    md5sum \"${filename}\" >> fastq_checksums.md5\n\n  done < <(find \"${directory}\" -name \"*.fastq\" -type f -print0)\n\ndone\n\n# Generate MD5 checksum for concatenated FastQ file\necho \"Now generating checksum for ${fastq_cat}...\"\necho \"\"\nmd5sum \"${fastq_cat}\" >> fastq_checksums.md5\n\n# Run NanoFilt\n## Sets readtype to 1D (default)\n## Filters on mean quality >= 7 (ONT \"standard\")\n## FYI: seems to require piping stdin (i.e. cat fastq |)to NanoFilt...\necho \"Running ${programs_array[nanofilt]}\"\necho \"\"\ncat ${fastq_cat} \\\n| ${programs_array[nanofilt]} \\\n--readtype 1D \\\n--quality ${quality} \\\n> ${fastq_filtered}\necho \"${programs_array[nanofilt]} complete.\"\necho \"\"\n\n# Generate MD5 checksum for concatenated FastQ file\necho \"Now generating checksum for ${fastq_filtered}...\"\necho \"\"\nmd5sum \"${fastq_filtered}\" >> fastq_checksums.md5\n\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${programs_array[program]}: \"\n    echo \"\"\n    ${programs_array[program]} -h\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nRESULTS\nRuntime was short, ~5.5mins:\n\n\n\nNanoFilt runtime on C.bairdi Q7 filtered NanoPore reads\n\n\nOutput folder:\n\n20200917_cbai_nanofilt_Q7_nanopore-data/\n\nQ7 Filtered FastQ file (2.2GB):\n\n20200917_cbai_nanofilt_Q7_nanopore-data/20200917_cbai_nanopore_all_quality-7.fastq\n\nMD5 checksum:\n\n2f3b651bb0b875b0287e71e315cad59a\n\n\n\nWill use this data set for all downstream manipulations."
  },
  {
    "objectID": "posts/2020/2020-01-14-RNAseq-Reads-Extractions---C.bairdi-Taxonomic-Reads-Extractions-with-MEGAN6-on-swoose/index.html",
    "href": "posts/2020/2020-01-14-RNAseq-Reads-Extractions---C.bairdi-Taxonomic-Reads-Extractions-with-MEGAN6-on-swoose/index.html",
    "title": "RNAseq Reads Extractions - C.bairdi Taxonomic Reads Extractions with MEGAN6 on swoose",
    "section": "",
    "text": "I previously ran BLASTx and “meganized” the output DAA files on 20200103 (for reference, these include RNAseq data using a newly established “shorthand”: 2018, 2019) and now need to use MEGAN6 to bin the results into the proper taxonomies. This is accomplished using the MEGAN6 graphical user interface (GUI). This is how the process goes:\n\nFile > Import from BLAST…\nSelect all “meganized” DAA files for a given set of sequencing (e.g. 304428_S1_L001_R1_001.blastx.daa, 304428_S1_L001_R2_001.blastx.daa, 304428_S1_L002_R1_001.blastx.daa, 304428_S1_L001_R2_001.blastx.daa )\nCheck the “Paired Reads” box. (I don’t think this actually does anything, though…)\nClick “Next”\nCheck the “Analyze Taxonomy Content” box.\nClick “Load Accession mapping file” and find the mapping file used for “meganizing the DAA file”: prot_acc2tax-Jul2019X1.abin\nClick “Next”\nClick “Load Accession mapping file” and find the mapping file used for “meganizing the DAA file”: acc2eggnog-Jul2019X.abin\nClick “Next”\nClick “Load Accession mapping file” and find the mapping file used for “meganizing the DAA file”: acc2interpro-Jul2019X.abin\nClick “Next” twice, to advance to the “SEED” tab.\nClick “Load Accession mapping file” and find the mapping file used for “meganizing the DAA file”: acc2seed-May2015XX.abin\nClick “Next” twice, to advance to the “LCA Params” tab.\nClick “Apply”\n\nThis will initiate the import process and will create a special MEGAN file: RMA6.\nNOTE: This will take a long time and will require a significant amount of disk space! The final files aren’t ridiculously large, but the intermediate file that gets generated quickly becomes extremely large (i.e. hundreds of GB)!\nAfter that has completed, use the MEGAN6 GUI to “Open” the RMA6 file. Once the file loads, you will get a nice looking taxonomic tree! From here, you can select any part of the taxonomic tree by right-clicking on the desired taxonomy and “Extract reads…”. Here, you have the option to include “Summarized reads”. This option allows you to extract just the reads that are part of the exact classification you’ve selected or all those within and “below” the classification you’ve selected (i.e. summarized reads).\nExtracted reads will be generated as FastA files.\nExample:\nIf you select Arthropoda and do not check the box for “Summarized Reads” you will only get reads classified as Arthropoda! You will not get any reads with more specific taxonomies. However, if you select Arthropoda and you do check the box for “Summarized Reads”, you will get all reads classified as Arthropoda AND all reads in more specific taxonomic classifications, down to the species level.\nI will extract reads from two phyla:\n\nArthropoda (for crabs)\nAlveolata (for Hematodinium)\n\n\n\nRESULTS\nI put the RMA6 files in the original DIAMOND BLASTx/meganization folder from 20200103, as it seemed to make most sense organizational-wise to keep those together.\nOutput folder:\n\n20200103_cbai_diamond_blastx/\n\nI put the extracted reads (FastA) here:\n\n20200114_cbai_MEGAN_read_extractions/\n\nOne good thing to see was that the samples that were considered “uninfected” (based on PCR/qPCR data) had no reads classified as Alveolata (see samples 329775 and 329777 below).\n\n\nTaxonomic Trees\n\n304428\n\n\n\n304428 MEGAN6 taxonomic tree\n\n\n\n\n\n329774\n\n\n\n329774 MEGAN6 taxonomic tree\n\n\n\n\n\n329775\n\n\n\n329775 MEGAN6 taxonomic tree\n\n\n\n\n\n329776\n\n\n\n329776 MEGAN6 taxonomic tree\n\n\n\n\n\n329777\n\n\n\n329777 MEGAN6 taxonomic tree"
  },
  {
    "objectID": "posts/2020/2020-08-18-Trimming-FastQC-MultiQC---Robertos-C.gigas-WGBS-FastQ-Data-with-fastp-FastQC-and-MultiQC-on-Mox/index.html",
    "href": "posts/2020/2020-08-18-Trimming-FastQC-MultiQC---Robertos-C.gigas-WGBS-FastQ-Data-with-fastp-FastQC-and-MultiQC-on-Mox/index.html",
    "title": "Trimming-FastQC-MultiQC - Robertos C.gigas WGBS FastQ Data with fastp FastQC and MultiQC on Mox",
    "section": "",
    "text": "Steven asked me to trim Roberto’s C.gigas whole genome bisulfite sequencing (WGBS) reads (GitHub Issue) “following his methods”. The only thing specified is trimming Illumina adaptors and then trimming 10bp from the 5’ end of reads. No mention of which software was used.\nI opted to use fastp, due to its speed and built-in QC metrics/plots. Despite the built-in tools, I also ran FastQC and MultiQC, post-trimming to get a more comprehensive overview. Process was run on Mox.\nSBATCH script (GitHub):\n\n20200818_cgig_wgbs_roberto_fastp_trimming.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cgigas_fastp_trimming_roberto_wgbs\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200818_cgig_wgbs_roberto_fastp_trimming\n\n### Roberto's C.gigas WGBS trimming using fastp.\n\n\n###################################################################################\n# These variables need to be set by user\n\n# Set number of CPUs to use\nthreads=28\n\n# Input/output files\ntrimmed_checksums=trimmed_fastq_checksums.md5\nraw_reads_dir=/gscratch/srlab/sam/data/C_gigas/wgbs/\n\n# Paths to programs\nfastp=/gscratch/srlab/programs/fastp-0.20.0/fastp\nfastqc=/gscratch/srlab/programs/fastqc_v0.11.8/fastqc\nmultiqc=/gscratch/srlab/programs/anaconda3/bin/multiqc\n\n\n###################################################################################\n\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Capture date\ntimestamp=$(date +%Y%m%d)\n\n## Inititalize arrays\nfastq_array_R1=()\nfastq_array_R2=()\nprograms_array=()\nR1_names_array=()\nR2_names_array=()\n\n# Programs array\nprograms_array=(\"${fastp}\" \"${multiqc}\" \"${fastqc}\")\n\n\n# Sync raw FastQ files to working directory\nrsync --archive --verbose \\\n\"${raw_reads_dir}\"[035]*.fastq.gz .\n\n\n# Create array of fastq R1 files\nfor fastq in *R1*.gz\ndo\n  fastq_array_R1+=(\"${fastq}\")\ndone\n\n# Create array of fastq R2 files\nfor fastq in *R2*.gz\ndo\n  fastq_array_R2+=(\"${fastq}\")\ndone\n\n\n# Create array of sample names\n## Uses awk to parse out sample name from filename\nfor R1_fastq in *R1*.gz\ndo\n  R1_names_array+=($(echo \"${R1_fastq}\" | awk -F\"_\" '{print $1}'))\ndone\n\n# Create array of sample names\n## Uses awk to parse out sample name from filename\nfor R2_fastq in *R2*.gz\ndo\n  R2_names_array+=($(echo \"${R2_fastq}\" | awk -F\"_\" '{print $1}'))\ndone\n\n# Create list of fastq files used in analysis\nfor fastq in *.gz\ndo\n  echo \"${fastq}\" >> fastq.list.txt\ndone\n\n# Run fastp on files\n# Trim 10bp from 5' from each read\nfor fastq in \"${!fastq_array_R1[@]}\"\ndo\n  R1_sample_name=$(echo \"${R1_names_array[fastq]}\")\n    R2_sample_name=$(echo \"${R2_names_array[fastq]}\")\n    ${fastp} \\\n    --in1 \"${fastq_array_R1[fastq]}\" \\\n    --in2 \"${fastq_array_R2[fastq]}\" \\\n    --detect_adapter_for_pe \\\n  --trim_front1 10 \\\n  --trim_front2 10 \\\n    --thread ${threads} \\\n    --html \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".report.html \\\n    --json \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".report.json \\\n    --out1 \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz \\\n    --out2 \"${R2_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz\n\n    # Generate md5 checksums for newly trimmed files\n    {\n        md5sum \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz\n        md5sum \"${R2_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz\n    } >> \"${trimmed_checksums}\"\n\n    # Run FastQC\n    ${fastqc} --threads ${threads} \\\n    \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz \\\n    \"${R2_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz\n\n    # Remove original FastQ files\n    rm \"${fastq_array_R1[fastq]}\" \"${fastq_array_R2[fastq]}\"\ndone\n\n\n\n# Run MultiQC\n${multiqc} .\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${programs_array[program]}: \"\n    echo \"\"\n    ${programs_array[program]} -h\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nRESULTS\nActually took longer than I expected; ~3.5hrs:\n\n\n\nfastp trimming runtime\n\n\nOutput folder:\n\n20200818_cgig_wgbs_roberto_fastp_trimming/\n\nTrimmed files can be found with this pattern: *fastp-trim*.fq.gz\n\n\nMultiQC Report (HTML):\n\n20200818_cgig_wgbs_roberto_fastp_trimming/multiqc_report.html\n\nNOTE: Report contains summaries from both fastp and FastQC results\nEach trimmed file has a corresponding *_fastqc.html"
  },
  {
    "objectID": "posts/2020/2020-08-14-Transcriptome-Assessment---BUSCO-Metazoa-on-Hematodinium-v1.6-v1.7-v2.1-and-v3.1-on-Mox/index.html",
    "href": "posts/2020/2020-08-14-Transcriptome-Assessment---BUSCO-Metazoa-on-Hematodinium-v1.6-v1.7-v2.1-and-v3.1-on-Mox/index.html",
    "title": "Transcriptome Assessment - BUSCO Metazoa on Hematodinium v1.6 v1.7 v2.1 and v3.1 on Mox",
    "section": "",
    "text": "Needed to assess the Hematodinium sp. transcriptomes that I’ve assembled to determine their “completeness” using BUSCO.\n\nhemat_transcriptome_v1.6.fasta (4.5MB; from 20210308)\nhemat_transcriptome_v1.7.fasta (1.9MB; from 20210308)\nhemat_transcriptome_v2.1.fasta (65MB; from 20200605)\nhemat_transcriptome_v3.1.fasta (65MB; from 20200605)\n\nAll of the above transcriptomes were assembled with different combinations of the crab RNAseq data we generated. Here’s a link to an overview of the various assemblies:\n\nhemat_transcriptome_comp (Google Sheet)\n\nSBATCH script (GitHub):\n\n20200814_hemat_busco_transcriptomes_v1.6_v1.7_v2.1_v.3.1.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_busco_megan_transcriptomes\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=3-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200814_hemat_busco_transcriptomes_v1.6_v1.7_v2.1_v.3.1\n\n###################################################################################\n# These variables need to be set by user\n\n## Save working directory\nwd=$(pwd)\n\n# Establish variables for more readable code\ntranscriptomes_dir=/gscratch/srlab/sam/data/Hematodinium/transcriptomes\n\n# Array of the various comparisons to evaluate\n# Each condition in each comparison should be separated by a \"-\"\ntranscriptomes_array=(\n\"${transcriptomes_dir}\"/hemat_transcriptome_v1.6.fasta \\\n\"${transcriptomes_dir}\"/hemat_transcriptome_v1.7.fasta \\\n\"${transcriptomes_dir}\"/hemat_transcriptome_v2.1.fasta \\\n\"${transcriptomes_dir}\"/hemat_transcriptome_v3.1.fasta\n)\n\n\n\n## Input files and settings\nbusco_db=/gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9\naugustus_species=fly\nthreads=28\n\n# Programs array\ndeclare -A programs_array\nprograms_array=(\n[busco]=\"/gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py\"\n)\n\n\n## Set program paths\naugustus_bin=/gscratch/srlab/programs/Augustus-3.3.2/bin\naugustus_orig_config_dir=/gscratch/srlab/programs/Augustus-3.3.2/config\naugustus_scripts=/gscratch/srlab/programs/Augustus-3.3.2/scripts\nblast_dir=/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin/\nhmm_dir=/gscratch/srlab/programs/hmmer-3.2.1/src/\n\n# Export Augustus variable\nexport PATH=\"${augustus_bin}:$PATH\"\nexport PATH=\"${augustus_scripts}:$PATH\"\n\n## BUSCO configs\nbusco_config_default=/gscratch/srlab/programs/busco-v3/config/config.ini.default\nbusco_config_ini=${wd}/config.ini\n\n# Export BUSCO config file location\nexport BUSCO_CONFIG_FILE=\"${busco_config_ini}\"\n\n# Copy BUSCO config file\ncp ${busco_config_default} \"${busco_config_ini}\"\n\n# Edit BUSCO config file\n## Set paths to various programs\n### The use of the % symbol sets the delimiter sed uses for arguments.\n### Normally, the delimiter that most examples use is a slash \"/\".\n### But, we need to expand the variables into a full path with slashes, which screws up sed.\n### Thus, the use of % symbol instead (it could be any character that is NOT present in the expanded variable; doesn't have to be \"%\").\nsed -i \"/^;cpu/ s/1/${threads}/\" \"${busco_config_ini}\"\nsed -i \"/^tblastn_path/ s%tblastn_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^makeblastdb_path/ s%makeblastdb_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^augustus_path/ s%augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^etraining_path/ s%etraining_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^gff2gbSmallDNA_path/ s%gff2gbSmallDNA_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^new_species_path/ s%new_species_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^optimize_augustus_path/ s%optimize_augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^hmmsearch_path/ s%hmmsearch_path = /home/osboxes/BUSCOVM/hmmer/hmmer-3.1b2-linux-intel-ia32/binaries/%path = ${hmm_dir}%\" \"${busco_config_ini}\"\n\n###################################################################################\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Load Open MPI module for parallel, multi-node processing\nmodule load icc_19-ompi_3.1.2\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\nfor transcriptome in \"${!transcriptomes_array[@]}\"\ndo\n\n  # Remove path from transcriptome using parameter substitution\n  transcriptome_name=\"${transcriptomes_array[$transcriptome]##*/}\"\n\n  ## Augustus config directories\n  augustus_dir=${wd}/${transcriptome_name}_augustus\n  augustus_config_dir=${augustus_dir}/config\n\n\n  export AUGUSTUS_CONFIG_PATH=\"${augustus_config_dir}\"\n\n\n  # Make Augustus directory if it doesn't exist\n  if [ ! -d \"${augustus_dir}\" ]; then\n    mkdir --parents \"${augustus_dir}\"\n  fi\n\n  # Copy Augustus config directory\n  cp --preserve -r ${augustus_orig_config_dir} \"${augustus_dir}\"\n\n\n  # Run BUSCO/Augustus training\n  ${programs_array[busco]} \\\n  --in ${transcriptomes_array[$transcriptome]} \\\n  --out ${transcriptome_name} \\\n  --lineage_path ${busco_db} \\\n  --mode transcriptome \\\n  --cpu ${threads} \\\n  --long \\\n  --species ${augustus_species} \\\n  --tarzip \\\n  --augustus_parameters='--progress=true'\n\n  # Capture FastA checksums for verification\n  cho \"\"\n  echo \"Generating checksum for ${transcriptome_name}\"\n  md5sum \"${transcriptomes_array[$transcriptome]}\" > \"${transcriptome_name}\".checksum.md5\n  echo \"Finished generating checksum for ${transcriptome_name}\"\n  echo \"\"\n\ndone\n\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n    ${programs_array[$program]} --help\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n\nRESULTS\nJust under 7mins to assess the four transcriptomes:\n\n\n\nBUSCO runtime\n\n\nOutput folder:\n\n20200814_hemat_busco_transcriptomes_v1.6_v1.7_v2.1_v.3.1/\n\nAll data below has been added to a transcriptome comparison spreadsheet:\n\nhemat_transcriptome_comp (Google Sheet)\n\n\nhemat_transcriptome_v1.6.fasta BUSCO Short Summary\n\n20200814_hemat_busco_transcriptomes_v1.6_v1.7_v2.1_v.3.1/run_hemat_transcriptome_v1.6.fasta/short_summary_hemat_transcriptome_v1.6.fasta.txt\n\n# BUSCO version is: 3.0.2\n# The lineage dataset is: metazoa_odb9 (Creation date: 2016-02-13, number of species: 65, number of BUSCOs: 978)\n# To reproduce this run: python /gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py -i /gscratch/srlab/sam/data/Hematodinium/transcriptomes/hemat_transcriptome_v1.6.fasta -o hemat_transcriptome_v1.6.fasta -l /gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9/ -m transcriptome -c 28 --long -z\n#\n# Summarized benchmarking in BUSCO notation for file /gscratch/srlab/sam/data/Hematodinium/transcriptomes/hemat_transcriptome_v1.6.fasta\n# BUSCO was run in mode: transcriptome\n\n    C:26.5%[S:20.7%,D:5.8%],F:11.2%,M:62.3%,n:978\n\n    259 Complete BUSCOs (C)\n    202 Complete and single-copy BUSCOs (S)\n    57  Complete and duplicated BUSCOs (D)\n    110 Fragmented BUSCOs (F)\n    609 Missing BUSCOs (M)\n    978 Total BUSCO groups searched\n\n\nhemat_transcriptome_v1.7.fasta BUSCO Short Summary\n\nhttps://gannet.fish.washington.edu/Atumefaciens/20200814_hemat_busco_transcriptomes_v1.6_v1.7_v2.1_v.3.1/run_hemat_transcriptome_v1.7.fasta/short_summary_hemat_transcriptome_v1.7.fasta.txt\n\n# BUSCO version is: 3.0.2\n# The lineage dataset is: metazoa_odb9 (Creation date: 2016-02-13, number of species: 65, number of BUSCOs: 978)\n# To reproduce this run: python /gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py -i /gscratch/srlab/sam/data/Hematodinium/transcriptomes/hemat_transcriptome_v1.7.fasta -o hemat_transcriptome_v1.7.fasta -l /gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9/ -m transcriptome -c 28 --long -z\n#\n# Summarized benchmarking in BUSCO notation for file /gscratch/srlab/sam/data/Hematodinium/transcriptomes/hemat_transcriptome_v1.7.fasta\n# BUSCO was run in mode: transcriptome\n\n    C:15.0%[S:12.2%,D:2.8%],F:12.3%,M:72.7%,n:978\n\n    146 Complete BUSCOs (C)\n    119 Complete and single-copy BUSCOs (S)\n    27  Complete and duplicated BUSCOs (D)\n    120 Fragmented BUSCOs (F)\n    712 Missing BUSCOs (M)\n    978 Total BUSCO groups searched\n\n\nhemat_transcriptome_v2.1.fasta BUSCO Short Summary\n\nhttps://gannet.fish.washington.edu/Atumefaciens/20200814_hemat_busco_transcriptomes_v1.6_v1.7_v2.1_v.3.1/run_hemat_transcriptome_v2.1.fasta/short_summary_hemat_transcriptome_v2.1.fasta.txt\n\n# BUSCO version is: 3.0.2\n# The lineage dataset is: metazoa_odb9 (Creation date: 2016-02-13, number of species: 65, number of BUSCOs: 978)\n# To reproduce this run: python /gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py -i /gscratch/srlab/sam/data/Hematodinium/transcriptomes/hemat_transcriptome_v2.1.fasta -o hemat_transcriptome_v2.1.fasta -l /gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9/ -m transcriptome -c 28 --long -z\n#\n# Summarized benchmarking in BUSCO notation for file /gscratch/srlab/sam/data/Hematodinium/transcriptomes/hemat_transcriptome_v2.1.fasta\n# BUSCO was run in mode: transcriptome\n\n    C:33.7%[S:6.2%,D:27.5%],F:2.9%,M:63.4%,n:978\n\n    330 Complete BUSCOs (C)\n    61  Complete and single-copy BUSCOs (S)\n    269 Complete and duplicated BUSCOs (D)\n    28  Fragmented BUSCOs (F)\n    620 Missing BUSCOs (M)\n    978 Total BUSCO groups searched\n\n\nhemat_transcriptome_v3.1.fasta BUSCO Short Summary\n\nhttps://gannet.fish.washington.edu/Atumefaciens/20200814_hemat_busco_transcriptomes_v1.6_v1.7_v2.1_v.3.1/run_hemat_transcriptome_v3.1.fasta/short_summary_hemat_transcriptome_v3.1.fasta.txt\n\n# BUSCO version is: 3.0.2\n# The lineage dataset is: metazoa_odb9 (Creation date: 2016-02-13, number of species: 65, number of BUSCOs: 978)\n# To reproduce this run: python /gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py -i /gscratch/srlab/sam/data/Hematodinium/transcriptomes/hemat_transcriptome_v3.1.fasta -o hemat_transcriptome_v3.1.fasta -l /gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9/ -m transcriptome -c 28 --long -z\n#\n# Summarized benchmarking in BUSCO notation for file /gscratch/srlab/sam/data/Hematodinium/transcriptomes/hemat_transcriptome_v3.1.fasta\n# BUSCO was run in mode: transcriptome\n\n    C:34.3%[S:6.3%,D:28.0%],F:3.2%,M:62.5%,n:978\n\n    336 Complete BUSCOs (C)\n    62  Complete and single-copy BUSCOs (S)\n    274 Complete and duplicated BUSCOs (D)\n    31  Fragmented BUSCOs (F)\n    611 Missing BUSCOs (M)\n    978 Total BUSCO groups searched"
  },
  {
    "objectID": "posts/2020/2020-10-13-Data-Wrangling---C.bairdi-NanoPore-Reads-Extractions-With-Seqtk-on-Mephisto/index.html",
    "href": "posts/2020/2020-10-13-Data-Wrangling---C.bairdi-NanoPore-Reads-Extractions-With-Seqtk-on-Mephisto/index.html",
    "title": "Data Wrangling - C.bairdi NanoPore Reads Extractions With Seqtk on Mephisto",
    "section": "",
    "text": "In my pursuit to identify which contigs/scaffolds of our “C.bairdi” genome assembly from 20200917 correspond to interesting taxa, based on taxonomic assignments produced by MEGAN6 on 20200928, I used MEGAN6 to extract taxa-specific reads from cbai_genome_v1.01 on 20201007 - the output is only available in FastA format. Since I want the original reads in FastQ format, I will use the FastA sequence IDs (from the FastA index file) and provide that to seqtk to extract the FastQ reads for each sample and corresponding taxa.\nThis was run on my personal computer (mephisto) and documented in a Jupyter Notebook:\nJupyter Notebook (GitHub):\n\n20201013_mephisto_cbai_seqtk_megan-fastq-read-extractions.ipynb\n\n\n\nRESULTS\nOutput folders/files:\n\nFastQ files end with the .fq suffix.\nThe ID list supplied to seqtk ends with the suffix seqtk-read-id-list. It is a simple text file.\n\n\n201002558-2729-Q7 (Hematodinium-free C.bairdi muscle)\n\n20201013_201002558-2729-Q7_megan-reads/\n\n20201013_201002558-2729-Q7_Aquifex_sp_megan.fq\n20201013_201002558-2729-Q7_Aquifex_sp_seqtk-read-id-list\n20201013_201002558-2729-Q7_Arthropoda_megan.fq\n20201013_201002558-2729-Q7_Arthropoda_seqtk-read-id-list\n20201013_201002558-2729-Q7_Enterospora_canceri_megan.fq\n20201013_201002558-2729-Q7_Enterospora_canceri_seqtk-read-id-list\n20201013_201002558-2729-Q7_Sar_megan.fq\n20201013_201002558-2729-Q7_Sar_seqtk-read-id-list\n\n\n\n\n6129-403-26-Q7 (Hematodinium-infected C.bairdi hemolymph)\n\n20201013_6129-403-26-Q7_megan-reads/\n\n20201013_6129-403-26-Q7_Alveolata_megan.fq\n20201013_6129-403-26-Q7_Alveolata_seqtk-read-id-list\n20201013_6129-403-26-Q7_Aquifex_sp_megan.fq\n20201013_6129-403-26-Q7_Aquifex_sp_seqtk-read-id-list\n20201013_6129-403-26-Q7_Arthropoda_megan.fq\n20201013_6129-403-26-Q7_Arthropoda_seqtk-read-id-list\n20201013_6129-403-26-Q7_Enterospora_canceri_megan.fq\n20201013_6129-403-26-Q7_Enterospora_canceri_seqtk-read-id-list\n\n\nNext up, use Minimap2 to map these reads to the cbai_genome_v1.01.fasta (18MB). After that’s complete I want to see which contigs/scaffolds generated in the assembly using Flye on 20200917 have reads mapped to them by each of the taxa.\nAdmittedly, I’m not entirely sure where I’m going with this, or if there’s even a point any more. However, it’s an interesting exercise in bioinformatics stuff (new tools/software, data “munging” practice)."
  },
  {
    "objectID": "posts/2020/2020-10-27-DNA-Shearing---M.magister-gDNA-Additional-Shearing-CH05-01_21-CH07-11-and-Bioanalyzer/index.html",
    "href": "posts/2020/2020-10-27-DNA-Shearing---M.magister-gDNA-Additional-Shearing-CH05-01_21-CH07-11-and-Bioanalyzer/index.html",
    "title": "DNA Shearing - M.magister gDNA Additional Shearing CH05-01_21 CH07-11 and Bioanalyzer",
    "section": "",
    "text": "After shearing all of the M.magister gill gDNA on 20201026, there were still three samples that still had average fragment lengths that were a bit longer than desired (~750bp, but want ~250 - 550bp):\n\nCH05-01\nCH05-21\nCH07-11\n\nI initially chose to run them on the sonicator (Bioruptor 300; Diagenode) for two successive rounds of 5 cycles (30s ON, 30s OFF; low intensity). This proved to be insufficient (see RESULTS section below), so I ran three additional successive rounds of 5 cycles (30s ON, 30s OFF; low intensity).\nThe original samples used 1ug of DNA in a volume of 51uL (this volume was selected to simplify downstream calculations, after using 1uL for the Bioanalyzer after shearing), using 0.65mL prelubricated snap cap tubes (Costar; Cat# 3206). Have ended up using a total of 3uL (includes two rounds of Bioanalyzer from today’s assays), leaving these three samples with a volume of 48uL.\nPost-sonication/shearing, samples were run on High Sensitivity DNA Assay chips in the Bioanalyzer 2100 (Agilent).\nAll samples and volumes used are listed in the following Google Sheet (originally provided by Mackenzie Gavery):\n\nOA Crab Sample Collection 071119\n\n\n\nRESULTS\nOutput folder:\n\n20201027_mmag_bioanazlyer_CH05-01-21_CH07-11/\n\nBioanalyzer files (XAD; require 2100 Expert software to open):\n- [2100 expert_High Sensitivity DNA Assay_DE72902486_2020-10-27_06-28-10.xad](https://gannet.fish.washington.edu/Atumefaciens/20201027_mmag_bioanazlyer_CH05-01-21_CH07-11/2100 expert_High Sensitivity DNA Assay_DE72902486_2020-10-27_06-28-10.xad)\n\n- [2100 expert_High Sensitivity DNA Assay_DE72902486_2020-10-27_07-41-41.xad](https://gannet.fish.washington.edu/Atumefaciens/20201027_mmag_bioanazlyer_CH05-01-21_CH07-11/2100 expert_High Sensitivity DNA Assay_DE72902486_2020-10-27_07-41-41.xad)\n\n\nImages of all electropherograms (shown in a single image), as well as individual sample electropherograms, are beneath the discussion that follows.\nI initially sheared the samples for an additional 10 cycles and the average fragment lengths of all three samples was still ~750bp; still a bit longer than desired. So I sheared all three samples for an additional 15 cycles (in successive 5 cycle runs).\nSamples CH05-01 and CH05-21 looked great after these additional 15 cycles.\nSample CH07-11 is still a bit stubborn, but the mean fragment length is ~640bp. A tad long still, but I think it’s acceptable.\nWill proceed with MDB enrichment using the MethylMiner Kit (Invitrogen) tomorrow.\n\nSamples sheared on 20201026 + 10 additional cycles:\n\nAll samples\n\n\n\nSheared 20201026+10-cycles Bioanalyzer electropherogram - all samples\n\n\n\n\nCH05-01\n\n\n\nSheared CH05-01 Bioanalyzer electropherogram\n\n\n\n\nCH05-21\n\n\n\nSheared CH05-21 Bioanalyzer electropherogram\n\n\n\n\nCH07-11\n\n\n\nSheared CH07-11 Bioanalyzer electropherogram\n\n\n\nSamples sheared on 20201026 + 10 cycles + 15 additional cycles:\n\n\nAll samples\n\n\n\nSheared sheared-20201026+10+15-cycles Bioanalyzer electropherogram\n\n\n\n\nCH05-01\n\n\n\nSheared CH05-01 Bioanalyzer electropherogram\n\n\n\n\nCH05-21\n\n\n\nSheared CH05-21 Bioanalyzer electropherogram\n\n\n\n\nCH07-11\n\n\n\nSheared CH07-11 Bioanalyzer electropherogram"
  },
  {
    "objectID": "posts/2020/2020-01-23-Transdecoder---Hematodinium-MEGAN6-Taxonomic-Specific-Reads-Assembly-from-20200122/index.html",
    "href": "posts/2020/2020-01-23-Transdecoder---Hematodinium-MEGAN6-Taxonomic-Specific-Reads-Assembly-from-20200122/index.html",
    "title": "Transdecoder - Hematodinium MEGAN6 Taxonomic-Specific Reads Assembly from 20200122",
    "section": "",
    "text": "Ran Trinity to de novo assembly on the the C.bairdi MEGAN6 taxonomic-specific RNAseq data on 201200122 and now will begin annotating the transcriptome using TransDecoder on Mox.\nSBATCH script (GitHub):\n\n20200123_hemat_transdecoder_megan.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=transdecoder_hemat\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200123_hemat_transdecoder_megan\n\n\n# Exit script if a command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# Set workind directory as current directory\nwd=\"$(pwd)\"\n\n# Capture date as YYYYMMDD\ntimestamp=$(date +%Y%m%d)\n\n# Set input file locations and species designation\ntrinity_fasta=\"/gscratch/srlab/sam/data/Hematodinium/transcriptomes/20200122.hemat.megan.Trinity.fasta\"\ntrinity_gene_map=\"/gscratch/srlab/sam/data/Hematodinium/transcriptomes/20200122.hemat.megan.Trinity.fasta.gene_trans_map\"\nspecies=\"hemat\"\n\n# Capture trinity file name\ntrinity_fasta_name=${trinity_fasta##*/}\n\n\n\n# Paths to input/output files\nblastp_out_dir=\"${wd}/blastp_out\"\ntransdecoder_out_dir=\"${wd}/${trinity_fasta_name}.transdecoder_dir\"\npfam_out_dir=\"${wd}/pfam_out\"\nblastp_out=\"${blastp_out_dir}/${timestamp}.${species}.blastp.outfmt6\"\npfam_out=\"${pfam_out_dir}/${timestamp}.${species}.pfam.domtblout\"\nlORFs_pep=\"${transdecoder_out_dir}/longest_orfs.pep\"\npfam_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/Pfam-A.hmm\"\nsp_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/uniprot_sprot.pep\"\n\n\n\n# Paths to programs\nblast_dir=\"/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin\"\nblastp=\"${blast_dir}/blastp\"\nhmmer_dir=\"/gscratch/srlab/programs/hmmer-3.2.1/src\"\nhmmscan=\"${hmmer_dir}/hmmscan\"\ntransdecoder_dir=\"/gscratch/srlab/programs/TransDecoder-v5.5.0\"\ntransdecoder_lORFs=\"${transdecoder_dir}/TransDecoder.LongOrfs\"\ntransdecoder_predict=\"${transdecoder_dir}/TransDecoder.Predict\"\n\n# Make output directories\nmkdir \"${blastp_out_dir}\"\nmkdir \"${pfam_out_dir}\"\n\n# Extract long open reading frames\n\"${transdecoder_lORFs}\" \\\n--gene_trans_map \"${trinity_gene_map}\" \\\n-t \"${trinity_fasta}\"\n\n# Run blastp on long ORFs\n\"${blastp}\" \\\n-query \"${lORFs_pep}\" \\\n-db \"${sp_db}\" \\\n-max_target_seqs 1 \\\n-outfmt 6 \\\n-evalue 1e-5 \\\n-num_threads 28 \\\n> \"${blastp_out}\"\n\n# Run pfam search\n\"${hmmscan}\" \\\n--cpu 28 \\\n--domtblout \"${pfam_out}\" \\\n\"${pfam_db}\" \\\n\"${lORFs_pep}\"\n\n# Run Transdecoder with blastp and Pfam results\n\"${transdecoder_predict}\" \\\n-t \"${trinity_fasta}\" \\\n--retain_pfam_hits \"${pfam_out}\" \\\n--retain_blastp_hits \"${blastp_out}\"\n\n\nRESULTS\nRuntime was a ~55mins:\n\n\n\nTransdecoder runtime\n\n\nOutput folder:\n\n20200123_hemat_transdecoder_megan/\n\nCoding Sequences (FastA):\n\n20200123_hemat_transdecoder_megan/20200122.hemat.megan.Trinity.fasta.transdecoder.cds\n\nPeptide Sequences (FastA):\n\n20200123_hemat_transdecoder_megan/20200122.hemat.megan.Trinity.fasta.transdecoder.pep\n\nBLASTp output (tab):\n\n20200123_hemat_transdecoder_megan/blastp_out/20200123.hemat.blastp.outfmt6\n\nPfam output:\n\n20200123_hemat_transdecoder_megan/pfam_out/20200123.hemat.pfam.domtblout\n\nWill get ready to run Trinotate with these output files."
  },
  {
    "objectID": "posts/2020/2020-03-11-NanoPore-Sequencing---C.bairdi-gDNA-6129_403_26/index.html",
    "href": "posts/2020/2020-03-11-NanoPore-Sequencing---C.bairdi-gDNA-6129_403_26/index.html",
    "title": "NanoPore Sequencing - C.bairdi gDNA 6129_403_26",
    "section": "",
    "text": "After getting high quality gDNA from Hematodinium-infected C.bairdi hemolymph on 2020210 we decided to run some of the sample on the NanoPore MinION, since the flowcells have a very short shelf life. Additionally, the results from this will also help inform us on whether this sample might worth submitting for PacBio sequencing. And, of course, this provides us with additional sequencing data to complement our previous NanoPore runs from 20200109.\nThe sample DNA was prepared according to the protocol for the Rapid Sequencing Kit (SQK-RAD004) and run on a FLO-MIN106 (ID: FAL86873) flowcell. Data acquisition was set to run without basecalling for a period of 48hrs. This will make sure the raw Fast5 output files will be preserved (not sure if they’re saved or not when basecalling is enabled), but will require conversion to FastQ at a later date.\n\n\nRESULTS\nOutput folder:\n\n20200311_cbai_nanopore_6129_403_26/\n\nFast5 directory:\n\n20200311_cbai_nanopore_6129_403_26/cbai_6129_403_26/20200311_1343_MN29908_FAL86873_d8db260e/fast5/\n\nRun report (PDF):\n\n20200311_cbai_nanopore_6129_403_26/cbai_6129_403_26/20200311_1343_MN29908_FAL86873_d8db260e/d8db260e-6ed1-43ce-8d8e-c03a376d4cb1–report.pdf\n\n\n\n\ncbai nanopore cumulative read plots\n\n\n\n\n\ncbai nanopore read length histograms\n\n\nWell, the data looks fine to me, but I don’t have much to compare to. Compared to our previous run (which had degraded gDNA as an input), this is certainly a significant improvement:\n\n~7x the total number of reads\n~30x the total number of bases\n~4x the N50\n\nWill get the data converted to FastQ for downstream handling."
  },
  {
    "objectID": "posts/2020/2020-10-26-DNA-Shearing---M.magister-gDNA-Shearing-All-Samples-and-Bioanalyzer/index.html",
    "href": "posts/2020/2020-10-26-DNA-Shearing---M.magister-gDNA-Shearing-All-Samples-and-Bioanalyzer/index.html",
    "title": "DNA Shearing - M.magister gDNA Shearing All Samples and Bioanalyzer",
    "section": "",
    "text": "I previously ran some shearing tests on 20201022 to determine how many cycles to run on the sonicator (Bioruptor 300; Diagenode) to achieve an average fragment length of ~350 - 500bp in preparation for MBD-BSseq. The determination was 70 cycles (30s ON, 30s OFF; low intensity), sonicating for 35 cycles, followed by successive rounds of 5 cycles each.\nI used 1ug of DNA in a volume of 51uL (this volume was selected to simplify downstream calculations, after using 1uL for the Bioanalyzer after shearing), using 0.65mL prelubricated snap cap tubes (Costar; Cat# 3206).\nPost-sonication/shearing, samples were run on High Sensitivity DNA Assay chips in the Bioanalyzer 2100 (Agilent).\nAll samples and volumes used are listed in the following Google Sheet (originally provided by Mackenzie Gavery):\n\nOA Crab Sample Collection 071119\n\n\n\nRESULTS\nOutput folder:\n\n20201026_mmag_bioanalyzer_all-samples\n\nBioanalyzer files (XAD; require 2100 Expert software to open):\n- [2100 expert_High Sensitivity DNA Assay_DE72902486_2020-10-26_07-43-19.xad](https://gannet.fish.washington.edu/Atumefaciens/20201026_mmag_bioanalyzer_all-samples/2100 expert_High Sensitivity DNA Assay_DE72902486_2020-10-26_07-43-19.xad)\n\n- [2100 expert_High Sensitivity DNA Assay_DE72902486_2020-10-26_10-22-41.xad](https://gannet.fish.washington.edu/Atumefaciens/20201026_mmag_bioanalyzer_all-samples/2100 expert_High Sensitivity DNA Assay_DE72902486_2020-10-26_10-22-41.xad)\n\n- [2100 expert_High Sensitivity DNA Assay_DE72902486_2020-10-26_11-09-26.xad](https://gannet.fish.washington.edu/Atumefaciens/20201026_mmag_bioanalyzer_all-samples/2100 expert_High Sensitivity DNA Assay_DE72902486_2020-10-26_11-09-26.xad)\n\n\nImages of all electropherograms (shown in a single image), as well as individual sample electropherograms, are beneath the discussion that follows.\nOverall, most samples look pretty good and fall within a range of ~250 - 550bp, which is acceptable for library prep. Admittedly, some of those on the lower end will likely end up having overlapping reads (assuming we sequence >100bp paired ends), but the software we use should easily handle these overlaps.\nThere are three samples that need additional sonication:\n\nCH05-01\nCH05-21\nCH07-11\n\nI will perform additional round of sonication these tomorrow.\n\nall-01\n\n\n\nSheared all-01 Bioanalyzer electropherogram\n\n\n\n\nall-02\n\n\n\nSheared all-02 Bioanalyzer electropherogram\n\n\n\n\nall-03\n\n\n\nSheared all-03 Bioanalyzer electropherogram\n\n\n\n\nCH01-06\n\n\n\nSheared CH01-06 Bioanalyzer electropherogram\n\n\n\n\nCH01-14\n\n\n\nSheared CH01-14 Bioanalyzer electropherogram\n\n\n\n\nCH01-22\n\n\n\nSheared CH01-22 Bioanalyzer electropherogram\n\n\n\n\nCH01-38\n\n\n\nSheared CH01-38 Bioanalyzer electropherogram\n\n\n\n\nCH03-04\n\n\n\nSheared CH03-04 Bioanalyzer electropherogram\n\n\n\n\nCH03-15\n\n\n\nSheared CH03-15 Bioanalyzer electropherogram\n\n\n\n\nCH03-33\n\n\n\nSheared CH03-33 Bioanalyzer electropherogram\n\n\n\n\nCH05-01\n\n\n\nSheared CH05-01 Bioanalyzer electropherogram\n\n\n\n\nCH05-06\n\n\n\nSheared CH05-06 Bioanalyzer electropherogram\n\n\n\n\nCH05-21\n\n\n\nSheared CH05-21 Bioanalyzer electropherogram\n\n\n\n\nCH05-24\n\n\n\nSheared CH05-24 Bioanalyzer electropherogram\n\n\n\n\nCH05-26\n\n\n\nSheared CH05-26 Bioanalyzer electropherogram\n\n\n\n\nCH07-06\n\n\n\nSheared CH07-06 Bioanalyzer electropherogram\n\n\n\n\nCH07-11\n\n\n\nSheared CH07-11 Bioanalyzer electropherogram\n\n\n\n\nCH07-24\n\n\n\nSheared CH07-24 Bioanalyzer electropherogram\n\n\n\n\nCH09-02\n\n\n\nSheared CH09-02 Bioanalyzer electropherogram\n\n\n\n\nCH09-11\n\n\n\nSheared CH09-11 Bioanalyzer electropherogram\n\n\n\n\nCH09-13\n\n\n\nSheared CH09-13 Bioanalyzer electropherogram\n\n\n\n\nCH09-28\n\n\n\nSheared CH09-28 Bioanalyzer electropherogram\n\n\n\n\nCH09-29\n\n\n\nSheared CH09-29 Bioanalyzer electropherogram\n\n\n\n\nCH10-01\n\n\n\nSheared CH10-01 Bioanalyzer electropherogram\n\n\n\n\nCH10-08\n\n\n\nSheared CH10-08 Bioanalyzer electropherogram\n\n\n\n\nCH10-11\n\n\n\nSheared CH10-11 Bioanalyzer electropherogram\n\n\n\n\nCH10-19\n\n\n\nSheared CH10-19 Bioanalyzer electropherogram"
  },
  {
    "objectID": "posts/2020/2020-04-29-Transcript-Abundance---C.bairdi-Alignment-free-with-Salmon-Using-2020-GW-Data-on-Mox/index.html",
    "href": "posts/2020/2020-04-29-Transcript-Abundance---C.bairdi-Alignment-free-with-Salmon-Using-2020-GW-Data-on-Mox/index.html",
    "title": "Transcript Abundance - C.bairdi Alignment-free with Salmon Using 2020-GW Data on Mox",
    "section": "",
    "text": "Clarified with Steven an approach for tackling multi-condition comparisons (see this GitHub Issue). As such, I need to have individual transcript abundances for each sample from the 2020 Genewiz RNAseq data before I can proceed. So, I ran salmon (v1.2.1) to perform an alignment-free set of transcript abundances. It’s ridiculously fast, btw…\nThis was run on Mox and used the C.bairdi-specific reads that were extracted using MEGAN6 on 202020330.\nSBATCH script (GitHub):\n\n20200429_cbai_salmon_2020GW_transcript_abundances.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_DEG_basic\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200429_cbai_salmon_2020GW_transcript_abundances\n\n# Script to generate set of transcript abundances for all C.bairdi Genewiz 2020 data.\n#\n# C.bairdi-specific reads were extracted with MEGAN6:\n# https://robertslab.github.io/sams-notebook/2020/03/30/RNAseq-Reads-Extractions-C.bairdi-Taxonomic-Reads-Extractions-with-MEGAN6-on-swoose.html\n#\n# Transcriptome was produced here: https://robertslab.github.io/sams-notebook/2020/03/30/Transcriptome-Assembly-C.bairdi-with-MEGAN6-Taxonomy-specific-Reads-with-Trinity-on-Mox.html\n# Transcriptome is the same as: cbai_transcriptome_v1.5.fasta\n#\n# Salmon index generated during a previous gene expression analysis:\n# https://robertslab.github.io/sams-notebook/2020/04/22/Gene-Expression-C.bairdi-Pairwise-DEG-Comparisons-with-2019-RNAseq-using-Trinity-Salmon-EdgeR-on-Mox.html\n\n\n\n###################################################################################################################\n# BEGIN USER SETTINGS\n\n\n# Programs array\ndeclare -A programs_array\nprograms_array=([salmon]=\"/gscratch/srlab/programs/salmon-1.2.1_linux_x86_64/bin/salmon\")\n\n## Designate input files and locations\nfastq_dir=\"/gscratch/srlab/sam/data/C_bairdi/RNAseq/\"\nsalmon_index=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200408.C_bairdi.megan.Trinity.fasta.salmon.idx\"\n\n# Set number of CPU threads\n# Salmon default is 56 threads - so not needed\n# threads=28\n\n# END USER SETTINGS\n####################################################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# Caputure working directory\n#wd=\"$(pwd)\"\n\n\n# Capture program options\n## NOTE: This particular instance is specific to salmon!\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${programs_array[$program]}: \"\n    echo \"\"\n    ${programs_array[$program]} quant --help\n    echo \"\"\n    ${programs_array[$program]} quant --help-reads\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n  } &>> program_options.log || true\ndone\n\n# Populate array with FastQ files\nreads_array=(\"${fastq_dir}\"*.fq)\n\n# Loop through read pairs\n# Increment by 2 to process next pair of FastQ files\nfor (( i=0; i<${#reads_array[@]} ; i+=2 ))\ndo\n\n    # Create list of FastQ files used\n    {\n    echo \"${reads_array[i]}\"\n    echo \"${reads_array[i+1]}\"\n} >> fastq-list.txt\n\n  # Strip path and save just sample number\n    # Expects sample name to be like:\n    # 20200413.C_bairdi.359.D12.infected.ambient.megan_R2.fq\n    # Will pull out '359'\n  sample=$(echo ${reads_array[i]##*/} | awk -F\".\" '{print $3}')\n\n    # Run salmon\n    # Library type (stranded or not) is set to auto (A)\n    ${programs_array[salmon]} quant \\\n    --index ${salmon_index} \\\n    --libType A \\\n    --validateMappings \\\n    --output \"${sample}\"_quant \\\n    -1 ${reads_array[i]} \\\n    -2 ${reads_array[i+1]}\ndone\n\n\nRESULTS\nExtremely fast, ~3mins:\n\n\n\nsalmon runtime\n\n\nOutput folder:\n\n20200429_cbai_salmon_2020GW_transcript_abundances\n\nHere are links to the individual quants files:\n\n\nSample 72\n\n72_quant.sf\n\n\n\nSample 73\n\n73_quant.sf\n\n\n\nSample 113\n\n113_quant.sf\n\n\n\nSample 118\n\n118_quant.sf\n\n\n\nSample 127\n\n127_quant.sf\n\n\n\nSample 132\n\n132_quant.sf\n\n\n\nSample 151\n\n151_quant.sf\n\n\n\nSample 173\n\n173_quant.sf\n\n\n\nSample 178\n\n178_quant.sf\n\n\n\nSample 221\n\n221_quant.sf\n\n\n\nSample 222\n\n222_quant.sf\n\n\n\nSample 254\n\n254_quant.sf\n\n\n\nSample 272\n\n272_quant.sf\n\n\n\nSample 280\n\n280_quant.sf\n\n\n\nSample 294\n\n294_quant.sf\n\n\n\nSample 334\n\n334_quant.sf\n\n\n\nSample 349\n\n349_quant.sf\n\n\n\nSample 359\n\n359_quant.sf\n\n\n\nSample 425\n\n425_quant.sf\n\n\n\nSample 427\n\n427_quant.sf\n\n\n\nSample 445\n\n445_quant.sf\n\n\n\nSample 463\n\n463_quant.sf\n\n\n\nSample 481\n\n481_quant.sf\n\n\n\nSample 485\n\n485_quant.sf"
  },
  {
    "objectID": "posts/2020/2020-09-14-qPCR---Geoduck-Normalizing-Gene-Primer-Checks/index.html",
    "href": "posts/2020/2020-09-14-qPCR---Geoduck-Normalizing-Gene-Primer-Checks/index.html",
    "title": "qPCR - Geoduck Normalizing Gene Primer Checks",
    "section": "",
    "text": "Shelly ordered some new primers (designed by Sam Gurr) (GitHub Issue) to potentially use as normalizing genes for her geoduck reproduction gene expression project and asked that I test them out.\nPrimers tested:\n\n\n\nSRID\nPrimer_Name\n\n\n\n\n1803\n28s_v1_FWD\n\n\n1802\n28s_v1_REV\n\n\n1801\n28s_v2_FWD\n\n\n1800\n28s_v2_REV\n\n\n1799\n28s_v3_FWD\n\n\n1798\n28s_v3_REV\n\n\n1797\n28s_v4_FWD\n\n\n1796\n28s_v4_REV\n\n\n1795\nEF1a_v1_FWD\n\n\n1794\nEF1a_v1_REV\n\n\n1793\nEF1a_v2_FWD\n\n\n1792\nEF1a_v2_REV\n\n\n1791\nEF1a_v3_FWD\n\n\n1790\nEF1a_v3_REV\n\n\n1789\nEF1a_v4_FWD\n\n\n1788\nEF1a_v4_REV\n\n\n\nI used pooled cDNA, created by combining 2uL from a variety of cDNA previously made by Kaitlyn (sorry, didn’t document which samples contributed this time…).\nI also used a 1:10 dilution of geoduck gDNA (162ng/uL; from 20170105) as a potential positive control, and/or as confirmation that these primers will/not amplify gDNA.\nMaster mix calcs are here:\n\n200200914_qPCR_geoduck_28s-v1-4_EF1a-v1-4 (Google Sheet)\n\nAll qPCR reactions were run in duplicate. See qPCR Report (Results section below) for plate layout, cycling params, etc.\n\n\nRESULTS\nqPCR Report (PDF):\n\nsam_2020-09-14_10-15-48_BR006896.pdf\n\nCFX Data File (PCRD):\n\nsam_2020-09-14_10-15-48_BR006896.pcrd\n\nCFX Results File (CSV):\n\nsam_2020-09-14_10-15-48_BR006896_Quantification-Cq-Results.csv\n\nOverall, all primer sets amplified gDNA and cDNA. All melt curves look really good, although for 28s I’d lean towards using 28s v4 due to the fact that the melt curve doesn’t mirror the gDNA melt curve like the others do. For the same reasons, I’d lean towards using EF1a v1.\nAmplifcation and melt plots for each primer set are below. Color coding:\n\nRED: No Template Control (NTC)\nCHARTREUSE: gDNA\nOTHER: cDNA\n\n\n28s v1\nAMPLIFICATION PLOTS\n\n\n\n28s-v1 amp plots.png\n\n\nMELT PLOTS\n\n\n\n28s-v1 melt plots.png\n\n\n\n\n28s v2\nAMPLIFICATION PLOTS\n\n\n\n28s-v2 amp plots.png\n\n\nMELT PLOTS\n\n\n\n28s-v2 melt plots.png\n\n\n\n\n28s v3\nAMPLIFICATION PLOTS\n\n\n\n28s-v3 amp plots.png\n\n\nMELT PLOTS\n\n\n\n28s-v3 melt plots.png\n\n\n\n\n28s v4\nAMPLIFICATION PLOTS\n\n\n\n28s-v4 amp plots.png\n\n\nMELT PLOTS\n\n\n\n28s-v4 melt plots.png\n\n\n\n\nEF1a v1\nAMPLIFICATION PLOTS\n\n\n\nEF1a-v1 amp plots.png\n\n\nMELT PLOTS\n\n\n\nEF1a-v1 melt plots.png\n\n\n\n\nEF1a v2\nAMPLIFICATION PLOTS\n\n\n\nEF1a-v2 amp plots.png\n\n\nMELT PLOTS\n\n\n\nEF1a-v2 melt plots.png\n\n\n\n\nEF1a v3\nAMPLIFICATION PLOTS\n\n\n\nEF1a-v3 amp plots.png\n\n\nMELT PLOTS\n\n\n\nEF1a-v3 melt plots.png\n\n\n\n\nEF1a v4\nAMPLIFICATION PLOTS\n\n\n\nEF1a-v4 amp plots.png\n\n\nMELT PLOTS\n\n\n\nEF1a-v4 melt plots.png"
  },
  {
    "objectID": "posts/2020/2020-09-04-Data-Wrangling---NanoPore-Fast5-Conversion-to-FastQ-of-C.bairdi-6129_403_26-on-Mox-with-GPU-Node/index.html",
    "href": "posts/2020/2020-09-04-Data-Wrangling---NanoPore-Fast5-Conversion-to-FastQ-of-C.bairdi-6129_403_26-on-Mox-with-GPU-Node/index.html",
    "title": "Data Wrangling - NanoPore Fast5 Conversion to FastQ of C.bairdi 6129_403_26 on Mox with GPU Node",
    "section": "",
    "text": "Time to start working with the NanoPore data that I generated back in March (???!!!). In order to proceed, I first need to convert the raw Fast5 files to FastQ. To do so, I’ll use the NanoPore program guppy.\nAs noted in a previous conversion, I’ll b processing this with a GPU node on Mox. Using a Mox GPU node decreases processing time by a ridiculous amount, compared to using CPUs. The only rub is that since we don’t own a GPU node, any jobs we submit are:\n\nlowest priority in any queue\ncan get interrupted at any time by jobs submitted by the node owner\n\nI’ll be submitting these very early in the morning and with runtimes this fast, I shouldn’t encounter any issues. Exciting!\nSBATCH script (GitHub):\n\n20200314_cbai_guppy_nanopore_6129_403_26.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_guppy_nanopore_6129_403_26\n## Allocation Definition\n#SBATCH --account=srlab-ckpt\n#SBATCH --partition=ckpt\n## Resources\n## GPU\n#SBATCH --gres=gpu:P100:1\n#SBATCH --constraint=gpu_default\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=0-02:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200314_cbai_guppy_nanopore_6129_403_26\n\n## Script for running ONT guppy to perform\n## basecalling (i.e. convert raw ONT Fast5 to FastQ) of NanaPore data generated\n## on 20200311 from C.bairdi 6129_403_26 gDNA.\n\n## This script utilizes a GPU node. These nodes are only available as part of the checkpoint\n## partition/account. Since we don't own a GPU node, our GPU jobs are lowest priority and\n## can be interrupted at any time if the node owner submits a new job.\n\n###################################################################################\n# These variables need to be set by user\n\nwd=$(pwd)\n\n# Programs array\ndeclare -A programs_array\nprograms_array=(\n[guppy_basecaller]=\"/gscratch/srlab/programs/ont-guppy_4.0.15_linux64/bin/guppy_basecaller\"\n)\n\n# Establish variables for more readable code\n\n# Input files directory\nfast5_dir=/gscratch/srlab/sam/data/C_bairdi/DNAseq/ont_FAL86873_d8db260e_cbai_6129_403_26\n\n# Output directory\nout_dir=${wd}\n\n# CPU threads\nthreads=28\n\n# Flowcell type\nflowcell=\"FLO-MIN106\"\n\n# Sequencing kit used\nkit=\"SQK-RAD004\"\n\n# GPU devices setting\nGPU_devices=auto\n\n# Set number of FastQ sequences written per file (0 means all in one file)\nrecords_per_fastq=0\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Load CUDA GPU module\nmodule load cuda/10.1.105_418.39\n\n\n${programs_array[guppy_basecaller]} \\\n--input_path ${fast5_dir} \\\n--save_path ${out_dir} \\\n--flowcell ${flowcell} \\\n--kit ${kit} \\\n--device ${GPU_devices} \\\n--records_per_fastq ${records_per_fastq} \\\n--num_callers ${threads}\n\n###################################################################################\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : n\n} >> system_path.log\n\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n    ${programs_array[$program]} --help\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n\nRESULTS\nTook just a bit over an hour to process 127 files:\n\n\n\nFast5 to FastQ conversion runtime using Mox GPU node\n\n\nOutput folder:\n\n20200314_cbai_guppy_nanopore_6129_403_26/\n\nSequencing Summary (113MB; TXT)\n\n20200314_cbai_guppy_nanopore_6129_403_26/sequencing_summary.txt\n\nUseful with downstream analysis tools, like NanoPlot.\n\n\nAll the resulting FastQ files can be accessed in the output folder linked above with this pattern:\n\n*.fastq\n\nUnbeknownst to me, I misinterpreted the behavior of the program. I thought the FastQs from all of the Fast5 would be concatenated into a single FastQ. However, that’s not the case. Each Fast5 got converted to its own FastQ. So, I now have 126 FastQ files instead of just one. Not a big deal as I can concatenate these at a later date.\nNow, I’ll get these run through some QC software (FastQC, NanoPlot) to get an idea of how things look before processing them further."
  },
  {
    "objectID": "posts/2020/2020-07-27-SRA-Submission---P.generosa-Metagenomics-Data/index.html",
    "href": "posts/2020/2020-07-27-SRA-Submission---P.generosa-Metagenomics-Data/index.html",
    "title": "SRA Submission - P.generosa Metagenomics Data",
    "section": "",
    "text": "Added our P.generosa metagenomics sequencing data to NCBI sequencing read archive (SRA).\nAll data is accessible via the following BioProject accession:\n\nPRJNA649049\n\nTable with links to individual BioSample and SRA Run entries:\n\n\n\nSample\npH\nDay\nBioSample\nRun\n\n\n\n\nMG_7\n7.1\n12\nSRR12334351\nSAMN15655975\n\n\nMG_6\n7.1\n8\nSRR12334352\nSAMN15655976\n\n\nMG_5\n8.2\n5\nSRR12334353\nSAMN15655977\n\n\nMG_3\n7.1\n1\nSRR12334354\nSAMN15655978\n\n\nMG_2\n8.2\n12\nSRR12334355\nSAMN15655979\n\n\nMG_1\n8.2\n8\nSRR12334356\nSAMN15655980"
  },
  {
    "objectID": "posts/2020/2020-01-23-Transcriptome-Annotation---C.bairdi-MEGAN-Trinity-Assembly-Using-DIAMOND-BLASTx-on-Mox/index.html",
    "href": "posts/2020/2020-01-23-Transcriptome-Annotation---C.bairdi-MEGAN-Trinity-Assembly-Using-DIAMOND-BLASTx-on-Mox/index.html",
    "title": "Transcriptome Annotation - C.bairdi MEGAN Trinity Assembly Using DIAMOND BLASTx on Mox",
    "section": "",
    "text": "As part of annotating the transcriptome assembly from the MEGAN6 C.bairdi taxonomic-specific reads, I need to run DIAMOND BLASTx to use with Trinotate.\nRan DIAMOND BLASTx against the UniProt/SwissProt database (downloaded today) on Mox.\nSBATCH script (GitHub):\n\n20200123_cbai_diamond_blastx_megan.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_blastx_DIAMOND\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200123_cbai_diamond_blastx_megan\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\n# Program paths\ndiamond=/gscratch/srlab/programs/diamond-0.9.29/diamond\n\n# DIAMOND UniProt database\ndmnd=/gscratch/srlab/blastdbs/uniprot_sprot_20200123/uniprot_sprot.dmnd\n\n\n# Trinity assembly (FastA)\nfasta=/gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200122.C_bairdi.megan.Trinity.fasta\n\n# Strip leading path and extensions\nno_path=$(echo \"${fasta##*/}\")\nno_ext=$(echo \"${no_path%.*}\")\n\n# Run DIAMOND with blastx\n# Output format 6 produces a standard BLAST tab-delimited file\n${diamond} blastx \\\n--db ${dmnd} \\\n--query \"${fasta}\" \\\n--out \"${no_ext}\".blastx.outfmt6 \\\n--outfmt 6 \\\n--evalue 1e-4 \\\n--max-target-seqs 1 \\\n--block-size 15.0 \\\n--index-chunks 4\n\n\nRESULTS\nWell, this ran in a riduculous 6 seconds!\n\n\n\nCbai DIAMOND runtime\n\n\nSeriously, 14,000 query sequences were aligned in 6 seconds!\nOutput folder:\n\n20200123_cbai_diamond_blastx_megan/\n\nBLASTx output - BLAST format 6 (tab):\n\n20200123_cbai_diamond_blastx_megan/20200122.C_bairdi.megan.Trinity.blastx.outfmt6\n\nWill proceed with Trinotate."
  },
  {
    "objectID": "posts/2020/2020-05-19-Transcriptome-Annotation---C.bairdi-Transcriptome-v3.0-Using-DIAMOND-BLASTx-on-Mox/index.html",
    "href": "posts/2020/2020-05-19-Transcriptome-Annotation---C.bairdi-Transcriptome-v3.0-Using-DIAMOND-BLASTx-on-Mox/index.html",
    "title": "Transcriptome Annotation - C.bairdi Transcriptome v3.0 Using DIAMOND BLASTx on Mox",
    "section": "",
    "text": "As part of annotating cbai_transcriptome_v3.0.fasta from 20200518, I need to run DIAMOND BLASTx to use with Trinotate.\nRan DIAMOND BLASTx against the UniProt/SwissProt database (downloaded 20200123) on Mox.\nSBATCH script (GitHub):\n\n20200519_cbai_diamond_blastx_transcriptome_v3.0.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_blastx_DIAMOND\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200519_cbai_diamond_blastx_transcriptome_v3.0\n\n### BLASTx of Trinity de novo assembly of all pooled C.bairdi RNAseq data:\n### cbai_transcriptome_v3.0.fasta (orginal name, used below, is 20200518.C_bairdi.Trinity.fasta)\n### Includes \"descriptor_1\" short-hand of: 2020-UW, 2019, 2018.\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\n# Program paths\ndiamond=/gscratch/srlab/programs/diamond-0.9.29/diamond\n\n# DIAMOND UniProt database\ndmnd=/gscratch/srlab/blastdbs/uniprot_sprot_20200123/uniprot_sprot.dmnd\n\n\n# Trinity assembly (FastA)\nfasta=/gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200518.C_bairdi.Trinity.fasta\n\n# Strip leading path and extensions\nno_path=$(echo \"${fasta##*/}\")\nno_ext=$(echo \"${no_path%.*}\")\n\n# Run DIAMOND with blastx\n# Output format 6 produces a standard BLAST tab-delimited file\n${diamond} blastx \\\n--db ${dmnd} \\\n--query \"${fasta}\" \\\n--out \"${no_ext}\".blastx.outfmt6 \\\n--outfmt 6 \\\n--evalue 1e-4 \\\n--max-target-seqs 1 \\\n--block-size 15.0 \\\n--index-chunks 4\n\n\nRESULTS\nAs usual, runtime was ridiculously fast: 23 seconds\n\n\n\ndiamond blastx runtime\n\n\nOutput folder:\n\n20200519_cbai_diamond_blastx_transcriptome_v3.0/\n\nBLASTx output (outfmt6; text; 5.7MB):\n\n20200519_cbai_diamond_blastx_transcriptome_v3.0/20200518.C_bairdi.Trinity.blastx.outfmt6"
  },
  {
    "objectID": "posts/2020/2020-01-17-DNA-Isolation-and-Quantification---C.bairdi-Hemolymph-Pellets-in-RNAlater/index.html",
    "href": "posts/2020/2020-01-17-DNA-Isolation-and-Quantification---C.bairdi-Hemolymph-Pellets-in-RNAlater/index.html",
    "title": "DNA Isolation and Quantification - C.bairdi Hemolymph Pellets in RNAlater",
    "section": "",
    "text": "Isolated DNA from the following 23 samples:\n\n6128_112_9\n6204_114_9\n6141_123_9\n6245_126_9\n6240_134_9\n6260_136_9\n6257_138_9\n6259_139_9\n6258_140_9\n6255_143_9\n6256_146_9\n6265_155_9\n6266_156_9\n6261_164_9\n6120_165_9\n6251_167_9\n6262_168_9\n6243_173_9\n6263_179_9\n6264_180_9\n6200_208_12\n6204_252_12\n6190_256_12\n\nIsolated DNA using the Quick DNA/RNA Microprep Kit (ZymoResearch; PDF) according to the manufacturer’s protocol for liquids/cells in RNAlater.\n\nUsed 35uL from each RNAlater/hemocyte slurry.\nMixed with equal volume of H2O (35uL).\nRetained DNA on the Zymo-Spin IC-XM columns for isolation after RNA isolation.\nDNA was eluted in 15uL H2O\n\nDNA was quantified on the Roberts Lab Qubit 3.0 using the 1x DNA High Sensitivity Assay (Invitrogen), using 2uL of each sample.\nTwo samples were too concentrated, so those two samples were re-quantified using 1uL of sample.\n\n\nRESULTS\nQubit results (Google Sheet):\n\n20200117_qubit_cbai_DNA\n\nGot DNA from all samples, despite the fact that I didn’t get any RNA from them…\nSamples were stored at -80oC in:\nRack 6, 4, 1 in C.bairdi gDNA Box #1"
  },
  {
    "objectID": "posts/2020/2020-01-09-NanoPore-Sequencing---C.bairdi-gDNA-Sample-20102558-2729/index.html",
    "href": "posts/2020/2020-01-09-NanoPore-Sequencing---C.bairdi-gDNA-Sample-20102558-2729/index.html",
    "title": "NanoPore Sequencing - C.bairdi gDNA Sample 20102558-2729",
    "section": "",
    "text": "I performed the initial Lambda sequencing test on 20200107 and everything went smoothly, so I’m ready to give the NanoPore (ONT) MinION a run with an actual sample!\nI isolated gDNA from an uninfected C.bairdi muscle sample yesterday (sample 20102558-2729). Earlier today I ran that DNA on a gel to assess it’s quality/integrity and it didn’t look very good - pretty degraded.\nDespite that fact, I’ll run this on the NanoPore MinION. This will provide me with additional experience on using the system and will also provide us with info about using degraded DNA. Presumably, sequencing will proceed without issue and we’ll just end up with shorter read lengths than if we had higher quality input DNA.\nThe sample DNA was prepared according to the protocol for the Rapid Sequencing Kit (SQK-RAD004) and run on a FLO-MIN106 (ID: FAL58500) flowcell. Data acquisition was set to run without basecalling for a period of 72hrs. This will make sure the raw Fast5 output files will be preserved (not sure if they’re saved or not when basecalling is enabled), but will require conversion to FastQ at a later date.\nStart of the run was good, with 1226 pores available for sequencing (minimum for a “good” flowcell, per ONT, is 800 pores). The number of available pores dropped below 800 after ~3hrs, which doesn’t seem good. Based on the various metrics for monitoring a sequencing run, I decided to terminate this run after ~17hrs. Available pores had dropped to 270 and data acquisition was minimal. With that being said, I should be able to wash the flowcell to restore everything back to normal (i.e. clean out clogged pores) and use it again.\nI washed the flowcell according the protocol for the Flowcell Wash Kit (WFC_9088) and decided to do a second run with this same gDNA sample to see how well washing/reusing actually seems to work.\nPrepared a fresh library as before and ran as before on the FLO-MIN106 (ID: FAL58500) flowcell. This time, I decided to just go with a “set it and forget it” approach. I set the run time to 72hrs and let the program finish. The washing/reusing of the flowcell didn’t really work as expected, though. Starting number of available pores was only 414, far short of the minimum of 800 indicative of a good flowcell. I’ll contact ONT about this and see what they can do.\n\n\nRESULTS\nOutput folder:\n\n20200109_cbai_nanopore_20102558-2729/\n\n\nFirst run outputs:\nFast5 directory:\n\n20200109_cbai_nanopore_20102558-2729/20102558-2729/20200109_2223_MN29908_FAL58500_3d288d14/fast5/\n\nRun report (PDF):\n\n20200109_cbai_nanopore_20102558-2729/20102558-2729/3d288d14-89d6-4ae4-8a76-18ec6ff63fc7–report.pdf\n\n\n\n\ncbai nanopore first run cumulative read plots\n\n\n\n\n\ncbai nanopore first run read length histograms\n\n\n\n\nSecond run outputs:\nFast5 directory:\n\n20200109_cbai_nanopore_20102558-2729/cbaI_20102558-2729/20200110_1705_MN29908_FAL58500_a909f60a/fast5/\n\nRun report (PDF):\n\n20200109_cbai_nanopore_20102558-2729/cbaI_20102558-2729/a909f60a-d49f-4564-8cd3-3c8a31e8c572–report.pdf\n\n\n\n\ncbai nanopore second run cumulative read plots\n\n\n\n\n\ncbai nanopore second run read length histograms\n\n\n\nAlrighty, here’s how I interpret things.\nFirst run:\n\n~3x more reads\n~3x more bases\nLower N50 (1.29Kbp vs 1.46Kbp)\nRun time was 4.5x shorter\n\nEverything’s as expected, except maybe the N50, and demonstrates the importance of the available sequencing pores in data acquisition.\nNext up, convert the raw Fast5 files to FastQ."
  },
  {
    "objectID": "posts/2020/2020-04-08-Transcriptome-Annotation---C.bairdi-MEGAN-Trinity-Assembly-Using-DIAMOND-BLASTx-on-Mox/index.html",
    "href": "posts/2020/2020-04-08-Transcriptome-Annotation---C.bairdi-MEGAN-Trinity-Assembly-Using-DIAMOND-BLASTx-on-Mox/index.html",
    "title": "Transcriptome Annotation - C.bairdi MEGAN Trinity Assembly Using DIAMOND BLASTx on Mox",
    "section": "",
    "text": "As part of annotating the most recent transcriptome assembly from the MEGAN6 Arthropoda taxonomic-specific reads, I need to run DIAMOND BLASTx to use with Trinotate.\nRan DIAMOND BLASTx against the UniProt/SwissProt database (downloaded 20200123) on Mox.\nSBATCH script (GitHub):\n\n20200408_cbai_diamond_blastx_megan.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=hemat_blastx_DIAMOND\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200408_cbai_diamond_blastx_megan\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\n# Program paths\ndiamond=/gscratch/srlab/programs/diamond-0.9.29/diamond\n\n# DIAMOND UniProt database\ndmnd=/gscratch/srlab/blastdbs/uniprot_sprot_20200123/uniprot_sprot.dmnd\n\n\n# Trinity assembly (FastA)\nfasta=/gscratch/srlab/sam/data/Hematodinium/transcriptomes/20200408.C_bairdi.megan.Trinity.fasta\n\n# Strip leading path and extensions\nno_path=$(echo \"${fasta##*/}\")\nno_ext=$(echo \"${no_path%.*}\")\n\n# Run DIAMOND with blastx\n# Output format 6 produces a standard BLAST tab-delimited file\n${diamond} blastx \\\n--db ${dmnd} \\\n--query \"${fasta}\" \\\n--out \"${no_ext}\".blastx.outfmt6 \\\n--outfmt 6 \\\n--evalue 1e-4 \\\n--max-target-seqs 1 \\\n--block-size 15.0 \\\n--index-chunks 4\n\n\nRESULTS\nVery fast, 13 seconds :\n\n\n\ncbai diamond blastx runtime\n\n\nOutput folder:\n\n20200408_cbai_diamond_blastx_megan/\n\nBLASTx output - BLAST format 6 (tab):\n\n20200408_cbai_diamond_blastx_megan/20200408.C_bairdi.megan.Trinity.blastx.outfmt6\n\nWill proceed with Trinotate."
  },
  {
    "objectID": "posts/2020/2020-08-20-Samples-Received---C.gigas-High-Low-pH-Triploid-Diploid-from-Maria-Haws-Lab/index.html",
    "href": "posts/2020/2020-08-20-Samples-Received---C.gigas-High-Low-pH-Triploid-Diploid-from-Maria-Haws-Lab/index.html",
    "title": "Samples Received - C.gigas High-Low pH Triploid Diploid from Maria Haws Lab",
    "section": "",
    "text": "Received Crassostrea gigas tissue samples from Maria Haws’ Lab at the University of Hawaii Hilo. Tissue samples are a set of triploid and diploid subjected to different pHs. All sample info is in the sample sheet provided below.\nSample sheet:\n\n20200816_hawaii_ploidy_samples (Google Sheet)\n\nImportant note. Email from Dr. Haws’ research Manager, Daniel Wilkie provides a correction for sample labeling:\n\nSam,\n\n\nThe package containing tissue samples was sent out today. The samples are separated by treatment group. I am realizing now while writing this email, that the labeling on the ziplock bags containing the samples is improper. The ziplock bags are labeled either “Low PCO2” or “High PCO2” respectively. These should read “Low pH” instead of “Low PCO2,” and “High pH” instead of “High pCO2”. I have attached a data sheet with information about each sample. The data sheet has the correct treatment group labeling.\n\n\nThe FedEx tracking number is 3959-4768-0634\n\n\nBest, Daniel\n\nAlso, received this follow up mail, after tracking info indicated the package was going to Sequim, WA instead of to Seattle:\n\nHi Sam,\n\n\nMy apologies, I definitely sent the wrong tracking number.\n\n\n395947596722\n\n\nLooks like the package was signed for this morning.\n\n\nDaniel\n\n\nSamples as Received\n\n\n\nFour labeled bags containing sample tubes\n\n\n\n\nContents of large “High pCO2” bag\n\n\n\nIndividual oyster bags from the high pCO2 bag\n\n\n\n\nExample of tissue sample in liquid\n\n\n\nExample tube of tissue sample with excessive liquid\n\n\n\n\nTops of tubes unlabeled\n\n\n\nExample of tops of tubes without labels\n\n\nThe tubes only had a single label on blue tape on the side of each tube (e.g. 01 gill) with no other indicator of ploidy or pH. To minimize potential confusion down the line, I minimally labeled the tops of all the tubes with their ploidy and then put the tubes in to separate boxes, based on pH treatment (high/low).\nBoxes were stored in the Roberts Lab -80oC (Google Sheet)."
  },
  {
    "objectID": "posts/2020/2020-02-25-qPCR---C.bairdi-Primer-Tests-on-gDNA/index.html",
    "href": "posts/2020/2020-02-25-qPCR---C.bairdi-Primer-Tests-on-gDNA/index.html",
    "title": "qPCR - C.bairdi Primer Tests on gDNA",
    "section": "",
    "text": "We received the primers I ordered on 20200220 and now need to test them to see if they detect gDNA. If yes, then they’re good candidates to assess the presence of residual gDNA in our RNA samples before we proceed with reverse transcription.\nThe three primer pairs to test are:\n\nSRIDs 1774/1775 (40s rRNA S30)\nSRIDS 1776/1777 (allantoicase)\nSRIDs 1778/1779 (ubiquitin thioesterase)\n\nUsed 1uL of a 1:10 dilution of the 6129_403_26 gDNA from 20200210 as template (equates to ~4ng/uL).\nAll samples were run in triplicate.\nqPCR Master Mix calcs (Google Sheet):\n\n20200225_qPCR_cbai_gDNA_primer_tests_master_mixes\n\nSee qPCR Report (see Results section below) for plate layout, cycling params, etc.\n\n\nRESULTS\nqPCR data file (CFX):\n\nsam_2020-02-25 2012-54-22_BR006896.pcrd\n\nqPCR report (PDF):\n\nsam_2020-02-25%2012-54-22_BR006896.pdf\n\nSRIDs 1774/1775 (40s rRNA S30) and 1776/1777 (allantoicase) both amplified, while SRIDs 1778/1779 (ubiquitin thioesterase) did not. There was no amplification in any of the no template controls (NTCs).\nSRIDs 1774/1775 (40s rRNA S30) generated a single peak in the melt curve, while SRIDs 1776/1777 (allantoicase) produced two peaks.\nDespite the fact that SRIDs 1776/1777 (allantoicase) generated multiple peaks in the melt curve analysis, it produces a lower Cq value, so I’ll go forward with this primer set for gDNA detection. Since this is just for testing for gDNA detection in our existing RNA, I’m not terribly concerned about the lack of specificity here. I would prefer to use the primer set that seems to have the higher sensitivity (i.e. produces the lowest Cq value)\n\n\n\nAmpflication Plots\n\nBlue: SRIDs 1776/1777 (allantoicase)\nGreen: SRIDs 1774/1775 (40s rRNA S30)\nPurple: SRIDs 1778/1779 (ubiquitin thioesterase)\nRed: NTCs\n\n\n\n\nqPCR amplification plots\n\n\n\n\n\nMelt Curve Plots\n(same color scheme as amp plots above)\n\n\n\nqPCR melt curve plots"
  },
  {
    "objectID": "posts/2020/2020-06-08-Transcriptome-Annotation---C.bairdi-Transcriptomes-v2.1-and-v3.1-Using-DIAMOND-BLASTx-on-Mox/index.html",
    "href": "posts/2020/2020-06-08-Transcriptome-Annotation---C.bairdi-Transcriptomes-v2.1-and-v3.1-Using-DIAMOND-BLASTx-on-Mox/index.html",
    "title": "Transcriptome Annotation - C.bairdi Transcriptomes v2.1 and v3.1 Using DIAMOND BLASTx on Mox",
    "section": "",
    "text": "Decided to annotate the two C.bairdi transcriptomes , cbai_transcriptome_v2.1 and cbai_transcriptome_v3.1, generated on 20200605 using DIAMOND BLASTx on Mox.\nSBATCH script (GitHub):\n\n20200608_cbai_diamond_blastx_v2.1_v3.1.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_diamond_blastx_v2.1_v3.1\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=0-08:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200608_cbai_diamond_blastx_v2.1_v3.1\n\n\n## Script for running BLASTx (using DIAMOND) to annotate\n## C.bairdi transcriptomes v2.1 and v3.1 against SwissProt database.\n## Output will be in standard BLAST output format 6.\n\n###################################################################################\n# These variables need to be set by user\n\nthreads=28\n\n# Programs array\ndeclare -A programs_array\nprograms_array=(\n[diamond]=\"/gscratch/srlab/programs/diamond-0.9.29/diamond\"\n)\n\n# Transcriptomes arrays\ntranscriptomes_dir=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes\"\ntranscriptomes=(\"${transcriptomes_dir}/cbai_transcriptome_v2.1.fasta\" \\\n\"${transcriptomes_dir}/cbai_transcriptome_v3.1.fasta\")\n\n# DIAMOND UniProt database\ndmnd=/gscratch/srlab/blastdbs/uniprot_sprot_20200123/uniprot_sprot.dmnd\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n\nfor fasta in \"${!transcriptomes[@]}\"\ndo\n  # Generate checksums for reference\n  md5sum \"${transcriptomes[$fasta]}\">> fasta.checksums.md5\n\n  # Strip leading path and extensions\n  no_path=\"${transcriptomes[$fasta]##*/}\"\n  no_ext=\"${no_path%.*}\"\n\n  # Run DIAMOND with blastx\n  # Output format 6 produces a standard BLAST tab-delimited file\n  ${programs_array[diamond]} blastx \\\n  --db ${dmnd} \\\n  --query \"${transcriptomes[$fasta]}\" \\\n  --out \"${no_ext}\".blastx.outfmt6 \\\n  --outfmt 6 \\\n  --evalue 1e-4 \\\n  --max-target-seqs 1 \\\n  --block-size 15.0 \\\n  --index-chunks 4\ndone\n\n\n###################################################################################\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : n\n} >> system_path.log\n\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n    ${programs_array[$program]} --help\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n\nRESULTS\nSuper fast - 40 seconds to process both transcriptomes:\n\n\n\ncbai v2.1 and v3.1 diamond blastx runtime\n\n\nOutput folder:\n\n20200608_cbai_diamond_blastx_v2.1_v3.1\n\nBLASTx output files (BLAST output format 6 text):\n\ncbai_transcriptome_v2.1.blastx.outfmt6\ncbai_transcriptome_v3.1.blastx.outfmt6\n\nWill put link to each annotation on the Genomic Resources wiki."
  },
  {
    "objectID": "posts/2020/2020-01-09-DNA-Quality-Assessment---Agarose-Gel-and-NanoDrop-on-C.bairdi-gDNA/index.html",
    "href": "posts/2020/2020-01-09-DNA-Quality-Assessment---Agarose-Gel-and-NanoDrop-on-C.bairdi-gDNA/index.html",
    "title": "DNA Quality Assessment - Agarose Gel and NanoDrop on C.bairdi gDNA",
    "section": "",
    "text": "I isolated C.bairdi gDNA yesterday (20200108) and now want to get an idea if it’s any good (i.e. no contaminants, high molecule weight).\nI loaded ~100ng (2uL) of the _C.bairdi_ 20102558-2729 gDNA sample, along with two molecular weight markers (see RESULTS below) on a 0.8% agarose, 1x low TAE gel with ethidium bromide. Gel was run for 1.5hrs at 75V.\n\n\nRESULTS\n\n\n\nNanoDrop results from C.bairdi 201002558-2729 gDNA\n\n\n\nGeneRuler HighRange Ladder (ThermoFisher):\n\n\n\nGeneRuler HighRange Ladder\n\n\nGeneRuler DNA Ladder Mix (ThermoFisher):\n\n\n\nGeneRuler DNA Ladder Mix\n\n\n\n\n\n\ngel image of C.bairdi gDNA\n\n\n\nNanoDrop indicates good, clean gDNA (260/230 = 2.12 and 260/280 = 1.99). Although, the NanoPore protocol indicates that the 260/280 should be ~1.75 and values of ~2.0 indicate RNA contamination. Personally, I’d never previously heard that. Interesting!\nThis DNA was RNase treated, however, the kit I was using was nearly four years old. Maybe the RNase is no longer good (the Proteinase K from that kit certainly wasn’t…).\nThe gel, on the otherhand, shows less-than-ideal DNA integrity. It’s mostly a degraded smear. This isn’t entirely surprising as the tissue sample had been stored in ethanol at room temperature for nearly a decade. But, the kit I used to isolate the DNA (E.Z.N.A. Mollusc Kit) does have a surprising number of steps where the sample is vortexed (usually a no-no when attempting to obtain intact, high molecular weight DNA).\nRegardless, I’ll go ahead and use this for a NanoPore run. This will serve a couple of purposes:\n\nFamiliarize myself with the NanoPore.\nEvaluate whether or not this DNA should be used to submit for PacBio sequencing. If we don’t get long reads from the NanoPore, it would be a waste of money and time to try to get long reads via the PacBio sequencing. In which case, I’d try a different DNA isolation method to try to see if I could obtain higher quality (i.e. intact) gDNA."
  },
  {
    "objectID": "posts/2020/2020-07-23-qPCR---Testing-P.generosa-Reproduction-related-Primers/index.html",
    "href": "posts/2020/2020-07-23-qPCR---Testing-P.generosa-Reproduction-related-Primers/index.html",
    "title": "qPCR - Testing P.generosa Reproduction-related Primers",
    "section": "",
    "text": "Shelly has asked me to test some qPCR primers related to geoduck reproduction.\nTable of SRIDs and primer name (sorted by primer name):\n\n\n\nSRID\nPrimer_Name\n\n\n\n\n1769\nAPLP_FWD\n\n\n1768\nAPLP_REV\n\n\n1761\nGSK3B_FWD\n\n\n1760\nGSK3B_REV\n\n\n1763\nNFIP1_FWD\n\n\n1762\nNFIP1_REV\n\n\n1745\nRPL5_FWD\n\n\n1744\nRPL5_REV\n\n\n1747\nSPTN1_FWD\n\n\n1746\nSPTN1_REV\n\n\n1773\nTIF3s6b_FWD\n\n\n1772\nTIF3s6b_REV\n\n\n\nUsed pooled cDNA, created by combining 2uL from each of the following:\n\n11-08 1H (made by me from 20191125)\n11-08 2H (made by me from 20191125)\n57H (made by me from 20191125)\n11/15 Chew (made by Kaitlyn, no date on tube)\n11/21 Star (made by Kaitlyn, no date on tube)\n\nI also used geoduck gDNA (162ng/uL; from 20170105) as a potential positive control, and/or as confirmation that these primers will not amplify gDNA.\nAll qPCR reactions were run in duplicate. See qPCR Report (Results section below) for plate layout, cycling params, etc.\nMaster mix calcs are here:\n\n20200723_qPCR_geoduck_primer_tests (Google Sheet)\n\n\n\nRESULTS\nqPCR Report (PDF):\n\nsam_2020-07-23_09-33-48_BR006896.pdf\n\nCFX Data File (PCRD):\n\nsam_2020-07-23%2009-33-48_BR006896.pcrd\n\nCFX Results File (CSV):\n\nsam_2020-07-23_09-33-48_BR006896-Quantification-Cq-Results.csv\n\n\nPlot color legend:\n\nAPLP: BLACK\nGSK3B: CHARTREUSE\nNFIP1: POWDER BLUE\nRPL5: BLUE\nSPTN1: LIGHT GREEN\nTIF3s6B: MAGENTA\nNo Template Controls: RED\n\n\n\nAmplification plots\n\n\n\nAmplifcation plots\n\n\n\n\nMelt curves\n\n\n\nMelt curves\n\n\n\nNo template controls (NTCs) did not generate any amplification in any of the primer sets.\nAll primer sets generated amplification in both cDNA and gDNA.\nThere are only two primer sets that produced acceptable melt curves:\n\nAPLP (BLACK melt plot)\nNFIP1 (POWDER BLUE melt plot)"
  },
  {
    "objectID": "posts/2020/2020-03-06-TrimmingMultiQC---Methcompare-Bisulfite-FastQs-with-fastp-on-Mox/index.html",
    "href": "posts/2020/2020-03-06-TrimmingMultiQC---Methcompare-Bisulfite-FastQs-with-fastp-on-Mox/index.html",
    "title": "Trimming/MultiQC - Methcompare Bisulfite FastQs with fastp on Mox",
    "section": "",
    "text": "Steven asked me to trim a set of FastQ files, provided by Hollie Putnam, in preparation for methylation analysis using Bismark. The analysis is part of a coral project comparing DNA methylation profiles of different species, as well as comparing different sample prep protocols. There’s a dedicated GitHub repo here:\n\nMeth_Compare\n\nI roughly followed the trimming pipeline that Hollie had already put together, but opted to use the program fastp as it is generally faster than other trimmers and comes with the bonus ability of generating pre/post-trimming graphs/tables; similar to FastQC. Additionally, [MultiQC(https://multiqc.info/)] can also interpret the output of fastp to generate summary statistics/graphs like it can with FastQC.\nThe data consisted of two different types of libraries: reduced representation bisfultie (RRBS) and whole genome bisulfite (WGBS). Knowing this, I followed the Bismark trimming guidelines for each library type. The fastp trimming and MultiQC were run with the following SBATCH script (GitHub):\n\n20200305_methcompare_fastp_trimming.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=pgen_fastp_trimming_EPI\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=1-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200305_methcompare_fastp_trimming\n\n\n### WGBS and RRBS trimming using fastp.\n### FastQ files were provide by Hollie Putnam.\n### See this GitHub repo for more info:\n### https://github.com/hputnam/Meth_Compare\n\n# Exit script if any command fails\n# set -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# Set number of CPUs to use\nthreads=27\n\n# Paths to programs\nfastp=/gscratch/srlab/programs/fastp-0.20.0/fastp\nmultiqc=/gscratch/srlab/programs/anaconda3/bin/multiqc\n\n# Programs array\nprograms_array=(\"${fastp}\" \"${multiqc}\")\n\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    echo \"Program options for ${programs_array[program]}: \"\n    echo \"\"\n    ${programs_array[program]} -h\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\ndone &>> program_options.log\n\n\n# Input/output files\ntrimmed_checksums=trimmed_fastq_checksums.md5\n\n# Inititalize arrays\n# These were provided by Hollie Putnam\n# See https://github.com/hputnam/Meth_Compare/blob/master/Meth_Compare_Pipeline.md\nrrbs_array=(Meth4 Meth5 Meth6 Meth13 Meth14 Meth15)\nwgbs_array=(Meth1 Meth2 Meth3 Meth7 Meth8 Meth9 Meth10 Meth11 Meth12 Meth16 Meth17 Meth18)\n\n# Assign file suffixes to variables\nread1=\"_R1_001.fastq.gz\"\nread2=\"_R2_001.fastq.gz\"\n\n# Create list of fastq files used in analysis\nfor fastq in *.gz\ndo\n  echo \"${fastq}\" >> fastq.list.txt\ndone\n\n# Run fastp on RRBS files\n# Specifies removal of first 2bp from 3' end of read1 and\n# removes 2bp from 5' end of read2, per Bismark instructions for RRBS\n# https://rawgit.com/FelixKrueger/Bismark/master/Docs/Bismark_User_Guide.html\nfor index in \"${!rrbs_array[@]}\"\ndo\n    timestamp=$(date +%Y%m%d%M%S)\n    ${fastp} \\\n    --in1 \"${rrbs_array[index]}${read1}\" \\\n    --in2 \"${rrbs_array[index]}${read2}\" \\\n    --detect_adapter_for_pe \\\n    --trim_tail1 2 \\\n    --trim_front2 2 \\\n    --thread ${threads} \\\n    --html \"${rrbs_array[index]}.fastp-trim.${timestamp}.report.html\" \\\n    --json \"${rrbs_array[index]}.fastp-trim.${timestamp}.report.json\" \\\n    --out1 \"${rrbs_array[index]}.fastp-trim.${timestamp}${read1}\" \\\n    --out2 \"${rrbs_array[index]}.fastp-trim.${timestamp}${read2}\"\n\n    # Generate md5 checksums for newly trimmed files\n    {\n        md5sum \"${rrbs_array[index]}.fastp-trim.${timestamp}${read1}\"\n        md5sum \"${rrbs_array[index]}.fastp-trim.${timestamp}${read2}\"\n    } >> \"${trimmed_checksums}\"\n\ndone\n\n# Run fastp on WGBS files\n# Specifies removal of first 10bp from 5' and 3' end of all reads\n# per Bismark instructions for WGBS Zymo/Swift library kits\n# https://rawgit.com/FelixKrueger/Bismark/master/Docs/Bismark_User_Guide.html\nfor index in \"${!wgbs_array[@]}\"\ndo\n    timestamp=$(date +%Y%m%d%M%S)\n    ${fastp} \\\n    --in1 \"${wgbs_array[index]}${read1}\" \\\n    --in2 \"${wgbs_array[index]}${read2}\" \\\n    --detect_adapter_for_pe \\\n    --trim_front1 10 \\\n    --trim_tail1 10 \\\n    --trim_front2 10 \\\n    --trim_tail2 10 \\\n    --thread ${threads} \\\n    --html \"${wgbs_array[index]}.fastp-trim.${timestamp}.report.html\" \\\n    --json \"${wgbs_array[index]}.fastp-trim.${timestamp}.report.json\" \\\n    --out1 \"${wgbs_array[index]}.fastp-trim.${timestamp}${read1}\" \\\n    --out2 \"${wgbs_array[index]}.fastp-trim.${timestamp}${read2}\"\n\n    # Generate md5 checksums for newly trimmed files\n    {\n        md5sum \"${wgbs_array[index]}.fastp-trim.${timestamp}${read1}\"\n        md5sum \"${wgbs_array[index]}.fastp-trim.${timestamp}${read2}\"\n    } >> \"${trimmed_checksums}\"\n\ndone\n\n# Run multiqc\n${multiqc} .\n\n\nRESULTS\nThis took ~6.5hrs to complete:\n\n\n\nScreencap of Mox runtime\n\n\nThe runtime in the image above shows a runtime of ~5hrs. However, a subset of samples were not properly processed by fastp (everything in the logs looked fine, no errors, but no output files were generated; very odd). I re-ran a subset of the code on the “missing” samples and it worked fine. Took ~1.5hrs to process the remaining samples.\nOutput folder:\n\n20200305_methcompare_fastp_trimming/\n\nI retained the raw FastQs provided by Hollie for posterity.\nTrimmed files are named with the following convention:\n\n.fastp-trim.gz\n\nIndividual (on a per read pair basis) fastp HTML reports are named similarly:\n\n*.report.html\n\nMultiQC report (HTML):\n\n20200305_methcompare_fastp_trimming/multiqc_report.html"
  },
  {
    "objectID": "posts/2020/2020-08-17-Assembly-Stats---Hematodinium-Transcriptomes-v2.1-and-v3.1-Trinity-Stats-on-Mox/index.html",
    "href": "posts/2020/2020-08-17-Assembly-Stats---Hematodinium-Transcriptomes-v2.1-and-v3.1-Trinity-Stats-on-Mox/index.html",
    "title": "Assembly Stats - cbaiodinium Transcriptomes v2.1 and v3.1 Trinity Stats on Mox",
    "section": "",
    "text": "Working on dealing with our various cbaiodinium sp. transcriptomes and realized that transcriptomes v2.1 and v3.1 (extracted from BLASTx-annotated FastAs from 20200605) didn’t have any associated stats.\nUsed built-in Trinity scripts to generate assembly stats on Mox.\nSBATCH script (GitHub):\n\n20200819_cbai_trinity_stats_v2.1_3.1.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=20200819_cbai_trinity_stats_v2.1_3.1\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=15-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200819_cbai_trinity_stats_v2.1_3.1\n\n\n# Script to generate cbaiodinium Trinity transcriptome stats:\n# v2.1\n# v3.1\n\n###################################################################################\n# These variables need to be set by user\n\n# Assign Variables\ntranscriptomes_dir=/gscratch/srlab/sam/data/cbaiodinium/transcriptomes\n\n\n# Paths to programs\ntrinity_dir=\"/gscratch/srlab/programs/trinityrnaseq-v2.9.0\"\nsamtools=\"/gscratch/srlab/programs/samtools-1.10/samtools\"\n\n\n# Array of the various comparisons to evaluate\n# Each condition in each comparison should be separated by a \"-\"\ntranscriptomes_array=(\n\"${transcriptomes_dir}\"/cbai_transcriptome_v2.1.fasta \\\n\"${transcriptomes_dir}\"/cbai_transcriptome_v3.1.fasta\n)\n\n\n\n\n# Programs array\ndeclare -A programs_array\nprograms_array=(\n[samtools_faidx]=\"${samtools} faidx\" \\\n[trinity_stats]=\"${trinity_dir}/util/TrinityStats.pl\" \\\n[trinity_gene_trans_map]=\"${trinity_dir}/util/support_scripts/get_Trinity_gene_to_trans_map.pl\" \\\n[trinity_fasta_seq_length]=\"${trinity_dir}/util/misc/fasta_seq_length.pl\"\n)\n\n\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n\n# Loop through each transcriptome\nfor transcriptome in \"${!transcriptomes_array[@]}\"\ndo\n\n\n  # Variables\n  transcriptome_name=\"${transcriptomes_array[$transcriptome]##*/}\"\n  assembly_stats=\"${transcriptome_name}_assembly_stats.txt\"\n\n\n  # Assembly stats\n  ${programs_array[trinity_stats]} \"${transcriptomes_array[$transcriptome]}\" \\\n  > \"${assembly_stats}\"\n\n  # Create gene map files\n  ${programs_array[trinity_gene_trans_map]} \\\n  \"${transcriptomes_array[$transcriptome]}\" \\\n  > \"${transcriptome_name}\".gene_trans_map\n\n  # Create sequence lengths file (used for differential gene expression)\n  ${programs_array[trinity_fasta_seq_length]} \\\n  \"${transcriptomes_array[$transcriptome]}\" \\\n  > \"${transcriptome_name}\".seq_lens\n\n  # Create FastA index\n  ${programs_array[samtools_faidx]} \\\n  \"${transcriptomes_array[$transcriptome]}\" \\\n  > \"${transcriptome_name}\".fai\n\n  # Copy files to transcriptomes directory\n  rsync -av \\\n  \"${transcriptome_name}\"* \\\n  ${transcriptomes_dir}\n\n  # Capture FastA checksums for verification\n  echo \"Generating checksum for ${transcriptome_name}\"\n  md5sum \"${transcriptomes_array[$transcriptome]}\" > \"${transcriptome_name}\".checksum.md5\n  echo \"Finished generating checksum for ${transcriptome_name}\"\n  echo \"\"\n\n\ndone\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# Capture program options\n## Note: Trinity util/support scripts don't have options/help menus\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n    ${programs_array[$program]} --help\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n\nRESULTS\nAs expected, very fast; ~2mins:\n\n\n\ncumulative runtime of running Trinity stats scripts on C.bairdi transcriptomes v2.1 and v3.1\n\n\nOutput folder:\n\n20200819_cbai_trinity_stats_v2.1_3.1/\n\nAll stats below have been added to the C.bairdi assembly comparison spreadsheet:\n\ncbai_transcriptome_comp (Google Sheet)\n\n\ncbai_transcriptome_v2.1.fasta\n\n20200819_cbai_trinity_stats_v2.1_3.1/cbai_transcriptome_v2.1.fasta_assembly_stats.txt\n\n################################\n## Counts of transcripts, etc.\n################################\nTotal trinity 'genes':  131239\nTotal trinity transcripts:  237494\nPercent GC: 50.37\n\n########################################\nStats based on ALL transcript contigs:\n########################################\n\n    Contig N10: 5347\n    Contig N20: 3867\n    Contig N30: 3024\n    Contig N40: 2457\n    Contig N50: 1996\n\n    Median contig length: 494\n    Average contig: 1037.76\n    Total assembled bases: 246461881\n\n\n#####################################################\n## Stats based on ONLY LONGEST ISOFORM per 'GENE':\n#####################################################\n\n    Contig N10: 5047\n    Contig N20: 3463\n    Contig N30: 2579\n    Contig N40: 1938\n    Contig N50: 1388\n\n    Median contig length: 344\n    Average contig: 722.72\n    Total assembled bases: 94849243\nOther useful files for downstream annotation using Trinotate:\nTrinity Gene Trans Map:\n\n20200819_cbai_trinity_stats_v2.1_3.1/cbai_transcriptome_v2.1.fasta.gene_trans_map\n\nTrinity FastA Sequence Lengths:\n\n20200819_cbai_trinity_stats_v2.1_3.1/cbai_transcriptome_v2.1.fasta.seq_lens\n\n\n\ncbai_transcriptome_v3.1.fasta\n\n20200819_cbai_trinity_stats_v2.1_3.1/cbai_transcriptome_v3.1.fasta_assembly_stats.txt\n\n################################\n## Counts of transcripts, etc.\n################################\nTotal trinity 'genes':  27399\nTotal trinity transcripts:  78649\nPercent GC: 48.83\n\n########################################\nStats based on ALL transcript contigs:\n########################################\n\n    Contig N10: 5638\n    Contig N20: 4370\n    Contig N30: 3580\n    Contig N40: 3016\n    Contig N50: 2580\n\n    Median contig length: 1522\n    Average contig: 1825.11\n    Total assembled bases: 143543003\n\n\n#####################################################\n## Stats based on ONLY LONGEST ISOFORM per 'GENE':\n#####################################################\n\n    Contig N10: 5753\n    Contig N20: 4423\n    Contig N30: 3622\n    Contig N40: 3052\n    Contig N50: 2597\n\n    Median contig length: 979\n    Average contig: 1505.44\n    Total assembled bases: 41247546\nOther useful files for downstream annotation using Trinotate:\nTrinity Gene Trans Map:\n\n20200819_cbai_trinity_stats_v2.1_3.1/cbai_transcriptome_v3.1.fasta.gene_trans_map\n\nTrinity FastA Sequence Lengths:\n\n20200819_cbai_trinity_stats_v2.1_3.1/cbai_transcriptome_v3.1.fasta.seq_lens"
  },
  {
    "objectID": "posts/2020/2020-11-06-Data-Wrangling---MultiQC-on-S.salar-RNAseq-from-fastp-and-HISAT2-on-Mox/index.html",
    "href": "posts/2020/2020-11-06-Data-Wrangling---MultiQC-on-S.salar-RNAseq-from-fastp-and-HISAT2-on-Mox/index.html",
    "title": "Data Wrangling - MultiQC on S.salar RNAseq from fastp and HISAT2 on Mox",
    "section": "",
    "text": "In Shelly’s GitHub Issue for this S.salar project, she also requested a MultiQC report for the trimming (completed on 20201029) and the genome alignments (completed on 20201103).\nI ran MultiQC on Mox using a build node and no script, since the command is so simple (e.g. multiqc .) and so quick.\n\n\nRESULTS\nOutput folder:\n\n20201106_ssalar_multiqc_fastp-hisat2/\n\n\nMultiQC report (HTML)\n\n20201106_ssalar_multiqc_fastp-hisat2/multiqc_report.html\n\nA couple of notes:\n\nThe [fastp](https://github.com/OpenGene/fastp) trimming results are reported with sample names with a _1. This is an unfortunate mistake with name parsing. The results are comprised of both Read 1 and Read 2 FastQ data; not just Read 1.\nThe HISAT2 results also suffer from a poor filename that ends with .err. Despite the name, these files actually contain the alignment summary data."
  },
  {
    "objectID": "posts/2020/2020-08-21-DNA-Isolation-and-Quantification---C.gigas-High-Low-pH-Triploid-and-Diploid-Ctenidia/index.html",
    "href": "posts/2020/2020-08-21-DNA-Isolation-and-Quantification---C.gigas-High-Low-pH-Triploid-and-Diploid-Ctenidia/index.html",
    "title": "DNA Isolation and Quantification - C.gigas High-Low pH Triploid and Diploid Ctenidia",
    "section": "",
    "text": "Isolated DNA from 24 of the Crassostrea gigas high/low pH triploid/diploid ctenidia samples that we received yesterday from the Haws Lab. Samples selected by Steven.\nAs noted yesterday, the samples appeared to be very liquid-y, so I spun them down for 1min @ 10,000g to help pellet the tissue. Discarded as much supernatant as possible. Isolated DNA using the E.Z.N.A. Mollusc Kit (Omega), according to the manufacturer’s protocol with the following changes/notes (no option steps were performed):\n\nincubated O/N @ 37oC\neluted with 100uL of Elution Buffer\n\nOf note, upon initial addition of the lysis buffer (MBL1), a thick, white precipitate formed immediately. Vortexing seemed to help emulsify this. However, upon retrieving the samples the next day, the sample appeared the same, with the thick, white precipitate sitting on top of the rest of the liquid. Many of the samples did not fully lyse.\nDNA was quantified using the Roberts Lab Qubit 3.0 and the ds DNA BR Assay (Invitrogen), using 2uL of each sample.\nUPDATE: It turns out the samples were preserved in DNA/RNA Shield (ZymoResearch)! I was not informed of this prior to my inquiry as to why all of the samples seemed to have so much liquid, when I was simply expecting frozen tissue.\n\n\nRESULTS\nQubit results:\n\n20200821_qubit_gDNA_cgigas_hawaii_ploidy_pH (Google Sheet)\n\nYields look good. So, good to know that DNA/RNA Shield doesn’t seem to have an impact on DNA isolations performed with the E.Z.N.A. Mollusc Kit!\nSamples were stored @ -20oC in Sam’s gDNA Box #3, positions F4 - H9.\n\n\n\nSample_ID\nConcentration(ng/uL)\nVolume(uL)\nTotal_DNA(ng)\n\n\n\n\n2N_HI_5\n40.4\n100\n4040\n\n\n2N_HI_8\n11.6\n100\n1160\n\n\n2N_HI_9\n32.3\n100\n3230\n\n\n2N_HI_10\n61\n100\n6100\n\n\n2N_HI_11\n21\n100\n2100\n\n\n2N_HI_12\n11.2\n100\n1120\n\n\n2N_LOW_1\n32.1\n100\n3210\n\n\n2N_LOW_2\n32.5\n100\n3250\n\n\n2N_LOW_3\n36\n100\n3600\n\n\n2N_LOW_4\n40.2\n100\n4020\n\n\n2N_LOW_5\n17.8\n100\n1780\n\n\n2N_LOW_6\n22.8\n100\n2280\n\n\n3N_HI_2\n29.6\n100\n2960\n\n\n3N_HI_3\n71.8\n100\n7180\n\n\n3N_HI_5\n29.3\n100\n2930\n\n\n3N_HI_8\n38.9\n100\n3890\n\n\n3N_HI_10\n38.3\n100\n3830\n\n\n3N_HI_11\n52.3\n100\n5230\n\n\n3N_LOW_6\n35.3\n100\n3530\n\n\n3N_LOW_7\n43.6\n100\n4360\n\n\n3N_LOW_8\n63.9\n100\n6390\n\n\n3N_LOW_10\n54.4\n100\n5440\n\n\n3N_LOW_11\n50.8\n100\n5080\n\n\n3N_LOW_12\n52\n100\n5200"
  },
  {
    "objectID": "posts/2020/2020-06-01-Transcriptome-Comparison---C.bairdi-Transcriptomes-Evaluations-with-DETONATE-on-Mox/index.html",
    "href": "posts/2020/2020-06-01-Transcriptome-Comparison---C.bairdi-Transcriptomes-Evaluations-with-DETONATE-on-Mox/index.html",
    "title": "Transcriptome Comparison - C.bairdi Transcriptomes Evaluations with DETONATE on Mox",
    "section": "",
    "text": "Attempting to get some other metrics regarding our various C.bairdi transcriptome assemblies other than BUSCO scores, I decided to try running DETONATE, as this is a recommended tool by Trinity.\nI recently ran DETONATE’s ref-eval (see 20200529) because it was relatively easy to do and thought it might be useful, as it’s included in the DETONATE package. However, the results are complicated to interpret and I’m not sure they actually tell us anything.\nContinuing with the DETONATE package, I ran the other component (which is probably what we really want and will provide us with a simple “score” which will be easier to understand), rsem-eval. Plus, it’s a very low effort process, so might as well give it a whirl.\nThe job was run on Mox.\nSBATCH script (GitHub):\n\n20200616_cbai_detonate_transcriptome_evaluations.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_detonate_transcriptome_evaluations\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=15-00:00:00\n## Memory per node\n#SBATCH --mem=500G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200616_cbai_detonate_transcriptome_evaluations\n\n\n###################################################################################\n# These variables need to be set by user\n\n# Assign Variables\n## frag_size is guesstimate of library fragment sizes\nfrag_size=500\nreads_dir=/gscratch/srlab/sam/data/C_bairdi/RNAseq\ntranscriptomes_dir=/gscratch/srlab/sam/data/C_bairdi/transcriptomes\nthreads=28\n\n# Array of the various comparisons to evaluate\n# Each condition in each comparison should be separated by a \"-\"\ntranscriptomes_array=(\n\"${transcriptomes_dir}\"/cbai_transcriptome_v1.0.fasta \\\n\"${transcriptomes_dir}\"/cbai_transcriptome_v1.5.fasta \\\n\"${transcriptomes_dir}\"/cbai_transcriptome_v1.6.fasta \\\n\"${transcriptomes_dir}\"/cbai_transcriptome_v1.7.fasta \\\n\"${transcriptomes_dir}\"/cbai_transcriptome_v2.0.fasta \\\n\"${transcriptomes_dir}\"/cbai_transcriptome_v2.1.fasta \\\n\"${transcriptomes_dir}\"/cbai_transcriptome_v3.0.fasta \\\n\"${transcriptomes_dir}\"/cbai_transcriptome_v3.1.fasta\n)\n\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n\n# Programs array\ndeclare -A programs_array\nprograms_array=(\n[bowtie2]=\"/gscratch/srlab/programs/bowtie2-2.3.5.1-linux-x86_64\" \\\n[detonate_trans_length]=\"/gscratch/srlab/programs/detonate-1.11/rsem-eval/rsem-eval-estimate-transcript-length-distribution\" \\\n[detonate]=\"/gscratch/srlab/programs/detonate-1.11/rsem-eval/rsem-eval-calculate-score\"\n)\n\n\n\n\n# Loop through each comparison\nfor transcriptome in \"${!transcriptomes_array[@]}\"\ndo\n\n  ## Inititalize arrays\n  R1_array=()\n  R2_array=()\n  reads_array=()\n\n  # Variables\n  R1_list=\"\"\n  R2_list=\"\"\n\n  transcriptome_name=\"${transcriptomes_array[$transcriptome]##*/}\"\n\n\n  rsem_eval_dist_mean_sd=\"${transcriptome_name}_true_length_dis_mean_sd.txt\"\n\n  # Capture FastA checksums for verification\n  echo \"Generating checksum for ${transcriptome_name}\"\n  md5sum \"${transcriptomes_array[transcriptome]}\" >> fasta.checksums.md5\n  echo \"Finished generating checksum for ${transcriptome_name}\"\n  echo \"\"\n\n    if [[ \"${transcriptome_name}\" == \"cbai_transcriptome_v1.0.fasta\" ]]; then\n\n    reads_array=(\"${reads_dir}\"/20200[15][13][138]*megan*.fq)\n\n    # Create array of fastq R1 files\n    R1_array=(\"${reads_dir}\"/20200[15][13][138]*megan*R1.fq)\n\n    # Create array of fastq R2 files\n    R2_array=(\"${reads_dir}\"/20200[15][13][138]*megan*R2.fq)\n\n\n\n  elif [[ \"${transcriptome_name}\" == \"cbai_transcriptome_v1.5.fasta\" ]]; then\n\n    reads_array=(\"${reads_dir}\"/20200[145][13][138]*megan*.fq)\n\n    # Create array of fastq R1 files\n    R1_array=(\"${reads_dir}\"/20200[145][13][138]*megan*R1.fq)\n\n    # Create array of fastq R2 files\n    R2_array=(\"${reads_dir}\"/20200[145][13][138]*megan*R2.fq)\n\n  elif [[ \"${transcriptome_name}\" == \"cbai_transcriptome_v1.6.fasta\" ]]; then\n\n    reads_array=(\"${reads_dir}\"/*megan*.fq)\n\n    # Create array of fastq R1 files\n    R1_array=(\"${reads_dir}\"/*megan*R1.fq)\n\n    # Create array of fastq R2 files\n    R2_array=(\"${reads_dir}\"/*megan*R2.fq)\n\n  elif [[ \"${transcriptome_name}\" == \"cbai_transcriptome_v1.7.fasta\" ]]; then\n\n    reads_array=(\"${reads_dir}\"/20200[145][13][189]*megan*.fq)\n\n    # Create array of fastq R1 files\n    R1_array=(\"${reads_dir}\"/20200[145][13][189]*megan*R1.fq)\n\n    # Create array of fastq R2 files\n    R2_array=(\"${reads_dir}\"/20200[145][13][189]*megan*R2.fq)\n\n  elif [[ \"${transcriptome_name}\" == \"cbai_transcriptome_v2.0.fasta\" ]] \\\n  || [[ \"${transcriptome_name}\" == \"cbai_transcriptome_v2.1.fasta\" ]]; then\n\n    reads_array=(\"${reads_dir}\"/*fastp-trim*.fq)\n\n    # Create array of fastq R1 files\n    R1_array=(\"${reads_dir}\"/*R1*fastp-trim*.fq)\n\n    # Create array of fastq R2 files\n    R2_array=(\"${reads_dir}\"/*R2*fastp-trim*.fq)\n\n  elif [[ \"${transcriptome_name}\" == \"cbai_transcriptome_v3.0.fasta\" ]] \\\n  || [[ \"${transcriptome_name}\" == \"cbai_transcriptome_v3.1.fasta\" ]]; then\n\n    reads_array=(\"${reads_dir}\"/*fastp-trim*20[12][09][01][24]1[48]*.fq)\n\n    # Create array of fastq R1 files\n    R1_array=(\"${reads_dir}\"/*R1*fastp-trim*20[12][09][01][24]1[48]*.fq)\n\n    # Create array of fastq R2 files\n    R2_array=(\"${reads_dir}\"/*R2*fastp-trim*20[12][09][01][24]1[48]*.fq)\n\n\n  fi\n\n  # Create list of fastq files used in analysis\n  ## Uses parameter substitution to strip leading path from filename\n  printf \"%s\\n\" \"${reads_array[@]##*/}\" >> \"${transcriptome_name}\".fastq.list.txt\n\n  # Create comma-separated lists of FastQ reads\n  R1_list=$(echo \"${R1_array[@]}\" | tr \" \" \",\")\n  R2_list=$(echo \"${R2_array[@]}\" | tr \" \" \",\")\n\n  # Determine transcript length\n  ${programs_array[detonate_trans_length]} \\\n  \"${transcriptomes_array[$transcriptome]}\" \\\n  \"${rsem_eval_dist_mean_sd}\"\n\n\n  # Run rsem-eval\n  # Use bowtie2 and paired-end options\n  ${programs_array[detonate]} \\\n  --bowtie2 \\\n  --bowtie2-path \"${programs_array[bowtie2]}\" \\\n  --num-threads ${threads} \\\n  --transcript-length-parameters \"${rsem_eval_dist_mean_sd}\" \\\n  --paired-end \\\n  \"${R1_list}\" \\\n  \"${R2_list}\" \\\n  \"${transcriptomes_array[$transcriptome]}\" \\\n  \"${transcriptome_name}\" \\\n  ${frag_size}\n\n\n\ndone\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n    ${programs_array[$program]} --help\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n\nRESULTS\nThis process was PAINFUL. Here’s the “runtime” for the failed job (due to it timing out; after 65 DAYS!). Also, this was just for cbai_transcriptome_v2.0!!!\n\n\n\nref-eval runtime of 65 days\n\n\nOverall, even though this required very little effort on my part, it was kind of a pain to manage. For some reason (I guess it’s due to the number of sequences it has to align) cbai_transcriptome_v2.0 alignments took too long (i.e. longer than the 30 days between Mox node maintenance). I restarted this job a couple of times and I finally lucked out for a bit when the October, November, and December 2020 Mox maintenance dates were canceled. Despite that, I neglected to extend the runtime further in December and the job timed out.\nBut, with that said, part of me thinks something weird was going on anyway. I mean, look at the size of the BAM file (remember, a BAM file is a compressed version of a SAM file, and is usually close to 10x smaller than the originating SAM file!) that was still being made when the job died:\n\n\n\ncbai_transcriptome_v2.0 BAM file size screencap\n\n\n789GB!!!!\nThat’s absurd! Not to mention the fact that this was generated over the course of two months!\nI’m going to try one more thing to see if I can get rsem-eval to work. Again, it’s low effort, so won’t take too much of my time. I’m going to run bowtie2 independently of rsem-eval (bowtie2 alignment is built-in to that, if the user wants to use it) and see if that is somehow faster. If it is, then I can provide the resulting BAM files as input to rsem-eval."
  },
  {
    "objectID": "posts/2020/2020-09-04-Data-Wrangling---NanoPore-Fast5-Conversion-to-FastQ-of-C.bairdi-20102558-2729-Run-02-on-Mox-with-GPU-Node/index.html",
    "href": "posts/2020/2020-09-04-Data-Wrangling---NanoPore-Fast5-Conversion-to-FastQ-of-C.bairdi-20102558-2729-Run-02-on-Mox-with-GPU-Node/index.html",
    "title": "Data Wrangling - NanoPore Fast5 Conversion to FastQ of C.bairdi 20102558-2729 Run-02 on Mox with GPU Node",
    "section": "",
    "text": "Continuing to work with the NanoPore data that I generated back in January(???!!!). In order to proceed, I first need to convert the raw Fast5 files to FastQ. To do so, I’ll use the NanoPore program guppy. I converted the first run from this flowcell earlier today.\nAs noted in that previous conversion, using a Mox GPU node decreases processing time by a ridiculous amount, compared to using CPUs. The only rub is that since we don’t own a GPU node, any jobs we submit are:\n\nlowest priority in any queue\ncan get interrupted at any time by jobs submitted by the node owner\n\nI’ll be submitting these very early in the morning and with runtimes this fast, I shouldn’t encounter any issues. Exciting!\nSBATCH script (GitHub):\n\n20200114_cbai_guppy_nanopore_20102558-2729.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_guppy_nanopore_20102558-2729\n## Allocation Definition\n#SBATCH --account=srlab-ckpt\n#SBATCH --partition=ckpt\n## Resources\n## GPU\n#SBATCH --gres=gpu:P100:1\n#SBATCH --constraint=gpu_default\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=0-01:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200114_cbai_guppy_nanopore_20102558-2729\n\n## Script for running ONT guppy to perform\n## basecalling (i.e. convert raw ONT Fast5 to FastQ) of NanaPore data generated\n## on 20200110 from C.bairdi 20102558-2729 gDNA. It is a second run using the same flowcell\n## used on 20200110.\n\n## This script utilizes a GPU node. These nodes are only available as part of the checkpoint\n## partition/account. Since we don't own a GPU node, our GPU jobs are lowest priority and\n## can be interrupted at any time if the node owner submits a new job.\n\n###################################################################################\n# These variables need to be set by user\n\nwd=$(pwd)\n\n# Programs array\ndeclare -A programs_array\nprograms_array=(\n[guppy_basecaller]=\"/gscratch/srlab/programs/ont-guppy_4.0.15_linux64/bin/guppy_basecaller\"\n)\n\n# Establish variables for more readable code\n\n# Input files directory\nfast5_dir=/gscratch/srlab/sam/data/C_bairdi/DNAseq/ont_FAL58500_04bb4d86_20102558-2729\n\n# Output directory\nout_dir=${wd}\n\n# CPU threads\nthreads=28\n\n# Flowcell type\nflowcell=\"FLO-MIN106\"\n\n# Sequencing kit used\nkit=\"SQK-RAD004\"\n\n# GPU devices setting\nGPU_devices=auto\n\n# Set number of FastQ sequences written per file (0 means all in one file)\nrecords_per_fastq=0\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Load CUDA GPU module\nmodule load cuda/10.1.105_418.39\n\n\n${programs_array[guppy_basecaller]} \\\n--input_path ${fast5_dir} \\\n--save_path ${out_dir} \\\n--flowcell ${flowcell} \\\n--kit ${kit} \\\n--device ${GPU_devices} \\\n--records_per_fastq ${records_per_fastq} \\\n--num_callers ${threads}\n\n###################################################################################\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : n\n} >> system_path.log\n\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n    ${programs_array[$program]} --help\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n\nRESULTS\nTook ~6mins to process the convert the six Fast5 files:\n\n\n\nFast5 to FastQ conversion runtime with Mox GPU node\n\n\nOutput folder:\n\n20200114_cbai_guppy_nanopore_20102558-2729/\n\nSequencing Summary (4.7MB; TXT)\n\n20200114_cbai_guppy_nanopore_20102558-2729/sequencing_summary.txt\n\nUseful with downstream analysis tools, like NanoPlot.\n\n\nAll the resulting FastQ files can be accessed in the output folder linked above with this pattern:\n\n*.fastq\n\nUnbeknownst to me, I misinterpreted the behavior of the program. I thought the FastQs from all of the Fast5 would be concatenated into a single FastQ. However, that’s not the case. Each Fast5 got converted to its own FastQ. So, I now have six FastQ files instead of just one. Not a big deal as I can concatenate these at a later date.\nNow, I’ll get these run through some QC software (FastQC, NanoPlot) to get an idea of how things look before processing them further."
  },
  {
    "objectID": "posts/2020/2020-12-02-Library-Quantification---M.magister-MBD-BSseq-Libraries-with-Qubit/index.html",
    "href": "posts/2020/2020-12-02-Library-Quantification---M.magister-MBD-BSseq-Libraries-with-Qubit/index.html",
    "title": "Library Quantification - M.magister MBD BSseq Libraries with Qubit",
    "section": "",
    "text": "After reviewing the Bionalyzer assays for the MBD BSseq libraries Mac indicated she’d like to have the libraries quantified using the Qubit.\nI used 1uL of all samples with the 1x DNA HS Qubit Assay (Invitrogen) on the Roberts Lab Qubit 3.0.\n\n\nRESULTS\nQubit data (Google Sheet):\n\n20201202_qubit_DNA_mmag_MBD-libraries\n\nWill use this data, in conjunction with the Bioanalyzer average fragment size to determine molarity of each library, in preparation for sample pooling.\nAll data has been added to the principal Google Sheet for tracking this project:\n\nOA Crab Sample Collection 071119\n\nAdditional details are available in this GitHub repo:\n\nproject-dungeness-crab"
  },
  {
    "objectID": "posts/2020/2020-02-26-qPCR---C.bairdi-RNA-Check-for-Residual-gDNA/index.html",
    "href": "posts/2020/2020-02-26-qPCR---C.bairdi-RNA-Check-for-Residual-gDNA/index.html",
    "title": "qPCR - C.bairdi RNA Check for Residual gDNA",
    "section": "",
    "text": "After deciding on a primer set to use for gDNA detection on 20200225, went ahead and ran a qPCR on most of the RNA samples described in Grace’s Google Sheet. Some samples were not run, as they had not yet been located at the time I began the qPCR.\nUsed 2ng of RNA (1uL) in each reaction. A 5uL dilution of each sample was made to a concentration of 2ng/uL. The decision for this quantity was based on the amount of RNA we might use in a reverse transcription reaction (50ng/25uL) and the volume of the resulting cDNA we’d run in a qPCR reaction (1uL). Calculations and the qPCR results (Cq values) are below (Google Sheet). It’s a modified version of Grace’s spreadsheet (linked above).\n\n20200226_cbai_RNA_calcs-qPCR_results\n\nAll reactions were run with 2x SsoFast EVA Green qPCR Master Mix (BioRad) on the Roberts Lab CFX Connect qPCR machine.\nAll samples were run in duplicate. See the qPCR Report (in Results section below) for plate layout, cycling params, etc.\nMaster mix calcs are here (Google Sheet):\n\n20200226_qPCR_cbai_RNA_checks_master_mix_calcs\n\nNOTE: Sample 238 has almost nothing left; maybe 1uL?\n\n\nRESULTS\nqPCR data file (CFX):\n\nsam_2020-02-26 2010-15-38_BR006896.pcrd\n\nqPCR Report (PDF):\n\nsam_2020-02-26 2010-15-38_BR006896.pdf\n\nqPCR results file (CSV):\n\nsam_2020-02-26%2010-15-38_BR006896_-_Quantification Cq Results.csv\n\nThe majority of samples that had been previously DNased did not have any residual gDNA. The majority of samples that had not been previously DNased still had residual gDNA.\nOverall, about 50% of the samples (n = 20) will either need to be DNased and/or have additional RNA isolated in conjunction with the DNase step of the Quick DNA/RNA Microprep Plus Kit (ZymoResearch). The remaining samples (n = 24) are free of gDNA, buta couple of them may require more RNA to be isolated.\nWe might proceed just proceed with reverse transcription of samples that:\n\nDo not need to be DNased.\nHave sufficient quantity of RNA (whatever we deem that quantity to be…).\n\nWill discuss with Steven and Grace to see how we want to roll.\n\n\n\nAmplification Plots\nBlue: RNA samples\nGreen: Positive control gDNA\nRed: No template controls\n\n\n\nqPCR amplification plots\n\n\n\n\n\nMelt curve plots\nSame color scheme as amplification plots\n\n\n\nqPCR melt curve plots"
  },
  {
    "objectID": "posts/2020/2020-10-21-DNA-Shearing---M.magister-gDNA-Shear-Testing-and-Bioanalyzer/index.html",
    "href": "posts/2020/2020-10-21-DNA-Shearing---M.magister-gDNA-Shear-Testing-and-Bioanalyzer/index.html",
    "title": "DNA Shearing - M.magister gDNA Shear Testing and Bioanalyzer",
    "section": "",
    "text": "Steven assigned me to do some MBD-BSseq library prep (GitHub Issue) for some Dungeness crab (Metacarcinus magister) DNA samples provided by Mackenzie Gavery. The DNA was isolated from juvenile (J6/J7 developmental stages) gill tissue. One of the first steps in MBD-BSseq is to fragment DNA to a desired size (~350 - 500bp in our case). However, we haven’t worked with Metacarcinus magister DNA previously, so I need to empirically determine sonicator (Bioruptor 300; Diagenode) settings for these samples.\nI used 1ug of DNA in a volume of 50uL, using 0.65mL prelubricated snap cap tubes (Costar; Cat# 3206).\nInitially, I did a 35 cycle (30s ON, 30s OFF; low intensity setting) run and determined it was insufficient, so ran increments of 5 cycles and pulled out 1.5uL after each one to run on the Bioanalyzer.\nPost-sonication/shearing, samples were run on High Sensitivity DNA Assay chips in the Bioanalyzer 2100 (Agilent).\n\n\nRESULTS\nOutput folder/files:\n\n20201021_mmag_bioanalyzer/\n\nBioanalyzer files (XAD; require 2100 Expert software to open)\n\n2100 expert_High Sensitivity DNA Assay_DE72902486_2020-10-21_07-26-05.xad\n2100 expert_High Sensitivity DNA Assay_DE72902486_2020-10-21_08-23-22.xad\n2100 expert_High Sensitivity DNA Assay_DE72902486_2020-10-21_09-50-46.xad\n\n\n\n\nQuick summary: Potentially need to cycle for 70 cycles (!!!!) to achieve desired average fragment length.\nWill test an uninterrupted run tomorrow to confirm that these settings are accurate.\nBelow are all of the electropherograms from each of the total cycles the CHO5-21 gDNA was subjected to: 35 - 80 cycles, increments of 5 cycles. Directly underneath each electropherogram (it’s small - you’ll need to open the image in a new tab to see better) is data showing the mean fragment size within the regions of 50 - 8000bp for each sample.\nThere are also two “pseudo-colored” (this is the software verbiage for heatmap-like coloration) gel representation comparisons of samples. It’s an easy way to see the progression of fragmentation as the cycle number increases.\nAlso, I ended up running three chips (gah!) to accommodate all of this (was not expecting to need to fragment for this number of cycles) and that is why there is not a singular gel representation image allowing for the comparison of all the samples together.\n\n\nElectropherogram: 35 cycles\n\n\n\nBioanalyzer electropherogram for M.magister gDNA sheared for 35 cycles\n\n\n\n\nElectropherogram: 40 cycles\n\n\n\nBioanalyzer electropherogram for M.magister gDNA sheared for 40 cycles\n\n\n\n\nElectropherogram: 45 cycles\n\n\n\nBioanalyzer electropherogram for M.magister gDNA sheared for 45 cycles\n\n\n\n\nElectropherogram: 50 cycles\n\n\n\nBioanalyzer electropherogram for M.magister gDNA sheared for 50 cycles\n\n\n\n\nGel comparison: 40, 45, and 50 cycles\n\n\n\nBioanalyzer gel representation and comparison for M.magister gDNA sheared for 40, 45, and 50 cycles\n\n\n\n\nElectropherogram: 55 cycles\n\n\n\nBioanalyzer electropherogram for M.magister gDNA sheared for 55 cycles\n\n\n\n\nElectropherogram: 60 cycles\n\n\n\nBioanalyzer electropherogram for M.magister gDNA sheared for 60 cycles\n\n\n\n\nElectropherogram: 65 cycles\n\n\n\nBioanalyzer electropherogram for M.magister gDNA sheared for 65 cycles\n\n\n\n\nElectropherogram: 70 cycles\n\n\n\nBioanalyzer electropherogram for M.magister gDNA sheared for 70 cycles\n\n\n\n\nElectropherogram: 75 cycles\n\n\n\nBioanalyzer electropherogram for M.magister gDNA sheared for 75 cycles\n\n\n\n\nElectropherogram: 80 cycles\n\n\n\nBioanalyzer electropherogram for M.magister gDNA sheared for 80 cycles\n\n\n\n\nGel comparison: 55, 60, 65, 70, 75, and 80 cycles\n\n\n\nBioanalyzer gel representation and comparison for M.magister gDNA sheared for 40, 45, and 50 cycles"
  },
  {
    "objectID": "posts/2020/2020-06-18-Metagenomics---Data-Extractions-Using-MEGAN6/index.html",
    "href": "posts/2020/2020-06-18-Metagenomics---Data-Extractions-Using-MEGAN6/index.html",
    "title": "Metagenomics - Data Extractions Using MEGAN6",
    "section": "",
    "text": "Decided to finally take the time to methodically extract data from our metagenomics project so that I have the tables handy when I need them and I can easily share them with other people. Previously, I hadn’t done this due to limitations on looking at the data remotely. I finally downloaded all of the RMA6 files from 20191014 after being fed up with the remote desktop connection and upgrading the size of my hard drive (5 of the six RMA6 files are >40GB in size).\nHere’s an explanation of what was done and how the output files (see RESULTS section below) are named.\n\nAll RMA6 files were imported Files using absolute read counts.\nFor taxonomic extraction, data was extracted at the Class level.\nAll output files were generated using the “summarized” option when exporting, meaning that all the reads at and below the terminal taxonomic class were summed to generate the counts for a given Class.\nAll output files are tab-delimited.\n\nFiles are named in the following fashions:\nPREFIXES:\n\nabs-reads_abs-comparison_: Files were imported using absolute read counts and comparison was run using absolute read counts.\nabs-reads-ind-samples_: Files were imported using absolute read counts and individual samples were analyzed.\n\nROOTS:\n\nday: Data is grouped by day.\npH: Data is grouped by pH.\n\nSUFFIXES:\n\ninterpro2go: Gene ontology assignments.\nreads: Read counts.\nPathToCount: Shows full “path” (either GO terms or taxonomy) leading to, and including, the terminal term and corresponding summarized counts (i.e. sum of all reads at terminal term and all below that term) of reads assigned to the terminal term.\nPathToPercent: Shows full “path” (either GO terms or taxonomy) leading to, and including, the terminal term and corresponding percentage of summarized counts (i.e. sum of all reads at terminal term and all below that term) of reads assigned to the terminal term. This is percentage of all reads assigned within the designated group/sample. It is NOT a percentage of all reads in the entire experiment!!\n\nHere’s how the sample names breakdown:\n\n\n\n\n\n\n\n\nSample\nDevelopmental Stage (days post-fertilization)\npH Treatment\n\n\n\n\nMG1\n13\n8.2\n\n\nMG2\n17\n8.2\n\n\nMG3\n6\n7.1\n\n\nMG5\n10\n8.2\n\n\nMG6\n13\n7.1\n\n\nMG7\n17\n7.1\n\n\n\nNOTE: Days used in analysis correspond to Emma’s day conversion:\n\n\n\nDate\nRhonda’s day\nEmma’s day\n\n\n\n\n5/15\n6\n1\n\n\n5/19\n10\n5\n\n\n5/22\n13\n8\n\n\n5/26\n17\n12\n\n\n\n\n\nRESULTS\nOutput folder:\n\n20200618_metagenomics_megan_tables\nabs-reads_abs-comparison_day_interpro2goPathToCount.txt\nabs-reads_abs-comparison_day_interpro2goPathToPercent.txt\nabs-reads_abs-comparison_Day.megan\nabs-reads_abs-comparison_day_readsTaxonPathToCount.txt\nabs-reads_abs-comparison_day_readsTaxonPathToPercent.txt\nabs-reads_abs-comparison_pH_interpro2goPathToCount.txt\nabs-reads_abs-comparison_pH_interpro2goPathToPercent.txt\nabs-reads_abs-comparison_pH.megan\nabs-reads_abs-comparison_pH_readsTaxonPathToCount.txt\nabs-reads_abs-comparison_pH_readsTaxonPathToPercent.txt\nabs-reads-ind-samples_readsTaxonPathToCount.txt\nabs-reads-ind-samples_readsTaxonPathToPercent.txt\nmegan_log.txt"
  },
  {
    "objectID": "posts/2020/2020-01-23-RNA-Isolation-and-Quantification---C.bairdi-Hemocyte-Pellets-in-RNAlater-Troubleshooting/index.html",
    "href": "posts/2020/2020-01-23-RNA-Isolation-and-Quantification---C.bairdi-Hemocyte-Pellets-in-RNAlater-Troubleshooting/index.html",
    "title": "RNA Isolation and Quantification - C.bairdi Hemocyte Pellets in RNAlater Troubleshooting",
    "section": "",
    "text": "After the failure to obtain RNA from any C.bairdi hemocytes pellets (out of 24 samples processed) on 20200117, I decided to isolate RNA from just a subset of that group to determine if I screwed something up last time or something. Also, I am testing two different preparations of the kit-supplied DNase I: one Kaitlyn prepped and a fresh preparation that I made. Admittedly, I’m not doing the “proper” testing by trying the different DNase preps on the same exact sample, but it’ll do. I just want to see if I get some RNA from these samples this time…\nIsolated RNA from the following 4 hemolymph pellet samples:\n\n6128_112_9 (Kaitlyn DNase)\n6204_114_9 (Kaitlyn DNase)\n6141_123_9 (Sam DNase)\n6245_126_9 (Sam DNase)\n\nIsolated RNA using the Quick DNA/RNA Microprep Kit (ZymoResearch; PDF) according to the manufacturer’s protocol for liquids/cells in RNAlater.\n\nUsed 35uL from each RNAlater/hemocyte slurry.\nMixed with equal volume of H2O (35uL).\nRetained DNA on the Zymo-Spin IC-XM columns for isolation after RNA isolation.\nPerformed on-column DNase step.\nRNA was eluted in 15uL H2O\n\nRNA was quantified on the Roberts Lab Qubit 3.0 using the RNA High Sensitivity Assay (Invitrogen), using 2uL of each sample.\n\n\nRESULTS\nQubit restuls (Google Sheet):\n\n20200123_qubit_cbai_RNA\n\n\n\n\nSample ID\n[RNA] (ng/uL)\nTotal (ng)\n\n\n\n\n6128_112_9\n17.1\n222.3\n\n\n6204_114_9\n5.37\n69.81\n\n\n6141_123_9\n13.1\n170.3\n\n\n6245_126_9\n17.2\n223.6\n\n\n\nWell, well, well! The isolation worked this time! Not sure what went wrong last time. Ugh. However, I’m stoked that things worked and will now plow ahead with the remainder of the samples (again)!"
  },
  {
    "objectID": "posts/2020/2020-04-07-Transdecoder---C.bairdi-MEGAN6-Taxonomic-Specific-Reads-Assembly-from-20200330/index.html",
    "href": "posts/2020/2020-04-07-Transdecoder---C.bairdi-MEGAN6-Taxonomic-Specific-Reads-Assembly-from-20200330/index.html",
    "title": "Transdecoder - C.bairdi MEGAN6 Taxonomic-Specific Reads Assembly from 20200330",
    "section": "",
    "text": "Ran Trinity to de novo assembly on the the Arthropoda MEGAN6 taxonomic-specific RNAseq data on 20120330 and now will begin annotating the transcriptome using TransDecoder on Mox.\nSBATCH script (GitHub):\n\n20200407_cbai_transdecoder_megan.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=transdecoder_cbai\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=1-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200407_cbai_transdecoder_megan\n\n\n# Exit script if a command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# Set workind directory as current directory\nwd=\"$(pwd)\"\n\n# Capture date as YYYYMMDD\ntimestamp=$(date +%Y%m%d)\n\n# Set input file locations and species designation\ntrinity_fasta=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200408.C_bairdi.megan.Trinity.fasta\"\ntrinity_gene_map=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200408.C_bairdi.megan.Trinity.fasta.gene_trans_map\"\nspecies=\"cbai\"\n\n# Capture trinity file name\ntrinity_fasta_name=${trinity_fasta##*/}\n\n\n\n# Paths to input/output files\nblastp_out_dir=\"${wd}/blastp_out\"\ntransdecoder_out_dir=\"${wd}/${trinity_fasta_name}.transdecoder_dir\"\npfam_out_dir=\"${wd}/pfam_out\"\nblastp_out=\"${blastp_out_dir}/${timestamp}.${species}.blastp.outfmt6\"\npfam_out=\"${pfam_out_dir}/${timestamp}.${species}.pfam.domtblout\"\nlORFs_pep=\"${transdecoder_out_dir}/longest_orfs.pep\"\npfam_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/Pfam-A.hmm\"\nsp_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/uniprot_sprot.pep\"\n\n\n\n# Paths to programs\nblast_dir=\"/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin\"\nblastp=\"${blast_dir}/blastp\"\nhmmer_dir=\"/gscratch/srlab/programs/hmmer-3.2.1/src\"\nhmmscan=\"${hmmer_dir}/hmmscan\"\ntransdecoder_dir=\"/gscratch/srlab/programs/TransDecoder-v5.5.0\"\ntransdecoder_lORFs=\"${transdecoder_dir}/TransDecoder.LongOrfs\"\ntransdecoder_predict=\"${transdecoder_dir}/TransDecoder.Predict\"\n\n# Make output directories\nmkdir \"${blastp_out_dir}\"\nmkdir \"${pfam_out_dir}\"\n\n# Extract long open reading frames\n\"${transdecoder_lORFs}\" \\\n--gene_trans_map \"${trinity_gene_map}\" \\\n-t \"${trinity_fasta}\"\n\n# Run blastp on long ORFs\n\"${blastp}\" \\\n-query \"${lORFs_pep}\" \\\n-db \"${sp_db}\" \\\n-max_target_seqs 1 \\\n-outfmt 6 \\\n-evalue 1e-5 \\\n-num_threads 28 \\\n> \"${blastp_out}\"\n\n# Run pfam search\n\"${hmmscan}\" \\\n--cpu 28 \\\n--domtblout \"${pfam_out}\" \\\n\"${pfam_db}\" \\\n\"${lORFs_pep}\"\n\n# Run Transdecoder with blastp and Pfam results\n\"${transdecoder_predict}\" \\\n-t \"${trinity_fasta}\" \\\n--retain_pfam_hits \"${pfam_out}\" \\\n--retain_blastp_hits \"${blastp_out}\"\n\n\nRESULTS\nTook about 7.75hrs:\n\n\n\ncbai transdecoder runtime\n\n\nOutput folder:\n\n20200407_cbai_transdecoder_megan/\n\nCoding Sequences (FastA):\n\n20200408.C_bairdi.megan.Trinity.fasta.transdecoder.cds\n\nPeptide Sequences (FastA):\n\n20200408.C_bairdi.megan.Trinity.fasta.transdecoder.pep\n\nBLASTp output (tab):\n\n20200407_cbai_transdecoder_megan/blastp_out/20200408.C_bairdi.blastp.outfmt6\n\nPfam output:\n\n20200407_cbai_transdecoder_megan/pfam_out/20200408.C_bairdi.pfam.domtblout\n\nWill get ready to run Trinotate with these output files."
  },
  {
    "objectID": "posts/2020/2020-01-22-Transcriptome-Assembly---Hematodinium-with-MEGAN6-Taxonomy-specific-Reads-with-Trinity-on-Mox/index.html",
    "href": "posts/2020/2020-01-22-Transcriptome-Assembly---Hematodinium-with-MEGAN6-Taxonomy-specific-Reads-with-Trinity-on-Mox/index.html",
    "title": "Transcriptome Assembly - Hematodinium with MEGAN6 Taxonomy-specific Reads with Trinity on Mox",
    "section": "",
    "text": "Ran a de novo assembly using the extracted reads classified under Alveolata from 20200122 The assembly was performed with Trinity on Mox.\nFor reference, these include RNAseq data using a newly established “shorthand”: 2018, 2019.\nSBATCH script (GitHub):\n\n20200122_hemat_trinity_megan_RNAseq.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=trinity_hemat\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200122_hemat_trinity_megan_RNAseq\n\n# Exit script if a command fails\nset -e\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# User-defined variables\nreads_dir=/gscratch/srlab/sam/data/C_bairdi/RNAseq\nthreads=27\nassembly_stats=assembly_stats.txt\ntimestamp=$(date +%Y%m%d)\nfasta_name=\"${timestamp}.hemat.megan.Trinity.fasta\"\n\n# Paths to programs\ntrinity_dir=\"/gscratch/srlab/programs/trinityrnaseq-v2.9.0\"\nsamtools=\"/gscratch/srlab/programs/samtools-1.10/samtools\"\n\n\n## Inititalize arrays\nR1_array=()\nR2_array=()\n\n# Variables for R1/R2 lists\nR1_list=\"\"\nR2_list=\"\"\n\n# Create array of fastq R1 files\nR1_array=(${reads_dir}/*_R1.fq)\n\n# Create array of fastq R2 files\nR2_array=(${reads_dir}/*_R2.fq)\n\n# Create list of fastq files used in analysis\n## Uses parameter substitution to strip leading path from filename\nfor fastq in ${reads_dir}/*.fq\ndo\n  echo \"${fastq##*/}\" >> fastq.list.txt\ndone\n\n# Create comma-separated lists of FastQ reads\nR1_list=$(echo \"${R1_array[@]}\" | tr \" \" \",\")\nR2_list=$(echo \"${R2_array[@]}\" | tr \" \" \",\")\n\n\n# Run Trinity using \"stranded\" setting (--SS_lib_type)\n${trinity_dir}/Trinity \\\n--seqType fq \\\n--max_memory 120G \\\n--CPU ${threads} \\\n--SS_lib_type RF \\\n--left \"${R1_list}\" \\\n--right \"${R2_list}\"\n\n# Rename generic assembly FastA\nmv trinity_out_dir/Trinity.fasta trinity_out_dir/${fasta_name}\n\n# Assembly stats\n${trinity_dir}/util/TrinityStats.pl trinity_out_dir/${fasta_name} \\\n> ${assembly_stats}\n\n# Create gene map files\n${trinity_dir}/util/support_scripts/get_Trinity_gene_to_trans_map.pl \\\ntrinity_out_dir/${fasta_name} \\\n> trinity_out_dir/${fasta_name}.gene_trans_map\n\n# Create FastA index\n${samtools} faidx \\\ntrinity_out_dir/${fasta_name}\n\n\nRESULTS\nThis was quick, ~11 minutes:\n\n\n\nTrinity runtime for hematodinium assembly\n\n\nOutput folder:\n\n20200122_hemat_trinity_megan_RNAseq\n\nAssembly (FastA; 20MB):\n\n20200122_hemat_trinity_megan_RNAseq/trinity_out_dir/20200122.hemat.megan.Trinity.fasta\n\nFastA Index (FAI):\n\n20200122_hemat_trinity_megan_RNAseq/trinity_out_dir/20200122.hemat.megan.Trinity.fasta.fai\n\nTrinity Gene Trans Map (txt):\n\n20200122_hemat_trinity_megan_RNAseq/trinity_out_dir/20200122.hemat.megan.Trinity.fasta.gene_trans_map\n\nAssembly Stats (txt):\n\n20200122_hemat_trinity_megan_RNAseq/assembly_stats.txt\n\n\n\n################################\n## Counts of transcripts, etc.\n################################\nTotal trinity 'genes':  4440\nTotal trinity transcripts:  5183\nPercent GC: 50.21\n\n########################################\nStats based on ALL transcript contigs:\n########################################\n\n    Contig N10: 1856\n    Contig N20: 1446\n    Contig N30: 1189\n    Contig N40: 1000\n    Contig N50: 870\n\n    Median contig length: 634\n    Average contig: 736.61\n    Total assembled bases: 3817832\n\n\n#####################################################\n## Stats based on ONLY LONGEST ISOFORM per 'GENE':\n#####################################################\n\n    Contig N10: 1803\n    Contig N20: 1422\n    Contig N30: 1175\n    Contig N40: 986\n    Contig N50: 848\n\n    Median contig length: 612\n    Average contig: 713.35\n    Total assembled bases: 3167294"
  },
  {
    "objectID": "posts/2020/2020-05-02-Transcriptome-Assembly---C.bairdi-All-RNAseq-Data-Without-Taxonomic-Filters-with-Trinity-on-Mox/index.html",
    "href": "posts/2020/2020-05-02-Transcriptome-Assembly---C.bairdi-All-RNAseq-Data-Without-Taxonomic-Filters-with-Trinity-on-Mox/index.html",
    "title": "Transcriptome Assembly - C.bairdi All RNAseq Data Without Taxonomic Filters with Trinity on Mox",
    "section": "",
    "text": "Steven asked that I assemble an unfiltered (i.e. no taxonomic selection) transcriptome with all of our C.bairdi RNAseq data (see the FastQ list file linked in the Results section below). A de novo assembly was run using Trinity on Mox. It should be noted that this assembly is a mixture of stranded/non-stranded library preps.\nSBATCH Script (GitHub):\n\n20200502_cbai_trinity_all_RNAseq.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=trinity_cbai\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=9-00:00:00\n## Memory per node\n#SBATCH --mem=500G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200502_cbai_trinity_all_RNAseq\n\n# Exit script if a command fails\nset -e\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# User-defined variables\nreads_dir=/gscratch/srlab/sam/data/C_bairdi/RNAseq\ntranscriptome_dir=/gscratch/srlab/sam/data/C_bairdi/transcriptomes\nthreads=28\nassembly_stats=assembly_stats.txt\ntimestamp=$(date +%Y%m%d)\nfasta_name=\"${timestamp}.C_bairdi.Trinity.fasta\"\n\n# Paths to programs\ntrinity_dir=\"/gscratch/srlab/programs/trinityrnaseq-v2.9.0\"\nsamtools=\"/gscratch/srlab/programs/samtools-1.10/samtools\"\n\n\n## Inititalize arrays\nR1_array=()\nR2_array=()\n\n# Variables for R1/R2 lists\nR1_list=\"\"\nR2_list=\"\"\n\n# Create array of fastq R1 files\nR1_array=(\"${reads_dir}\"/*_R1*fastp-trim*.fq.gz)\n\n# Create array of fastq R2 files\nR2_array=(\"${reads_dir}\"/*_R2*fastp-trim*.fq.gz)\n\n# Create list of fastq files used in analysis\n## Uses parameter substitution to strip leading path from filename\nfor fastq in \"${reads_dir}\"/*fastp-trim*.fq.gz\ndo\n  echo \"${fastq##*/}\" >> fastq.list.txt\ndone\n\n# Create comma-separated lists of FastQ reads\nR1_list=$(echo \"${R1_array[@]}\" | tr \" \" \",\")\nR2_list=$(echo \"${R2_array[@]}\" | tr \" \" \",\")\n\n\n# Run Trinity\n## Not running as \"stranded\", due to mix of library types\n${trinity_dir}/Trinity \\\n--seqType fq \\\n--max_memory 500G \\\n--CPU ${threads} \\\n--left \"${R1_list}\" \\\n--right \"${R2_list}\"\n\n# Rename generic assembly FastA\nmv trinity_out_dir/Trinity.fasta trinity_out_dir/\"${fasta_name}\"\n\n# Assembly stats\n${trinity_dir}/util/TrinityStats.pl trinity_out_dir/\"${fasta_name}\" \\\n> ${assembly_stats}\n\n# Create gene map files\n${trinity_dir}/util/support_scripts/get_Trinity_gene_to_trans_map.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n> trinity_out_dir/\"${fasta_name}\".gene_trans_map\n\n# Create sequence lengths file (used for differential gene expression)\n${trinity_dir}/util/misc/fasta_seq_length.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n> trinity_out_dir/\"${fasta_name}\".seq_lens\n\n# Create FastA index\n${samtools} faidx \\\ntrinity_out_dir/\"${fasta_name}\"\n\n# Copy files to transcriptome directory\nrsync -av \\\ntrinity_out_dir/\"${fasta_name}\"* \\\n${transcriptome_dir}\n\n\nRESULTS\nThere were some hiccups (Mox crashes, weird Trinity error that interrupted job), but overall, it took ~4 days of actual run time.\n\n\n\ncbai Trinity all RNAseq runtime\n\n\nOutput folder:\n\n20200502_cbai_trinity_all_RNAseq/\n\nFastQ list (text):\n\n20200502_cbai_trinity_all_RNAseq/fastq.list.txt\n\nFastA (904MB):\n\n20200502_cbai_trinity_all_RNAseq/trinity_out_dir/20200507.C_bairdi.Trinity.fasta\n\nFastA MD5 checksum:\n01adbd54298495c147767b19ee5c0de9\nFastA Index (text):\n\n20200502_cbai_trinity_all_RNAseq/trinity_out_dir/20200507.C_bairdi.Trinity.fasta.fai\n\n\n\n\nNOTE: The transcriptome will be referred to as cbai_transcriptome_v2.0.fasta and has been added to our Genomic Resources wiki.\nTrinity gene trans map (text; useful for downstream gene expression/annotation with Trinity/Trinotate):\n\n20200502_cbai_trinity_all_RNAseq/trinity_out_dir/20200507.C_bairdi.Trinity.fasta.gene_trans_map\n\nTrinity FastA sequence lengths file (text; useful for downstream gene expression/annotation with Trinity/Trinotate):\n\n20200502_cbai_trinity_all_RNAseq/trinity_out_dir/20200507.C_bairdi.Trinity.fasta.seq_lens\n\nAssemby stats (text):\n\n20200502_cbai_trinity_all_RNAseq/assembly_stats.txt\n\n################################\n## Counts of transcripts, etc.\n################################\nTotal trinity 'genes':  783006\nTotal trinity transcripts:  1412254\nPercent GC: 45.41\n\n########################################\nStats based on ALL transcript contigs:\n########################################\n\n    Contig N10: 3733\n    Contig N20: 2571\n    Contig N30: 1863\n    Contig N40: 1285\n    Contig N50: 811\n\n    Median contig length: 325\n    Average contig: 579.92\n    Total assembled bases: 819000346\n\n\n#####################################################\n## Stats based on ONLY LONGEST ISOFORM per 'GENE':\n#####################################################\n\n    Contig N10: 3093\n    Contig N20: 1768\n    Contig N30: 933\n    Contig N40: 576\n    Contig N50: 431\n\n    Median contig length: 285\n    Average contig: 434.16\n    Total assembled bases: 339947966"
  },
  {
    "objectID": "posts/2020/2020-05-08-TransDecoder---C.bairdi-Transcriptome-v2.0-from-20200502-on-Mox/index.html",
    "href": "posts/2020/2020-05-08-TransDecoder---C.bairdi-Transcriptome-v2.0-from-20200502-on-Mox/index.html",
    "title": "TransDecoder - C.bairdi Transcriptome v2.0 from 20200502 on Mox",
    "section": "",
    "text": "Need to run TransDecoder on Mox on the C.bairdi transcriptome v2.0 from 20200502.\nSBATCH script (GitHub):\n\n20200508_cbai_transdecoder_transcriptome-v2.0.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=transdecoder_cbai\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=1-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200508_cbai_transdecoder_transcriptome-v2.0\n\n\n# Exit script if a command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# Set workind directory as current directory\nwd=\"$(pwd)\"\n\n# Capture date as YYYYMMDD\ntimestamp=$(date +%Y%m%d)\n\n# Set input file locations and species designation\ntrinity_fasta=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200507.C_bairdi.Trinity.fasta\"\ntrinity_gene_map=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200507.C_bairdi.Trinity.fasta.gene_trans_map\"\nspecies=\"cbai\"\n\n# Capture trinity file name\ntrinity_fasta_name=${trinity_fasta##*/}\n\n\n\n# Paths to input/output files\nblastp_out_dir=\"${wd}/blastp_out\"\ntransdecoder_out_dir=\"${wd}/${trinity_fasta_name}.transdecoder_dir\"\npfam_out_dir=\"${wd}/pfam_out\"\nblastp_out=\"${blastp_out_dir}/${timestamp}.${species}.blastp.outfmt6\"\npfam_out=\"${pfam_out_dir}/${timestamp}.${species}.pfam.domtblout\"\nlORFs_pep=\"${transdecoder_out_dir}/longest_orfs.pep\"\npfam_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/Pfam-A.hmm\"\nsp_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/uniprot_sprot.pep\"\n\n\n\n# Paths to programs\nblast_dir=\"/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin\"\nblastp=\"${blast_dir}/blastp\"\nhmmer_dir=\"/gscratch/srlab/programs/hmmer-3.2.1/src\"\nhmmscan=\"${hmmer_dir}/hmmscan\"\ntransdecoder_dir=\"/gscratch/srlab/programs/TransDecoder-v5.5.0\"\ntransdecoder_lORFs=\"${transdecoder_dir}/TransDecoder.LongOrfs\"\ntransdecoder_predict=\"${transdecoder_dir}/TransDecoder.Predict\"\n\n# Make output directories\nmkdir \"${blastp_out_dir}\"\nmkdir \"${pfam_out_dir}\"\n\n# Extract long open reading frames\n\"${transdecoder_lORFs}\" \\\n--gene_trans_map \"${trinity_gene_map}\" \\\n-t \"${trinity_fasta}\"\n\n# Run blastp on long ORFs\n\"${blastp}\" \\\n-query \"${lORFs_pep}\" \\\n-db \"${sp_db}\" \\\n-max_target_seqs 1 \\\n-outfmt 6 \\\n-evalue 1e-5 \\\n-num_threads 28 \\\n> \"${blastp_out}\"\n\n# Run pfam search\n\"${hmmscan}\" \\\n--cpu 28 \\\n--domtblout \"${pfam_out}\" \\\n\"${pfam_db}\" \\\n\"${lORFs_pep}\"\n\n# Run Transdecoder with blastp and Pfam results\n\"${transdecoder_predict}\" \\\n-t \"${trinity_fasta}\" \\\n--retain_pfam_hits \"${pfam_out}\" \\\n--retain_blastp_hits \"${blastp_out}\"\n\n\nRESULTS\nTook a bit over four days to run (not including short downtime due to the initial job running out of time):\n\n\n\nTransDecoder runtime for v2.0 transcriptome\n\n\nOutput folder:\n\n20200508_cbai_transdecoder_transcriptome-v2.0/\n\nBED (text; 102MB)\n\n[20200507.C_bairdi.Trinity.fasta.transdecoder.bed](https://gannet.fish.washington.edu/Atumefaciens/20200508_cbai_transdecoder_transcriptome-v2.0/20200507.C_bairdi.Trinity.fasta.transdecoder.bed]\n\nCDS (FastA; 357MB)\n\n[20200507.C_bairdi.Trinity.fasta.transdecoder.cds](https://gannet.fish.washington.edu/Atumefaciens/20200508_cbai_transdecoder_transcriptome-v2.0/20200507.C_bairdi.Trinity.fasta.transdecoder.cds]\n\nGFF3 (text; 367MB)\n\n[20200507.C_bairdi.Trinity.fasta.transdecoder.gff3](https://gannet.fish.washington.edu/Atumefaciens/20200508_cbai_transdecoder_transcriptome-v2.0/20200507.C_bairdi.Trinity.fasta.transdecoder.gff3]\n\nPeptides (FastA; 184MB)\n\n[20200507.C_bairdi.Trinity.fasta.transdecoder.pep](https://gannet.fish.washington.edu/Atumefaciens/20200508_cbai_transdecoder_transcriptome-v2.0/20200507.C_bairdi.Trinity.fasta.transdecoder.pep]\n\n\nThe files linked below are needed as inputs for Trinotate:\nBLASTp (text; outfmt6; 16MB):\n\n20200508_cbai_transdecoder_transcriptome-v2.0/blastp_out/20200508.cbai.blastp.outfmt6\n\npfam (420MB):\n\n20200508_cbai_transdecoder_transcriptome-v2.0/pfam_out/20200508.cbai.pfam.domtblout\n\nLongest Peptide ORFs (FastA; 209MB):\n\n20200508_cbai_transdecoder_transcriptome-v2.0/20200507.C_bairdi.Trinity.fasta.transdecoder_dir/longest_orfs.pep"
  },
  {
    "objectID": "posts/2020/2020-08-26-TransDecoder---C.bairdi-Transcriptomes-v2.1-and-v3.1-on-Mox/index.html",
    "href": "posts/2020/2020-08-26-TransDecoder---C.bairdi-Transcriptomes-v2.1-and-v3.1-on-Mox/index.html",
    "title": "TransDecoder - C.bairdi Transcriptomes v2.1 and v3.1 on Mox",
    "section": "",
    "text": "To continue annotation of our C.bairdi v2.1 & v3.1 transcriptome assemblies, I needed to run TransDecoder before performing the more thorough annotation with Trinotate.\nInfo for each transcriptome version (library composition, assembly dates, BUSCO, etc) can be found in this table:\n\ncbai_transcriptome_comp\n\nThis was run on Mox.\nSBATCH script (GitHub):\n\n20200826_cbai_transdecoder_transcriptomes_v2.1_v.3.1.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_transdecoder_transcriptomes_v2.1_v.3.1\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=7-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200826_cbai_transdecoder_transcriptomes_v2.1_v.3.1\n\n# Script to run TransDecoder on C.bairdi transcriptomes:\n# v2.1, v3.1\n\n###################################################################################\n# These variables need to be set by user\n\n# Capture date. E.g. format is: 20190820\ntimestamp=$(date +\"%Y%m%d\")\n\ntranscriptomes_dir=/gscratch/srlab/sam/data/C_bairdi/transcriptomes\n\n# Paths to program directories\nblast_dir=\"/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin\"\nhmmer_dir=\"/gscratch/srlab/programs/hmmer-3.2.1/src\"\ntransdecoder_dir=\"/gscratch/srlab/programs/TransDecoder-v5.5.0\"\n\n# Paths to Trinotate databases\npfam_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/Pfam-A.hmm\"\nsp_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/uniprot_sprot.pep\"\n\n# Array of the various comparisons to evaluate\n# Each condition in each comparison should be separated by a \"-\"\ndeclare -A transcriptomes_gene_maps_array\ntranscriptomes_gene_maps_array=(\n[\"${transcriptomes_dir}/cbai_transcriptome_v2.1.fasta\"]=\"${transcriptomes_dir}/cbai_transcriptome_v2.1.fasta.gene_trans_map\" \\\n[\"${transcriptomes_dir}/cbai_transcriptome_v3.1.fasta\"]=\"${transcriptomes_dir}/cbai_transcriptome_v3.1.fasta.gene_trans_map\"\n)\n\n\ndeclare -A programs_array\nprograms_array=(\n[blastp]=\"${blast_dir}/blastp\" \\\n[hmmscan]=\"${hmmer_dir}/hmmscan\" \\\n[transdecoder_lORFs]=\"${transdecoder_dir}/TransDecoder.LongOrfs\" \\\n[transdecoder_predict]=\"${transdecoder_dir}/TransDecoder.Predict\"\n)\n\nthreads=28\n\n###################################################################################\n\n# Exit script if a command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n\nfor transcriptome in \"${!transcriptomes_gene_maps_array[@]}\"\ndo\n\n  # Remove path from transcriptome using parameter substitution\n  transcriptome_name=\"${transcriptome##*/}\"\n\n  # Set a prefix that utilizes timestamp and name of transcriptome\n  prefix=\"${timestamp}_${transcriptome_name}\"\n\n  # Make output directory and change to directory\n  mkdir --parents \"${prefix}.transdecoder\" && cd \"$_\"\n\n  # Paths to input/output files\n\n  blastp_out_dir=\"${prefix}.blastp_out\"\n  pfam_out_dir=\"${prefix}.pfam_out\"\n\n  # Make output directories\n  mkdir \"${blastp_out_dir}\"\n  mkdir \"${pfam_out_dir}\"\n\n  blastp_out=\"${blastp_out_dir}/${prefix}.blastp.outfmt6\"\n  pfam_out=\"${pfam_out_dir}/${prefix}.pfam.domtblout\"\n  lORFs_pep=\"${transcriptome_name}.transdecoder_dir/longest_orfs.pep\"\n\n\n\n  # Extract long open reading frames\n  \"${programs_array[transdecoder_lORFs]}\" \\\n  --gene_trans_map \"${transcriptomes_gene_maps_array[$transcriptome]}\" \\\n  -t \"${transcriptome}\"\n\n  # Run blastp on long ORFs\n  \"${programs_array[blastp]}\" \\\n  -query \"${lORFs_pep}\" \\\n  -db \"${sp_db}\" \\\n  -max_target_seqs 1 \\\n  -outfmt 6 \\\n  -evalue 1e-5 \\\n  -num_threads ${threads} \\\n  > \"${blastp_out}\"\n\n  # Run pfam search\n  \"${programs_array[hmmscan]}\" \\\n  --cpu ${threads} \\\n  --domtblout \"${pfam_out}\" \\\n  \"${pfam_db}\" \\\n  \"${lORFs_pep}\"\n\n  # Run Transdecoder with blastp and Pfam results\n  \"${programs_array[transdecoder_predict]}\" \\\n  -t \"${transcriptome}\" \\\n  --retain_pfam_hits \"${pfam_out}\" \\\n  --retain_blastp_hits \"${blastp_out}\"\n\n  # Capture FastA MD5 checksum for future reference\n  md5sum \"${transcriptome}\" > \"${prefix}\".checksum.md5\n\n  # Move back up to main directory\n  cd ..\n\ndone\n\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n    ${programs_array[$program]} -h\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n\nRESULTS\nTook a bit over 3 days to process both transcriptomes:\n\n\n\ncombined transdecoder runtimes for v2.1 and v3.1 transcriptomes\n\n\nOutput folder:\n\n20200826_cbai_transdecoder_transcriptomes_v2.1_v.3.1/\n\n\ncbai_transcriptome_v2.1\nCoding Sequences (FastA):\n\n20200826_cbai_transcriptome_v2.1.fasta.transdecoder.cds\n\nPeptide Sequences (FastA):\n\n20200826_cbai_transcriptome_v2.1.fasta.transdecoder.pep\n\nBLASTp output (tab):\n\n20200826_cbai_transcriptome_v2.1.fasta.blastp.outfmt6\n\nPfam output:\n\n20200826_cbai_transcriptome_v2.1.fasta.pfam.domtblout\n\n\n\ncbai_transcriptome_v3.1\nCoding Sequences (FastA):\n\n20200826_cbai_transcriptome_v3.1.fasta.transdecoder.cds\n\nPeptide Sequences (FastA):\n\n20200826_cbai_transcriptome_v3.1.fasta.transdecoder.pep\n\nBLASTp output (tab):\n\n20200826_cbai_transcriptome_v3.1.fasta.blastp.outfmt6\n\nPfam output:\n\n20200826_cbai_transcriptome_v3.1.fasta.pfam.domtblout"
  },
  {
    "objectID": "posts/2020/2020-02-11-DNA-Isolation-and-Quantification---C.bairdi-RNA-from-Samples-6212_132_9-6212_334_12-6212_485_26/index.html",
    "href": "posts/2020/2020-02-11-DNA-Isolation-and-Quantification---C.bairdi-RNA-from-Samples-6212_132_9-6212_334_12-6212_485_26/index.html",
    "title": "DNA Isolation & Quantification - C.bairdi RNA from Samples 6212_132_9 6212_334_12 6212_485_26",
    "section": "",
    "text": "Isolated DNA from three samples (see Qubit spreadsheet in “Results” below for sample IDs) using the Quick DNA/RNA Microprep Kit (ZymoResearch; PDF) according to the manufacturer’s protocol for liquids/cells in RNAlater.\nThese samples were from RNA isolations earlier today:\n\n20200211\n\nBrief rundown of method:\n\nUsed 35uL from each RNAlater/hemocyte slurry.\nMixed with equal volume of H2O (35uL).\nRetained DNA on the Zymo-Spin IC-XM columns at 4oC for isolation after RNA isolation.\nDNA was eluted in 15uL H2O\n\nDNA was quantified on the Roberts Lab Qubit 3.0 using the 1x DNA High Sensitivity Assay (Invitrogen), using 1uL of each sample.\n\n\nRESULTS\nQubit results (Google Sheet):\n\n20200211_qubit_crab_gDNA\n\nSamples were stored at -80oC in:\nRack 15, 4, 5 in C.bairdi gDNA Box #2\n\n\n\nSample ID\n[DNA] (ng/uL)\n\n\n\n\n6212_485_26\n28.8\n\n\n6212_132_9\n19.7\n\n\n6212_334_12\n23.6"
  },
  {
    "objectID": "posts/2020/2020-06-05-Transcriptome-Assessment---BUSCO-Metazoa-on-C.bairdi-Transcriptome-v3.1/index.html",
    "href": "posts/2020/2020-06-05-Transcriptome-Assessment---BUSCO-Metazoa-on-C.bairdi-Transcriptome-v3.1/index.html",
    "title": "Transcriptome Assessment - BUSCO Metazoa on C.bairdi Transcriptome v3.1",
    "section": "",
    "text": "Continuing to try to identify the best C.bairdi transcriptome, we decided to extract all non-dinoflagellate sequences from cbai_transcriptome_v2.0 (RNAseq shorthand: 2018, 2019, 2020-GW, 2020-UW) and cbai_transcriptome_v3.0 (RNAseq shorthand: 2018, 2019, 2020-UW).\nNow, want to assess its cbai_transcriptome_v3.1 “completeness” using BUSCO and the metazoa_odb9 database.\nBUSCO was run with the --mode transcriptome option on Mox.\nSBATCH script (GitHub):\n\n20200605_cbai_busco_transcriptome_v3.1.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_busco_v3.1_transcriptome\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=1-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200605_cbai_busco_transcriptome_v3.1\n\n### C.bairdi transcriptome assembly completeness assessment using BUSCO.\n### This is checking cbai_transcriptome_v1.7.fasta\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Load Open MPI module for parallel, multi-node processing\nmodule load icc_19-ompi_3.1.2\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\n## Input files and settings\nbusco_db=/gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9\ntranscriptome_fasta=/gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v3.1.fasta\naugustus_species=fly\nthreads=28\n\n## Save working directory\nwd=$(pwd)\n\n# Extract FastA filename\nfasta_name=${transcriptome_fasta##*/}\n\n## Set program paths\naugustus_bin=/gscratch/srlab/programs/Augustus-3.3.2/bin\naugustus_scripts=/gscratch/srlab/programs/Augustus-3.3.2/scripts\nblast_dir=/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin/\nbusco=/gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py\nhmm_dir=/gscratch/srlab/programs/hmmer-3.2.1/src/\n\n## Augustus configs\naugustus_dir=${wd}/augustus\naugustus_config_dir=${augustus_dir}/config\naugustus_orig_config_dir=/gscratch/srlab/programs/Augustus-3.3.2/config\n\n## BUSCO configs\nbusco_config_default=/gscratch/srlab/programs/busco-v3/config/config.ini.default\nbusco_config_ini=${wd}/config.ini\n\n# Export BUSCO config file location\nexport BUSCO_CONFIG_FILE=\"${busco_config_ini}\"\n\n# Export Augustus variable\nexport PATH=\"${augustus_bin}:$PATH\"\nexport PATH=\"${augustus_scripts}:$PATH\"\nexport AUGUSTUS_CONFIG_PATH=\"${augustus_config_dir}\"\n\n\n# Copy BUSCO config file\ncp ${busco_config_default} \"${busco_config_ini}\"\n\n# Make Augustus directory if it doesn't exist\nif [ ! -d \"${augustus_dir}\" ]; then\n  mkdir --parents \"${augustus_dir}\"\nfi\n\n# Copy Augustus config directory\ncp --preserve -r ${augustus_orig_config_dir} \"${augustus_dir}\"\n\n# Edit BUSCO config file\n## Set paths to various programs\n### The use of the % symbol sets the delimiter sed uses for arguments.\n### Normally, the delimiter that most examples use is a slash \"/\".\n### But, we need to expand the variables into a full path with slashes, which screws up sed.\n### Thus, the use of % symbol instead (it could be any character that is NOT present in the expanded variable; doesn't have to be \"%\").\nsed -i \"/^;cpu/ s/1/${threads}/\" \"${busco_config_ini}\"\nsed -i \"/^tblastn_path/ s%tblastn_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^makeblastdb_path/ s%makeblastdb_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^augustus_path/ s%augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^etraining_path/ s%etraining_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^gff2gbSmallDNA_path/ s%gff2gbSmallDNA_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^new_species_path/ s%new_species_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^optimize_augustus_path/ s%optimize_augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^hmmsearch_path/ s%hmmsearch_path = /home/osboxes/BUSCOVM/hmmer/hmmer-3.1b2-linux-intel-ia32/binaries/%path = ${hmm_dir}%\" \"${busco_config_ini}\"\n\n\n# Run BUSCO/Augustus training\n${busco} \\\n--in ${transcriptome_fasta} \\\n--out ${fasta_name} \\\n--lineage_path ${busco_db} \\\n--mode transcriptome \\\n--cpu ${threads} \\\n--long \\\n--species ${augustus_species} \\\n--tarzip \\\n--augustus_parameters='--progress=true'\n\n# Create checksum for potential verification\nmd5sum \"${transcriptome_fasta}\" >> \"${fasta_name}\".checksum.md5\n\n\nRESULTS\nAs always, very quick; ~4.5mins:\n\n\n\ncbai v3.1 BUSCO runtime\n\n\nOutput folder:\n\n20200605_cbai_busco_transcriptome_v3.1/\n\nShort summary file (text):\n\n20200605_cbai_busco_transcriptome_v3.1/run_cbai_transcriptome_v3.1.fasta/short_summary_cbai_transcriptome_v3.1.fasta.txt\n\n# BUSCO version is: 3.0.2\n# The lineage dataset is: metazoa_odb9 (Creation date: 2016-02-13, number of species: 65, number of BUSCOs: 978)\n# To reproduce this run: python /gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py -i /gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v3.1.fasta -o cbai_transcriptome_v3.1.fasta -l /gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9/ -m transcriptome -c 28 --long -z\n#\n# Summarized benchmarking in BUSCO notation for file /gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v3.1.fasta\n# BUSCO was run in mode: transcriptome\n\n    C:96.5%[S:40.3%,D:56.2%],F:2.2%,M:1.3%,n:978\n\n    944 Complete BUSCOs (C)\n    394 Complete and single-copy BUSCOs (S)\n    550 Complete and duplicated BUSCOs (D)\n    22  Fragmented BUSCOs (F)\n    12  Missing BUSCOs (M)\n    978 Total BUSCO groups searched\nWill add scores to Genomic Resources wiki. Also, after running BUSCO on the cbai_transcriptome_v3.1 transcriptome, I will update my BUSCO comparision notebook entry from 20200528."
  },
  {
    "objectID": "posts/2020/2020-05-20-Transcriptome-Annotation---Trinotate-C.bairdi-Transcriptome-v1.6-on-Mox/index.html",
    "href": "posts/2020/2020-05-20-Transcriptome-Annotation---Trinotate-C.bairdi-Transcriptome-v1.6-on-Mox/index.html",
    "title": "Transcriptome Annotation - Trinotate C.bairdi Transcriptome-v1.6 on Mox",
    "section": "",
    "text": "After creating a de novo assembly of C.bairdi transcriptome v1.6 on 20200518, performing BLASTx annotation on 202000519, and TransDecoder for ORF identification on 20200519, I continued the annotation process by running Trinotate.\nTrinotate will perform functional annotation of the transcriptome assembly, including GO terms and an annotation feature map that can be used in subsequent Trinity-based differential gene expression analysis so that functional annotations are carried downstream through that process.\nSBATCH script (GitHub):\n\n20200520_cbai_trinotate_transcriptome-v1.6.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=trinotate_cbai_v1.6\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200520_cbai_trinotate_transcriptome-v1.6\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nwd=\"$(pwd)\"\ntimestamp=$(date +%Y%m%d)\n\n\n## Paths to input/output files\n\n## New folders for working directory\nrnammer_out_dir=\"${wd}/RNAmmer_out\"\nsignalp_out_dir=\"${wd}/signalp_out\"\ntmhmm_out_dir=\"${wd}/tmhmm_out\"\n\n# Input files\n## BLASTx\nblastx_out=\"/gscratch/scrubbed/samwhite/outputs/20200519_cbai_diamond_blastx_transcriptome_v1.6/cbai_transcriptome_v1.6.blastx.outfmt6\"\n\n## TransDecoder\nblastp_out=\"/gscratch/scrubbed/samwhite/outputs/20200519_cbai_transdecoder_transcriptome-v1.6/blastp_out/20200519.cbai.blastp.outfmt6\"\npfam_out=\"/gscratch/scrubbed/samwhite/outputs/20200519_cbai_transdecoder_transcriptome-v1.6/pfam_out/20200519.cbai.pfam.domtblout\"\nlORFs_pep=\"/gscratch/scrubbed/samwhite/outputs/20200519_cbai_transdecoder_transcriptome-v1.6/cbai_transcriptome_v1.6.fasta.transdecoder_dir/longest_orfs.pep\"\n\n## Transcriptomics\ntrinity_fasta=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v1.6.fasta\"\ntrinity_gene_map=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v1.6.fasta.gene_trans_map\"\n\nrnammer_prefix=${trinity_fasta##*/}\nprefix=\"${timestamp}.${rnammer_prefix}.trinotate\"\n\n# Output files\nrnammer_out=\"${rnammer_out_dir}/${rnammer_prefix}.rnammer.gff\"\nsignalp_out=\"${signalp_out_dir}/${prefix}.signalp.out\"\ntmhmm_out=\"${tmhmm_out_dir}/${prefix}.tmhmm.out\"\ntrinotate_report=\"${wd}/${prefix}_annotation_report.txt\"\n\n# Paths to programs\nrnammer_dir=\"/gscratch/srlab/programs/RNAMMER-1.2\"\nrnammer=\"${rnammer_dir}/rnammer\"\nsignalp_dir=\"/gscratch/srlab/programs/signalp-4.1\"\nsignalp=\"${signalp_dir}/signalp\"\ntmhmm_dir=\"/gscratch/srlab/programs/tmhmm-2.0c/bin\"\ntmhmm=\"${tmhmm_dir}/tmhmm\"\ntrinotate_dir=\"/gscratch/srlab/programs/Trinotate-v3.1.1\"\ntrinotate=\"${trinotate_dir}/Trinotate\"\ntrinotate_rnammer=\"${trinotate_dir}/util/rnammer_support/RnammerTranscriptome.pl\"\ntrinotate_GO=\"${trinotate_dir}/util/extract_GO_assignments_from_Trinotate_xls.pl\"\ntrinotate_features=\"${trinotate_dir}/util/Trinotate_get_feature_name_encoding_attributes.pl\"\ntrinotate_sqlite_db=\"Trinotate.sqlite\"\n\n# Generate FastA checksum, for reference if needed.\nmd5sum ${trinity_fasta} > fasta.checksum.md5\n\n# Make output directories\nmkdir \"${rnammer_out_dir}\" \"${signalp_out_dir}\" \"${tmhmm_out_dir}\"\n\n# Copy sqlite database template\n\ncp ${trinotate_dir}/admin/Trinotate.sqlite .\n\n# Run signalp\n${signalp} \\\n-f short \\\n-n \"${signalp_out}\" \\\n${lORFs_pep}\n\n# Run tmHMM\n${tmhmm} \\\n--short \\\n< ${lORFs_pep} \\\n> \"${tmhmm_out}\"\n\n# Run RNAmmer\ncd \"${rnammer_out_dir}\" || exit\n${trinotate_rnammer} \\\n--transcriptome ${trinity_fasta} \\\n--path_to_rnammer ${rnammer}\ncd \"${wd}\" || exit\n\n# Run Trinotate\n## Load transcripts and coding regions into database\n${trinotate} \\\n${trinotate_sqlite_db} \\\ninit \\\n--gene_trans_map \"${trinity_gene_map}\" \\\n--transcript_fasta \"${trinity_fasta}\" \\\n--transdecoder_pep \"${lORFs_pep}\"\n\n## Load BLAST homologies\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_swissprot_blastp \\\n\"${blastp_out}\"\n\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_swissprot_blastx \\\n\"${blastx_out}\"\n\n## Load Pfam\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_pfam \\\n\"${pfam_out}\"\n\n## Load transmembrane domains\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_tmhmm \\\n\"${tmhmm_out}\"\n\n## Load signal peptides\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_signalp \\\n\"${signalp_out}\"\n\n## Load RNAmmer\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_rnammer \\\n\"${rnammer_out}\"\n\n## Creat annotation report\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nreport \\\n> \"${trinotate_report}\"\n\n# Extract GO terms from annotation report\n\"${trinotate_GO}\" \\\n--Trinotate_xls \"${trinotate_report}\" \\\n-G \\\n--include_ancestral_terms \\\n> \"${prefix}\".go_annotations.txt\n\n# Make transcript features annotation map\n\"${trinotate_features}\" \\\n\"${trinotate_report}\" \\\n> \"${prefix}\".annotation_feature_map.txt\n\n\nRESULTS\nPretty quick, just under 45 mins:\n\n\n\ncbai v1.6 trinotate runtime\n\n\nOutput folder:\n\n20200520_cbai_trinotate_transcriptome-v1.6/\n\nAnnotation feature map. This can be used to update Trinity-based gene expression matrices like so:\n\n${TRINITY_HOME}/Analysis/DifferentialExpression/rename_matrix_feature_identifiers.pl Trinity_trans.counts.matrix annot_feature_map.txt > Trinity_trans.counts.wAnnot.matrix\n20200520.cbai_transcriptome_v1.6.fasta.trinotate.annotation_feature_map.txt\n\nAnnotation report (CSV)\n\n20200520.cbai_transcriptome_v1.6.fasta.trinotate_annotation_report.txt\n\nGene ontology (GO) annotations (TXT)\n\n20200520.cbai_transcriptome_v1.6.fasta.trinotate.go_annotations.txt\n\nSQlite database:\n\nTrinotate.sqlite"
  },
  {
    "objectID": "posts/2020/2020-01-07-NanoPore-Sequencing---Initial-NanoPore-MinION-Lambda-Sequencing-Test/index.html",
    "href": "posts/2020/2020-01-07-NanoPore-Sequencing---Initial-NanoPore-MinION-Lambda-Sequencing-Test/index.html",
    "title": "NanoPore Sequencing - Initial NanoPore MinION Lambda Sequencing Test",
    "section": "",
    "text": "We recently acquired a NanoPore MinION sequencer, FLO-MIN106 flow cell and the Rapid Sequencing Kit (SQK-RAD004). The NanoPore website provides a pretty thorough an user-friendly walk-through of how to begin using the system for the first time. With that said, I believe the user needs to have a registered account with NanoPore and needs to have purchased some products to have full access to the protocols they provide.\nFor first time users, they provide a “Lambda Control experiment” which:\n\nteaches you how to use the sequencer, flow cells, and sequencing Kit\nsequences a known, small genome to allow fast sequencing and analysis\nfree access to their EPI2ME analysis platform (which will perform basecalling, quality analysis, alignment, and generate a visually pleasing sequencing summary/report)\n\nHonestly, it’s a really helpful and easy way to get introduced to using the entire system. It’s also not a bad way to sell the EPI2ME service, as it’s very hands-off and easy to run.\nAnyway, I set up the Lambda Control experiment sequencing run and ran it for the recommended duration (6hrs) with basecalling enabled (this will help speed up the subsequent EPI2ME service after sequencing is complete).\n\n\nRESULTS\nOutput folder:\n\n20200107_nanopore-minION_lambda_test/20200107_2035_MN29908_FAL48614_885ed0db/\n\nFast5 format reads:\n\n20200107_nanopore-minION_lambda_test/20200107_2035_MN29908_FAL48614_885ed0db/fast5_pass/\n\nFastQ format reads:\n\n20200107_nanopore-minION_lambda_test/20200107_2035_MN29908_FAL48614_885ed0db/fastq_pass/\n\nEPI2ME Report #1 (Flow cell performance; PDF):\n\n20200107_nanopore-minION_lambda_test/20200107_2035_MN29908_FAL48614_885ed0db/EPI2ME_Report_224980.pdf\n\nEPI2ME Report #2 (Alignment stats; PDF):\n\n20200107_nanopore-minION_lambda_test/20200107_2035_MN29908_FAL48614_885ed0db/EPI2ME_Report_224980-02.pdf\n\nOverall, the run went as expected and yielded >8,000x coverage of the Lambda genome, with only ~2.8% of reads failing to map to the genome. Will proceed to running an actual sample!\nScreencaps below are taken directly from the two EPI2ME reports linked above.\n\n\n\nminION Lamba read count per hour plot\n\n\n\n\n\nminION Lamba reads stats: num reads, mean quality, mean length, total bases\n\n\n\n\n\nminION Lamba read quality scores and read lengths plots\n\n\n\n\n\nminION Lamba read quality scores and read lengths plots\n\n\n\n\n\nminION Lamba alignment and coverage plots/stats"
  },
  {
    "objectID": "posts/2020/2020-05-18-Transcriptome-Assembly---C.bairdi-All-Pooled-RNAseq-Data-Without-Taxonomic-Filters-with-Trinity-on-Mox/index.html",
    "href": "posts/2020/2020-05-18-Transcriptome-Assembly---C.bairdi-All-Pooled-RNAseq-Data-Without-Taxonomic-Filters-with-Trinity-on-Mox/index.html",
    "title": "Transcriptome Assembly - C.bairdi All Pooled RNAseq Data Without Taxonomic Filters with Trinity on Mox",
    "section": "",
    "text": "Steven asked that I assemble a transcriptome with just our pooled C.bairdi RNAseq data (not taxonomically filtered; see the FastQ list file linked in the Results section below). This constitutes samples we have designated: 2018, 2019, 2020-UW. A de novo assembly was run using Trinity on Mox. Since all pooled RNAseq libraries were stranded, I added this option to Trinity command.\nSBATCH script (GitHub):\n\n20200518_cbai_trinity_pooled_RNAseq.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=trinity_cbai\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=9-00:00:00\n## Memory per node\n#SBATCH --mem=500G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200518_cbai_trinity_pooled_RNAseq\n\n\n### Trinity de novo assembly of all pooled C.bairdi RNAseq data.\n### Includes \"descriptor_1\" short-hand of: 2020-UW, 2019, 2018.\n### See fastq.list.txt file for list of input files used for assembly.\n\n# Exit script if a command fails\nset -e\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# User-defined variables\nreads_dir=/gscratch/srlab/sam/data/C_bairdi/RNAseq\ntranscriptome_dir=/gscratch/srlab/sam/data/C_bairdi/transcriptomes\nthreads=28\nassembly_stats=assembly_stats.txt\ntimestamp=$(date +%Y%m%d)\nfasta_name=\"${timestamp}.C_bairdi.Trinity.fasta\"\n\n# Paths to programs\ntrinity_dir=\"/gscratch/srlab/programs/trinityrnaseq-v2.9.0\"\nsamtools=\"/gscratch/srlab/programs/samtools-1.10/samtools\"\n\n\n## Inititalize arrays\nR1_array=()\nR2_array=()\n\n# Variables for R1/R2 lists\nR1_list=\"\"\nR2_list=\"\"\n\n# Create array of fastq R1 files\nR1_array=(\"${reads_dir}\"/3*_S[0-9]*R1*-trim*.gz)\n\n# Create array of fastq R2 files\nR2_array=(\"${reads_dir}\"/3*_S[0-9]*R2*-trim*.gz)\n\n# Create list of fastq files used in analysis\n## Uses parameter substitution to strip leading path from filename\nfor fastq in \"${reads_dir}\"/3*_S[0-9]*-trim*.gz\ndo\n  echo \"${fastq##*/}\" >> fastq.list.txt\ndone\n\n# Create comma-separated lists of FastQ reads\nR1_list=$(echo \"${R1_array[@]}\" | tr \" \" \",\")\nR2_list=$(echo \"${R2_array[@]}\" | tr \" \" \",\")\n\n\n# Run Trinity\n## Not running as \"stranded\", due to mix of library types\n${trinity_dir}/Trinity \\\n--seqType fq \\\n--max_memory 500G \\\n--CPU ${threads} \\\n--SS_lib_type RF \\\n--left \"${R1_list}\" \\\n--right \"${R2_list}\"\n\n# Rename generic assembly FastA\nmv trinity_out_dir/Trinity.fasta trinity_out_dir/\"${fasta_name}\"\n\n# Assembly stats\n${trinity_dir}/util/TrinityStats.pl trinity_out_dir/\"${fasta_name}\" \\\n> ${assembly_stats}\n\n# Create gene map files\n${trinity_dir}/util/support_scripts/get_Trinity_gene_to_trans_map.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n> trinity_out_dir/\"${fasta_name}\".gene_trans_map\n\n# Create sequence lengths file (used for differential gene expression)\n${trinity_dir}/util/misc/fasta_seq_length.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n> trinity_out_dir/\"${fasta_name}\".seq_lens\n\n# Create FastA index\n${samtools} faidx \\\ntrinity_out_dir/\"${fasta_name}\"\n\n# Copy files to transcriptome directory\nrsync -av \\\ntrinity_out_dir/\"${fasta_name}\"* \\\n${transcriptome_dir}\n\n# Generate FastA MD5 checksum\n# See last line of SLURM output file\nmd5sum trinity_out_dir/\"${fasta_name}\"\n\n\nRESULTS\nPretty quick; only ~18hrs:\n\n\n\nTrinity pooled RNAseq runtime\n\n\nNOTE: The resulting FastA will be referred to as cbai_transcriptome_v3.0.fasta in future references.\nOutput folder:\n\n20200518_cbai_trinity_pooled_RNAseq\n\nInput FastQ list (text):\n\nfastq.list.txt\n\nFastA (412MB):\n\n20200518.C_bairdi.Trinity.fasta\n\nMD5 = 5516789cbad5fa9009c3566003557875\n\n\nFastA Index (text):\n\n20200518.C_bairdi.Trinity.fasta.fai\n\nThe following sets of files are useful for downstream gene expression and annotation using Trinity.\nTrinity FastA Gene Trans Map (text):\n\n20200518.C_bairdi.Trinity.fasta.gene_trans_map\n\nTrinity FastA Sequence Lengths (text):\n\n20200518.C_bairdi.Trinity.fasta.seq_lens\n\nAssembly stats (text):\n\nassembly_stats.txt\n\n################################\n## Counts of transcripts, etc.\n################################\nTotal trinity 'genes':  127738\nTotal trinity transcripts:  344944\nPercent GC: 46.21\n\n########################################\nStats based on ALL transcript contigs:\n########################################\n\n    Contig N10: 4597\n    Contig N20: 3479\n    Contig N30: 2835\n    Contig N40: 2375\n    Contig N50: 1985\n\n    Median contig length: 650\n    Average contig: 1132.95\n    Total assembled bases: 390805991\n\n\n#####################################################\n## Stats based on ONLY LONGEST ISOFORM per 'GENE':\n#####################################################\n\n    Contig N10: 4680\n    Contig N20: 3487\n    Contig N30: 2791\n    Contig N40: 2266\n    Contig N50: 1791\n\n    Median contig length: 381\n    Average contig: 845.46\n    Total assembled bases: 107996989"
  },
  {
    "objectID": "posts/2020/2020-01-17-RNA-Isolation-and-Quantification---C.bairdi-Hemolymph-Pellets-in-RNAlater/index.html",
    "href": "posts/2020/2020-01-17-RNA-Isolation-and-Quantification---C.bairdi-Hemolymph-Pellets-in-RNAlater/index.html",
    "title": "RNA Isolation and Quantification - C.bairdi Hemolymph Pellets in RNAlater",
    "section": "",
    "text": "TL;DR - Recovered absolutely no RNA from any sample! However, I did recover DNA from each sample.\nIsolated RNA from the following 23 hemolymph pellet samples:\n\n6128_112_9\n6204_114_9\n6141_123_9\n6245_126_9\n6240_134_9\n6260_136_9\n6257_138_9\n6259_139_9\n6258_140_9\n6255_143_9\n6256_146_9\n6265_155_9\n6266_156_9\n6261_164_9\n6120_165_9\n6251_167_9\n6262_168_9\n6243_173_9\n6263_179_9\n6264_180_9\n6200_208_12\n6204_252_12\n6190_256_12\n\nIsolated RNA using the Quick DNA/RNA Microprep Kit (ZymoResearch; PDF) according to the manufacturer’s protocol for liquids/cells in RNAlater.\n\nUsed 35uL from each RNAlater/hemocyte slurry.\nMixed with equal volume of H2O (35uL).\nRetained DNA on the Zymo-Spin IC-XM columns for isolation after RNA isolation.\nPerformed on-column DNase step.\nRNA was eluted in 15uL H2O\n\nRNA was quantified on the Roberts Lab Qubit 3.0 using the RNA High Sensitivity Assay (Invitrogen), using 2uL of each sample.\n\n\nRESULTS\nQubit results (Google Sheet):\n\n20200117_qubit_cbai_RNA\n\nWell, none of these samples appear to have any RNA in them! The last time I did this, I started with 70uL of each sample and had yields high enough that cutting the sample volume in half should still have yielded ample RNA. This makes me think I screwed something up, particularly since I obtained DNA from each of the samples. However, I’ve reviewed all the steps and don’t see anything obvious that I forgot/screwed up.\nI could re-quantify these using a higher volume, but I think it’s pointless. Samples that are too low for quantification on the Qubit are <1ng/uL. So, even if I were to increase the quantification volume to 5uL (i.e. 2.5x the volume I used initially), at best, the concentrations only be 2.5ng/uL. And, the the remaining volume of sample would be ~5uL; yielding 7.5ng of RNA in total. As such, I’ve discarded the samples and will attempt to re-isolate RNA from them."
  },
  {
    "objectID": "posts/2020/2020-08-24-qPCR---P.generosa-RPL5-v2-v3-and-TIF3s6b-v2-v3-Primer-Tests/index.html",
    "href": "posts/2020/2020-08-24-qPCR---P.generosa-RPL5-v2-v3-and-TIF3s6b-v2-v3-Primer-Tests/index.html",
    "title": "qPCR - P.generosa RPL5-v2-v3 and TIF3s6b-v2-v3 Primer Tests",
    "section": "",
    "text": "Shelly ordered some new primers as potential normalizing genes and asked me to test them out (GitHub Issue).\nPrimers used:\n\n\n\nSRID\nPrimer_Name\n\n\n\n\n1787\nRPL5_v2_FWD\n\n\n1786\nRPL5_v2_REV\n\n\n1785\nRPL5_v3_FWD\n\n\n1784\nRPL5_v3_REV\n\n\n1783\nTIF3s6b_v2_FWD\n\n\n1782\nTIF3s6b_v2_REV\n\n\n1781\nTIF3s6b_v3_FWD\n\n\n1780\nTIF3s6b_v3_REV\n\n\n\nPositive control was pooled cDNA, created by combining 2uL from each of the following:\n\n11-08 1H (made by me from 20191125)\n11-08 2H (made by me from 20191125)\n57H (made by me from 20191125)\n11/15 Chew (made by Kaitlyn, no date on tube)\n11/21 Star (made by Kaitlyn, no date on tube)\n\nI also used geoduck gDNA (162ng/uL; from 20170105) as a potential positive control, and/or as confirmation that these primers will/not amplify gDNA.\nMaster mix calcs are here:\n\n200200824_qPCR_geoduck_RPL5-v2-v3_TIF2s6b-v2-v3 (Google Sheet)\n\nAll qPCR reactions were run in duplicate. See qPCR Report (Results section below) for plate layout, cycling params, etc.\n\n\nRESULTS\nqPCR Report (PDF):\n\nsam_2020-08-24_05-17-26_BR006896.pdf\n\nCFX Data File (PCRD):\n\nsam_2020-08-24%2005-17-26_BR006896.pcrd\n\nCFX Results File (CSV):\n\nsam_2020-08-24_05-17-26_BR006896_Quantification-Cq-Results.csv\n\nAll the primers look good:\n\nCq is reasonably low\nMelt curves have single peak\n\nAmplifcation/melt plots for each primer are below.\nNOTE: Genomic DNA is amplified by all three primer sets and comes up at an earlier Cq than cDNA. In TIF3s6b v3, gDNA exhibits a small, secondary peak at ~75oC.\n\nRPL5 v2\nAMPLIFICATION PLOTS\n\n\n\nRPL5 v2 amplification plots\n\n\nMELT PLOTS\n\n\n\nRPL5 v2 melt plots\n\n\n\n\nRPL5 v3\n\n\n\nRPL5 v3 amplification plots\n\n\n\n\n\nRPL5 v3 melt plots\n\n\n\n\nTIF3s6b v2\n\n\n\nTIF3s6b v2 amplification plots\n\n\n\n\n\nTIF3s6b v2 melt plots\n\n\n\n\nTIF3s6b v3\n\n\n\nTIF3s6b v3 amplification plots\n\n\n\n\n\nTIF3s6b v3 melt plots"
  },
  {
    "objectID": "posts/2020/2020-04-09-Transcriptome-Annotation---Trinotate-C.bairdi-MEGAN6-Taxonomic-specific-Trinity-Assembly-on-Mox/index.html",
    "href": "posts/2020/2020-04-09-Transcriptome-Annotation---Trinotate-C.bairdi-MEGAN6-Taxonomic-specific-Trinity-Assembly-on-Mox/index.html",
    "title": "Transcriptome Annotation - Trinotate C.bairdi MEGAN6 Taxonomic-specific Trinity Assembly on Mox",
    "section": "",
    "text": "After performing de novo assembly on our Tanner crab MEGAN6 taxonomic-specific RNAseq data on 20200330 and performing BLASTx annotation on 20200408, I continued the annotation process by running Trinotate.\nTrinotate will perform functional annotation of the transcriptome assembly, including GO terms and an annotation feature map that can be used in subsequent Trinity-based differential gene expression analysis so that functional annotations are carried downstream through that process.\nSBATCH script (GitHub):\n\n20200409_cbai_trinotate_megan.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=trinotate_cbai\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=05-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200409_cbai_trinotate_megan\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nwd=\"$(pwd)\"\ntimestamp=$(date +%Y%m%d)\nspecies=\"cbai\"\n\nprefix=\"${timestamp}.${species}.trinotate\"\n\n\n## Paths to input/output files\n\n## New folders for working directory\nrnammer_out_dir=\"${wd}/RNAmmer_out\"\nsignalp_out_dir=\"${wd}/signalp_out\"\ntmhmm_out_dir=\"${wd}/tmhmm_out\"\n\n# Input files\n## BLASTx\nblastx_out=\"/gscratch/scrubbed/samwhite/outputs/20200408_cbai_diamond_blastx_megan/20200408.C_bairdi.megan.Trinity.blastx.outfmt6\"\n\n## TransDecoder\nblastp_out=\"/gscratch/scrubbed/samwhite/outputs/20200407_cbai_transdecoder_megan/blastp_out/20200408.cbai.blastp.outfmt6\"\npfam_out=\"/gscratch/scrubbed/samwhite/outputs/20200407_cbai_transdecoder_megan/pfam_out/20200408.cbai.pfam.domtblout\"\nlORFs_pep=\"/gscratch/scrubbed/samwhite/outputs/20200407_cbai_transdecoder_megan/20200408.C_bairdi.megan.Trinity.fasta.transdecoder_dir/longest_orfs.pep\"\n\n## Transcriptomics\ntrinity_fasta=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200408.C_bairdi.megan.Trinity.fasta\"\ntrinity_gene_map=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200408.C_bairdi.megan.Trinity.fasta.gene_trans_map\"\n\nrnammer_prefix=${trinity_fasta##*/}\n\n# Output files\nrnammer_out=\"${rnammer_out_dir}/${rnammer_prefix}.rnammer.gff\"\nsignalp_out=\"${signalp_out_dir}/${prefix}.signalp.out\"\ntmhmm_out=\"${tmhmm_out_dir}/${prefix}.tmhmm.out\"\ntrinotate_report=\"${wd}/${prefix}_annotation_report.txt\"\n\n# Paths to programs\nrnammer_dir=\"/gscratch/srlab/programs/RNAMMER-1.2\"\nrnammer=\"${rnammer_dir}/rnammer\"\nsignalp_dir=\"/gscratch/srlab/programs/signalp-4.1\"\nsignalp=\"${signalp_dir}/signalp\"\ntmhmm_dir=\"/gscratch/srlab/programs/tmhmm-2.0c/bin\"\ntmhmm=\"${tmhmm_dir}/tmhmm\"\ntrinotate_dir=\"/gscratch/srlab/programs/Trinotate-v3.1.1\"\ntrinotate=\"${trinotate_dir}/Trinotate\"\ntrinotate_rnammer=\"${trinotate_dir}/util/rnammer_support/RnammerTranscriptome.pl\"\ntrinotate_GO=\"${trinotate_dir}/util/extract_GO_assignments_from_Trinotate_xls.pl\"\ntrinotate_features=\"${trinotate_dir}/util/Trinotate_get_feature_name_encoding_attributes.pl\"\ntrinotate_sqlite_db=\"Trinotate.sqlite\"\n\n# Make output directories\nmkdir \"${rnammer_out_dir}\" \"${signalp_out_dir}\" \"${tmhmm_out_dir}\"\n\n# Copy sqlite database template\n\ncp ${trinotate_dir}/admin/Trinotate.sqlite .\n\n# Run signalp\n${signalp} \\\n-f short \\\n-n \"${signalp_out}\" \\\n${lORFs_pep}\n\n# Run tmHMM\n${tmhmm} \\\n--short \\\n< ${lORFs_pep} \\\n> \"${tmhmm_out}\"\n\n# Run RNAmmer\ncd \"${rnammer_out_dir}\" || exit\n${trinotate_rnammer} \\\n--transcriptome ${trinity_fasta} \\\n--path_to_rnammer ${rnammer}\ncd \"${wd}\" || exit\n\n# Run Trinotate\n## Load transcripts and coding regions into database\n${trinotate} \\\n${trinotate_sqlite_db} \\\ninit \\\n--gene_trans_map \"${trinity_gene_map}\" \\\n--transcript_fasta \"${trinity_fasta}\" \\\n--transdecoder_pep \"${lORFs_pep}\"\n\n## Load BLAST homologies\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_swissprot_blastp \\\n\"${blastp_out}\"\n\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_swissprot_blastx \\\n\"${blastx_out}\"\n\n## Load Pfam\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_pfam \\\n\"${pfam_out}\"\n\n## Load transmembrane domains\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_tmhmm \\\n\"${tmhmm_out}\"\n\n## Load signal peptides\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_signalp \\\n\"${signalp_out}\"\n\n## Load RNAmmer\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_rnammer \\\n\"${rnammer_out}\"\n\n## Creat annotation report\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nreport \\\n> \"${trinotate_report}\"\n\n# Extract GO terms from annotation report\n\"${trinotate_GO}\" \\\n--Trinotate_xls \"${trinotate_report}\" \\\n-G \\\n--include_ancestral_terms \\\n> \"${prefix}\".go_annotations.txt\n\n# Make transcript features annotation map\n\"${trinotate_features}\" \\\n\"${trinotate_report}\" \\\n> \"${prefix}\".annotation_feature_map.txt\n\n\nRESULTS\nTook a little over 50 mins to run:\n\n\n\ncbai trinotate runtime\n\n\nOutput folder:\n\n20200409_cbai_trinotate_megan/\n\nAnnotation feature map. This can be used to update Trinity-based gene expression matrices like so:\n\n${TRINITY_HOME}/Analysis/DifferentialExpression/rename_matrix_feature_identifiers.pl Trinity_trans.counts.matrix annot_feature_map.txt > Trinity_trans.counts.wAnnot.matrix\n20200409.cbai.trinotate.annotation_feature_map.txt\n\nAnnotation report (CSV)\n\n20200126.cbai.trinotate_annotation_report.txt\n\nGene ontology (GO) annotations (TXT)\n\n20200409.cbai.trinotate.go_annotations.txt\n\nSQlite database:\n\nTrinotate.sqlite"
  },
  {
    "objectID": "posts/2020/2020-04-07-Transdecoder---Hematodinium-MEGAN6-Taxonomic-Specific-Reads-Assembly-from-20200330/index.html",
    "href": "posts/2020/2020-04-07-Transdecoder---Hematodinium-MEGAN6-Taxonomic-Specific-Reads-Assembly-from-20200330/index.html",
    "title": "Transdecoder - Hematodinium MEGAN6 Taxonomic-Specific Reads Assembly from 20200330",
    "section": "",
    "text": "Ran Trinity to de novo assembly on the the Alveolata MEGAN6 taxonomic-specific RNAseq data on 20120330 and now will begin annotating the transcriptome using TransDecoder on Mox.\nSBATCH script (GitHub):\n\n20200407_hemat_transdecoder_megan.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=transdecoder_hemat\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=1-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200407_hemat_transdecoder_megan\n\n\n# Exit script if a command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# Set workind directory as current directory\nwd=\"$(pwd)\"\n\n# Capture date as YYYYMMDD\ntimestamp=$(date +%Y%m%d)\n\n# Set input file locations and species designation\ntrinity_fasta=\"/gscratch/srlab/sam/data/Hematodinium/transcriptomes/20200408.hemat.megan.Trinity.fasta\"\ntrinity_gene_map=\"/gscratch/srlab/sam/data/Hematodinium/transcriptomes/20200408.hemat.megan.Trinity.fasta.gene_trans_map\"\nspecies=\"hemat\"\n\n# Capture trinity file name\ntrinity_fasta_name=${trinity_fasta##*/}\n\n\n\n# Paths to input/output files\nblastp_out_dir=\"${wd}/blastp_out\"\ntransdecoder_out_dir=\"${wd}/${trinity_fasta_name}.transdecoder_dir\"\npfam_out_dir=\"${wd}/pfam_out\"\nblastp_out=\"${blastp_out_dir}/${timestamp}.${species}.blastp.outfmt6\"\npfam_out=\"${pfam_out_dir}/${timestamp}.${species}.pfam.domtblout\"\nlORFs_pep=\"${transdecoder_out_dir}/longest_orfs.pep\"\npfam_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/Pfam-A.hmm\"\nsp_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/uniprot_sprot.pep\"\n\n\n\n# Paths to programs\nblast_dir=\"/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin\"\nblastp=\"${blast_dir}/blastp\"\nhmmer_dir=\"/gscratch/srlab/programs/hmmer-3.2.1/src\"\nhmmscan=\"${hmmer_dir}/hmmscan\"\ntransdecoder_dir=\"/gscratch/srlab/programs/TransDecoder-v5.5.0\"\ntransdecoder_lORFs=\"${transdecoder_dir}/TransDecoder.LongOrfs\"\ntransdecoder_predict=\"${transdecoder_dir}/TransDecoder.Predict\"\n\n# Make output directories\nmkdir \"${blastp_out_dir}\"\nmkdir \"${pfam_out_dir}\"\n\n# Extract long open reading frames\n\"${transdecoder_lORFs}\" \\\n--gene_trans_map \"${trinity_gene_map}\" \\\n-t \"${trinity_fasta}\"\n\n# Run blastp on long ORFs\n\"${blastp}\" \\\n-query \"${lORFs_pep}\" \\\n-db \"${sp_db}\" \\\n-max_target_seqs 1 \\\n-outfmt 6 \\\n-evalue 1e-5 \\\n-num_threads 28 \\\n> \"${blastp_out}\"\n\n# Run pfam search\n\"${hmmscan}\" \\\n--cpu 28 \\\n--domtblout \"${pfam_out}\" \\\n\"${pfam_db}\" \\\n\"${lORFs_pep}\"\n\n# Run Transdecoder with blastp and Pfam results\n\"${transdecoder_predict}\" \\\n-t \"${trinity_fasta}\" \\\n--retain_pfam_hits \"${pfam_out}\" \\\n--retain_blastp_hits \"${blastp_out}\"\n\n\nRESULTS\nTook a bit over an hour to run:\n\n\n\nHemat transdecoder runtime\n\n\nOutput folder:\n\n20200407_hemat_transdecoder_megan/\n\nCoding Sequences (FastA):\n\n20200408.hemat.megan.Trinity.fasta.transdecoder.cds\n\nPeptide Sequences (FastA):\n\n20200408.hemat.megan.Trinity.fasta.transdecoder.pep\n\nBLASTp output (tab):\n\n20200407_hemat_transdecoder_megan/blastp_out/20200408.hemat.blastp.outfmt6\n\nPfam output:\n\n20200407_hemat_transdecoder_megan/pfam_out/20200408.hemat.pfam.domtblout\n\nWill get ready to run Trinotate with these output files."
  },
  {
    "objectID": "posts/2020/2020-12-24-Alignments---C.bairdi-RNAseq-Transcriptome-Alignments-Using-Bowtie2-on-Mox/index.html",
    "href": "posts/2020/2020-12-24-Alignments---C.bairdi-RNAseq-Transcriptome-Alignments-Using-Bowtie2-on-Mox/index.html",
    "title": "Alignments - C.bairdi RNAseq Transcriptome Alignments Using Bowtie2 on Mox",
    "section": "",
    "text": "I had previously attempted to compare all of our C.bairdi transcriptome assemblies using DETONATE on 20200601, but, due to hitting time limits on Mox, failed to successfully get the analysis to complete. I realized that the limiting factor was performing FastQ alignments, so I decided to run this step independently to see if I could at least get that step resolved. DETONATE (rsem-eval) will accept BAM files as input, so I’m hoping I can power through this alignment step and then provided DETONATE (rsem-eval) with the BAM files.\nI ran bowtie2 on Mox using the alignment settings described in the DETONATE (rsem-eval) documentation (see SBATCH script below for actual bowtie2 parameters).\nSBATCH script (GitHub):\n\n20201224_cbai_bowtie2_transcriptomes_alignments.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=20201224_cbai_bowtie2_transcriptomes_alignments\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=15-00:00:00\n## Memory per node\n#SBATCH --mem=500G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20201224_cbai_bowtie2_transcriptomes_alignments\n# This is a script to generate BAM files for use in DETONATE's\n# rsem-eval program to compare C.bairdi transcriptome assembly \"qualities\".\n\n###################################################################################\n# These variables need to be set by user\n\n# Assign Variables\nreads_dir=/gscratch/srlab/sam/data/C_bairdi/RNAseq\ntranscriptomes_dir=/gscratch/srlab/sam/data/C_bairdi/transcriptomes\nthreads=28\nmem_per_thread=10G\n\n# Program paths\nbowtie2_dir=\"/gscratch/srlab/programs/bowtie2-2.4.2-linux-x86_64\"\nsamtools=\"/gscratch/srlab/programs/samtools-1.10/samtools\"\n\n# Array of the various comparisons to evaluate\n# Each condition in each comparison should be separated by a \"-\"\ntranscriptomes_array=(\n\"${transcriptomes_dir}\"/cbai_transcriptome_v1.0.fasta \\\n\"${transcriptomes_dir}\"/cbai_transcriptome_v1.5.fasta \\\n\"${transcriptomes_dir}\"/cbai_transcriptome_v1.6.fasta \\\n\"${transcriptomes_dir}\"/cbai_transcriptome_v1.7.fasta \\\n\"${transcriptomes_dir}\"/cbai_transcriptome_v2.0.fasta \\\n\"${transcriptomes_dir}\"/cbai_transcriptome_v2.1.fasta \\\n\"${transcriptomes_dir}\"/cbai_transcriptome_v3.0.fasta \\\n\"${transcriptomes_dir}\"/cbai_transcriptome_v3.1.fasta\n)\n\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n\n# Programs array\ndeclare -A programs_array\nprograms_array=(\n[bowtie2]=\"${bowtie2_dir}/bowtie2\" \\\n[bowtie2_build]=\"${bowtie2_dir}/bowtie2-build\" \\\n[samtools_index]=\"${samtools} index\" \\\n[samtools_sort]=\"${samtools} sort\" \\\n[samtools_view]=\"${samtools} view\"\n)\n\n\n\n\n# Loop through each comparison\nfor transcriptome in \"${!transcriptomes_array[@]}\"\ndo\n\n  ## Inititalize arrays\n  R1_array=()\n  R2_array=()\n  reads_array=()\n\n  # Variables\n  R1_list=\"\"\n  R2_list=\"\"\n\n  transcriptome_name=\"${transcriptomes_array[$transcriptome]##*/}\"\n\n  # Capture FastA checksums for verification\n  echo \"Generating checksum for ${transcriptome_name}\"\n  md5sum \"${transcriptomes_array[transcriptome]}\" >> fasta.checksums.md5\n  echo \"Finished generating checksum for ${transcriptome_name}\"\n  echo \"\"\n\n    if [[ \"${transcriptome_name}\" == \"cbai_transcriptome_v1.0.fasta\" ]]; then\n\n    reads_array=(\"${reads_dir}\"/20200[15][13][138]*megan*.fq)\n\n    # Create array of fastq R1 files\n    R1_array=(\"${reads_dir}\"/20200[15][13][138]*megan*R1.fq)\n\n    # Create array of fastq R2 files\n    R2_array=(\"${reads_dir}\"/20200[15][13][138]*megan*R2.fq)\n\n\n\n  elif [[ \"${transcriptome_name}\" == \"cbai_transcriptome_v1.5.fasta\" ]]; then\n\n    reads_array=(\"${reads_dir}\"/20200[145][13][138]*megan*.fq)\n\n    # Create array of fastq R1 files\n    R1_array=(\"${reads_dir}\"/20200[145][13][138]*megan*R1.fq)\n\n    # Create array of fastq R2 files\n    R2_array=(\"${reads_dir}\"/20200[145][13][138]*megan*R2.fq)\n\n  elif [[ \"${transcriptome_name}\" == \"cbai_transcriptome_v1.6.fasta\" ]]; then\n\n    reads_array=(\"${reads_dir}\"/*megan*.fq)\n\n    # Create array of fastq R1 files\n    R1_array=(\"${reads_dir}\"/*megan*R1.fq)\n\n    # Create array of fastq R2 files\n    R2_array=(\"${reads_dir}\"/*megan*R2.fq)\n\n  elif [[ \"${transcriptome_name}\" == \"cbai_transcriptome_v1.7.fasta\" ]]; then\n\n    reads_array=(\"${reads_dir}\"/20200[145][13][189]*megan*.fq)\n\n    # Create array of fastq R1 files\n    R1_array=(\"${reads_dir}\"/20200[145][13][189]*megan*R1.fq)\n\n    # Create array of fastq R2 files\n    R2_array=(\"${reads_dir}\"/20200[145][13][189]*megan*R2.fq)\n\n  elif [[ \"${transcriptome_name}\" == \"cbai_transcriptome_v2.0.fasta\" ]] \\\n  || [[ \"${transcriptome_name}\" == \"cbai_transcriptome_v2.1.fasta\" ]]; then\n\n    reads_array=(\"${reads_dir}\"/*fastp-trim*.fq)\n\n    # Create array of fastq R1 files\n    R1_array=(\"${reads_dir}\"/*R1*fastp-trim*.fq)\n\n    # Create array of fastq R2 files\n    R2_array=(\"${reads_dir}\"/*R2*fastp-trim*.fq)\n\n  elif [[ \"${transcriptome_name}\" == \"cbai_transcriptome_v3.0.fasta\" ]] \\\n  || [[ \"${transcriptome_name}\" == \"cbai_transcriptome_v3.1.fasta\" ]]; then\n\n    reads_array=(\"${reads_dir}\"/*fastp-trim*20[12][09][01][24]1[48]*.fq)\n\n    # Create array of fastq R1 files\n    R1_array=(\"${reads_dir}\"/*R1*fastp-trim*20[12][09][01][24]1[48]*.fq)\n\n    # Create array of fastq R2 files\n    R2_array=(\"${reads_dir}\"/*R2*fastp-trim*20[12][09][01][24]1[48]*.fq)\n\n\n  fi\n\n  # Create list of fastq files used in analysis\n  ## Uses parameter substitution to strip leading path from filename\n  printf \"%s\\n\" \"${reads_array[@]##*/}\" >> \"${transcriptome_name}\".fastq.list.txt\n\n  # Create comma-separated lists of FastQ reads\n  R1_list=$(echo \"${R1_array[@]}\" | tr \" \" \",\")\n  R2_list=$(echo \"${R2_array[@]}\" | tr \" \" \",\")\n\n  # Build Bowtie2 index\n  # Transcriptome name is used as index basename\n  ${programs_array[bowtie2_build]} \\\n  --threads ${threads} \\\n  ${transcriptomes_array[$transcriptome]} \\\n  ${transcriptome_name}\n\n  # Run rsem-eval\n  # Use bowtie2 and paired-end options\n  # Uses settings specified for use with DETONATE\n  # and for paired end reads when using DETONATE.\n  ${programs_array[bowtie2]} \\\n  -x ${transcriptome_name} \\\n  -S ${transcriptome_name}.sam \\\n  --threads ${threads} \\\n  -1 ${R1_list} \\\n  -2 ${R2_list} \\\n  --sensitive \\\n  --dpad 0 \\\n  --gbar 99999999 \\\n  --mp 1,1 \\\n  --np 1 \\\n  --score-min L,0,-0.1 \\\n  --no-mixed \\\n  --no-discordant\n\n  # Convert SAM to sorted BAM\n  #\n  ${programs_array[samtools_view]} \\\n  -b \\\n  ${transcriptome_name}.sam \\\n  | ${programs_array[samtools_sort]} \\\n  -m ${mem_per_thread} \\\n  --threads ${threads} \\\n  -o ${transcriptome_name}.sorted.bam \\\n  -\n\n  # Capture BAM checksums for verification\n  echo \"Generating checksum for ${transcriptome_name}.sorted.bam\"\n  md5sum ${transcriptome_name}.sorted.bam >> bam.checksums.md5\n  echo \"Finished generating checksum for ${transcriptome_name}.sorted.bam\"\n  echo \"\"\n\ndone\n\n# Remove leftover SAM files\nrm *.sam\n\n# Capture program options\necho \"Logging program options...\"\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n  # Handle samtools help menus\n  if [[ \"${program}\" == \"samtools_index\" ]] \\\n  || [[ \"${program}\" == \"samtools_sort\" ]] \\\n  || [[ \"${program}\" == \"samtools_view\" ]]\n  then\n    ${programs_array[$program]}\n  fi\n    ${programs_array[$program]} -h\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\n\n  # If MultiQC is in programs_array, copy the config file to this directory.\n  if [[ \"${program}\" == \"multiqc\" ]]; then\n    cp --preserve ~/.multiqc_config.yaml multiqc_config.yaml\n  fi\ndone\n\necho \"\"\necho \"Finished logging program options.\"\necho \"\"\n\necho \"\"\necho \"Logging system PATH.\"\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\necho \"Finished logging system PATH\"\n\n\nRESULTS\nRun time was ~2.5 days (not counting some weird issues with Mox):\n~Runtime for bowtie2 alignments on Mox\nThese will be used in a subsequent analysis using DETONATE (rsem-eval) to generate a score for each transcriptome. This score can be utilized to help compare the transcriptomes to identify which is the best assembly.\nImportant output files are linked below (BAMs, checksums, list of FastQs for each alignment).\nOutput folder:\n\n20201224_cbai_bowtie2_transcriptomes_alignments/\n\nMD5 checksum files (text) for input FastAs and resulting BAMs:\n\nbam.checksums.md5\nfasta.checksums.md5\n\ncbai_transcriptome_v1.0 files:\n\nbowtie2 BAM file:\n\ncbai_transcriptome_v1.0.fasta.sorted.bam\n\nList of FastQs used for alignment (text):\n\ncbai_transcriptome_v1.0.fasta.fastq.list.txt\n\n\ncbai_transcriptome_v1.5 files:\n\n[bowtie2](https://gith - List of FastQs used for alignment (text):\n\ncbai_transcriptome_v1.7.fasta.fastq.list.txtub.com/BenLangmead/bowtie2) BAM file:\ncbai_transcriptome_v1.5.fasta.sorted.bam\n\nList of FastQs used for alignment (text):\n\ncbai_transcriptome_v1.5.fasta.fastq.list.txt\n\n\ncbai_transcriptome_v1.6 files:\n\nbowtie2 BAM file:\n\ncbai_transcriptome_v1.6.fasta.sorted.bam\n\nList of FastQs used for alignment (text):\n\ncbai_transcriptome_v1.6.fasta.fastq.list.txt\n\n\ncbai_transcriptome_v1.7 files:\n\nbowtie2 BAM file:\n\ncbai_transcriptome_v1.7.fasta.sorted.bam\n\nList of FastQs used for alignment (text):\n\ncbai_transcriptome_v1.7.fasta.fastq.list.txt\n\n\ncbai_transcriptome_v2.0 files:\n\nbowtie2 BAM file:\n\ncbai_transcriptome_v2.0.fasta.sorted.bam\n\nList of FastQs used for alignment (text):\n\ncbai_transcriptome_v1.7.fasta.fastq.list.txt\n\n\ncbai_transcriptome_v2.1 files:\n\nbowtie2 BAM file:\n\ncbai_transcriptome_v2.1.fasta.sorted.bam\n\nList of FastQs used for alignment (text):\n\ncbai_transcriptome_v2.1.fasta.fastq.list.txt\n\n\ncbai_transcriptome_v3.0 files:\n\nbowtie2 BAM file:\n\ncbai_transcriptome_v3.0.fasta.sorted.bam\n\nList of FastQs used for alignment (text):\n\ncbai_transcriptome_v3.0.fasta.fastq.list.txt\n\n\ncbai_transcriptome_v3.1 files:\n\nbowtie2 BAM file:\n\ncbai_transcriptome_v3.1.fasta.sorted.bam\n\nList of FastQs used for alignment (text):\n\ncbai_transcriptome_v3.1.fasta.fastq.list.txt"
  },
  {
    "objectID": "posts/2020/2020-09-14-Data-Wrangling---Visualization-of-C.bairdi-NanoPore-Sequencing-Using-NanoPlot-on-Mox/index.html",
    "href": "posts/2020/2020-09-14-Data-Wrangling---Visualization-of-C.bairdi-NanoPore-Sequencing-Using-NanoPlot-on-Mox/index.html",
    "title": "Data Wrangling - Visualization of C.bairdi NanoPore Sequencing Using NanoPlot on Mox",
    "section": "",
    "text": "I previously converting our C.bairdi NanoPre sequencing data from the raw Fast5 format to FastQ format for our three sets of data:\n\nC.bairdi-20102558-2729-Run-01\nC.bairdi-20102558-2729-Run-02\nC.bairdi-6129_403_26\n\nBefore proceeding with assembly and/or trying to tease out taxonomic differences (the C.bairdi-6129_403_26 is from an individual infected with Hematodinium), I want to get an idea of how the data looks. So, I’ve decided to process the sequencing_summary.txt file from each Fast5 conversion with NanoPlot. This software spits out some tables and some very nice visualizations to help get a better idea of how the sequencing runs look. This was run on Mox.\nSBATCH script (GitHub):\n\n20200914_cbai_nanoplot_nanopore-data.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_nanoplot_nanopore-data\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200914_cbai_nanoplot_nanopore-data\n\n\n\n\n###################################################################################\n# These variables need to be set by user\n\n# Load Anaconda\n# Uknown why this is needed, but Anaconda will not run if this line is not included.\n. \"/gscratch/srlab/programs/anaconda3/etc/profile.d/conda.sh\"\n\n\n# Activate the NanoPlot Anaconda environment\nconda activate nanoplot_env\n\n# Set number of CPUs to use\nthreads=28\n\n# Paths to reads\nraw_reads_dir_array=(\n\"/gscratch/srlab/sam/data/C_bairdi/DNAseq/ont_FAL58500_04bb4d86_20102558-2729\" \\\n\"/gscratch/srlab/sam/data/C_bairdi/DNAseq/ont_FAL58500_94244ffd_20102558-2729\" \\\n\"/gscratch/srlab/sam/data/C_bairdi/DNAseq/ont_FAL86873_d8db260e_cbai_6129_403_26\"\n)\n\n# Paths to programs\nnanoplot=NanoPlot\n\n\n###################################################################################\n\n\n# Exit script if any command fails\nset -e\n\n\n# Capture this directory\nwd=$(pwd)\n\n# Inititalize array\nprograms_array=()\n\n\n# Programs array\nprograms_array=(\"${nanoplot}\")\n\n\n# Loop through NanoPore data directories\n# to run NanoPlot, FastQC, and MultiQC\nfor directory in \"${!raw_reads_dir_array[@]}\"\ndo\n\n\n  # Capture NanoPore directory name\n  dir_name=${raw_reads_dir_array[directory]##*/}\n\n  # Make new directory and change to that directory\n  mkdir \"${dir_name}\" && cd \"$_\"\n\n  current_dir=$(pwd)\n\n\n  # Run NanoPlot\n  ## Sets readtype to 1D (default)\n  ## Shows N50 on histograms\n  ## Analysis perfomred using the sequencing summary file generated by\n  ## guppy when converting from Fast5 to FastQ\n  ${programs_array[nanoplot]} \\\n  --threads ${threads} \\\n  --outdir ${current_dir} \\\n  --readtype 1D \\\n  --N50 \\\n  --summary \"${raw_reads_dir_array[directory]}\"/sequencing_summary.txt\n\n  # Change back to working directory\n  cd \"${wd}\"\n\ndone\n\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${programs_array[program]}: \"\n    echo \"\"\n    ${programs_array[program]} -h\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\n\nRESULTS\nVery fast, 50s:\n\n\n\nNanoPlot cumulative runtime for all three C.bairdi NanoPore data sets\n\n\nOutput folder:\n\n20200914_cbai_nanoplot_nanopore-data/\n\nEach of the NanoPore NanoPlot analyses are in individual folders, linked below. Although I’ve only linked to the full report (in HTML format) for each, the plots and data present in the full report are also available in individual images/files within those folders.\n\nC.bairdi-20102558-2729_Run-01 (FAL58500_94244ffd)\nOutput folder:\n\n20200914_cbai_nanoplot_nanopore-data/ont_FAL58500_94244ffd_20102558-2729/\n\nFull report (HTML):\n\n20200914_cbai_nanoplot_nanopore-data/ont_FAL58500_94244ffd_20102558-2729/NanoPlot-report.html\n\n\n\n\nGeneral summary\n\n\n\n\n\nActive channels\n491.0\n\n\nMean read length\n821.6\n\n\nMean read quality\n10.1\n\n\nMedian read length\n533.0\n\n\nMedian read quality\n10.6\n\n\nNumber of reads\n78,720.0\n\n\nRead length N50\n1,254.0\n\n\nTotal bases\n64,672,912.0\n\n\n\nNumber, percentage and megabases of reads above quality cutoffs:\n\n\n\nQuality_cutoff\nreads(count)\npercentage\nbases(count)\n\n\n\n\n>Q5\n73315\n(93.1%)\n60.5Mb\n\n\n>Q7\n67186\n(85.3%)\n56.5Mb\n\n\n>Q10\n46724\n(59.4%)\n41.4Mb\n\n\n>Q12\n20961\n(26.6%)\n20.6Mb\n\n\n>Q15\n966\n(1.2%)\n0.8Mb\n\n\n\nTop 5 highest mean basecall quality scores and their read lengths:\n\n\n\nRank\nmean_quality\nread_length(bp)\nbases(count)\n\n\n\n\n1\n22\n(682)\n60.5Mb\n\n\n2\n19.8\n(471)\n56.5Mb\n\n\n3\n19.1\n(414)\n41.4Mb\n\n\n4\n19.1\n(1539)\n20.6Mb\n\n\n5\n19\n(234)\n0.8Mb\n\n\n\nTop 5 longest reads and their mean basecall quality score:\n\n\n\nRank\nread_length(bp)\nmean_quality_score\n\n\n\n\n1\n62629\n(3.3)\n\n\n2\n51173\n(3.5)\n\n\n3\n45909\n(3.0)\n\n\n4\n44689\n(3.4)\n\n\n5\n42633\n(3.0)\n\n\n\n\n\n\nFAL58500_94244ffd NanoPlot read density plot\n\n\n\n\n\nC.bairdi-20102558-2729_Run-02 (FAL58500_04bb4d86)\nOutput folder:\n\n20200914_cbai_nanoplot_nanopore-data/ont_FAL58500_04bb4d86_20102558-2729/\n\nFull report (HTML):\n\n20200914_cbai_nanoplot_nanopore-data/ont_FAL58500_04bb4d86_20102558-2729/NanoPlot-report.html\n\n\n\n\nGENERAL SUMMARY\n\n\n\n\n\nActive channels\n424.0\n\n\nMean read length\n845.5\n\n\nMean read quality\n8.7\n\n\nMedian read length\n521.0\n\n\nMedian read quality\n9.3\n\n\nNumber of reads\n21,519.0\n\n\nRead length N50\n1,406.0\n\n\nTotal bases\n18,195,027.0\n\n\n\nNumber, percentage and megabases of reads above quality cutoffs:\n\n\n\nQuality_cutoff\nreads(count)\npercentage\nbases(count)\n\n\n\n\n>Q5\n17207\n(80.0%)\n15.4Mb\n\n\n>Q7\n14864\n(69.1%)\n13.9Mb\n\n\n>Q10\n8797\n(40.9%)\n8.9Mb\n\n\n>Q12\n3257\n(15.1%)\n3.6Mb\n\n\n>Q15\n121\n(0.6%)\n0.1Mb\n\n\n\nTop 5 highest mean basecall quality scores and their read lengths:\n\n\n\nRank\nmean_quality\nread_length(bp)\n\n\n\n\n1\n18.3\n(323)\n\n\n2\n17.8\n(1064)\n\n\n3\n17.4\n(201)\n\n\n4\n17.3\n(761)\n\n\n5\n16.9\n(642)\n\n\n\nTop 5 longest reads and their mean basecall quality score:\n\n\n\nRank\nread_length(bp)\nmean_quality_score\n\n\n\n\n1\n31170\n(3.4)\n\n\n2\n28158\n(3.2)\n\n\n3\n27016\n(3.3)\n\n\n4\n24304\n(3.6)\n\n\n5\n15552\n(2.9)\n\n\n\n\n\n\nFAL58500_04bb4d86 NanoPlot read density plot\n\n\n\n\n\n\nC.bairdi-6129_403_26 (FAL86873_d8db260e)\nOutput folder:\n\n20200914_cbai_nanoplot_nanopore-data/ont_FAL86873_d8db260e_cbai_6129_403_26/\n\nFull report (HTML):\n\n20200914_cbai_nanoplot_nanopore-data/ont_FAL86873_d8db260e_cbai_6129_403_26/NanoPlot-report.html\n\n\n\n\nGENERAL SUMMARY\n\n\n\n\n\nActive channels\n503\n\n\nMean read length\n2254.5\n\n\nMean read quality\n10.9\n\n\nMedian read length\n965\n\n\nMedian read quality\n11.2\n\n\nNumber of reads\n506495\n\n\nRead length N50\n5232\n\n\nTotal bases\n1141890358\n\n\n\nNumber, percentage and megabases of reads above quality cutoffs:\n\n\n\nQuality_cutoff\nreads(count)\npercentage\nbases(count)\n\n\n\n\n>Q5\n493598\n(97.5%)\n1124.9Mb\n\n\n>Q7\n465033\n(91.8%)\n1075.5Mb\n\n\n>Q10\n343296\n(67.8%)\n880.9Mb\n\n\n>Q12\n186709\n(36.9%)\n568.7Mb\n\n\n>Q15\n7394\n(1.5%)\n17.9Mb\n\n\n\nTop 5 highest mean basecall quality scores and their read lengths:\n\n\n\nRank\nmean_quality\nread_length(bp)\n\n\n\n\n1\n20.6\n(980)\n\n\n2\n20.2\n(1228)\n\n\n3\n19.7\n(902)\n\n\n4\n19.6\n(466)\n\n\n5\n19.6\n(757)\n\n\n\nTop 5 longest reads and their mean basecall quality score:\n\n\n\nRank\nread_length(bp)\nmean_quality_score\n\n\n\n\n1\n58854\n(11.8)\n\n\n2\n57315\n(10.8)\n\n\n3\n51351\n(11.5)\n\n\n4\n51326\n(13.7)\n\n\n5\n49825\n(12.9)\n\n\n\n\n\n\nFAL86873_d8db260e NanoPlot read density plot\n\n\n\nFirst, we should compare the two C.bairdi-20102558-2729 runs (degraded input DNA, no Hematodinium infection), as these were the same sample, run on the same flowcell.\nBasically, the second run on the flowcell performs worse in every metric: fewer reads, lower quality scores, shorter read lengths, etc. This is despite the fact that this flowcell was run for nearly 4.5x longer period of time (72hrs vs. 16hrs). This isn’t terribly surprising, as the second run started with only 414 available pores, which is well below the ONT-suggested minimum of 800 pores for a “good” flowcell, but it is interesting to see the actual impacts on sequencing that this has.\nThe C.bairdi-6129_403_26 run (high quality input DNA, with Hematodinium infection) is a better example of what to expect when using non-degraded DNA. Every metric is substantially better than the C.bairdi-20102558-2729 runs.\nNow, how to proceed? First, I think I’ll just get an assembly made, utilizing all three sets of data, despite the presence of Hematodinium in the C.bairdi-6129_403_26 run. I’ll tackle the assembly using Flye, as it seems straightforward, is specifically designed for long read assembly, and has built-in assembly “polishing”. This will be a start.\nIn regards to teasing out Hematodinium sequences, I’ll probably go through the DIAMOND BLASTx -> MEGAN6 process that I’ve used throughout our C.baird RNAseq project for transcriptome assemblies. MEGAN6 can handle long reads and makes taxonomic read extraction straightforward."
  },
  {
    "objectID": "posts/2020/2020-05-18-Transcriptome-Assembly---C.bairdi-All-Arthropoda-specific-RNAseq-Data-with-Trinity-on-Mox/index.html",
    "href": "posts/2020/2020-05-18-Transcriptome-Assembly---C.bairdi-All-Arthropoda-specific-RNAseq-Data-with-Trinity-on-Mox/index.html",
    "title": "Transcriptome Assembly - C.bairdi All Arthropoda-specific RNAseq Data with Trinity on Mox",
    "section": "",
    "text": "I realized I hadn’t performed taxonomic read separation from one set of RNAseq data we had. And, since I was on a transcriptome assembly kick, I figured I’d generate another C.bairdi transcriptome that included only Arthropoda-specific sequence data from all of our RNAseq.\nshorthand: 2018, 2019, GW-2020, UW-2020\nIt’s quick and doesn’t require much effort, so why not?\nSBATCH script (GitHub):\n\n20200518_cbai_trinity_all_Arthropoda_RNAseq.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=trinity_cbai\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=9-00:00:00\n## Memory per node\n#SBATCH --mem=500G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200518_cbai_trinity_all_Arthropoda_RNAseq\n\n### De novo transcriptome assembly of all Arthropoda-specific reads\n### Includes \"descriptor_1\" short-hand of: 2020-GW, 2020-UW, 2019, 2018.\n### See fastq.list.txt file for list of input files used for assembly.\n\n# Exit script if a command fails\nset -e\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# User-defined variables\nreads_dir=/gscratch/srlab/sam/data/C_bairdi/RNAseq\ntranscriptome_dir=/gscratch/srlab/sam/data/C_bairdi/transcriptomes\nthreads=28\nassembly_stats=assembly_stats.txt\nfasta_name=\"cbai_transcriptome_v1.6.fasta\"\n\n# Paths to programs\ntrinity_dir=\"/gscratch/srlab/programs/trinityrnaseq-v2.9.0\"\nsamtools=\"/gscratch/srlab/programs/samtools-1.10/samtools\"\n\n\n## Inititalize arrays\nR1_array=()\nR2_array=()\n\n# Variables for R1/R2 lists\nR1_list=\"\"\nR2_list=\"\"\n\n# Create array of fastq R1 files\nR1_array=(\"${reads_dir}\"/*megan_R1*.fq)\n\n# Create array of fastq R2 files\nR2_array=(\"${reads_dir}\"/*megan_R2*.fq)\n\n# Create list of fastq files used in analysis\n## Uses parameter substitution to strip leading path from filename\nfor fastq in \"${!R1_array[@]}\"\ndo\n  {\n    echo \"${R1_array[${fastq}]##*/}\"\n    echo \"${R2_array[${fastq}]##*/}\"\n  } >> fastq.list.txt\ndone\n\n# Create comma-separated lists of FastQ reads\nR1_list=$(echo \"${R1_array[@]}\" | tr \" \" \",\")\nR2_list=$(echo \"${R2_array[@]}\" | tr \" \" \",\")\n\n\n# Run Trinity\n## Not running as \"stranded\", due to mix of library types\n${trinity_dir}/Trinity \\\n--seqType fq \\\n--max_memory 500G \\\n--CPU ${threads} \\\n--left \"${R1_list}\" \\\n--right \"${R2_list}\"\n\n# Rename generic assembly FastA\nmv trinity_out_dir/Trinity.fasta trinity_out_dir/\"${fasta_name}\"\n\n# Assembly stats\n${trinity_dir}/util/TrinityStats.pl trinity_out_dir/\"${fasta_name}\" \\\n> ${assembly_stats}\n\n# Create gene map files\n${trinity_dir}/util/support_scripts/get_Trinity_gene_to_trans_map.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n> trinity_out_dir/\"${fasta_name}\".gene_trans_map\n\n# Create sequence lengths file (used for differential gene expression)\n${trinity_dir}/util/misc/fasta_seq_length.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n> trinity_out_dir/\"${fasta_name}\".seq_lens\n\n# Create FastA index\n${samtools} faidx \\\ntrinity_out_dir/\"${fasta_name}\"\n\n# Copy files to transcriptome directory\nrsync -av \\\ntrinity_out_dir/\"${fasta_name}\"* \\\n${transcriptome_dir}\n\n# Generate FastA MD5 checksum\n# See last line of SLURM output file\ncd trinity_out_dir\nmd5sum trinity_out_dir/\"${fasta_name}\"\n\n\nRESULTS\nPretty quick; only ~2.5hrs (NOTE: Job indicates it failed. This is due to wrong path for md5sum command on last line of script. Trinity de novo assembly completed without issue.):\n\n\n\nTrinity all Arthropoda-specific RNAseq runtime\n\n\nOutput folder:\n\n20200518_cbai_trinity_all_Arthropoda_RNAseq/\n\nInput FastQ list (text):\n\nfastq.list.txt\n\nFastA (36MB):\n\ncbai_transcriptome_v1.6.fasta\n\nMD5 = 46d77ce86cdbbcac26bf1a6cb820651e\n\n\nFastA Index (text):\n\ncbai_transcriptome_v1.6.fasta.fai\n\nThe following sets of files are useful for downstream gene expression and annotation using Trinity.\nTrinity FastA Gene Trans Map (text):\n\ncbai_transcriptome_v1.6.fasta.gene_trans_map\n\nTrinity FastA Sequence Lengths (text):\n\ncbai_transcriptome_v1.6.fasta.seq_lens\n\nAssembly stats (text):\n\n20200518_cbai_trinity_all_Arthropoda_RNAseq/assembly_stats.txt\n\n################################\n## Counts of transcripts, etc.\n################################\nTotal trinity 'genes':  23199\nTotal trinity transcripts:  40130\nPercent GC: 53.22\n\n########################################\nStats based on ALL transcript contigs:\n########################################\n\n    Contig N10: 3643\n    Contig N20: 2619\n    Contig N30: 2077\n    Contig N40: 1716\n    Contig N50: 1419\n\n    Median contig length: 557\n    Average contig: 895.83\n    Total assembled bases: 35949841\n\n\n#####################################################\n## Stats based on ONLY LONGEST ISOFORM per 'GENE':\n#####################################################\n\n    Contig N10: 3401\n    Contig N20: 2491\n    Contig N30: 1978\n    Contig N40: 1634\n    Contig N50: 1333\n\n    Median contig length: 438\n    Average contig: 795.21\n    Total assembled bases: 18448144"
  },
  {
    "objectID": "posts/2020/2020-10-02-Comparison---C.bairdi-20102558-2729-vs.-6129-403-26-NanoPore-Taxonomic-Assignments-Using-MEGAN6/index.html",
    "href": "posts/2020/2020-10-02-Comparison---C.bairdi-20102558-2729-vs.-6129-403-26-NanoPore-Taxonomic-Assignments-Using-MEGAN6/index.html",
    "title": "Comparison - C.bairdi 20102558-2729 vs. 6129-403-26 NanoPore Taxonomic Assignments Using MEGAN6",
    "section": "",
    "text": "After noticing that the initial MEGAN6 taxonomic assignments for our combined C.bairdi NanoPore data from 20200917 revealed a high number of bases assigned to E.canceri and Aquifex sp., I decided to explore the taxonomic breakdown of just the individual samples to see which of the samples was contributing to these taxonomic assignments most.\n\n20102558-2729-Q7 on 20200928: uninfected muscle\n6129-403-26-Q7 on 20200928: Hematodinium-infected hemolymph\n\nAfter completing the individual taxonomic assignments, I compared the two sets of assignments using MEGAN6 and generated this bar plot showing percentage of normalized base counts assigned to the following groups within each sample:\n\nAquifex sp.\nArthropoda\nE.canceri\nSAR (Supergroup within which Alveolata/Hematodinium sp. falls)\n\n\nIMPORTANT!!!\n\nThe taxonomic makeup shown in these comparisons is only a comparison of bases assigned amongst the four taxa selected above. It is not a comparison of the full taxonomic makeup of the two samples. I will discuss the data shown here in that context.\n\n\n\n\n20201002_cbai_nanopore_20102558-2729-Q7-vs-6129-403-26-Q7_megan-taxonomic-comparison-bar-plot\n\n\nComparison table:\n\n\n\n\n\n\n\n\n\n\nTaxa\n20102558-2729-Q7_base-counts\n20102558-2729-Q7_base-counts(%)\n6129-403-26-Q7_base-counts\n6129-403-26-Q7_base-counts(%)\n\n\n\n\nAquifex sp.\n221,823.00\n10.25\n199,287.06\n10.43\n\n\nArthropoda\n1,046,619.00\n48.38\n1,134,731.00\n59.40\n\n\nEnterospora canceri\n889,082.00\n41.10\n561,754.19\n29.41\n\n\nSar\n5,855.00\n0.27\n14,582.56\n0.76\n\n\nTOTAL\n2,163,379.00\n\n1,910,354.81\n\n\n\n\nSome observations:\n\nAquifex sp. account for nearly the same percentage of assignments in both samples.\nArthropoda makes up ~50% of assigned bases in the uninfected muscle sample (20102558-2729), but ~60% in the Hematodinium-infected hemolymph sample. (6129-403-26).\nE.canceri makes up ~41% of assigned bases in the uninfected muscle sample (20102558-2729), but only ~30% in the Hematodinium-infected hemolymph sample.\nSAR contributes a very small percentage to each of the two samples, but has ~2.8x the number of assigned bases. Additionally, as noted in the taxonomic assignment analysis of 20102558-2729-Q7 on 20200928, no bases are assigned to descendants of this Supergroup, whereas in the taxonomic analysis of 6129-403-26-Q7 on 20200928, there are bases assigned within the descendants of this Supergroup, down the level of Hematodinium sp. Genus.\n\nPretty interesting stuff!\nI also briefly looked at the taxonomic assignments from all of our hemolymph RNAseq samples to see if if Aquifex sp. and/or E.canceri appear:\n\n20200114\n202020330\n20200419\n\nInterestingly, a high number of reads are assigned to E.canceri in all samples, but no reads are assigned to Aquifex sp.. Another observation is that a fair number of reads get assigned to Vibrio parahemolyticus, but very few number of NanoPore DNA bases get assigned to V.parahemolyticus.\nNext up I think I might try to identify which contigs/scaffolds from the cbai_genome_v1.0 Flye assembly correspond to these taxa. The approach would be to create a BLAST database (DB) from the cbai_genome_v1.0.fasta (19MB). Then extract the NanoPore reads assigned to each of the taxa above, then BLAST them against the cbai_genome_v1.0 BLAST DB."
  },
  {
    "objectID": "posts/2020/2020-03-18-TrimmingQCMultiQC---C.bairdi-RNAseq-FastQ-with-fastp-on-Mox/index.html",
    "href": "posts/2020/2020-03-18-TrimmingQCMultiQC---C.bairdi-RNAseq-FastQ-with-fastp-on-Mox/index.html",
    "title": "Trimming/FastQC/MultiQC - C.bairdi RNAseq FastQ with fastp on Mox",
    "section": "",
    "text": "After receiving our RNAseq data from Genewiz earlier today, needed to run FastQC, trim, check trimmed reads with FastQC.\nFastQC on raw reads was run locally and files were kept on owl/nightingales/C_bairdi.\nfastp trimming was run on Mox, followed by MultiQC.\nFastQC on trimmed reads were run locally, followed by MultiQC.\nSBATCH script (GitHub):\n\n20200318_cbai_RNAseq_fastp_trimming.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_fastp_trimming_RNAseq\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200318_cbai_RNAseq_fastp_trimming\n\n\n### C.bairdi RNAseq trimming using fastp.\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# Set number of CPUs to use\nthreads=27\n\n# Input/output files\ntrimmed_checksums=trimmed_fastq_checksums.md5\nraw_reads_dir=/gscratch/scrubbed/samwhite/data/C_bairdi/RNAseq/\n\n# Paths to programs\nfastp=/gscratch/srlab/programs/fastp-0.20.0/fastp\nmultiqc=/gscratch/srlab/programs/anaconda3/bin/multiqc\n\n## Inititalize arrays\nfastq_array_R1=()\nfastq_array_R2=()\nprograms_array=()\nR1_names_array=()\nR2_names_array=()\n\n# Programs array\nprograms_array=(\"${fastp}\" \"${multiqc}\")\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${programs_array[program]}: \"\n    echo \"\"\n    ${programs_array[program]} -h\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n# Sync raw FastQ files to working directory\nrsync --archive --verbose \\\n\"${raw_reads_dir}\"*.gz .\n\n# Create array of fastq R1 files\nfor fastq in *R1*.gz\ndo\n  fastq_array_R1+=(\"${fastq}\")\ndone\n\n# Create array of fastq R2 files\nfor fastq in *R2*.gz\ndo\n  fastq_array_R2+=(\"${fastq}\")\ndone\n\n\n# Create array of sample names\n## Uses awk to parse out sample name from filename\nfor R1_fastq in *R1*.gz\ndo\n  R1_names_array+=($(echo \"${R1_fastq}\" | awk -F\".\" '{print $1}'))\ndone\n\n# Create array of sample names\n## Uses awk to parse out sample name from filename\nfor R2_fastq in *R2*.gz\ndo\n  R2_names_array+=($(echo \"${R2_fastq}\" | awk -F\".\" '{print $1}'))\ndone\n\n# Create list of fastq files used in analysis\nfor fastq in *.gz\ndo\n  echo \"${fastq}\" >> fastq.list.txt\ndone\n\n# Run fastp on files\nfor index in \"${!fastq_array_R1[@]}\"\ndo\n    timestamp=$(date +%Y%m%d%M%S)\n  R1_sample_name=$(echo \"${R1_names_array[index]}\")\n    R2_sample_name=$(echo \"${R2_names_array[index]}\")\n    ${fastp} \\\n    --in1 \"${fastq_array_R1[index]}\" \\\n    --in2 \"${fastq_array_R2[index]}\" \\\n    --detect_adapter_for_pe \\\n    --thread ${threads} \\\n    --html \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".report.html \\\n    --json \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".report.json \\\n    --out1 \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz \\\n    --out2 \"${R2_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz\n\n    # Generate md5 checksums for newly trimmed files\n    {\n        md5sum \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz\n        md5sum \"${R2_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz\n    } >> \"${trimmed_checksums}\"\n    # Remove original FastQ files\n    rm \"${fastq_array_R1[index]}\" \"${fastq_array_R2[index]}\"\ndone\n\n# Run MultiQC\n${multiqc} .\n\n\nRESULTS\nRun time was just under three hours:\n\n\n\nfastp runtime screencap\n\n\nNOTE: Although the job indicates “FAILED”, this was simply due to a MultiQC failing (path to MultiQC was incorrect). Trimming proceeded/completed properly.\nOutput folder:\n\n20200318_cbai_RNAseq_fastp_trimming/\n\nfastp MultiQC report (HTML):\n\n20200318_cbai_RNAseq_fastp_trimming/multiqc_report.html\n\nIndividual fastp reports are also available (HTML). An example is below.\nhttps://gannet.fish.washington.edu/Atumefaciens/20200318_cbai_RNAseq_fastp_trimming/485_R1_001.fastp-trim.202003181245_fastqc.html\nFastQC MultiQC report (HTML):\n\n20200318_cbai_RNAseq_fastp_trimming/multiqc_report_1.html\n\nSome of the samples are potentially problematic, based on FastQC plots (see end of post). Despite the weirdness, I think I’m going to leave things as they are and try to filter these reads out downstream. Downstream stuff entails:\n\nBLASTx\ntaxonomic read assignment using MEGAN6\n\nI feel like crappy reads will get filtered out based on BLAST results and subsequent taxonomic assignment, since we’ll only be using Arthropoda and Alveolata reads.\n\n\nSAMPLE 73\n\n\n\n73 Read1 FastQC\n\n\n\n\n\n73 Read2 FastQC\n\n\n\n\n\nSAMPLE 113\n\n\n\n113 Read1 FastQC\n\n\n\n\n\n113 Read2 FastQC\n\n\n\n\n\nSAMPLE 118\n\n\n\n118 Read1 FastQC\n\n\n\n\n\n118 Read2 FastQC\n\n\n\n\n\nSAMPLE 127\n\n\n\n127 Read1 FastQC\n\n\n\n\n\n127 Read2 FastQC\n\n\n\n\n\nSAMPLE 222\n\n\n\n222 Read1 FastQC\n\n\n\n\n\n222 Read2 FastQC\n\n\n\n\n\nSAMPLE 272\n\n\n\n272 Read1 FastQC\n\n\n\n\n\n272 Read2 FastQC\n\n\n\n\n\nSAMPLE 280\n\n\n\n280 Read1 FastQC\n\n\n\n\n\n280 Read2 FastQC\n\n\n\n\n\nSAMPLE 425\n\n\n\n425 Read1 FastQC\n\n\n\n\n\n425 Read2 FastQC\n\n\n\n\n\nSAMPLE 427\n\n\n\n427 Read1 FastQC\n\n\n\n\n\n427 Read2 FastQC\n\n\n\n\n\nSAMPLE 445\n\n\n\n445 Read1 FastQC\n\n\n\n\n\n445 Read2 FastQC\n\n\n\n\n\nSAMPLE 463\n\n\n\n463 Read1 FastQC\n\n\n\n\n\n463 Read2 FastQC\n\n\n\n\n\nSAMPLE 481\n\n\n\n481 Read1 FastQC\n\n\n\n\n\n481 Read2 FastQC"
  },
  {
    "objectID": "posts/2020/2020-02-10-DNA-Isolation-and-Quantification---Additional-C.bairdi-gDNA-from-Sample-6129_403_26/index.html",
    "href": "posts/2020/2020-02-10-DNA-Isolation-and-Quantification---Additional-C.bairdi-gDNA-from-Sample-6129_403_26/index.html",
    "title": "DNA Isolation & Quantification - Additional C.bairdi gDNA from Sample 6129_403_26",
    "section": "",
    "text": "Earlier today I isolated gDNA from C.bairi 6129_403_26 hemolymph pellets and recovered decently intact gDNA that could be used for sequencing. However, I still need more gDNA, so will isolate that (and co-isolate RNA, since I’m going through the procedure anyway) using the rest of the sample using the Quick DNA/RNA Microprep Plus Kit (ZymoResearch).\nFollowed the manufacturer’s protocol with the following notes/changes:\n\nUsed 480uL of sample, combined with 1:1 H2O (480uL), with 4:1 Lysis Buffer (3840uL) and mixed in 15mL conical\nFlow-through was retained in a 15mL concial for RNA isolation\nEluted with 45uL\n\nI combined this isolation with the isolation from earlier today. I have updated that post to reflect this.\nQuantified on the Roberts Lab Qubit 3.0 using the dsDNA BR Assay (Invitrogen) and 2uL of sample.\n\n\nRESULTS\nQubit results (Google Sheet):\n\n20200210_qubit_crab_gDNA-02\n\n[DNA] = 40.7ng/uL in ~70uL\nYield = ~2849ng\nSample was stored at -80oC in:\nRack 15, 4, 5 in C.bairdi gDNA Box #2\nThis is still too low for PacBio sequencing. The UW facility suggests 5-8ug for 50X coverage of a 2Gbp genome (which is a rough guesstimate of the Tanner crab genome size) for a decent genome assembly. Maybe I can just send them 2000ng and see what we get out of it? Or, maybe I’ll just isolate DNA from some other individuals and pool them. Will discuss with Steven and see how he feels about this."
  },
  {
    "objectID": "posts/2020/2020-08-31-Transcriptome-Annotation---Trinotate-C.bairdi-v2.1-on-Mox/index.html",
    "href": "posts/2020/2020-08-31-Transcriptome-Annotation---Trinotate-C.bairdi-v2.1-on-Mox/index.html",
    "title": "Transcriptome Annotation - Trinotate C.bairdi v2.1 on Mox",
    "section": "",
    "text": "To continue annotation of our C.bairdi v2.1 transcriptome assembly], I wanted to run Trinotate.\nInfo for each transcriptome version (library composition, assembly dates, BUSCO, etc) can be found in this table:\n\ncbai_transcriptome_comp\n\nThis was run on Mox.\nSBATCH script (GitHub):\n\n20200831_cbai_trinotate_transcriptome-v2.1.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_trinotate_transcriptome-v2.1\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=3-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200831_cbai_trinotate_transcriptome-v2.1\n\n\n# Script to run Trinotate on C.bairdi transcriptome:\n# v2.1\n\n###################################################################################\n# These variables need to be set by user\n\n# Input files\n## BLASTx\nblastx_out=\"/gscratch/scrubbed/samwhite/outputs/20200608_cbai_diamond_blastx_v2.1_v2.1/cbai_transcriptome_v2.1.blastx.outfmt6\"\n\n## TransDecoder\ntransdecoder_dir=\"/gscratch/scrubbed/samwhite/outputs/20200826_cbai_transdecoder_transcriptomes_v2.1_v.3.1/20200826_cbai_transcriptome_v2.1.fasta.transdecoder\"\nblastp_out=\"${transdecoder_dir}/20200826_cbai_transcriptome_v2.1.fasta.blastp_out/20200826_cbai_transcriptome_v2.1.fasta.blastp.outfmt6\"\npfam_out=\"${transdecoder_dir}/20200826_cbai_transcriptome_v2.1.fasta.pfam_out/20200826_cbai_transcriptome_v2.1.fasta.pfam.domtblout\"\nlORFs_pep=\"${transdecoder_dir}/cbai_transcriptome_v2.1.fasta.transdecoder_dir/longest_orfs.pep\"\n\n## Transcriptomics\ntranscriptomes_dir=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes\"\ntrinity_fasta=\"${transcriptomes_dir}/cbai_transcriptome_v2.1.fasta\"\ntrinity_gene_map=\"${transcriptomes_dir}/cbai_transcriptome_v2.1.fasta.gene_trans_map\"\n\n###################################################################################\n\nwd=\"$(pwd)\"\ntimestamp=$(date +%Y%m%d)\n\n\n## Paths to input/output files\n\n## New folders for working directory\nrnammer_out_dir=\"${wd}/RNAmmer_out\"\nsignalp_out_dir=\"${wd}/signalp_out\"\ntmhmm_out_dir=\"${wd}/tmhmm_out\"\n\n\nrnammer_prefix=${trinity_fasta##*/}\nprefix=\"${timestamp}.${rnammer_prefix}.trinotate\"\n\n# Output files\nrnammer_out=\"${rnammer_out_dir}/${rnammer_prefix}.rnammer.gff\"\nsignalp_out=\"${signalp_out_dir}/${prefix}.signalp.out\"\ntmhmm_out=\"${tmhmm_out_dir}/${prefix}.tmhmm.out\"\ntrinotate_report=\"${wd}/${prefix}_annotation_report.txt\"\n\n# Paths to programs\nrnammer_dir=\"/gscratch/srlab/programs/RNAMMER-1.2\"\nrnammer=\"${rnammer_dir}/rnammer\"\nsignalp_dir=\"/gscratch/srlab/programs/signalp-4.1\"\nsignalp=\"${signalp_dir}/signalp\"\ntmhmm_dir=\"/gscratch/srlab/programs/tmhmm-2.0c/bin\"\ntmhmm=\"${tmhmm_dir}/tmhmm\"\ntrinotate_dir=\"/gscratch/srlab/programs/Trinotate-v2.1.1\"\ntrinotate=\"${trinotate_dir}/Trinotate\"\ntrinotate_rnammer=\"${trinotate_dir}/util/rnammer_support/RnammerTranscriptome.pl\"\ntrinotate_GO=\"${trinotate_dir}/util/extract_GO_assignments_from_Trinotate_xls.pl\"\ntrinotate_features=\"${trinotate_dir}/util/Trinotate_get_feature_name_encoding_attributes.pl\"\ntrinotate_sqlite_db=\"Trinotate.sqlite\"\n\n# Generate FastA checksum, for reference if needed.\nmd5sum ${trinity_fasta} > fasta.checksum.md5\n\n# Make output directories\nmkdir \"${rnammer_out_dir}\" \"${signalp_out_dir}\" \"${tmhmm_out_dir}\"\n\n# Copy sqlite database template\n\ncp ${trinotate_dir}/admin/Trinotate.sqlite .\n\n# Run signalp\n${signalp} \\\n-f short \\\n-n \"${signalp_out}\" \\\n${lORFs_pep}\n\n# Run tmHMM\n${tmhmm} \\\n--short \\\n< ${lORFs_pep} \\\n> \"${tmhmm_out}\"\n\n# Run RNAmmer\ncd \"${rnammer_out_dir}\" || exit\n${trinotate_rnammer} \\\n--transcriptome ${trinity_fasta} \\\n--path_to_rnammer ${rnammer}\ncd \"${wd}\" || exit\n\n# Run Trinotate\n## Load transcripts and coding regions into database\n${trinotate} \\\n${trinotate_sqlite_db} \\\ninit \\\n--gene_trans_map \"${trinity_gene_map}\" \\\n--transcript_fasta \"${trinity_fasta}\" \\\n--transdecoder_pep \"${lORFs_pep}\"\n\n## Load BLAST homologies\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_swissprot_blastp \\\n\"${blastp_out}\"\n\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_swissprot_blastx \\\n\"${blastx_out}\"\n\n## Load Pfam\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_pfam \\\n\"${pfam_out}\"\n\n## Load transmembrane domains\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_tmhmm \\\n\"${tmhmm_out}\"\n\n## Load signal peptides\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_signalp \\\n\"${signalp_out}\"\n\n## Load RNAmmer\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_rnammer \\\n\"${rnammer_out}\"\n\n## Creat annotation report\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nreport \\\n> \"${trinotate_report}\"\n\n# Extract GO terms from annotation report\n\"${trinotate_GO}\" \\\n--Trinotate_xls \"${trinotate_report}\" \\\n-G \\\n--include_ancestral_terms \\\n> \"${prefix}\".go_annotations.txt\n\n# Make transcript features annotation map\n\"${trinotate_features}\" \\\n\"${trinotate_report}\" \\\n> \"${prefix}\".annotation_feature_map.txt\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nRESULTS\nRuntime was surprisingly long; ~6hrs:\n\n\n\ncbai v2.1 Trinotate runtime\n\n\nOutput folder:\n\n20200831_cbai_trinotate_transcriptome-v2.1\n\nAnnotation feature map (20MB; text):\n\n20200831.cbai_transcriptome_v2.1.fasta.trinotate.annotation_feature_map.txt\n\nThis can be used to update Trinity-based gene expression matrices like so:\n\n${TRINITY_HOME}/Analysis/DifferentialExpression/rename_matrix_feature_identifiers.pl Trinity_trans.counts.matrix annot_feature_map.txt > Trinity_trans.counts.wAnnot.matrix\n\n\n\nAnnotation report (190MB; CSV)\n\n20200831.cbai_transcriptome_v2.1.fasta.trinotate_annotation_report.txt\n\nGene ontology (GO) annotations (37MB; text)\n\n20200831.cbai_transcriptome_v2.1.fasta.trinotate.go_annotations.txt\n\nSQlite database (1.1GB; SQLITE):\n\nTrinotate.sqlite"
  },
  {
    "objectID": "posts/2020/2020-05-27-Transcriptome-Assessment---BUSCO-Metazoa-on-C.bairdi-Transcriptome-v1.7/index.html",
    "href": "posts/2020/2020-05-27-Transcriptome-Assessment---BUSCO-Metazoa-on-C.bairdi-Transcriptome-v1.7/index.html",
    "title": "Transcriptome Assessment - BUSCO Metazoa on C.bairdi Transcriptome v1.7",
    "section": "",
    "text": "I previously created a C.bairdi de novo transcriptome assembly v1.7 with Trinity from all our C.bairdi taxonomically filtered pooled RNAseq samples on 20200527 and decided to assess its “completeness” using BUSCO and the metazoa_odb9 database.\nBUSCO was run with the --mode transcriptome option on Mox.\nSBATCH script (GitHub):\n\n20200527_cbai_busco_transcriptome_v1.7.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_busco_v1.7_transcriptome\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=5-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200527_cbai_busco_transcriptome_v1.7\n\n### C.bairdi transcriptome assembly completeness assessment using BUSCO.\n### This is checking cbai_transcriptome_v1.7.fasta\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Load Open MPI module for parallel, multi-node processing\nmodule load icc_19-ompi_3.1.2\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\n## Input files and settings\nbusco_db=/gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9\ntranscriptome_fasta=/gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v1.7.fasta\naugustus_species=fly\nthreads=28\n\n## Save working directory\nwd=$(pwd)\n\n# Extract FastA filename\nfasta_name=${transcriptome_fasta##*/}\n\n## Set program paths\naugustus_bin=/gscratch/srlab/programs/Augustus-3.3.2/bin\naugustus_scripts=/gscratch/srlab/programs/Augustus-3.3.2/scripts\nblast_dir=/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin/\nbusco=/gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py\nhmm_dir=/gscratch/srlab/programs/hmmer-3.2.1/src/\n\n## Augustus configs\naugustus_dir=${wd}/augustus\naugustus_config_dir=${augustus_dir}/config\naugustus_orig_config_dir=/gscratch/srlab/programs/Augustus-3.3.2/config\n\n## BUSCO configs\nbusco_config_default=/gscratch/srlab/programs/busco-v3/config/config.ini.default\nbusco_config_ini=${wd}/config.ini\n\n# Export BUSCO config file location\nexport BUSCO_CONFIG_FILE=\"${busco_config_ini}\"\n\n# Export Augustus variable\nexport PATH=\"${augustus_bin}:$PATH\"\nexport PATH=\"${augustus_scripts}:$PATH\"\nexport AUGUSTUS_CONFIG_PATH=\"${augustus_config_dir}\"\n\n\n# Copy BUSCO config file\ncp ${busco_config_default} \"${busco_config_ini}\"\n\n# Make Augustus directory if it doesn't exist\nif [ ! -d \"${augustus_dir}\" ]; then\n  mkdir --parents \"${augustus_dir}\"\nfi\n\n# Copy Augustus config directory\ncp --preserve -r ${augustus_orig_config_dir} \"${augustus_dir}\"\n\n# Edit BUSCO config file\n## Set paths to various programs\n### The use of the % symbol sets the delimiter sed uses for arguments.\n### Normally, the delimiter that most examples use is a slash \"/\".\n### But, we need to expand the variables into a full path with slashes, which screws up sed.\n### Thus, the use of % symbol instead (it could be any character that is NOT present in the expanded variable; doesn't have to be \"%\").\nsed -i \"/^;cpu/ s/1/${threads}/\" \"${busco_config_ini}\"\nsed -i \"/^tblastn_path/ s%tblastn_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^makeblastdb_path/ s%makeblastdb_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^augustus_path/ s%augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^etraining_path/ s%etraining_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^gff2gbSmallDNA_path/ s%gff2gbSmallDNA_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^new_species_path/ s%new_species_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^optimize_augustus_path/ s%optimize_augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^hmmsearch_path/ s%hmmsearch_path = /home/osboxes/BUSCOVM/hmmer/hmmer-3.1b2-linux-intel-ia32/binaries/%path = ${hmm_dir}%\" \"${busco_config_ini}\"\n\n\n# Run BUSCO/Augustus training\n${busco} \\\n--in ${transcriptome_fasta} \\\n--out ${fasta_name} \\\n--lineage_path ${busco_db} \\\n--mode transcriptome \\\n--cpu ${threads} \\\n--long \\\n--species ${augustus_species} \\\n--tarzip \\\n--augustus_parameters='--progress=true'\n\n\nRESULTS\nAs usual, super quick - 1m14s:\n\n\n\ncbai v1.7 busco runtime\n\n\nOutput folder:\n\n20200527_cbai_busco_transcriptome_v1.7\n\nShort summary (text):\n\n20200527_cbai_busco_transcriptome_v1.7/run_cbai_transcriptome_v1.7.fasta/short_summary_cbai_transcriptome_v1.7.fasta.txt\n\n# BUSCO version is: 3.0.2\n# The lineage dataset is: metazoa_odb9 (Creation date: 2016-02-13, number of species: 65, number of BUSCOs: 978)\n# To reproduce this run: python /gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py -i /gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v1.7.fasta -o cbai_transcriptome_v1.7.fasta -l /gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9/ -m transcriptome -c 28 --long -z\n#\n# Summarized benchmarking in BUSCO notation for file /gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v1.7.fasta\n# BUSCO was run in mode: transcriptome\n\n    C:86.7%[S:66.5%,D:20.2%],F:8.2%,M:5.1%,n:978\n\n    848 Complete BUSCOs (C)\n    650 Complete and single-copy BUSCOs (S)\n    198 Complete and duplicated BUSCOs (D)\n    80  Fragmented BUSCOs (F)\n    50  Missing BUSCOs (M)\n    978 Total BUSCO groups searched"
  },
  {
    "objectID": "posts/2020/2020-03-31-Transcriptome-Annotation---Hematodinium-MEGAN-Trinity-Assembly-Using-DIAMOND-BLASTx-on-Mox/index.html",
    "href": "posts/2020/2020-03-31-Transcriptome-Annotation---Hematodinium-MEGAN-Trinity-Assembly-Using-DIAMOND-BLASTx-on-Mox/index.html",
    "title": "Transcriptome Annotation - Hematodinium MEGAN Trinity Assembly Using DIAMOND BLASTx on Mox",
    "section": "",
    "text": "As part of annotating the most recent transcriptome assembly from the MEGAN6 Hematodinium taxonomic-specific reads, I need to run DIAMOND BLASTx to use with Trinotate.\nRan DIAMOND BLASTx against the UniProt/SwissProt database (downloaded 20200123) on Mox.\nSBATCH script (GitHub):\n\n20200331_hemat_diamond_blastx_megan.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=hemat_blastx_DIAMOND\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200331_hemat_diamond_blastx_megan\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\n# Program paths\ndiamond=/gscratch/srlab/programs/diamond-0.9.29/diamond\n\n# DIAMOND UniProt database\ndmnd=/gscratch/srlab/blastdbs/uniprot_sprot_20200123/uniprot_sprot.dmnd\n\n\n# Trinity assembly (FastA)\nfasta=/gscratch/srlab/sam/data/Hematodinium/transcriptomes/20200408.hemat.megan.Trinity.fasta\n\n# Strip leading path and extensions\nno_path=$(echo \"${fasta##*/}\")\nno_ext=$(echo \"${no_path%.*}\")\n\n# Run DIAMOND with blastx\n# Output format 6 produces a standard BLAST tab-delimited file\n${diamond} blastx \\\n--db ${dmnd} \\\n--query \"${fasta}\" \\\n--out \"${no_ext}\".blastx.outfmt6 \\\n--outfmt 6 \\\n--evalue 1e-4 \\\n--max-target-seqs 1 \\\n--block-size 15.0 \\\n--index-chunks 4\n\n\nRESULTS\nCompleted in 9 seconds!\n\n\n\nDIAMOND BLASTx runtime\n\n\nOutput folder:\n\n20200331_hemat_diamond_blastx_megan/\n\nBLASTx output - BLAST format 6 (tab):\n\n20200331_hemat_diamond_blastx_megan/20200408.hemat.megan.Trinity.fasta.blastx.outfmt6\n\nWill proceed with Trinotate."
  },
  {
    "objectID": "posts/2020/2020-04-07-Transcriptome-Assessment---BUSCO-Metazoa-on-C.bairdi-MEGAN-Transcriptome/index.html",
    "href": "posts/2020/2020-04-07-Transcriptome-Assessment---BUSCO-Metazoa-on-C.bairdi-MEGAN-Transcriptome/index.html",
    "title": "Transcriptome Assessment - BUSCO Metazoa on C.bairdi MEGAN Transcriptome",
    "section": "",
    "text": "I previously created a C.bairdi de novo transcriptome assembly with Trinity from the MEGAN6 taxonomic-specific reads for Arthropoda on 20200330 and decided to assess its “completeness” using BUSCO and the metazoa_odb9 database.\nBUSCO was run with the --mode transcriptome option on Mox.\nSBATCH script (GitHub):\n\n20200407_cbai_busco_megan.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_busco_megan_transcriptome\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=1-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200407_cbai_busco_megan\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Load Open MPI module for parallel, multi-node processing\nmodule load icc_19-ompi_3.1.2\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\n# Establish variables for more readable code\ntimestamp=$(date +%Y%m%d)\nspecies=\"cbai\"\nprefix=\"${timestamp}.${species}\"\n\n## Input files and settings\nbase_name=\"${prefix}.megan\"\nbusco_db=/gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9\ntranscriptome_fasta=/gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200406.C_bairdi.megan.Trinity.fasta\naugustus_species=fly\nthreads=28\n\n## Save working directory\nwd=$(pwd)\n\n## Set program paths\naugustus_bin=/gscratch/srlab/programs/Augustus-3.3.2/bin\naugustus_scripts=/gscratch/srlab/programs/Augustus-3.3.2/scripts\nblast_dir=/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin/\nbusco=/gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py\nhmm_dir=/gscratch/srlab/programs/hmmer-3.2.1/src/\n\n## Augustus configs\naugustus_dir=${wd}/augustus\naugustus_config_dir=${augustus_dir}/config\naugustus_orig_config_dir=/gscratch/srlab/programs/Augustus-3.3.2/config\n\n## BUSCO configs\nbusco_config_default=/gscratch/srlab/programs/busco-v3/config/config.ini.default\nbusco_config_ini=${wd}/config.ini\n\n# Export BUSCO config file location\nexport BUSCO_CONFIG_FILE=\"${busco_config_ini}\"\n\n# Export Augustus variable\nexport PATH=\"${augustus_bin}:$PATH\"\nexport PATH=\"${augustus_scripts}:$PATH\"\nexport AUGUSTUS_CONFIG_PATH=\"${augustus_config_dir}\"\n\n\n# Copy BUSCO config file\ncp ${busco_config_default} \"${busco_config_ini}\"\n\n# Make Augustus directory if it doesn't exist\nif [ ! -d \"${augustus_dir}\" ]; then\n  mkdir --parents \"${augustus_dir}\"\nfi\n\n# Copy Augustus config directory\ncp --preserve -r ${augustus_orig_config_dir} \"${augustus_dir}\"\n\n# Edit BUSCO config file\n## Set paths to various programs\n### The use of the % symbol sets the delimiter sed uses for arguments.\n### Normally, the delimiter that most examples use is a slash \"/\".\n### But, we need to expand the variables into a full path with slashes, which screws up sed.\n### Thus, the use of % symbol instead (it could be any character that is NOT present in the expanded variable; doesn't have to be \"%\").\nsed -i \"/^;cpu/ s/1/${threads}/\" \"${busco_config_ini}\"\nsed -i \"/^tblastn_path/ s%tblastn_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^makeblastdb_path/ s%makeblastdb_path = /usr/bin/%path = ${blast_dir}%\" \"${busco_config_ini}\"\nsed -i \"/^augustus_path/ s%augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^etraining_path/ s%etraining_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/bin/%path = ${augustus_bin}%\" \"${busco_config_ini}\"\nsed -i \"/^gff2gbSmallDNA_path/ s%gff2gbSmallDNA_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^new_species_path/ s%new_species_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^optimize_augustus_path/ s%optimize_augustus_path = /home/osboxes/BUSCOVM/augustus/augustus-3.2.2/scripts/%path = ${augustus_scripts}%\" \"${busco_config_ini}\"\nsed -i \"/^hmmsearch_path/ s%hmmsearch_path = /home/osboxes/BUSCOVM/hmmer/hmmer-3.1b2-linux-intel-ia32/binaries/%path = ${hmm_dir}%\" \"${busco_config_ini}\"\n\n\n# Run BUSCO/Augustus training\n${busco} \\\n--in ${transcriptome_fasta} \\\n--out ${base_name} \\\n--lineage_path ${busco_db} \\\n--mode transcriptome \\\n--cpu ${threads} \\\n--long \\\n--species ${augustus_species} \\\n--tarzip \\\n--augustus_parameters='--progress=true'\n\n\nRESULTS\nVery quick, 1.5 minutes:\n\n\n\nBUSCO runtime\n\n\nOutput folder:\n\n20200407_cbai_busco_megan/\n\nBUSCO short summary (text):\n\n20200407_cbai_busco_megan/run_20200408.cbai.megan/short_summary_20200408.cbai.megan.txt\n\n# BUSCO version is: 3.0.2\n# The lineage dataset is: metazoa_odb9 (Creation date: 2016-02-13, number of species: 65, number of BUSCOs: 978)\n# To reproduce this run: python /gscratch/srlab/programs/busco-v3/scripts/run_BUSCO.py -i /gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200406.C_bairdi.megan.Trinity.fasta -o 20200407.cbai.megan -l /gscratch/srlab/sam/data/databases/BUSCO/metazoa_odb9/ -m transcriptome -c 28 --long -z\n#\n# Summarized benchmarking in BUSCO notation for file /gscratch/srlab/sam/data/C_bairdi/transcriptomes/20200406.C_bairdi.megan.Trinity.fasta\n# BUSCO was run in mode: transcriptome\n\n    C:91.8%[S:64.0%,D:27.8%],F:5.9%,M:2.3%,n:978\n\n    898 Complete BUSCOs (C)\n    626 Complete and single-copy BUSCOs (S)\n    272 Complete and duplicated BUSCOs (D)\n    58  Fragmented BUSCOs (F)\n    22  Missing BUSCOs (M)\n    978 Total BUSCO groups searched\nIn terms of BUSCO scoring, this iteration of the transcriptome is “better” (i.e. more complete) than the previous transcriptome BUSCO analysis on 20200207: 91.8% vs 85.5% complete BUSCOs identified. However, this is increase is primarily due to an increase in duplicated BUSCOs (27.8% vs 20.8%)."
  },
  {
    "objectID": "posts/2020/2020-03-18-Data-Received---C.bairdi-RNAseq-Data-from-Genewiz/index.html",
    "href": "posts/2020/2020-03-18-Data-Received---C.bairdi-RNAseq-Data-from-Genewiz/index.html",
    "title": "Data Received - C.bairdi RNAseq Data from Genewiz",
    "section": "",
    "text": "We received the RNAseq data from the RNA that was sent out by Grace on 20200212.\nSequencing is 150bp PE.\nGrace has a Google Sheet that describes what the samples constitute (e.g. ambient/cold/warm, infected/uninfect, day, etc.)\n\n02122020-samples-sent-to-genewiz\n\nGenewiz report:\n\n\n\n\n\n\n\n\n\n\n\n\nProject\nSample ID\nBarcode Sequence\n# Reads\nYield (Mbases)\nMean Quality Score\n% Bases >= 30\n\n\n\n\n30-343338329\n72\nACTCGCTA+TCGACTAG\n27,249,335\n8,175\n34.16\n85.82\n\n\n30-343338329\n73\nACTCGCTA+TTCTAGCT\n25,856,008\n7,757\n33.87\n84.36\n\n\n30-343338329\n113\nACTCGCTA+CCTAGAGT\n31,638,462\n9,492\n32.38\n77.77\n\n\n30-343338329\n118\nACTCGCTA+GCGTAAGA\n29,253,455\n8,776\n33.50\n82.62\n\n\n30-343338329\n127\nACTCGCTA+CTATTAAG\n27,552,329\n8,266\n33.14\n81.13\n\n\n30-343338329\n132\nACTCGCTA+AAGGCTAT\n27,518,702\n8,256\n34.86\n88.87\n\n\n30-343338329\n151\nACTCGCTA+GAGCCTTA\n33,430,314\n10,029\n35.01\n89.35\n\n\n30-343338329\n173\nACTCGCTA+TTATGCGA\n33,262,459\n9,979\n34.45\n87.06\n\n\n30-343338329\n178\nGGAGCTAC+TCGACTAG\n29,495,389\n8,849\n35.01\n89.62\n\n\n30-343338329\n221\nGGAGCTAC+TTCTAGCT\n25,902,415\n7,771\n34.76\n88.40\n\n\n30-343338329\n222\nGGAGCTAC+CCTAGAGT\n53,808,137\n16,142\n30.90\n71.11\n\n\n30-343338329\n254\nGGAGCTAC+GCGTAAGA\n16,771,613\n5,031\n35.14\n90.03\n\n\n30-343338329\n272\nGGAGCTAC+CTATTAAG\n27,818,893\n8,346\n33.30\n81.70\n\n\n30-343338329\n280\nGGAGCTAC+AAGGCTAT\n61,008,799\n18,303\n30.85\n70.86\n\n\n30-343338329\n294\nGGAGCTAC+GAGCCTTA\n28,539,233\n8,562\n35.12\n90.04\n\n\n30-343338329\n334\nGGAGCTAC+TTATGCGA\n25,916,895\n7,775\n34.98\n89.39\n\n\n30-343338329\n349\nGCGTAGTA+TCGACTAG\n32,868,756\n9,861\n33.53\n82.69\n\n\n30-343338329\n359\nGCGTAGTA+TTCTAGCT\n27,274,149\n8,182\n34.96\n89.20\n\n\n30-343338329\n425\nGCGTAGTA+CCTAGAGT\n66,224,932\n19,867\n29.54\n65.13\n\n\n30-343338329\n427\nGCGTAGTA+GCGTAAGA\n18,918,640\n5,676\n33.31\n80.87\n\n\n30-343338329\n445\nGCGTAGTA+CTATTAAG\n30,745,388\n9,224\n33.07\n80.83\n\n\n30-343338329\n463\nGCGTAGTA+AAGGCTAT\n19,531,145\n5,859\n34.27\n86.08\n\n\n30-343338329\n481\nGCGTAGTA+GAGCCTTA\n50,592,084\n15,178\n31.92\n75.59\n\n\n30-343338329\n485\nGCGTAGTA+TTATGCGA\n26,010,208\n7,803\n34.63\n87.48\n\n\n\nConfirmed that SFTP transfer from Genewiz to owl/nightingales/C_bairdi/ was successful:\n\n\n\nscreencap of md5sum output\n\n\n\n\nRESULTS\nOutput folder:\n\nowl/nightingales/C_bairdi/\n\nWill update the nightingales Google Sheet with the appropriate info shortly."
  },
  {
    "objectID": "posts/2020/2020-12-11-Data-Received---M.magister-MBD-BSseq-Pool-Test-MiSeq-Run/index.html",
    "href": "posts/2020/2020-12-11-Data-Received---M.magister-MBD-BSseq-Pool-Test-MiSeq-Run/index.html",
    "title": "Data Received - M.magister MBD-BSseq Pool Test MiSeq Run",
    "section": "",
    "text": "After creating _M.magister (C.magister; Dungeness crab) MBD-BSseq libraries (on 20201124), I gave the pooled set of samples to Mac for a test sequencing run on the MiSeq on 20201202.\nMiSeq data consisted of 76bp paired-end (PE) sequencing.\nAll files were downloaded to the C_magister folder on Owl(Synology server).\nHave added files to our high-throughput sequencing database (Google Sheet):\n\nnightingales\n\nNext up:\n\nFastQC"
  },
  {
    "objectID": "posts/2020/2020-09-28-Data-Wrangling---C.bairdi-NanoPore-20102558-2729-Quality-Filtering-Using-NanoFilt-on-Mox/index.html",
    "href": "posts/2020/2020-09-28-Data-Wrangling---C.bairdi-NanoPore-20102558-2729-Quality-Filtering-Using-NanoFilt-on-Mox/index.html",
    "title": "Data Wrangling - C.bairdi NanoPore 20102558-2729 Quality Filtering Using NanoFilt on Mox",
    "section": "",
    "text": "Last week, I ran all of our Q7-filtered C.baird NanoPore reads through MEGAN6 to evaluate the taxonomic breakdown (on 20200917) and noticed that there were a large quantity of bases assigned to E.canceri (a known microsporidian agent of infection in crabs) and Aquifex sp. (a genus of thermophylic bacteria), in addition to the expected Arthropoda assignments. Notably, Alveolata assignments were remarkably low.\nSince our NanoPore data was a combination of an uninfected sample and a Hematodinium-infected sample, I decided to find out which of the two samples was contributing to the E.canceri and Aquifex sp. assignments. To do so, first I need to generate a singular Q7-filtered FastQ using NanoFilt.\nThis set was the uninfected muscle sample:\n\nC.bairdi-20102558-2729-Run-01\nC.bairdi-20102558-2729-Run-02\n\nJob was run on Mox.\nSBATCH script (GitHub):\n\n20200928_cbai_nanofilt_Q7_20102558-2729_nanopore-data.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_nanofilt_Q7_20102558-2729_nanopore-data\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=200G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200928_cbai_nanofilt_Q7_20102558-2729_nanopore-data\n\n\n\n\n###################################################################################\n# These variables need to be set by user\n\n# Load Anaconda\n# Uknown why this is needed, but Anaconda will not run if this line is not included.\n. \"/gscratch/srlab/programs/anaconda3/etc/profile.d/conda.sh\"\n\n\n# Activate the NanoPlot Anaconda environment\nconda activate nanofilt_2.6.0_env\n\n\n# Declare array\nraw_reads_dir_array=()\n\n# Paths to reads\nraw_reads_dir_array=(\n\"/gscratch/srlab/sam/data/C_bairdi/DNAseq/ont_FAL58500_04bb4d86_20102558-2729\" \\\n\"/gscratch/srlab/sam/data/C_bairdi/DNAseq/ont_FAL58500_94244ffd_20102558-2729\"\n)\n\n# FastQ concatenation filename\nfastq_cat=20200928_cbai_nanopore_20102558-2729.fastq\n\nfastq_filtered=20200928_cbai_nanopore_20102558-2729_quality-7.fastq\n\n# Paths to programs\nnanofilt=NanoFilt\n\n# Set mean quality filter (integer)\nquality=7\n\n###################################################################################\n\n\n# Exit script if any command fails\nset -e\n\n# Inititalize array\nprograms_array=()\n\n# Programs array\nprograms_array=(\"${nanofilt}\")\n\n\n# Loop through NanoPore data directories\n# to run NanoPlot, FastQC, and MultiQC\nfor directory in \"${raw_reads_dir_array[@]}\"\ndo\n\n  # Find all FastQ files and concatenate into singel file\n  while IFS= read -r -d '' filename\n  do\n    # Concatenate all FastQ files into single file\n    # for NanoFilt and generate MD5 checksums\n    echo \"Now concatenating ${filename} to ${fastq_cat}...\"\n    cat \"${filename}\" >> ${fastq_cat}\n    echo \"Concatenation of ${filename} to ${fastq_cat} complete.\"\n\n    # Create checksums file\n    echo \"Now generating checksum for ${filename}...\"\n    echo \"\"\n    md5sum \"${filename}\" >> fastq_checksums.md5\n    echo \"Checksum for ${filename} complete.\"\n    echo \"\"\n\n  done < <(find \"${directory}\" -name \"*.fastq\" -type f -print0)\n\ndone\n\n# Generate MD5 checksum for concatenated FastQ file\necho \"Now generating checksum for ${fastq_cat}...\"\necho \"\"\nmd5sum \"${fastq_cat}\" >> fastq_checksums.md5\necho \"checksum for ${fastq_cat} complete.\"\necho \"\"\n\n# Run NanoFilt\n## Sets readtype to 1D (default)\n## Filters on mean quality >= 7 (ONT \"standard\")\n## FYI: seems to require piping stdin (i.e. cat fastq |)to NanoFilt...\necho \"Running ${programs_array[nanofilt]}\"\necho \"\"\ncat ${fastq_cat} \\\n| ${programs_array[nanofilt]} \\\n--readtype 1D \\\n--quality ${quality} \\\n> ${fastq_filtered}\necho \"${programs_array[nanofilt]} complete.\"\necho \"\"\n\n# Generate MD5 checksum for concatenated FastQ file\necho \"Now generating checksum for ${fastq_filtered}...\"\necho \"\"\nmd5sum \"${fastq_filtered}\" >> fastq_checksums.md5\necho \"checksum for ${fastq_filtered} complete.\"\necho \"\"\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${programs_array[program]}: \"\n    echo \"\"\n    ${programs_array[program]} -h\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nRESULTS\nRuntime was very fast, 43s:\n\n\n\nNanoFilt runtime on mox for 20102558-2729\n\n\nOutput folder:\n\n20200928_cbai_nanofilt_Q7_20102558-2729_nanopore-data/\n\nQ7 Filtered FastQ file (148MB):\n\n20200928_cbai_nanofilt_Q7_20102558-2729_nanopore-data/20200928_cbai_nanopore_20102558-2729_quality-7.fastq\n\nMD5 checksum:\n\neb439470cbc765052b4b190e837fcdd7\n\n\n\nWill get taxonomy assignments using MEGAN6."
  },
  {
    "objectID": "posts/2020/2020-08-24-Sample-Submitted---C.gigas-Diploid-Triploid-pH-Treatments-Ctenidia-to-ZymoResearch-for-WGBS/index.html",
    "href": "posts/2020/2020-08-24-Sample-Submitted---C.gigas-Diploid-Triploid-pH-Treatments-Ctenidia-to-ZymoResearch-for-WGBS/index.html",
    "title": "Sample Submitted - C.gigas Diploid-Triploid pH Treatments Ctenidia to ZymoResearch for WGBS",
    "section": "",
    "text": "Submitted 1.5ug of the 24 C.gigas ctenidia ctenidia gDNA isolated last week (20200821) to ZymoResearch for whole genome bisulfite sequencing (WGBS) to compare differences in diploid/triploids and responses to elevated pH:\n\n150bp PE reads\n~60M reads/sample\n\n\n\n\nSample_ID\nConcentration(ng/uL)\nVol_for_1.5ug(uL)\n\n\n\n\n2N_HI_5\n40.4\n37.1\n\n\n2N_HI_8\n11.6\n100.0\n\n\n2N_HI_9\n32.3\n46.4\n\n\n2N_HI_10\n61\n24.6\n\n\n2N_HI_11\n21\n71.4\n\n\n2N_HI_12\n11.2\n100.0\n\n\n2N_LOW_1\n32.1\n46.7\n\n\n2N_LOW_2\n32.5\n46.2\n\n\n2N_LOW_3\n36\n41.7\n\n\n2N_LOW_4\n40.2\n37.3\n\n\n2N_LOW_5\n17.8\n84.3\n\n\n2N_LOW_6\n22.8\n65.8\n\n\n3N_HI_2\n29.6\n50.7\n\n\n3N_HI_3\n71.8\n20.9\n\n\n3N_HI_5\n29.3\n51.2\n\n\n3N_HI_8\n38.9\n38.6\n\n\n3N_HI_10\n38.3\n39.2\n\n\n3N_HI_11\n52.3\n28.7\n\n\n3N_LOW_6\n35.3\n42.5\n\n\n3N_LOW_7\n43.6\n34.4\n\n\n3N_LOW_8\n63.9\n23.5\n\n\n3N_LOW_10\n54.4\n27.6\n\n\n3N_LOW_11\n50.8\n29.5\n\n\n3N_LOW_12\n52\n28.8\n\n\n\nNOTE: Those samples listed as 100.0uL used the entirety of the sample and did not have a full 1.5ug. However, ZymoResearch only needs 1.0ug; sending 1.5ug just ensures they have a bit extra if needed."
  },
  {
    "objectID": "posts/2020/2020-09-28-Data-Wrangling---C.bairdi-NanoPore-6129-403-26-Quality-Filtering-Using-NanoFilt-on-Mox/index.html",
    "href": "posts/2020/2020-09-28-Data-Wrangling---C.bairdi-NanoPore-6129-403-26-Quality-Filtering-Using-NanoFilt-on-Mox/index.html",
    "title": "Data Wrangling - C.bairdi NanoPore 6129-403-26 Quality Filtering Using NanoFilt on Mox",
    "section": "",
    "text": "Last week, I ran all of our Q7-filtered C.baird NanoPore reads through MEGAN6 to evaluate the taxonomic breakdown (on 20200917) and noticed that there were a large quantity of bases assigned to E.canceri (a known microsporidian agent of infection in crabs) and Aquifex sp. (a genus of thermophylic bacteria), in addition to the expected Arthropoda assignments. Notably, Alveolata assignments were remarkably low.\nSince our NanoPore data was a combination of an uninfected sample and a Hematodinium-infected sample, I decided to find out which of the two samples was contributing to the E.canceri and Aquifex sp. assignments. To do so, first I need to generate a singular Q7-filtered FastQ using NanoFilt.\nThis set was the Hematodinium-infected hemolymph sample:\n\nC.bairdi-6129_403_26\n\nJob was run on Mox.\nSBATCH script (GitHub):\n\n20200928_cbai_nanofilt_Q7_6129_403_26_nanopore-data.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_nanofilt_Q7_6129_403_26_nanopore-data\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=200G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200928_cbai_nanofilt_Q7_6129_403_26_nanopore-data\n\n\n\n\n###################################################################################\n# These variables need to be set by user\n\n# Load Anaconda\n# Uknown why this is needed, but Anaconda will not run if this line is not included.\n. \"/gscratch/srlab/programs/anaconda3/etc/profile.d/conda.sh\"\n\n\n# Activate the NanoPlot Anaconda environment\nconda activate nanofilt_2.6.0_env\n\n\n# Declare array\nraw_reads_dir_array=()\n\n# Paths to reads\nraw_reads_dir_array=(\n\"/gscratch/srlab/sam/data/C_bairdi/DNAseq/ont_FAL86873_d8db260e_cbai_6129_403_26\"\n)\n\n# FastQ concatenation filename\nfastq_cat=20200928_cbai_nanopore_6129_403_26.fastq\n\nfastq_filtered=20200928_cbai_nanopore_6129_403_26_quality-7.fastq\n\n# Paths to programs\nnanofilt=NanoFilt\n\n# Set mean quality filter (integer)\nquality=7\n\n###################################################################################\n\n\n# Exit script if any command fails\nset -e\n\n# Inititalize array\nprograms_array=()\n\n# Programs array\nprograms_array=(\"${nanofilt}\")\n\n\n# Loop through NanoPore data directories\n# to run NanoPlot, FastQC, and MultiQC\nfor directory in \"${raw_reads_dir_array[@]}\"\ndo\n\n  # Find all FastQ files and concatenate into singel file\n  while IFS= read -r -d '' filename\n  do\n    # Concatenate all FastQ files into single file\n    # for NanoFilt and generate MD5 checksums\n    echo \"Now concatenating ${filename} to ${fastq_cat}...\"\n    cat \"${filename}\" >> ${fastq_cat}\n    echo \"Concatenation of ${filename} to ${fastq_cat} complete.\"\n\n    # Create checksums file\n    echo \"Now generating checksum for ${filename}...\"\n    echo \"\"\n    md5sum \"${filename}\" >> fastq_checksums.md5\n    echo \"Checksum for ${filename} complete.\"\n    echo \"\"\n\n  done < <(find \"${directory}\" -name \"*.fastq\" -type f -print0)\n\ndone\n\n# Generate MD5 checksum for concatenated FastQ file\necho \"Now generating checksum for ${fastq_cat}...\"\necho \"\"\nmd5sum \"${fastq_cat}\" >> fastq_checksums.md5\necho \"checksum for ${fastq_cat} complete.\"\necho \"\"\n\n# Run NanoFilt\n## Sets readtype to 1D (default)\n## Filters on mean quality >= 7 (ONT \"standard\")\n## FYI: seems to require piping stdin (i.e. cat fastq |)to NanoFilt...\necho \"Running ${programs_array[nanofilt]}\"\necho \"\"\ncat ${fastq_cat} \\\n| ${programs_array[nanofilt]} \\\n--readtype 1D \\\n--quality ${quality} \\\n> ${fastq_filtered}\necho \"${programs_array[nanofilt]} complete.\"\necho \"\"\n\n# Generate MD5 checksum for concatenated FastQ file\necho \"Now generating checksum for ${fastq_filtered}...\"\necho \"\"\nmd5sum \"${fastq_filtered}\" >> fastq_checksums.md5\necho \"checksum for ${fastq_filtered} complete.\"\necho \"\"\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${programs_array[program]}: \"\n    echo \"\"\n    ${programs_array[program]} -h\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nRESULTS\nRuntime was very fast, ~4.5mins:\n\n\n\nNanoFilt runtime on mox for 6129-403-26\n\n\nOutput folder:\n\n20200928_cbai_nanofilt_Q7_6129_403_26_nanopore-data/\n\nQ7 Filtered FastQ file (2.1GB):\n\n20200928_cbai_nanofilt_Q7_6129_403_26_nanopore-data/20200928_cbai_nanopore_6129_403_26_quality-7.fastq\n\nMD5 checksum:\n\n803dbec872739826e3d6c0dc5cd4e678\n\n\n\nWill get taxonomy assignments using MEGAN6."
  },
  {
    "objectID": "posts/2020/2020-04-14-Taxonomic-Assignments---C.bairdi-RNAseq-Using-DIAMOND-BLASTx-on-Mox-and-MEGAN6-Meganizer-on-swoose/index.html",
    "href": "posts/2020/2020-04-14-Taxonomic-Assignments---C.bairdi-RNAseq-Using-DIAMOND-BLASTx-on-Mox-and-MEGAN6-Meganizer-on-swoose/index.html",
    "title": "Taxonomic Assignments - C.bairdi RNAseq Using DIAMOND BLASTx on Mox and MEGAN6 Meganizer on swoose",
    "section": "",
    "text": "After receiving/trimming the latest round of C.bairdi RNAseq data on 20200413, need to get the data ready to perform taxonomic selection of sequencing reads. To do this, I first need to run DIAMOND BLASTx, then “meganize” the output files in preparation for loading into MEGAN6, which will allow for taxonomic-specific read separation.\nDIAMOND BLASTx will and Meganization will be run on Mox. Conversion to RMA6 files will be done on my computer (swoose), due to MEGAN6’s reliance on Java X11 window (this is not available on Mox - throws an error when trying to run it).\nI fully anticipate this process to take a week or two (DIAMOND BLASTx will likely take a few days and read extraction will definitely take many days…)\nSBATCH script (GitHub):\n\n20200414_cbai_diamond_blastx.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_blastx_DIAMOND\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200414_cbai_diamond_blastx\n\n## Perform DIAMOND BLASTx on trimmed Chionoecetes bairdi (Tanner crab) FastQ files.\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\n\n# Program paths\ndiamond=/gscratch/srlab/programs/diamond-0.9.29/diamond\n\n# DIAMOND NCBI nr database\ndmnd=/gscratch/srlab/blastdbs/ncbi-nr-20190925/nr.dmnd\n\n# Capture program options\n{\necho \"Program options for DIAMOND: \"\necho \"\"\n\"${diamond}\" help\necho \"\"\necho \"\"\necho \"----------------------------------------------\"\necho \"\"\necho \"\"\n} &>> program_options.log || true\n\n# Trimmed FastQ files directory\nfastq_dir=/gscratch/scrubbed/samwhite/outputs/20200414_cbai_RNAseq_fastp_trimming/\n\n\n# Loop through FastQ files, log filenames to fastq_list.txt.\n# Run DIAMOND on each FastQ\nfor fastq in ${fastq_dir}*fastp-trim*.fq.gz\ndo\n    # Log input FastQs\n    echo \"${fastq}\" >> fastq_list.txt\n\n    # Strip leading path and extensions\n    no_path=$(echo \"${fastq##*/}\")\n    no_ext=$(echo \"${no_path%%.*}\")\n\n    # Run DIAMOND with blastx\n    # Output format 100 produces a DAA binary file for use with MEGAN\n    ${diamond} blastx \\\n    --db ${dmnd} \\\n    --query \"${fastq}\" \\\n    --out \"${no_ext}\".blastx.daa \\\n    --outfmt 100 \\\n    --top 5 \\\n    --block-size 15.0 \\\n    --index-chunks 4\ndone\nDAA conversion to RMA6 on swoose (GitHub):\n\n20200414_cbai_diamond_blastx_daa2rma.sh\n\n#!/bin/bash\n\n# Script to run MEGAN6 meganizer on DIAMOND DAA files from\n# 20200414_cbai_diamond_blastx Mox job.\n\n# Requires MEGAN mapping files from:\n# http://ab.inf.uni-tuebingen.de/data/software/megan6/download/\n\n# Exit script if any command fails\nset -e\n\n# Program path\nmeganizer=/home/sam/programs/megan/tools/daa2rma\n\n# MEGAN mapping files\nprot_acc2tax=/home/sam/data/databases/MEGAN/prot_acc2tax-Jul2019X1.abin\nacc2interpro=/home/sam/data/databases/MEGAN/acc2interpro-Jul2019X.abin\nacc2eggnog=/home/sam/data/databases/MEGAN/acc2eggnog-Jul2019X.abin\n\n\n## Inititalize arrays\ndaa_array_R1=()\ndaa_array_R2=()\n\n\n# Populate array with unique sample names\n## NOTE: Requires Bash >=v4.0\nmapfile -t samples_array < <( for daa in *.daa; do echo \"${daa}\" | awk -F\"_\" '{print $1}'; done | sort -u )\n\n# Loop to concatenate same sample R1 and R2 reads\nfor sample in \"${!samples_array[@]}\"\ndo\n  # Concatenate R1 reads for each sample\n  for daa in *R1*.daa\n  do\n    daa_sample=$(echo \"${daa}\" | awk -F\"_\" '{print $1}')\n    if [ \"${samples_array[sample]}\" == \"${daa_sample}\" ]; then\n      reads_1=${samples_array[sample]}_reads_1.daa\n      echo \"Concatenating ${daa} with ${reads_1}\"\n      cat \"${daa}\" >> \"${reads_1}\"\n    fi\n  done\n\n  # Concatenate R2 reads for each sample\n  for daa in *R2*.daa\n  do\n    daa_sample=$(echo \"${daa}\" | awk -F\"_\" '{print $1}')\n    if [ \"${samples_array[sample]}\" == \"${daa_sample}\" ]; then\n      reads_2=${samples_array[sample]}_reads_2.daa\n      echo \"Concatenating ${daa} with ${reads_2}\"\n      cat \"${daa}\" >> \"${reads_2}\"\n    fi\n  done\ndone\n\n# Create array of DAA R1 files\nfor daa in *reads_1.daa\ndo\n  daa_array_R1+=(\"${daa}\")\ndone\n\n# Create array of DAA R2 files\nfor daa in *reads_2.daa\ndo\n  daa_array_R2+=(\"${daa}\")\ndone\n\n## Run MEGANIZER\n\n# Capture start \"time\"\n# Uses builtin bash variable called ${SECONDS}\nstart=${SECONDS}\n\nfor index in \"${!daa_array_R1[@]}\"\ndo\n  start_loop=${SECONDS}\n  sample_name=$(echo \"${daa_array_R1[index]}\" | awk -F \"_\" '{print $1}')\n\n  echo \"Now processing ${sample_name}.daa2rma.rma6\"\n  echo \"\"\n\n  # Run daa2rma with paired option\n  ${meganizer} \\\n  --paired \\\n  --in \"${daa_array_R1[index]}\" \"${daa_array_R2[index]}\" \\\n    --acc2taxa ${prot_acc2tax} \\\n    --acc2interpro2go ${acc2interpro} \\\n    --acc2eggnog ${acc2eggnog} \\\n  --out \"${sample_name}\".daa2rma.rma6 \\\n  2>&1 | tee --append daa2rma_log.txt\n\n  end_loop=${SECONDS}\n  loop_runtime=$((end_loop-start_loop))\n\n\n  echo \"Finished processing ${sample_name}.daa2rma.rma6 in ${loop_runtime} seconds.\"\n  echo \"\"\n\ndone\n\n# Caputure end \"time\"\nend=${SECONDS}\n\nruntime=$((end-start))\n\n# Print MEGANIZER runtime, in seconds\n\n{\n  echo \"\"\n  echo \"---------------------\"\n  echo \"\"\n  echo \"Total runtime was: ${runtime} seconds\"\n} >> daa2rma_log.txt\n\n\nRESULTS\nThe initial BLASTx and meganization didn’t take terribly long, ~1.6 days :\n\n\n\ndiamond/meganization runtime\n\n\nConversion from DAA to RMA6 took almost the same amount of time.\nOutput folder:\n\n20200414_cbai_diamond_blastx/\n\nOutput files (“meganized” DAA files):\n\n380820_reads_1.daa (49G)\n380820_reads_2.daa (46G)\n380820_S1_L001_R1_001.blastx.daa (25G)\n380820_S1_L001_R2_001.blastx.daa (23G)\n380820_S1_L002_R1_001.blastx.daa (25G)\n380820_S1_L002_R2_001.blastx.daa (23G)\n380821_reads_1.daa (42G)\n380821_reads_2.daa (40G)\n380821_S2_L001_R1_001.blastx.daa (21G)\n380821_S2_L001_R2_001.blastx.daa (20G)\n380821_S2_L002_R1_001.blastx.daa (21G)\n380821_S2_L002_R2_001.blastx.daa (20G)\n380822_reads_1.daa (44G)\n380822_reads_2.daa (40G)\n380822_S3_L001_R1_001.blastx.daa (22G)\n380822_S3_L001_R2_001.blastx.daa (20G)\n380822_S3_L002_R1_001.blastx.daa (22G)\n380822_S3_L002_R2_001.blastx.daa (20G)\n380823_reads_1.daa (37G)\n380823_reads_2.daa (34G)\n380823_S4_L001_R1_001.blastx.daa (19G)\n380823_S4_L001_R2_001.blastx.daa (17G)\n380823_S4_L002_R1_001.blastx.daa (19G)\n380823_S4_L002_R2_001.blastx.daa (17G)\n380824_reads_1.daa (47G)\n380824_reads_2.daa (42G)\n380824_S5_L001_R1_001.blastx.daa (24G)\n380824_S5_L001_R2_001.blastx.daa (21G)\n380824_S5_L002_R1_001.blastx.daa (23G)\n380824_S5_L002_R2_001.blastx.daa (22G)\n380825_reads_1.daa (43G)\n380825_reads_2.daa (40G)\n380825_S6_L001_R1_001.blastx.daa (22G)\n380825_S6_L001_R2_001.blastx.daa (20G)\n380825_S6_L002_R1_001.blastx.daa (22G)\n380825_S6_L002_R2_001.blastx.daa (20G)\n\nOutput files for loading into MEGAN6 (RMA6):\n\n380820.daa2rma.rma6 (5.0G)\n380821.daa2rma.rma6 (4.7G)\n380822.daa2rma.rma6 (4.6G)\n380823.daa2rma.rma6 (4.1G)\n380824.daa2rma.rma6 (5.0G)\n380825.daa2rma.rma6 (5.1G)\n\nThese will be loaded into MEGAN6 and reads will be extracted based on classification to Alveolata and/or Arthropoda phyla."
  },
  {
    "objectID": "posts/2020/2020-01-31-Data-Wrangling---Arthropoda-and-Alveolata-Day-and-Treatment-Taxonomic-RNAseq-FastQ-Extractions/index.html",
    "href": "posts/2020/2020-01-31-Data-Wrangling---Arthropoda-and-Alveolata-Day-and-Treatment-Taxonomic-RNAseq-FastQ-Extractions/index.html",
    "title": "Data Wrangling - Arthropoda and Alveolata Day and Treatment Taxonomic RNAseq FastQ Extractions",
    "section": "",
    "text": "After using MEGAN6 to extract Arthropoda and Alveolata reads from our RNAseq data on 20200114, I had then extracted taxonomic-specific reads and aggregated each into basic Read 1 and Read 2 FastQs to simplify transcriptome assembly for C.bairdi and for Hematodinium. That was fine and all, but wasn’t fully thought through.\nFor gene expression analysis, I need the FastQs based on infection status and sample days. So, I need to modify the read extraction procedure to parse reads based on those conditions. I could’ve/should’ve done this originally, as I could’ve just assembled the transcriptome from the FastQs I’m going to generate now. Oh well.\nFor reference, these include RNAseq data using a newly established “shorthand”: 2019)\nAs a reminder, the reason I’m doing this is that I realized that the FastA headers were incomplete and did not distinguish between paired reads. Here’s an example:\nR1 FastQ header:\n@A00147:37:HG2WLDMXX:1:1101:5303:1000 1:N:0:AGGCGAAG+AGGCGAAG\nR2 FastQ header:\n@A00147:37:HG2WLDMXX:1:1101:5303:1000 2:N:0:AGGCGAAG+AGGCGAAG\nHowever, the reads extracted via MEGAN have FastA headers like this:\n>A00147:37:HG2WLDMXX:1:1101:5303:1000\nSEQUENCE1\n>A00147:37:HG2WLDMXX:1:1101:5303:1000\nSEQUENCE2\nThose are a set of paired reads, but there’s no way to distinguish between R1/R2. This may not be an issue, but I’m not sure how downstream programs (i.e. Trinity) will handle duplicate FastA IDs as inputs. To avoid any headaches, I’ve decided to parse out the corresponding FastQ reads which have the full header info.\nAnyway, here’s a brief rundown of the approach:\n\nCreate list of unique read headers from MEGAN6 FastA files.\nUse list with seqtk program to pull out corresponding FastQ reads from the trimmed FastQ R1 and R2 files.\n\nThe entire procedure is documented in a Jupyter Notebook below.\nJupyter notebook (GitHub):\n\n20200131_swoose_cbai_megan_day-treatment_read_extractions.ipynb\n\n\n\nRESULTS\nOutput folders:\n\n20200131.C_bairdi_megan_reads\n20200131.Hematodinium_megan_reads/\n\nWe now have two distinct sets of RNAseq reads from C.bairdi (Arhtropoda) and Hematodinium (Alveolata), split by infection status and sample day! Will get some gene expression analysis going.\nAlso of note, and this is a nice bit of confirmation, there are no reads present in the Hematodinium extractions in either of the uninfected samples (D12 or D26). So, the only comparisons to be performed for them will be comparing D12 vs D26."
  },
  {
    "objectID": "posts/2020/2020-02-28-Data-Wrangling---Create-Canonical-Olurida_v081-Genes-FastA/index.html",
    "href": "posts/2020/2020-02-28-Data-Wrangling---Create-Canonical-Olurida_v081-Genes-FastA/index.html",
    "title": "Data Wrangling - Create Canonical Olurida_v081 Genes FastA",
    "section": "",
    "text": "I finally had some time to tackle this GitHub Issue and create a canonical genes FastA file using the MAKER IDs, instead of the original contig IDs from our Olympia oyster genome assembly - https://owl.fish.washington.edu/halfshell/genomic-databank/Olurida_v081.fa (FastA; 1.1GB).\nEverything was documented in a Jupyter Notebook (see link below), but here’s the skinny on how I did it:\n\nPull existing FastA-formatted sequences from the fully annotated GFF (GFF; 2.9GB; MAKER appended the FastAs to the end of the GFF).\nUse ‘bedTools fastaFromBed’ to create FastA for all genes using gene GFF coordinates and generate unique FastA headers for each sequence.\nUse sed to do a substitution using the MAKER IDs and the bedTools fastaFromBed IDs.\n\nJupyter Notebook (GitHub):\n\n20200228_swoose_olur_v081_fasta_renaming.ipynb\n\n\n\nRESULTS\nThis ran for a surprisingly long time - a bit over 17 hours just for a find/replace. I think I could’ve speeded things up if the last sed command looked only at lines beginning with “>”, instead of scanning each line for each possible match. Oh well.\nOutput folder:\n\n20200228_swoose_olur_v081_fasta_renaming\n\nRenamed FastA ():\n\nOlurida_v081.genes.fasta\n\nRenamed FastA Index (txt):\n\nOlurida_v081.genes.fasta.fai\n\nWill add to Genomic Resources wiki."
  },
  {
    "objectID": "posts/2020/2020-09-23-Data-Wrangling---Subsetting-cbai_genome_v1.0-Assembly-with-faidx/index.html",
    "href": "posts/2020/2020-09-23-Data-Wrangling---Subsetting-cbai_genome_v1.0-Assembly-with-faidx/index.html",
    "title": "Data Wrangling - Subsetting cbai_genome_v1.0 Assembly with faidx",
    "section": "",
    "text": "Previously assembled cbai_genome_v1.0.fasta with our NanoPore Q7 reads on 20200917 and noticed that there were numerous sequences that were well shorter than the expected 500bp threshold that the assembler (Flye) was supposed to spit out. I created an Issue on the Flye GitHub page to find out why. The developer responded and determined it was an issue with the assembly polisher and that sequences <500bp could be safely ignored.\nSo, I’ve decided to subset the cbai_genome_v1.0.fasta to exclude all sequences <1000bp, as that seems like a more reasonable minimum length for potential genes. I did not run this in a Jupyter Notebook, due to the brevity of the commands. Here are the commands, using faidx:\n\n>1kbp subsetting\nfaidx --size-range 1000,1000000000 cbai_genome_v1.0.fasta > cbai_genome_v1.01.fasta\n\n\nIndex new FastA\nfaidx Pgenerosa_v071.fasta\nsamb@mephisto:~/data/C_bairdi/genomes$ sort -nk2,2 cbai_genome_v1.01.fasta.fai | head\n\ncontig_4272 1000    15642836    60  61\ncontig_4503 1000    16422183    60  61\ncontig_4429 1001    16145927    60  61\ncontig_1038 1002    230201  60  61\ncontig_1691 1005    1716551 60  61\ncontig_2992 1005    7322005 60  61\ncontig_3284 1006    9674445 60  61\ncontig_1810 1008    2050977 60  61\ncontig_408  1008    15069716    60  61\ncontig_1616 1009    1549839 60  61\nSubsetting looks like it worked.\nLooking at sequence counts in FastAs:\nsamb@mephisto:~/data/C_bairdi/genomes$ for file in *.fasta; do grep --with-filename -c \">\" $file; done\n\ncbai_genome_v1.01.fasta:2431\ncbai_genome_v1.0.fasta:3294\n\n\n\nMD5 checksums\n5a08d8b0651484e3ff75fcf032804596  cbai_genome_v1.01.fasta\n\nAny future work with C.bairdi genome assemblies will be with cbai_genome_v1.01.fasta (until a better assembly comes along).\nAll files were copied to our genomic databank on Owl.\nSee our Genomic Resources wiki (GitHub) for a more concise overview."
  },
  {
    "objectID": "posts/2020/2020-07-22-DNA-Isolation-and-Quantification---C.gigas-Diploid-Ronit-and-Triploid-Nisbet/index.html",
    "href": "posts/2020/2020-07-22-DNA-Isolation-and-Quantification---C.gigas-Diploid-Ronit-and-Triploid-Nisbet/index.html",
    "title": "DNA Isolation and Quantification - C.gigas Diploid (Ronit) and Triploid (Nisbet)",
    "section": "",
    "text": "Isolated some gDNA from the triploid Nisbet oysters we received on 20200218 and one of Ronit’s diploid ctenidia samples (Google Sheet) using the E.Z.N.A. Mollusc DNA Kit (Omega). See the “Results” section for sample info.\nSamples were pulverized under liquid nitrogen (LN2). Samples were not weighed beforehand; simply “eye-balled” pieces to get close to ~30 - 50mg. Manufacturer’s protocol (PDF) was followed with the following notes/changes:\n\nProteinase K was not from kit (seem to be out). Instead was ThermoFisher brand (stored in -20C) with a concentration of ~20mg/mL and expiration date of September 2019.\neluted in 100uL of elution buffer\n\nDNA was quantified using the Roberts Lab Qubit 3.0 using the dsDNA BR Assay (Invitrogen) and 1uL of each sample.\nResulting DNA was stored in Sam’s gDNA Box #3, Positions I4 - I9\n\n\nRESULTS\nQubit results (Google Sheet):\n\n20200722_qubit_DNA_gigas_ploidy\n\n\n\n\n\n\n\n\n\n\nSample\nOriginal sample conc. (ng/uL)\nElution volume (uL)\nYield (ng)\n\n\n\n\nNisbet #1 adductor\n50.4\n100\n5040\n\n\nNisbet #1 ctenidia\n80.2\n100\n8020\n\n\nNisbet #1 gonad\n14.8\n100\n1480\n\n\nNisbet #1 mantle\n18.8\n100\n1880\n\n\nRonit D05 C2\n89.4\n100\n8940\n\n\nRonit D04 C\n97.0\n100\n9700"
  },
  {
    "objectID": "posts/2020/2020-12-01-Samples-Submitted---Cockle-Clam-Gonad-Histology-Cassettes-for-H-and-E/index.html",
    "href": "posts/2020/2020-12-01-Samples-Submitted---Cockle-Clam-Gonad-Histology-Cassettes-for-H-and-E/index.html",
    "title": "Samples Submitted - Cockle Clam Gonad Histology Cassettes for H and E",
    "section": "",
    "text": "Per this GitHub Issue, Steven asked that I submit a set of fixed cockle clam gonad tissues (currently stored in histology cassettes in 70% EtOH) for Hematoxylin and eosin stain (H&E). I submitted the following samples to the UW Pathology Research Services Laboratory (UW PRSL):\n\ncockle_gonad_6\ncockle_gonad_7\ncockle_gonad_8\ncockle_gonad_10\ncockle_gonad_11\ncockle_gonad_12\ncockle_gonad_13\ncockle_gonad_14\ncockle_gonad_42\ncockle_gonad_43\ncockle_gonad_44\ncockle_gonad_45\ncockle_gonad_46\ncockle_gonad_47\ncockle_gonad_48\ncockle_gonad_49\ncockle_gonad_60\ncockle_gonad_64\ncockle_gonad_68\ncockle_gonad_72\ncockle_gonad_76\ncockle_gonad_82\ncockle_gonad_83\ncockle_gonad_84\ncockle_gonad_85\ncockle_gonad_86\ncockle_gonad_87\ncockle_gonad_88\ncockle_gonad_89"
  },
  {
    "objectID": "posts/2020/2020-11-10-FastQC-MultiQC---C.gigas-Ploidy-WGBS-Raw-Sequence-Data-from-Ronits-Project-on-Mox/index.html",
    "href": "posts/2020/2020-11-10-FastQC-MultiQC---C.gigas-Ploidy-WGBS-Raw-Sequence-Data-from-Ronits-Project-on-Mox/index.html",
    "title": "FastQC-MultiQc - C.gigas Ploidy WGBS Raw Sequence Data from Ronits Project on Mox",
    "section": "",
    "text": "Earlier today, we received the C.gigas ploidy WGBS data that we submitted to ZymoResearch on 20200820.\nAs part of our usual work flow, I needed to run FastQC.\nRan FastQC on Mox.\nSBATCH script (GitHub):\n\n20201110_cgig_fastqc_ronit-ploidy-wgbs.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=20201110_cgig_fastqc_ronit-ploidy-wgbs\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20201110_cgig_fastqc_ronit-ploidy-wgbs\n\n\n### FastQC assessment of raw sequencing from Ronit's ploidy WGBS.\n\n\n###################################################################################\n# These variables need to be set by user\n\n# FastQC output directory\noutput_dir=$(pwd)\n\n# Set number of CPUs to use\nthreads=28\n\n# Input/output files\nchecksums=fastq_checksums.md5\nfastq_list=fastq_list.txt\nraw_reads_dir=/gscratch/srlab/sam/data/C_gigas/wgbs/\n\n# Paths to programs\nfastqc=/gscratch/srlab/programs/fastqc_v0.11.9/fastqc\nmultiqc=/gscratch/srlab/programs/anaconda3/bin/multiqc\n\n\n# Programs associative array\ndeclare -A programs_array\nprograms_array=(\n[fastqc]=\"${fastqc}\" \\\n[multiqc]=\"${multiqc}\"\n)\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Sync raw FastQ files to working directory\nrsync --archive --verbose \\\n\"${raw_reads_dir}\"zr3534*.fq.gz .\n\n# Populate array with FastQ files\nfastq_array=(*.fq.gz)\n\n# Pass array contents to new variable\nfastqc_list=$(echo \"${fastq_array[*]}\")\n\n# Run FastQC\n# NOTE: Do NOT quote ${fastqc_list}\n${programs_array[fastqc]} \\\n--threads ${threads} \\\n--outdir ${output_dir} \\\n${fastqc_list}\n\n\n# Create list of fastq files used in analysis\necho \"${fastqc_list}\" | tr \" \" \"\\n\" >> ${fastq_list}\n\n# Generate checksums for reference\nwhile read -r line\ndo\n\n    # Generate MD5 checksums for each input FastQ file\n    echo \"Generating MD5 checksum for ${line}.\"\n    md5sum \"${line}\" >> \"${checksums}\"\n    echo \"Completed: MD5 checksum for ${line}.\"\n    echo \"\"\n\n    # Remove fastq files from working directory\n    echo \"Removing ${line} from directory\"\n    rm \"${line}\"\n    echo \"Removed ${line} from directory\"\n    echo \"\"\ndone < ${fastq_list}\n\n# Run MultiQC\n${programs_array[multiqc]} .\n\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n  # Handle samtools help menus\n  if [[ \"${program}\" == \"samtools_index\" ]] \\\n  || [[ \"${program}\" == \"samtools_sort\" ]] \\\n  || [[ \"${program}\" == \"samtools_view\" ]]\n  then\n    ${programs_array[$program]}\n  fi\n    ${programs_array[$program]} -h\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\n\n  # If MultiQC is in programs_array, copy the config file to this directory.\n  if [[ \"${program}\" == \"multiqc\" ]]; then\n    cp --preserve ~/.multiqc_config.yaml .\n  fi\ndone\n\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nRESULTS\nRuntime was relatively quick, ~18mins:\n\n\n\nFastQC runtime on Mox\n\n\nWill add links to individual FastQC reports to our Nightingales Google Sheet\nOutput folder:\n\n20201110_cgig_fastqc_ronit-ploidy-wgbs\n\nMultiQC Report (HTML - open with web browser):\n\nmultiqc_report.html\n\n\nIndividual FastQC Reports:\n\nzr3534_10_R1_fastqc.html\nzr3534_10_R2_fastqc.html\nzr3534_1_R1_fastqc.html\nzr3534_1_R2_fastqc.html\nzr3534_2_R1_fastqc.html\nzr3534_2_R2_fastqc.html\nzr3534_3_R1_fastqc.html\nzr3534_3_R2_fastqc.html\nzr3534_4_R1_fastqc.html\nzr3534_4_R2_fastqc.html\nzr3534_5_R1_fastqc.html\nzr3534_5_R2_fastqc.html\nzr3534_6_R1_fastqc.html\nzr3534_6_R2_fastqc.html\nzr3534_7_R1_fastqc.html\nzr3534_7_R2_fastqc.html\nzr3534_8_R1_fastqc.html\nzr3534_8_R2_fastqc.html\nzr3534_9_R1_fastqc.html\nzr3534_9_R2_fastqc.html"
  },
  {
    "objectID": "posts/2020/2020-01-03-Transcriptome-Annotation---C.bairdi-Using-DIAMOND-BLASTx-on-Mox-and-MEGAN6-Meganizer/index.html",
    "href": "posts/2020/2020-01-03-Transcriptome-Annotation---C.bairdi-Using-DIAMOND-BLASTx-on-Mox-and-MEGAN6-Meganizer/index.html",
    "title": "Transcriptome Annotation - C.bairdi Using DIAMOND BLASTx on Mox and MEGAN6 Meganizer",
    "section": "",
    "text": "Although I previously annotated our C.bairdi transcriptome from 20191218, I realized that the assembly and annotations were combine infected/uninfected samples, possibly making separating crab/Hematodinium sequences a bit more difficult.\nI also realized that the MEGAN6 software that I’d previously used for metagenomic taxonomic classification can actually extract sequencing reads. So, I decided to run all of our Tanner crab RNAseq reads through the MEGAN6 process. At the end, I’ll separate out reads, based on taxonomy, and then generate “clean” de novo assemblies of Tanner crab and Hematodinium!\nTo start this process, the trimmed reads need to be annotated using DIAMOND BLASTx. Then, the DIAMOND output files need to be “meganized” for importing to MEGAN6.\nDIAMOND BLASTx took place on Mox, while “meganization” took place on my lab computer (swoose); this is due to the way that MEGAN6 uses Java - it doesn’t run properly on Mox.\nFor reference, these include RNAseq data using a newly established “shorthand”: 2018, 2019.\nSBATCH script (GitHub):\n\n20200103_cbai_diamond_blastx.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_blastx_DIAMOND\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=20-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200103_cbai_diamond_blastx\n\n## Perform DIAMOND BLASTx on trimmed Chionoecetes bairdi (Tanner crab) FastQ files.\n\n## Trimmed FastQ files originated here:\n## https://gannet.fish.washington.edu/Atumefaciens/20191218_cbai_fastp_RNAseq_trimming/\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\n# Program paths\ndiamond=/gscratch/srlab/programs/diamond-0.9.29/diamond\n\n# DIAMOND NCBI nr database\ndmnd=/gscratch/srlab/blastdbs/ncbi-nr-20190925/nr.dmnd\n\n\n# FastQ files directory\nfastq_dir=/gscratch/srlab/sam/data/C_bairdi/RNAseq/\n\n\n# Loop through FastQ files, log filenames to fastq_list.txt.\n# Run DIAMOND on each FastQ\nfor fastq in ${fastq_dir}*fastp-trim*.fq.gz\ndo\n    # Log input FastQs\n    echo \"${fastq}\" >> fastq_list.txt\n\n    # Strip leading path and extensions\n    no_path=$(echo \"${fastq##*/}\")\n    no_ext=$(echo \"${no_path%%.*}\")\n\n    # Run DIAMOND with blastx\n    # Output format 100 produces a DAA binary file for use with MEGAN\n    ${diamond} blastx \\\n    --db ${dmnd} \\\n    --query \"${fastq}\" \\\n    --out \"${no_ext}\".blastx.daa \\\n    --outfmt 100 \\\n    --top 5 \\\n    --block-size 15.0 \\\n    --index-chunks 4\ndone\nMEGANIZER script (GitHub):\n\n20200107_cbai_diamond_blastx_meganizer.sh\n\n#!/bin/bash\n\n# Script to run MEGAN6 meganizer on DIAMOND DAA files from\n# 20200103_cbai_diamond_blastx Mox job.\n\n# Requires MEGAN mapping files from:\n# http://ab.inf.uni-tuebingen.de/data/software/megan6/download/\n\n# Program path\nmeganizer=/home/sam/programs/megan/tools/daa-meganizer\n\n# MEGAN mapping files\nprot_acc2tax=/home/sam/data/databases/MEGAN/prot_acc2tax-Jul2019X1.abin\nacc2interpro=/home/sam/data/databases/MEGAN/acc2interpro-Jul2019X.abin\nacc2eggnog=/home/sam/data/databases/MEGAN/acc2eggnog-Jul2019X.abin\n\n# Variables\nthreads=20\n\n## Run MEGANIZER\n\n# Capture start \"time\"\nstart=${SECONDS}\nfor daa in *.daa\ndo\n  ${meganizer} \\\n  --in \"${daa}\" \\\n    --threads \"${threads}\" \\\n    --acc2taxa ${prot_acc2tax} \\\n    --acc2interpro2go ${acc2interpro} \\\n    --acc2eggnog ${acc2eggnog}\ndone\n\n# Caputure end \"time\"\nend=${SECONDS}\n\nruntime=$((end-start))\n\n# Print MEGANIZER runtime, in seconds\necho \"Runtime was: ${runtime} seconds\"\n\n\nRESULTS\nRuntime was just a bit over two days (but, it sat in the queue for a full day before being able to run):\n\n\n\nDIAMOND BLASTx runtime\n\n\nOutput folder:\n\n20200103_cbai_diamond_blastx/\n\nNow that this is complete, I will proceed with using importing into MEGAN6, to create rma6 file and then separately extract crab reads and Hematodinium reads. These will then be used to generate “clean” transcriptome assemblies for Tanner crab and Hematodinium.\nHere’s the full list of MEGANIZED DIAMOND daa files and their sizes (note: they’re huge files):\n\n304428_S1_L001_R1_001.blastx.daa (56GB)\n304428_S1_L001_R2_001.blastx.daa (54GB)\n304428_S1_L002_R1_001.blastx.daa (54GB)\n304428_S1_L002_R2_001.blastx.daa (52GB)\n329774_S1_L001_R1_001.blastx.daa (39GB)\n329774_S1_L001_R2_001.blastx.daa (36GB)\n329774_S1_L002_R1_001.blastx.daa (34GB)\n329774_S1_L002_R2_001.blastx.daa (32GB)\n329775_S2_L001_R1_001.blastx.daa (40GB)\n329775_S2_L001_R2_001.blastx.daa (36GB)\n329775_S2_L002_R1_001.blastx.daa (37GB)\n329775_S2_L002_R2_001.blastx.daa (32GB)\n329776_S3_L001_R1_001.blastx.daa (35GB)\n329776_S3_L001_R2_001.blastx.daa (32GB)\n329776_S3_L002_R1_001.blastx.daa (30GB)\n329776_S3_L002_R2_001.blastx.daa (29GB)\n329777_S4_L001_R1_001.blastx.daa (40GB)\n329777_S4_L001_R2_001.blastx.daa (34GB)\n329777_S4_L002_R1_001.blastx.daa (36GB)\n329777_S4_L002_R2_001.blastx.daa (31GB)"
  },
  {
    "objectID": "posts/2020/2020-05-23-Transcriptome-Assembly---P.trituberculatus-Japanese-blue-crab-NCBI-SRA-BioProject-PRJNA597187-Data-with-Trinity-on-Mox/index.html",
    "href": "posts/2020/2020-05-23-Transcriptome-Assembly---P.trituberculatus-Japanese-blue-crab-NCBI-SRA-BioProject-PRJNA597187-Data-with-Trinity-on-Mox/index.html",
    "title": "Transcriptome Assembly - P.trituberculatus (Japanese blue crab) NCBI SRA BioProject PRJNA597187 Data with Trinity on Mox",
    "section": "",
    "text": "After generating a number of C.bairdi (Tanner crab) transcriptomes, we decided we should compare them to evaluate which to help decide which one should become our “canonical” version. As part of that, the Trinity wiki offers a list of tools that one can use to check the quality of transcriptome assemblies. Some of those require a transcriptome of a related species.\nA cursory search didn’t yield anything that jumped out at me, so I downloaded (and checked strandedness) of NCBI SRA RNAseq data for P.trituberculatus (Japanese blue crab) and decided to assemble a transcriptome myself.\nRan Trinity on Mox.\nSBATCH script (GitHub):\n\n20200523_ptri_trinity_transcriptome.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=trinity_cbai\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=12-00:00:00\n## Memory per node\n#SBATCH --mem=500G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200523_ptri_trinity_transcriptome\n\n\n### Trinity de novo assembly of all pooled P.trituberculatus RNAseq data.\n### Assembly to be used for assessing our C.bairdi transcriptome assemblies.\n### Data was taken from NCBI SRA BioProject PRJNA597187.\n### See fastq.list.txt file for list of input files used for assembly.\n\n# Exit script if a command fails\nset -e\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# User-defined variables\nreads_dir=/gscratch/srlab/sam/data/P_trituberculatus/RNAseq\ntranscriptome_dir=/gscratch/srlab/sam/data/P_trituberculatus/transcriptomes\nthreads=28\nassembly_stats=assembly_stats.txt\ntimestamp=$(date +%Y%m%d)\nfasta_name=\"${timestamp}.P_trituberculatus.Trinity.fasta\"\n\n# Paths to programs\ntrinity_dir=\"/gscratch/srlab/programs/trinityrnaseq-v2.9.0\"\nsamtools=\"/gscratch/srlab/programs/samtools-1.10/samtools\"\n\n\n## Inititalize arrays\nR1_array=()\nR2_array=()\n\n# Variables for R1/R2 lists\nR1_list=\"\"\nR2_list=\"\"\n\n# Create array of fastq R1 files\nR1_array=(\"${reads_dir}\"/*.fastq)\n\n# Create array of fastq R2 files\nR2_array=(\"${reads_dir}\"/*.fastq)\n\n# Create list of fastq files used in analysis\n## Uses parameter substitution to strip leading path from filename\nfor fastq in \"${reads_dir}\"/*.fastq\ndo\n  echo \"${fastq##*/}\" >> fastq.list.txt\ndone\n\n# Create comma-separated lists of FastQ reads\nR1_list=$(echo \"${R1_array[@]}\" | tr \" \" \",\")\nR2_list=$(echo \"${R2_array[@]}\" | tr \" \" \",\")\n\n\n# Run Trinity\n# Running as stranded, based off of analysis on 20200521:\n# https://robertslab.github.io/sams-notebook/2020/05/21/SRA-Library-Assessment-Determine-RNAseq-Library-Strandedness-from-P.trituberculatus-SRA-BioProject-PRJNA597187.html\n${trinity_dir}/Trinity \\\n--seqType fq \\\n--max_memory 500G \\\n--CPU ${threads} \\\n--SS_lib_type RF \\\n--left \"${R1_list}\" \\\n--right \"${R2_list}\"\n\n# Rename generic assembly FastA\nmv trinity_out_dir/Trinity.fasta trinity_out_dir/\"${fasta_name}\"\n\n# Assembly stats\n${trinity_dir}/util/TrinityStats.pl trinity_out_dir/\"${fasta_name}\" \\\n> ${assembly_stats}\n\n# Create gene map files\n${trinity_dir}/util/support_scripts/get_Trinity_gene_to_trans_map.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n> trinity_out_dir/\"${fasta_name}\".gene_trans_map\n\n# Create sequence lengths file (used for differential gene expression)\n${trinity_dir}/util/misc/fasta_seq_length.pl \\\ntrinity_out_dir/\"${fasta_name}\" \\\n> trinity_out_dir/\"${fasta_name}\".seq_lens\n\n# Create FastA index\n${samtools} faidx \\\ntrinity_out_dir/\"${fasta_name}\"\n\n# Copy files to transcriptome directory\nrsync -av \\\ntrinity_out_dir/\"${fasta_name}\"* \\\n${transcriptome_dir}\n\n# Generate FastA MD5 checksum\n# See last line of SLURM output file\ncd trinity_out_dir\nmd5sum \"${fasta_name}\" > \"${fasta_name}\".checksum.md5\n\n\nRESULTS\nTook ~2 days to run:\n\n\n\nptri trinity assembly runtime\n\n\nThis assembly did hit a small hiccup during the Butterfly portion where it hung indefinitely. I posted an issue on the Trinity GitHub Issues and received instructions on how to resolve it. Apparently, it was due to a very high number of low complexity sequences. Check that issue for info on how it was resolved.\nAlso, while this was running, I ended up tracking down two additional crab transcriptomes on NCBI:\n\nCarcinus maenas (European green crab; Thanks to Grace)\nPortunus trituberculatus\n\nSo, I don’t really need the resulting transcriptome assembly… Oh well, here it is anyway!\nOutput folder:\n\n20200523_ptri_trinity_transcriptome\n\nFastA:\n\n20200523_ptri_trinity_transcriptome/trinity_out_dir/20200526.P_trituberculatus.Trinity.fasta (386MB)\n\nFastA Index:\n\n20200523_ptri_trinity_transcriptome/trinity_out_dir/20200526.P_trituberculatus.Trinity.fasta.fai\n\nAssembly stats (text):\n\n20200523_ptri_trinity_transcriptome/assembly_stats.txt\n\n################################\n## Counts of transcripts, etc.\n################################\nTotal trinity 'genes':  408543\nTotal trinity transcripts:  580098\nPercent GC: 44.63\n\n########################################\nStats based on ALL transcript contigs:\n########################################\n\n    Contig N10: 3865\n    Contig N20: 2697\n    Contig N30: 1980\n    Contig N40: 1442\n    Contig N50: 1012\n\n    Median contig length: 331\n    Average contig: 628.37\n    Total assembled bases: 364514830\n\n\n#####################################################\n## Stats based on ONLY LONGEST ISOFORM per 'GENE':\n#####################################################\n\n    Contig N10: 3226\n    Contig N20: 2047\n    Contig N30: 1310\n    Contig N40: 840\n    Contig N50: 564\n\n    Median contig length: 284\n    Average contig: 483.10\n    Total assembled bases: 197366539"
  },
  {
    "objectID": "posts/2020/2020-11-03-RNAseq-Alignments---Trimmed-S.salar-RNAseq-to-GCF_000233375.1_ICSASG_v2_genomic.fa-Using-Hisat2-on-Mox/index.html",
    "href": "posts/2020/2020-11-03-RNAseq-Alignments---Trimmed-S.salar-RNAseq-to-GCF_000233375.1_ICSASG_v2_genomic.fa-Using-Hisat2-on-Mox/index.html",
    "title": "RNAseq Alignments - Trimmed S.salar RNAseq to GCF_000233375.1_ICSASG_v2_genomic.fa Using Hisat2 on Mox",
    "section": "",
    "text": "This is a continuation of addressing Shelly Trigg’s (regarding some Salmo salar RNAseq data) request (GitHub Issue) to trim (completed 20201029), perform genome alignment, and transcriptome alignment.\nRan HISAT2 with the trimmed FastQ files from 20201029 with the following options:\n\n--dta: This stands for “downstream transcriptome alignment”. Since we’ll be performing a subsequent alignment using the transcriptome using StringTie, I decided to add this option.\n--new-summary: This creates a summary file that can be easily read by MultiQC.\n\nThis was run on Mox.\nSBATCH script (GitHub):\n\n20201103_ssal_RNAseq_hisat2_alignment.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=20201103_ssal_RNAseq_hisat2_alignment\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=200G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20201103_ssal_RNAseq_hisat2_alignment\n\n\n### S.salar RNAseq Hisat2 alignment.\n\n### Uses fastp-trimmed FastQ files from 20201029.\n\n### Uses GCF_000233375.1_ICSASG_v2_genomic.fa as reference,\n### created by Shelly Trigg.\n### This is a subset of the NCBI RefSeq GCF_000233375.1_ICSASG_v2_genomic.fna.\n### Includes only \"chromosome\" sequence entries.\n\n\n\n###################################################################################\n# These variables need to be set by user\n\n## Assign Variables\n\n# Set number of CPUs to use\nthreads=27\n\n# Input/output files\nfastq_checksums=fastq_checksums.md5\nfastq_dir=\"/gscratch/srlab/sam/data/S_salar/RNAseq/\"\ngenome_fasta=\"/gscratch/srlab/sam/data/S_salar/genomes/GCF_000233375.1_ICSASG_v2_genomic.fa\"\n\ngenome_index_name=\"GCF_000233375.1_ICSASG_v2\"\n\n# Paths to programs\nhisat2_dir=\"/gscratch/srlab/programs/hisat2-2.1.0\"\nhisat2=\"${hisat2_dir}/hisat2\"\nhisat2_build=\"${hisat2_dir}/hisat2-build\"\nsamtools=\"/gscratch/srlab/programs/samtools-1.10/samtools\"\n\n## Inititalize arrays\nfastq_array_R1=()\nfastq_array_R2=()\nnames_array=()\n\n\n\n# Programs associative array\ndeclare -A programs_array\nprograms_array=(\n[hisat2]=\"${hisat2}\" \\\n[hisat2-build]=\"${hisat2_build}\"\n[samtools_index]=\"${samtools} index\" \\\n[samtools_sort]=\"${samtools} sort\" \\\n[samtools_view]=\"${samtools} view\"\n)\n\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Capture date\ntimestamp=$(date +%Y%m%d)\n\n# Create array of fastq R1 files\nfor fastq in \"${fastq_dir}\"*_1.fastp-trim.20201029.fq.gz\ndo\n    fastq_array_R1+=(\"${fastq}\")\n  # Create array of sample names\n  ## Uses parameter substitution to strip leading path from filename\n  ## Uses awk to parse out sample name from filename\n  names_array+=($(echo \"${fastq#${fastq_dir}}\" | awk -F\"[_]\" '{print $1 \"_\" $2}'))\ndone\n\n# Create array of fastq R2 files\nfor fastq in \"${fastq_dir}\"*_2.fastp-trim.20201029.fq.gz\ndo\n  fastq_array_R2+=(\"${fastq}\")\ndone\n\n\n# Build Hisat2 reference index\n\"${programs_array[hisat2-build]}\" \\\n\"${genome_fasta}\" \\\n\"${genome_index_name}\" \\\n-p \"${threads}\" \\\n2> hisat2_build.err\n\n\n# Hisat2 alignments\nfor index in \"${!fastq_array_R1[@]}\"\ndo\n  # Get current sample name\n  sample_name=$(echo \"${names_array[index]}\")\n\n  # Run Hisat2\n  # Sets --dta which tailors output for downstream transcriptome assemblers (e.g. Stringtie)\n  # Sets --new-summary option for use with MultiQC\n  \"${programs_array[hisat2]}\" \\\n  -x \"${genome_index_name}\" \\\n  --dta \\\n  --new-summary \\\n  -1 \"${fastq_array_R1[index]}\" \\\n  -2 \"${fastq_array_R2[index]}\" \\\n  -S \"${sample_name}\".sam \\\n  2> \"${sample_name}\"_hisat2.err\n# Sort SAM files, convert to BAM\n  ${programs_array[samtools_view]} \\\n  -@ \"${threads}\" \\\n  -Su \"${sample_name}\".sam \\\n  | ${programs_array[samtools_sort]} - \\\n  -@ \"${threads}\" \\\n  -o \"${sample_name}\".sorted.bam\n  # Index sorted BAM file\n  ${programs_array[samtools_index]} \"${sample_name}\".sorted.bam\ndone\n\n# Create list of fastq files used in analysis\n## Uses parameter substitution to strip leading path from filename\nfor fastq in \"${fastq_dir}\"*fastp-trim.20201029.fq.gz\ndo\n  echo \"${fastq#${fastq_dir}}\" >> fastq.list.txt\n  md5sum \"${fastq}\" >> ${fastq_checksums}\ndone\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n  # Handle samtools help menus\n  if [[ \"${program}\" == \"samtools_index\" ]] \\\n  || [[ \"${program}\" == \"samtools_sort\" ]] \\\n  || [[ \"${program}\" == \"samtools_view\" ]]\n  then\n    ${programs_array[$program]}\n  fi\n    ${programs_array[$program]} -h\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\n\n  # If MultiQC is in programs_array, copy the config file to this directory.\n  if [[ \"${program}\" == \"multiqc\" ]]; then\n    cp --preserve ~/.multiqc_config.yaml \"${timestamp}_multiqc_config.yaml\"\n  fi\ndone\n\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\nNOTE: I manually removed the SAM files that were generated during this process. This step was not included in the SBATCH script above because I didn’t realize the SAM files would remain after creating the (desired) BAM files. The SAM files were very large and not necessary for downstream analysis.\n\n\nRESULTS\nRuntime was close to 3hrs:\n\n\n\nCumulative HISAT2 runtime on Mox\n\n\nOutput folder:\n\n20201103_ssal_RNAseq_hisat2_alignment/\n\nBAM files for each alignment are linked below. The BAM files will be used for subsequent usage in StringTie. Additionally, each BAM file has an associated index file and a HISAT2 “error” file. This “error” file is actually the summary report of the alignment and will be used by MultiQC later on. In the future, I’ll try to remember to change the labelling for this…\n\nPool26_16.sorted.bam (2.4G)\n\nPool26_16.sorted.bam.bai (2.3M)\nPool26_16_hisat2.err (4.0K)\n\nPool26_8.sorted.bam (2.5G)\n\nPool26_8.sorted.bam.bai (2.3M)\nPool26_8_hisat2.err (4.0K)\n\nPool32_16.sorted.bam (1.9G)\n\nPool32_16.sorted.bam.bai (2.2M)\nPool32_16_hisat2.err (4.0K)\n\nPool32_8.sorted.bam (2.4G)\n\nPool32_8.sorted.bam.bai (2.3M)\nPool32_8_hisat2.err (4.0K)"
  },
  {
    "objectID": "posts/2020/2020-12-06-FastQC-MultiQc---C.gigas-Ploidy-pH-WGBS-Raw-Sequence-Data-from-Haws-Lab-on-Mox/index.html",
    "href": "posts/2020/2020-12-06-FastQC-MultiQc---C.gigas-Ploidy-pH-WGBS-Raw-Sequence-Data-from-Haws-Lab-on-Mox/index.html",
    "title": "FastQC-MultiQc - C.gigas Ploidy pH WGBS Raw Sequence Data from Haws Lab on Mox",
    "section": "",
    "text": "Yesterday (20201205), we received the whole genome bisulfite sequencing (WGBS) data back from ZymoResearch from the 24 C.gigas diploid/triploid subjected to two different pH treatments (received from the Haws’ Lab on 20200820 that we submitted to ZymoResearch on 20200824. As part of our standard sequencing data receipt pipeline, I needed to generate FastQC files for each sample.\nFastQC was run on Mox.\nLinks to FastQC reports will be added to our NGS database spreadsheet, Nightingales (Google Sheet).\nSBATCH script (GitHub):\n\n20201206_cgig_fastqc_multiqc_ploidy-pH-wgbs.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=20201206_cgig_fastqc_multiqc_ploidy-pH-wgbs\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20201206_cgig_fastqc_multiqc_ploidy-pH-wgbs\n\n\n### FastQC assessment of raw sequencing from Haw's Lab ploidy pH WGBS.\n\n\n###################################################################################\n# These variables need to be set by user\n\n# FastQC output directory\noutput_dir=$(pwd)\n\n# Set number of CPUs to use\nthreads=28\n\n# Input/output files\nchecksums=fastq_checksums.md5\nfastq_list=fastq_list.txt\nraw_reads_dir=/gscratch/srlab/sam/data/C_gigas/wgbs/\n\n# Paths to programs\nfastqc=/gscratch/srlab/programs/fastqc_v0.11.9/fastqc\nmultiqc=/gscratch/srlab/programs/anaconda3/bin/multiqc\n\n\n# Programs associative array\ndeclare -A programs_array\nprograms_array=(\n[fastqc]=\"${fastqc}\" \\\n[multiqc]=\"${multiqc}\"\n)\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Sync raw FastQ files to working directory\nrsync --archive --verbose \\\n\"${raw_reads_dir}\"zr3644*.fq.gz .\n\n# Populate array with FastQ files\nfastq_array=(*.fq.gz)\n\n# Pass array contents to new variable\nfastqc_list=$(echo \"${fastq_array[*]}\")\n\n# Run FastQC\n# NOTE: Do NOT quote ${fastqc_list}\n${programs_array[fastqc]} \\\n--threads ${threads} \\\n--outdir ${output_dir} \\\n${fastqc_list}\n\n\n# Create list of fastq files used in analysis\necho \"${fastqc_list}\" | tr \" \" \"\\n\" >> ${fastq_list}\n\n# Generate checksums for reference\nwhile read -r line\ndo\n\n    # Generate MD5 checksums for each input FastQ file\n    echo \"Generating MD5 checksum for ${line}.\"\n    md5sum \"${line}\" >> \"${checksums}\"\n    echo \"Completed: MD5 checksum for ${line}.\"\n    echo \"\"\n\n    # Remove fastq files from working directory\n    echo \"Removing ${line} from directory\"\n    rm \"${line}\"\n    echo \"Removed ${line} from directory\"\n    echo \"\"\ndone < ${fastq_list}\n\n# Run MultiQC\n${programs_array[multiqc]} .\n\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n  # Handle samtools help menus\n  if [[ \"${program}\" == \"samtools_index\" ]] \\\n  || [[ \"${program}\" == \"samtools_sort\" ]] \\\n  || [[ \"${program}\" == \"samtools_view\" ]]\n  then\n    ${programs_array[$program]}\n  fi\n    ${programs_array[$program]} -h\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\n\n  # If MultiQC is in programs_array, copy the config file to this directory.\n  if [[ \"${program}\" == \"multiqc\" ]]; then\n    cp --preserve ~/.multiqc_config.yaml multiqc_config.yaml\n  fi\ndone\n\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nRESULTS\nRuntime was ~30mins:\n\n\n\nFastQC and MultiQC cumulative runtime on Mox\n\n\nOutput folder:\n\n20201206_cgig_fastqc_multiqc_ploidy-pH-wgbs\n\nFastQ MD5 checksums (TEXT):\n\nfastq_checksums.md5\n\nMultiQC Report (HTML; open in web browser):\n\nmultiqc_report.html\n\nIndividual FastQC Reports (HTML; open in web browser):\n\nzr3644_10_R1_fastqc.html\nzr3644_10_R2_fastqc.html\nzr3644_11_R1_fastqc.html\nzr3644_11_R2_fastqc.html\nzr3644_12_R1_fastqc.html\nzr3644_12_R2_fastqc.html\nzr3644_13_R1_fastqc.html\nzr3644_13_R2_fastqc.html\nzr3644_14_R1_fastqc.html\nzr3644_14_R2_fastqc.html\nzr3644_15_R1_fastqc.html\nzr3644_15_R2_fastqc.html\nzr3644_16_R1_fastqc.html\nzr3644_16_R2_fastqc.html\nzr3644_17_R1_fastqc.html\nzr3644_17_R2_fastqc.html\nzr3644_18_R1_fastqc.html\nzr3644_18_R2_fastqc.html\nzr3644_19_R1_fastqc.html\nzr3644_19_R2_fastqc.html\nzr3644_1_R1_fastqc.html\nzr3644_1_R2_fastqc.html\nzr3644_20_R1_fastqc.html\nzr3644_20_R2_fastqc.html\nzr3644_21_R1_fastqc.html\nzr3644_21_R2_fastqc.html\nzr3644_22_R1_fastqc.html\nzr3644_22_R2_fastqc.html\nzr3644_23_R1_fastqc.html\nzr3644_23_R2_fastqc.html\nzr3644_24_R1_fastqc.html\nzr3644_24_R2_fastqc.html\nzr3644_2_R1_fastqc.html\nzr3644_2_R2_fastqc.html\nzr3644_3_R1_fastqc.html\nzr3644_3_R2_fastqc.html\nzr3644_4_R1_fastqc.html\nzr3644_4_R2_fastqc.html\nzr3644_5_R1_fastqc.html\nzr3644_5_R2_fastqc.html\nzr3644_6_R1_fastqc.html\nzr3644_6_R2_fastqc.html\nzr3644_7_R1_fastqc.html\nzr3644_7_R2_fastqc.html\nzr3644_8_R1_fastqc.html\nzr3644_8_R2_fastqc.html\nzr3644_9_R1_fastqc.html\nzr3644_9_R2_fastqc.html"
  },
  {
    "objectID": "posts/2020/2020-09-17-Taxonomic-Assignments---C.bairdi-NanoPore-Reads-Using-DIAMOND-BLASTx-on-Mox-and-MEGAN6-daa2rma-on-swoose/index.html",
    "href": "posts/2020/2020-09-17-Taxonomic-Assignments---C.bairdi-NanoPore-Reads-Using-DIAMOND-BLASTx-on-Mox-and-MEGAN6-daa2rma-on-swoose/index.html",
    "title": "Taxonomic Assignments - C.bairdi NanoPore Reads Using DIAMOND BLASTx on Mox and MEGAN6 daa2rma on swoose",
    "section": "",
    "text": "Earlier today I quality filtered (>=Q7) our C.baird NanoPore reads. One of the things I’d like to do now is to attempt to filter reads taxonomically, since the NanoPore data came from both an uninfected crab and Hematodinium-infected crab.\nI ran DIAMOND BLASTx (on Mox), followed by MEGAN6 daa2rma (on swoose - MEGAN6 requires some weird Java X11 thingy that won’t work on Mox) to convert the DIAMOND output to the proper MEGAN6 format for visualizing taxonomic assignments.\nSBATCH script (GitHub) for DIAMOND BLASTx on Mox:\n\n20200917_cbai_diamond_blastx_nanopore_all_Q7.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_blastx_DIAMOND_nanopore_all\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=200G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200917_cbai_diamond_blastx_nanopore_all_Q7\n\n# Script to run DIAMOND BLASTx on all quality filtered (Q7) C.bairdi NanoPore reads\n# from 20200917 using the --long-reads option\n# for subsequent import into MEGAN6 to try to separate reads taxonomically.\n\n###################################################################################\n# These variables need to be set by user\n\n# Input FastQ file\nfastq=/gscratch/srlab/sam/data/C_bairdi/DNAseq/20200917_cbai_nanopore_all_quality-7.fastq\n\n# DIAMOND Output filename prefix\nprefix=20200917_cbai_diamond_blastx_nanopore_all_Q7\n\n# Set number of CPUs to use\nthreads=28\n\n# Program paths\ndiamond=/gscratch/srlab/programs/diamond-2.0.4/diamond\n\n# DIAMOND NCBI nr database with taxonomy dumps\ndmnd_db=/gscratch/srlab/blastdbs/ncbi-nr-20190925/nr.dmnd\n\n\n###################################################################################\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# SegFault fix?\nexport THREADS_DAEMON_MODEL=1\n\n\n# Inititalize arrays\nprograms_array=()\n\n\n# Programs array\nprograms_array=(\"${diamond}\")\n\n\nmd5sum \"${fastq}\" > fastq_checksums.md5\n\n\n# Run DIAMOND with blastx\n# Output format 6 produces a standard BLAST tab-delimited file\n# Run DIAMOND with blastx\n# Output format 100 produces a DAA binary file for use with MEGAN\n${diamond} blastx \\\n--long-reads \\\n--db ${dmnd_db} \\\n--query \"${fastq}\" \\\n--out \"${prefix}\".blastx.daa \\\n--outfmt 100 \\\n--top 5 \\\n--block-size 8.0 \\\n--index-chunks 1 \\\n--threads ${threads}\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${programs_array[program]}: \"\n    echo \"\"\n    ${programs_array[program]} help\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\nBash script (GitHub) for daa2rma on Emu:\n\n20200917_cbai_nanopore_diamond_blastx_daa2rma.sh\n\n#!/bin/bash\n\n# Script to run MEGAN6 daa2rma on DIAMOND DAA files from\n# 20200917_cbai_diamond_blastx_nanopore_all_Q7.\n# Utilizes the --longReads option\n\n# Requires MEGAN mapping file from:\n# http://ab.inf.uni-tuebingen.de/data/software/megan6/download/\n\n\n# MEGAN mapping file\nmegan_map=/home/sam/data/databases/MEGAN6/megan-map-Jul2020-2.db\n\n# Programs array\ndeclare -A programs_array\nprograms_array=(\n[daa2rma]=\"/home/shared/megan_6.19.9/tools/daa2rma\"\n)\n\nthreads=16\n\n#########################################################################\n\n# Exit script if any command fails\nset -e\n\n\n## Run daa2rma\n\n# Capture start \"time\"\n# Uses builtin bash variable called ${SECONDS}\nstart=${SECONDS}\n\nfor daa in *.daa\ndo\n  start_loop=${SECONDS}\n  sample_name=$(basename --suffix \".blastx.daa\" \"${daa}\")\n\n  echo \"Now processing ${sample_name}.daa2rma.rma6\"\n  echo \"\"\n\n  # Run daa2rma with long reads option\n  ${programs_array[daa2rma]} \\\n  --in \"${daa}\" \\\n  --longReads \\\n  --mapDB ${megan_map} \\\n  --out \"${sample_name}\".daa2rma.rma6 \\\n  --threads ${threads} \\\n  2>&1 | tee --append daa2rma_log.txt\n\n  end_loop=${SECONDS}\n  loop_runtime=$((end_loop-start_loop))\n\n\n  echo \"Finished processing ${sample_name}.daa2rma.rma6 in ${loop_runtime} seconds.\"\n  echo \"\"\n\ndone\n\n# Caputure end \"time\"\nend=${SECONDS}\n\nruntime=$((end-start))\n\n# Print daa2rma runtime, in seconds\n\n{\n  echo \"\"\n  echo \"---------------------\"\n  echo \"\"\n  echo \"Total runtime was: ${runtime} seconds\"\n} >> daa2rma_log.txt\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n    ${programs_array[$program]} --help\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n# Document programs in PATH\n{\ndate\necho \"\"\necho \"System PATH:\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nRESULTS\nDIAMOND runtime was pretty quick, 37mins:\n\n\n\nDIAMOND BLASTx runtime of C.baird Q7 NanoPore reads on Mox\n\n\nDIAMOND BLASTx Output folder:\n\n20200917_cbai_diamond_blastx_nanopore_all_Q7/\n\nDIAMOND BLASTx DAA file:\n\n20200917_cbai_diamond_blastx_nanopore_all_Q7/20200917_cbai_diamond_blastx_nanopore_all_Q7.blastx.daa (47MB)\n\n\n\ndaa2rma Output folder:\n\n20200917_cbai_nanopore_diamond_blastx_daa2rma/\n\nRMA6 file:\n\n20200917_cbai_nanopore_diamond_blastx_daa2rma/20200917_cbai_diamond_blastx_nanopore_all_Q7.daa2rma.rma6\n\n\n\nI opened the RMA6 file in MEGAN6 to see the taxonomic breakdown and this is what I got:\n\n\n\nscreencap of MEGAN6 C.bairdi NanoPore Q7 taxonomic assignments; Alveolata, Arthropoda, and E.canceri highlighted\n\n\nNOTE: When using --long-read mode, taxonomic assignments counts are always in aligned bases, not aligned reads!\nWell, the results are pretty intriguing. Here’s a short table of the most intriguing data:\n\n\n\nTaxonomy\nBases\n\n\n\n\nAlveolata\n436,841\n\n\nArthropoda\n35,864,420\n\n\nEnterospora canceri\n18,134,246\n\n\n\nA few things to note:\n\nAs expected, Arthropoda comprises the bulk of assignments.\nAlveolata is far fewer than I expected, but it is important to remember that the NanoPore data analyzed here is from two samples: one uninfected, the other infected, so Hematodinium sequence is going to make up a much smaller proportion of reads/bases.\nEnterospora canceri (a known microsporidian agent of infection in crabs) ha the second most number of bases assigned. AND, this is at the species level, not Phylum level like Arthropoda and Alveolata!\n\nI think I’ve previously noticed a relatively high abundance of Enterospora canceri read assignments in some previous RNAseq taxonomic assignment I performed, but I’ll have to double check…\n\nAlthough not highlighted in the tree/table above, I should not ignore Aquifex sp., which has 6,338,292 bases assigned to it! It turns out that members of the Aquifex genus are thermophylic bacteria… Crabs live on the sea floor (which is where one would find hydrothermal vents), but why would we see such a high abundance of these bacteria in muscle/hemolymph? Very curious!\n\nWhere to go from here. Well, I think I might extract the reads and, well, I don’t know what. Individual genome assemblies? I need to think about this a bit more and probably discuss with Steven."
  },
  {
    "objectID": "posts/2020/2020-11-04-RNAseq-Alignments---S.salar-HISAT2-BAMs-to-GCF_000233375.1_ICSASG_v2_genomic.gtf-Transcriptome-Using-StringTie-on-Mox/index.html",
    "href": "posts/2020/2020-11-04-RNAseq-Alignments---S.salar-HISAT2-BAMs-to-GCF_000233375.1_ICSASG_v2_genomic.gtf-Transcriptome-Using-StringTie-on-Mox/index.html",
    "title": "RNAseq Alignments - S.salar HISAT2 BAMs to GCF_000233375.1_ICSASG_v2_genomic.gtf Transcriptome Using StringTie on Mox",
    "section": "",
    "text": "This is a continuation of addressing Shelly Trigg’s (regarding some Salmo salar RNAseq data) request (GitHub Issue) to trim (completed 20201029), perform genome alignment (completed on 20201103), and transcriptome alignment.\nTo finish this up, I used StringTie to align to a subset of the GCF_000233375.1_ICSASG_v2_genomic.gtf provided by Shelly. I created a subset (see SBATCH script below for deets) that only included the same sequence IDs in Shelly’s subsetted genome Fasta (see genome alignment completed on 20201103 for more info on that.).\nShelly indicated she really just needed the FPKM and/or TPM values, so I ran StringTie with the -A option which spits out a tab-delimited table with both of those values in columns 8 and 9.\nThis was run on Mox.\nSBATCH script (GitHub):\n\n20201104_ssal_RNAseq_stringtie_alignment.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=20201104_ssal_RNAseq_stringtie_alignment\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=200G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20201104_ssal_RNAseq_stringtie_alignment\n\n\n### S.salar RNAseq StringTie alignment.\n\n### Uses BAM alignment files from 20201103 and transcriptome\n### GTF provided by Shelly (presumably GTF is from NCBI).\n\n\n###################################################################################\n# These variables need to be set by user\n\n## Assign Variables\n\nwd=$(pwd)\n\n# Set number of CPUs to use\nthreads=27\n\n# Input/output files\nbam_dir=\"/gscratch/scrubbed/samwhite/outputs/20201103_ssal_RNAseq_hisat2_alignment/\"\nbam_md5s=bam_checksums.md5\ngenome=\"/gscratch/srlab/sam/data/S_salar/genomes/GCF_000233375.1_ICSASG_v2_genomic.fa\"\ngtf_md5=gtf_checksums.md5\nncbi_transcriptome=\"/gscratch/srlab/sam/data/S_salar/transcriptomes/GCF_000233375.1_ICSASG_v2_genomic.gtf\"\nchr_only_transriptome=\"GCF_000233375.1_ICSASG_v2_genomic_NC-chr-only.gtf\"\n# Paths to programs\nstringtie=\"/gscratch/srlab/programs/stringtie-2.1.4.Linux_x86_64/stringtie\"\n\n# Programs associative array\ndeclare -A programs_array\nprograms_array=(\n[stringtie]=\"${stringtie}\"\n)\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Subset transcriptome with NC_ only entries to match Shelly's genome\n# Only lines beginning with \"NC_\"\ngrep \"^NC_\" \"${ncbi_transcriptome}\" >> \"${chr_only_transriptome}\"\n\n\n# Run StringTie\nfor bam in \"${bam_dir}\"*.bam\ndo\n  # Parse out sample name by removing all text up to and including the last period.\n  sample_name_no_path=${bam##*/}\n  sample_name=${sample_name_no_path%%.*}\n\n  # Exectute StringTie\n  # Use list of of chromosome IDs (ref_list)\n  # Output an abundance file with TPM and FPKM data in dedicated columns\n  ${programs_array[stringtie]} \\\n  ${bam} \\\n  -G ${chr_only_transriptome} \\\n  -A ${sample_name}_gene-abund.tab \\\n  -p ${threads}\n\n  # Generate BAM MD5 checksums\n  md5sum \"${bam}\" >> \"${bam_md5s}\"\ndone\n\n\n# Generate GTF MD5 checksum\nmd5sum \"${ncbi_transcriptome}\" >> \"${gtf_md5}\"\nmd5sum \"${chr_only_transriptome}\" >> \"${gtf_md5}\"\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n  # Handle samtools help menus\n  if [[ \"${program}\" == \"samtools_index\" ]] \\\n  || [[ \"${program}\" == \"samtools_sort\" ]] \\\n  || [[ \"${program}\" == \"samtools_view\" ]]\n  then\n    ${programs_array[$program]}\n  fi\n    ${programs_array[$program]} -h\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\n\n  # If MultiQC is in programs_array, copy the config file to this directory.\n  if [[ \"${program}\" == \"multiqc\" ]]; then\n    cp --preserve ~/.multiqc_config.yaml .\n  fi\ndone\n\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nRESULTS\nRuntime was pretty quick, just under 18mins:\n\n\n\nRuntime of StringTie RNAseq alignments on Mox\n\n\nOutput folder/files:\nRuntime was fast; just under 18mins:\n\n\n\nCumulative StringTie runtime on Mox\n\n\n\n20201104_ssal_RNAseq_stringtie_alignment\nSubsetted GTF file used for alignment:\n\nGCF_000233375.1_ICSASG_v2_genomic_NC-chr-only.gtf\n\nAbundance files with FPKM and TPM in columns 8 & 9.\n\nPool26_16_gene-abund.tab\nPool26_8_gene-abund.tab\nPool32_16_gene-abund.tab\nPool32_8_gene-abund.tab"
  },
  {
    "objectID": "posts/2020/2020-03-30-RNAseq-Reads-Extractions---C.bairdi-Taxonomic-Reads-Extractions-with-MEGAN6-on-swoose/index.html",
    "href": "posts/2020/2020-03-30-RNAseq-Reads-Extractions---C.bairdi-Taxonomic-Reads-Extractions-with-MEGAN6-on-swoose/index.html",
    "title": "RNAseq Reads Extractions - C.bairdi Taxonomic Reads Extractions with MEGAN6 on swoose",
    "section": "",
    "text": "I previously annotated reads and converted them to the MEGAN6 format RMA6 on 20200318.\nI’ll use the MEGAN6 GUI to “Open” the RMA6 file. Once the file loads, you get a nice looking taxonomic tree! From here, you can select any part of the taxonomic tree by right-clicking on the desired taxonomy and “Extract reads…”. Here, you have the option to include “Summarized reads”. This option allows you to extract just the reads that are part of the exact classification you’ve selected or all those within and “below” the classification you’ve selected (i.e. summarized reads).\nExtracted reads will be generated as FastA files.\nExample:\nIf you select Arthropoda and do not check the box for “Summarized Reads” you will only get reads classified as Arthropoda! You will not get any reads with more specific taxonomies. However, if you select Arthropoda and you do check the box for “Summarized Reads”, you will get all reads classified as Arthropoda AND all reads in more specific taxonomic classifications, down to the species level.\nI will extract reads from two phyla:\n\nArthropoda (for crabs)\nAlveolata (for Hematodinium)\n\nAfter read extractions using MEGAN6, I’ll need to extract the actual reads from the trimmed FastQ files. This will actually entail extracting all trimmed reads from two different sets of RNAseq:\n\n20191218_cbai_fastp_RNAseq_trimming/\n20200318_cbai_RNAseq_fastp_trimming/\n\nIt’s a bit convoluted, but I realized that the FastA headers were incomplete and did not distinguish between paired reads. Here’s an example:\nR1 FastQ header:\n@A00147:37:HG2WLDMXX:1:1101:5303:1000 1:N:0:AGGCGAAG+AGGCGAAG\nR2 FastQ header:\n@A00147:37:HG2WLDMXX:1:1101:5303:1000 2:N:0:AGGCGAAG+AGGCGAAG\nHowever, the reads extracted via MEGAN have FastA headers like this:\n>A00147:37:HG2WLDMXX:1:1101:5303:1000\nSEQUENCE1\n>A00147:37:HG2WLDMXX:1:1101:5303:1000\nSEQUENCE2\nThose are a set of paired reads, but there’s no way to distinguish between R1/R2. This may not be an issue, but I’m not sure how downstream programs (i.e. Trinity) will handle duplicate FastA IDs as inputs. To avoid any headaches, I’ve decided to parse out the corresponding FastQ reads which have the full header info.\nHere’s a brief rundown of the approach:\n\nCreate list of unique read headers from MEGAN6 FastA files.\nUse list with seqtk program to pull out corresponding FastQ reads from the trimmed FastQ R1 and R2 files.\n\nThis aspect of read extractions/concatenations is documented in the following Jupyter notebook (GitHub):\n\n20200330_swoose_cbai_megan_read_extractions.ipynb\n\n\n\nRESULTS\nOUTPUT FOLDERS\nInitial reads extracted as FastAs:\n\n20200323_cbai_MEGAN_read_extractions/\n\nFastQ C.bairdi read extractions:\n\n20200330.C_bairdi_megan_reads/\n\nFastQ Hematodinium read extractions:\n\n20200330.Hematodinium_megan_reads\n\nThe taxonomic tree from each MEGAN6 RMA6 file is shown below. There are a couple of interesting things to notice from these:\n\nSome samples have a high abundance of reads assigned to Bacteria. My guess is that this was due to a slight misstep in sampling, leading to collecting mostly sea water instead of mostly hemolymph. I say this because in these samples, there are still a large amount of Arthropoda reads, so it’s clear that some hemolymph was collected.\nMost samples which should have reads assigned to Hematodinium (18 samples were considered “infected” via qPCR) do not have any reads assigned. In fact, only four samples ended up having Hematodinium reads extracted:\n\n\n132\n178\n349\n485\n\nAt this point in time, it’s not that big of a deal, since we’re currently just using this data to create an updated transcriptome for each of the two phyla.\n\nMany (most?) of the samples had a relatively high abundance of reads assigned to a microsporidian, Enterospora canceri, a known crab parasite. This is intriguing and not entirely sure what the implications are for analyzing the crab gene expression are. Also, it might be interesting to try to extract these reads and assemble a Enterospora canceri transcriptome…\n\nNext up, creating some updated transcriptome assemblies/annotations for these two phyla.\n\n\n\nTaxonomic Trees\n\n113\n\n\n\n113 MEGAN6 taxonomic tree\n\n\n\n\n\n118\n\n\n\n118 MEGAN6 taxonomic tree\n\n\n\n\n\n127\n\n\n\n127 MEGAN6 taxonomic tree\n\n\n\n\n\n132\n\n\n\n132 MEGAN6 taxonomic tree\n\n\n\n\n\n151\n\n\n\n151 MEGAN6 taxonomic tree\n\n\n\n\n\n173\n\n\n\n173 MEGAN6 taxonomic tree\n\n\n\n\n\n178\n\n\n\n178 MEGAN6 taxonomic tree\n\n\n\n\n\n221\n\n\n\n221 MEGAN6 taxonomic tree\n\n\n\n\n\n222\n\n\n\n222 MEGAN6 taxonomic tree\n\n\n\n\n\n254\n\n\n\n254 MEGAN6 taxonomic tree\n\n\n\n\n\n272\n\n\n\n272 MEGAN6 taxonomic tree\n\n\n\n\n\n280\n\n\n\n280 MEGAN6 taxonomic tree\n\n\n\n\n\n294\n\n\n\n294 MEGAN6 taxonomic tree\n\n\n\n\n\n334\n\n\n\n334 MEGAN6 taxonomic tree\n\n\n\n\n\n349\n\n\n\n349 MEGAN6 taxonomic tree\n\n\n\n\n\n359\n\n\n\n359 MEGAN6 taxonomic tree\n\n\n\n\n\n425\n\n\n\n425 MEGAN6 taxonomic tree\n\n\n\n\n\n427\n\n\n\n427 MEGAN6 taxonomic tree\n\n\n\n\n\n445\n\n\n\n445 MEGAN6 taxonomic tree\n\n\n\n\n\n463\n\n\n\n463 MEGAN6 taxonomic tree\n\n\n\n\n\n481\n\n\n\n481 MEGAN6 taxonomic tree\n\n\n\n\n\n485\n\n\n\n485 MEGAN6 taxonomic tree\n\n\n\n\n\n72\n\n\n\n72 MEGAN6 taxonomic tree\n\n\n\n\n\n73\n\n\n\n73 MEGAN6 taxonomic tree"
  },
  {
    "objectID": "posts/2020/2020-02-10-DNA-Isolation-Quantification-and-Gel---C.bairdi-gDNA-Sample-6129_403_26/index.html",
    "href": "posts/2020/2020-02-10-DNA-Isolation-Quantification-and-Gel---C.bairdi-gDNA-Sample-6129_403_26/index.html",
    "title": "DNA Isolation, Quantification, and Gel - C.bairdi gDNA Sample 6129_403_26",
    "section": "",
    "text": "In order to do some genome sequencing on C.bairid and Hematodinium, we need hihg molecular weight gDNA. I attempted this twice before, using two different methods (Quick DNA/RNA Microprep Kit (ZymoResearch) on 20200122 and the E.Z.N.A Mollusc DNA Kit (Omega) on 20200108) using ~10yr old ethanol-preserved tissue provided by Pam Jensen. Both methods yielded highly degrade gDNA. So, I’m now attempting to get higher quality gDNA from the RNAlater-preserved hemolymph pellets from this experiment.\nUsed the Quick DNA/RNA Microprep Kit (ZymoResearch) to perform four parallel isolations using four separate aliquots of sample 6129_403_26 with the following changes/notes:\n\nUsed 75uL of each hemolyph pellet slurry from each tube\nEluted all columns with a single 30uL elution (i.e. used 30uL for first column, then used that same elution to elute the next column, etc.) to try to concentrate the sample.\n\nDNA was quantified using the Roberts Lab Qubit 3.0, using 1uL of sample, with the ds DNA BR Assay (Invitrogen).\nUsed 4uL of sample (~200ng) to run on 1x low-TAE 0.8% agarose gel.\n\n\nRESULTS\nUPDATE: I isolated additional DNA later in the day and combined this isolation with the one from later. See this post. I’ll leave the original info below for posterity.\n\nQubit results (Google Sheet):\n\n20200210_qubit_crab_gDNA-01\n\n[RNA] = 58.4ng/uL\nYield: 1752ng\n\n\nYields a bit lower than I would’ve liked, but this is isolation is primarily to see what the gDNA integrity looks like from these RNAlater-preserved hemolyph samples.\nSample was stored at -80oC in:\nRack 15, 4, 5 in C.bairdi gDNA Box #2\nGeneRuler HighRange Ladder (ThermoFisher):\n\n\n\nGeneRuler HighRange Ladder\n\n\nGeneRuler DNA Ladder Mix (ThermoFisher):\n\n\n\nGeneRuler DNA Ladder Mix\n\n\n\n\n\n\ngel image of C.bairdi 6129_403_26 gDNA\n\n\nAlrighty, this gDNA looks significantly better than the two previous attempts using the EtOH-preserved tissue. Still smearing, but the bulk of the sample is high molecular weight gDNA, which will be suitable for sequencing via PacBio and/or NanoPore. Will isolate some more DNA in order to get enough to send for PacBio sequencing (need ~4x this amount…)."
  },
  {
    "objectID": "posts/2020/2020-05-19-TransDecoder---C.bairdi-Transcriptome-v3.0-from-20200518-on-Mox/index.html",
    "href": "posts/2020/2020-05-19-TransDecoder---C.bairdi-Transcriptome-v3.0-from-20200518-on-Mox/index.html",
    "title": "TransDecoder - C.bairdi Transcriptome v3.0 from 20200518 on Mox",
    "section": "",
    "text": "Need to run TransDecoder on Mox on the C.bairdi transcriptome v3.0 from 20200518.\nSBATCH script (GitHub):\n\n20200519_cbai_transdecoder_transcriptome-v3.0.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=transdecoder_cbai\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200519_cbai_transdecoder_transcriptome-v3.0\n\n\n# Exit script if a command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n# Set workind directory as current directory\nwd=\"$(pwd)\"\n\n# Capture date as YYYYMMDD\ntimestamp=$(date +%Y%m%d)\n\n# Set input file locations and species designation\ntrinity_fasta=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v3.0.fasta\"\ntrinity_gene_map=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v3.0.fasta.gene_trans_map\"\nspecies=\"cbai\"\n\n# Capture trinity file name\ntrinity_fasta_name=${trinity_fasta##*/}\n\n\n\n# Paths to input/output files\nblastp_out_dir=\"${wd}/blastp_out\"\ntransdecoder_out_dir=\"${wd}/${trinity_fasta_name}.transdecoder_dir\"\npfam_out_dir=\"${wd}/pfam_out\"\nblastp_out=\"${blastp_out_dir}/${timestamp}.${species}.blastp.outfmt6\"\npfam_out=\"${pfam_out_dir}/${timestamp}.${species}.pfam.domtblout\"\nlORFs_pep=\"${transdecoder_out_dir}/longest_orfs.pep\"\npfam_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/Pfam-A.hmm\"\nsp_db=\"/gscratch/srlab/programs/Trinotate-v3.1.1/admin/uniprot_sprot.pep\"\n\n\n\n# Paths to programs\nblast_dir=\"/gscratch/srlab/programs/ncbi-blast-2.8.1+/bin\"\nblastp=\"${blast_dir}/blastp\"\nhmmer_dir=\"/gscratch/srlab/programs/hmmer-3.2.1/src\"\nhmmscan=\"${hmmer_dir}/hmmscan\"\ntransdecoder_dir=\"/gscratch/srlab/programs/TransDecoder-v5.5.0\"\ntransdecoder_lORFs=\"${transdecoder_dir}/TransDecoder.LongOrfs\"\ntransdecoder_predict=\"${transdecoder_dir}/TransDecoder.Predict\"\n\n# Capture FastA MD5 checksum for future reference\nmd5sum \"${trinity_fasta}\" >> fasta.checksum.md5\n\n# Make output directories\nmkdir \"${blastp_out_dir}\"\nmkdir \"${pfam_out_dir}\"\n\n# Extract long open reading frames\n\"${transdecoder_lORFs}\" \\\n--gene_trans_map \"${trinity_gene_map}\" \\\n-t \"${trinity_fasta}\"\n\n# Run blastp on long ORFs\n\"${blastp}\" \\\n-query \"${lORFs_pep}\" \\\n-db \"${sp_db}\" \\\n-max_target_seqs 1 \\\n-outfmt 6 \\\n-evalue 1e-5 \\\n-num_threads 28 \\\n> \"${blastp_out}\"\n\n# Run pfam search\n\"${hmmscan}\" \\\n--cpu 28 \\\n--domtblout \"${pfam_out}\" \\\n\"${pfam_db}\" \\\n\"${lORFs_pep}\"\n\n# Run Transdecoder with blastp and Pfam results\n\"${transdecoder_predict}\" \\\n-t \"${trinity_fasta}\" \\\n--retain_pfam_hits \"${pfam_out}\" \\\n--retain_blastp_hits \"${blastp_out}\"\n\n\nRESULTS\nTook about 2.5 days to complete:\n\n\n\ncbai v3.0 TransDecoder runtime\n\n\nOutput folder:\n\n20200519_cbai_transdecoder_transcriptome-v3.0/\n\nCoding Sequences (FastA):\n\ncbai_transcriptome_v3.0.fasta.transdecoder.cds\n\nPeptide Sequences (FastA):\n\ncbai_transcriptome_v3.0.fasta.transdecoder.pep\n\nBLASTp output (tab):\n\n20200519_cbai_transdecoder_transcriptome-v3.0/blastp_out/20200519.cbai.blastp.outfmt6\n\nPfam output:\n\n20200519_cbai_transdecoder_transcriptome-v3.0/pfam_out/20200519.cbai.pfam.domtblout\n\nWill get ready to run Trinotate with these output files."
  },
  {
    "objectID": "posts/2020/2020-12-06-Trimming---Haws-Lab-C.gigas-Ploidy-pH-WGBS-10bp-5-and-3-Prime-Ends-Using-fastp-and-MultiQC-on-Mox/index.html",
    "href": "posts/2020/2020-12-06-Trimming---Haws-Lab-C.gigas-Ploidy-pH-WGBS-10bp-5-and-3-Prime-Ends-Using-fastp-and-MultiQC-on-Mox/index.html",
    "title": "Trimming - Haws Lab C.gigas Ploidy pH WGBS 10bp 5 and 3 Prime Ends Using fastp and MultiQC on Mox",
    "section": "",
    "text": "Making the assumption that the 24 C.gigas ploidy pH WGBS data we receved 20201205 will be analyzed using Bismark, I decided to go ahead and trim the files according to Bismark guidelines for libraries made with the ZymoResearch Pico MethylSeq Kit.\nI trimmed the files using fastp.\nThe trimming trims adapters and 10bp from both the 5’ and 3’ ends of each read. The Bismark guidelines suggest that the user “probably should” trim in this fashion (as opposed to just trimming 10bp from the 5’ end).\nThe job was run on Mox.\nSBATCH script (GitHub):\n\n20201206_cgig_fastp-10bp-5-3-prime_ploidy-pH-wgbs.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=20201206_cgig_fastp-10bp-5-3-prime_ploidy-pH-wgbs\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20201206_cgig_fastp-10bp-5-3-prime_ploidy-pH-wgbs\n\n\n### Fastp trimming of Haw's Lab ploidy pH WGBS.\n\n### Trims adapters, 10bp from 5' and 3' ends of reads\n\n### Trimming is performed according to recommendation for use with Bismark\n### for libraries created using ZymoResearch Pico MethylSeq Kit:\n### https://github.com/FelixKrueger/Bismark/blob/master/Docs/README.md#ix-notes-about-different-library-types-and-commercial-kits\n\n\n### Expects input filenames to be in format: zr3644_3_R1.fq.gz\n\n\n###################################################################################\n# These variables need to be set by user\n\n## Assign Variables\n\n# Set number of CPUs to use\nthreads=27\n\n# Input/output files\ntrimmed_checksums=trimmed_fastq_checksums.md5\nraw_reads_dir=/gscratch/srlab/sam/data/C_gigas/wgbs/\nfastq_checksums=raw_fastq_checksums.md5\n\n# Paths to programs\nfastp=/gscratch/srlab/programs/fastp-0.20.0/fastp\nmultiqc=/gscratch/srlab/programs/anaconda3/bin/multiqc\n\n## Inititalize arrays\nfastq_array_R1=()\nfastq_array_R2=()\nR1_names_array=()\nR2_names_array=()\n\n\n# Programs associative array\ndeclare -A programs_array\nprograms_array=(\n[fastp]=\"${fastp}\" \\\n[multiqc]=\"${multiqc}\"\n)\n\n\n###################################################################################\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\nmodule load intel-python3_2017\n\n# Capture date\ntimestamp=$(date +%Y%m%d)\n\n# Sync raw FastQ files to working directory\nrsync --archive --verbose \\\n\"${raw_reads_dir}\"zr3644*.fq.gz .\n\n# Create arrays of fastq R1 files and sample names\nfor fastq in *R1.fq.gz\ndo\n  fastq_array_R1+=(\"${fastq}\")\n    R1_names_array+=(\"$(echo \"${fastq}\" | awk 'BEGIN {FS = \"[_.]\"; OFS = \"_\"} {print $1, $2, $3}')\")\ndone\n\n# Create array of fastq R2 files\nfor fastq in *R2.fq.gz\ndo\n  fastq_array_R2+=(\"${fastq}\")\n    R2_names_array+=(\"$(echo \"${fastq}\" | awk 'BEGIN {FS = \"[_.]\"; OFS = \"_\"} {print $1, $2, $3}')\")\ndone\n\n\n# Run fastp on files\n# Trim 10bp from 5' from each read\n# Adds JSON report output for downstream usage by MultiQC\nfor index in \"${!fastq_array_R1[@]}\"\ndo\n  R1_sample_name=$(echo \"${R1_names_array[index]}\")\n    R2_sample_name=$(echo \"${R2_names_array[index]}\")\n    ${fastp} \\\n    --in1 ${fastq_array_R1[index]} \\\n    --in2 ${fastq_array_R2[index]} \\\n    --detect_adapter_for_pe \\\n  --detect_adapter_for_pe \\\n  --trim_front1 10 \\\n  --trim_front2 10 \\\n  --trim_tail1 10 \\\n  --trim_tail2 10 \\\n    --thread ${threads} \\\n    --html \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".report.html \\\n    --json \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".report.json \\\n    --out1 \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz \\\n    --out2 \"${R2_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz\n\n    # Generate md5 checksums for newly trimmed files\n    {\n        md5sum \"${R1_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz\n        md5sum \"${R2_sample_name}\".fastp-trim.\"${timestamp}\".fq.gz\n    } >> \"${trimmed_checksums}\"\n\n  # Create list of fastq files used in analysis\n  # Create MD5 checksum for reference\n  echo \"${fastq_array_R1[index]}\" >> input.fastq.list.txt\n  echo \"${fastq_array_R2[index]}\" >> input.fastq.list.txt\n  md5sum \"${fastq_array_R1[index]}\" >> ${fastq_checksums}\n  md5sum \"${fastq_array_R2[index]}\" >> ${fastq_checksums}\n\n    # Remove original FastQ files\n    rm \"${fastq_array_R1[index]}\" \"${fastq_array_R2[index]}\"\ndone\n\n# Run MultiQC\n${multiqc} .\n\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${program}: \"\n    echo \"\"\n  # Handle samtools help menus\n  if [[ \"${program}\" == \"samtools_index\" ]] \\\n  || [[ \"${program}\" == \"samtools_sort\" ]] \\\n  || [[ \"${program}\" == \"samtools_view\" ]]\n  then\n    ${programs_array[$program]}\n  fi\n    ${programs_array[$program]} -h\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\n\n  # If MultiQC is in programs_array, copy the config file to this directory.\n  if [[ \"${program}\" == \"multiqc\" ]]; then\n    cp --preserve ~/.multiqc_config.yaml multiqc_config.yaml\n  fi\ndone\n\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nRESULTS\nRuntime was just shy of 3.5hrs:\n\n\n\nfastp runtime on Mox\n\n\nNOTE: The report files from (MultiQC and fastp) all suffer from a naming error, but do contain data for both read 1 (R1) and read 2 (R2).\nOutput folder:\n\n20201206_cgig_fastp-10bp-5-3-prime_ploidy-pH-wgbs\n\nMultiQC Report (HTML; open in web browser):\n\nmultiqc_report.html\n\nTrimmed FastQ MD5 checksums (TEXT):\n\ntrimmed_fastq_checksums.md5\n\n[fastp] Reports (HTML; open in web browser):\n\nzr3644_10_R1.fastp-trim.20201206.report.html\nzr3644_11_R1.fastp-trim.20201206.report.html\nzr3644_12_R1.fastp-trim.20201206.report.html\nzr3644_13_R1.fastp-trim.20201206.report.html\nzr3644_14_R1.fastp-trim.20201206.report.html\nzr3644_15_R1.fastp-trim.20201206.report.html\nzr3644_16_R1.fastp-trim.20201206.report.html\nzr3644_17_R1.fastp-trim.20201206.report.html\nzr3644_18_R1.fastp-trim.20201206.report.html\nzr3644_19_R1.fastp-trim.20201206.report.html\nzr3644_1_R1.fastp-trim.20201206.report.html\nzr3644_20_R1.fastp-trim.20201206.report.html\nzr3644_21_R1.fastp-trim.20201206.report.html\nzr3644_22_R1.fastp-trim.20201206.report.html\nzr3644_23_R1.fastp-trim.20201206.report.html\nzr3644_24_R1.fastp-trim.20201206.report.html\nzr3644_2_R1.fastp-trim.20201206.report.html\nzr3644_3_R1.fastp-trim.20201206.report.html\nzr3644_4_R1.fastp-trim.20201206.report.html\nzr3644_5_R1.fastp-trim.20201206.report.html\nzr3644_6_R1.fastp-trim.20201206.report.html\nzr3644_7_R1.fastp-trim.20201206.report.html\nzr3644_8_R1.fastp-trim.20201206.report.html\nzr3644_9_R1.fastp-trim.20201206.report.html\n\n\n\n\nList of trimmed FastQs and corresponding MD5 checksums:\n\nzr3644_10_R1.fastp-trim.20201206.fq.gz (2.7G)\n\nMD5: 1d5aa2fc7d812281bafa7ecacc10d065\n\nzr3644_10_R2.fastp-trim.20201206.fq.gz (2.7G)\n\nMD5: 93d62fca7cb553a421782714f023da67\n\nzr3644_11_R1.fastp-trim.20201206.fq.gz (2.9G)\n\nMD5: e7002c3fc579137d9b2d96367ab38a65\n\nzr3644_11_R2.fastp-trim.20201206.fq.gz (2.9G)\n\nMD5: 870412d303f4a0bc1557ff6ef0780fab\n\nzr3644_12_R1.fastp-trim.20201206.fq.gz (2.4G)\n\nMD5: 3f83cc934f90939447e1d8dc4699ef9f\n\nzr3644_12_R2.fastp-trim.20201206.fq.gz (2.5G)\n\nMD5: df9cbbbc0b578fa49f9340cd05daffb3\n\nzr3644_13_R1.fastp-trim.20201206.fq.gz (2.8G)\n\nMD5: 8fd09a92630d8e087facfd51152bc0de\n\nzr3644_13_R2.fastp-trim.20201206.fq.gz (2.8G)\n\nMD5: 660e1b48b4d5ad3be6fa8261c979e4a2\n\nzr3644_14_R1.fastp-trim.20201206.fq.gz (2.1G)\n\nMD5: 099bdd1ee643c359178c90a1b95dcf8a\n\nzr3644_14_R2.fastp-trim.20201206.fq.gz (1.9G)\n\nMD5: 63f688d1a5253d083bbe65916b876ea7\n\nzr3644_15_R1.fastp-trim.20201206.fq.gz (3.0G)\n\nMD5: 1033bb9db553f48dd0d09ec248a47607\n\nzr3644_15_R2.fastp-trim.20201206.fq.gz (3.1G)\n\nMD5: b57c5a5773a4639895e54ed4032bbb46\n\nzr3644_16_R1.fastp-trim.20201206.fq.gz (2.7G)\n\nMD5: 145b0de1fa99bce71b75ae626399e1b1\n\nzr3644_16_R2.fastp-trim.20201206.fq.gz (2.7G)\n\nMD5: 496ee5843c2605aaaebaed8e3d276d3d\n\nzr3644_17_R1.fastp-trim.20201206.fq.gz (2.9G)\n\nMD5: 14e082604a8511e32a14879db230a7ba\n\nzr3644_17_R2.fastp-trim.20201206.fq.gz (3.0G)\n\nMD5: 819e432d9c6099a00aa9bb94efdd5b1e\n\nzr3644_18_R1.fastp-trim.20201206.fq.gz (2.6G)\n\nMD5: 9eaf6df5cfe7871697dae993082dda1f\n\nzr3644_18_R2.fastp-trim.20201206.fq.gz (2.7G)\n\nMD5: 70f7fa3d3311ec9c2450bbb6f66e2e3d\n\nzr3644_19_R1.fastp-trim.20201206.fq.gz (2.5G)\n\nMD5: 2fdaa42984c74f731092acbfe589f896\n\nzr3644_19_R2.fastp-trim.20201206.fq.gz (2.6G)\n\nMD5: 793bf4226b452e676d8b6ddcadb2ba09\n\nzr3644_1_R1.fastp-trim.20201206.fq.gz (2.6G)\n\nMD5: 5ee80234cac3d8e8017ca57bccb21eaf\n\nzr3644_1_R2.fastp-trim.20201206.fq.gz (2.8G)\n\nMD5: 668ae326f386d7f02158f2023044e0ef\n\nzr3644_20_R1.fastp-trim.20201206.fq.gz (3.2G)\n\nMD5: c6b535af634b6ca6fed1e7e970c03440\n\nzr3644_20_R2.fastp-trim.20201206.fq.gz (2.8G)\n\nMD5: c14c2165e7a1d1cdbdb39b00b813ad78\n\nzr3644_21_R1.fastp-trim.20201206.fq.gz (2.8G)\n\nMD5: 07d78424ad87f66731a598497c7465b0\n\nzr3644_21_R2.fastp-trim.20201206.fq.gz (2.7G)\n\nMD5: 283c84e628237f5f9a2d0ff2302e9b9d\n\nzr3644_22_R1.fastp-trim.20201206.fq.gz (2.4G)\n\nMD5: 1a66fb92e4da94af67738e47639654e6\n\nzr3644_22_R2.fastp-trim.20201206.fq.gz (2.5G)\n\nMD5: 6e0cd9c04f559c71f10a9ba881841c15\n\nzr3644_23_R1.fastp-trim.20201206.fq.gz (2.1G)\n\nMD5: 6d2e5db2770ad49b5c6055a73f813870\n\nzr3644_23_R2.fastp-trim.20201206.fq.gz (2.1G)\n\nMD5: 35d8f23c55d2885774bbc667e7ea6438\n\nzr3644_24_R1.fastp-trim.20201206.fq.gz (2.7G)\n\nMD5: 5670f429eec3fda094d2956c5b6f73e4\n\nzr3644_24_R2.fastp-trim.20201206.fq.gz (2.8G)\n\nMD5: a2dec66c27ef6b35cab389c17adfad3b\n\nzr3644_2_R1.fastp-trim.20201206.fq.gz (2.9G)\n\nMD5: 3b78ac1977ed68ee6483fce4141863cd\n\nzr3644_2_R2.fastp-trim.20201206.fq.gz (2.9G)\n\nMD5: 16ede2aa44b0d61e54cb51a33730e443\n\nzr3644_3_R1.fastp-trim.20201206.fq.gz (2.1G)\n\nMD5: 9c9990d2f982461576dece29dd429e40\n\nzr3644_3_R2.fastp-trim.20201206.fq.gz (2.1G)\n\nMD5: f4e79bb6c49492ae1935c1a642c27a7d\n\nzr3644_4_R1.fastp-trim.20201206.fq.gz (2.7G)\n\nMD5: 918e02f3067d6ab374734dae1bdf5cd7\n\nzr3644_4_R2.fastp-trim.20201206.fq.gz (2.6G)\n\nMD5: a2ce85d93d20d4b57500e3f1e89d4511\n\nzr3644_5_R1.fastp-trim.20201206.fq.gz (2.5G)\n\nMD5: 061394481f1e9f3cce686db052ef57d7\n\nzr3644_5_R2.fastp-trim.20201206.fq.gz (2.3G)\n\nMD5: eb25b5f76c81ab58fbd1e404008c045c\n\nzr3644_6_R1.fastp-trim.20201206.fq.gz (2.8G)\n\nMD5: d6bef0da74751e12604c1ac74d846dd9\n\nzr3644_6_R2.fastp-trim.20201206.fq.gz (2.8G)\n\nMD5: bb9ad6883c228f7f9d6b58e942009546\n\nzr3644_7_R1.fastp-trim.20201206.fq.gz (4.2G)\n\nMD5: 423e07836aaef454e6cb19828fccd2f2\n\nzr3644_7_R2.fastp-trim.20201206.fq.gz (4.3G)\n\nMD5: 3a0922fdd5ca436c9a3ea6c40e2a4d9d\n\nzr3644_8_R1.fastp-trim.20201206.fq.gz (2.2G)\n\nMD5: d3905851870ecbce6b3a35c3734b9509\n\nzr3644_8_R2.fastp-trim.20201206.fq.gz (2.3G)\n\nMD5: a14a1c6c7ab5fc5ac6ace28f10af0e3f\n\nzr3644_9_R1.fastp-trim.20201206.fq.gz (2.4G)\n\nMD5: 2870c21684f14487d7e040e2dda48b79\n\nzr3644_9_R2.fastp-trim.20201206.fq.gz (2.5G)\n\nMD5: dab6d90fff69aac28a819fad25c21975"
  },
  {
    "objectID": "posts/2020/2020-05-29-Transcriptome-Annotation---Trinotate-C.bairdi-Transcriptome-v1.7-on-Mox/index.html",
    "href": "posts/2020/2020-05-29-Transcriptome-Annotation---Trinotate-C.bairdi-Transcriptome-v1.7-on-Mox/index.html",
    "title": "Transcriptome Annotation - Trinotate C.bairdi Transcriptome-v1.7 on Mox",
    "section": "",
    "text": "After creating a de novo assembly of C.bairdi transcriptome v1.7 on 20200527, performing BLASTx annotation on 202000527, and TransDecoder for ORF identification on 20200527, I continued the annotation process by running Trinotate.\nTrinotate will perform functional annotation of the transcriptome assembly, including GO terms and an annotation feature map that can be used in subsequent Trinity-based differential gene expression analysis so that functional annotations are carried downstream through that process.\nSBATCH script (GitHub):\n\n20200529_cbai_trinotate_transcriptome-v1.7.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=trinotate_cbai_v1.7\n## Allocation Definition\n#SBATCH --account=coenv\n#SBATCH --partition=coenv\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=10-00:00:00\n## Memory per node\n#SBATCH --mem=120G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200529_cbai_trinotate_transcriptome-v1.7\n\n# Exit script if any command fails\nset -e\n\n# Load Python Mox module for Python module availability\n\nmodule load intel-python3_2017\n\n# Document programs in PATH (primarily for program version ID)\n\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nwd=\"$(pwd)\"\ntimestamp=$(date +%Y%m%d)\n\n\n## Paths to input/output files\n\n## New folders for working directory\nrnammer_out_dir=\"${wd}/RNAmmer_out\"\nsignalp_out_dir=\"${wd}/signalp_out\"\ntmhmm_out_dir=\"${wd}/tmhmm_out\"\n\n# Input files\n## BLASTx\nblastx_out=\"/gscratch/scrubbed/samwhite/outputs/20200527_cbai_diamond_blastx_transcriptome_v1.7/cbai_transcriptome_v1.7.blastx.outfmt6\"\n\n## TransDecoder\nblastp_out=\"/gscratch/scrubbed/samwhite/outputs/20200527_cbai_transdecoder_transcriptome-v1.7/blastp_out/cbai_transcriptome_v1.7.fasta.blastp.outfmt6\"\npfam_out=\"/gscratch/scrubbed/samwhite/outputs/20200527_cbai_transdecoder_transcriptome-v1.7/pfam_out/cbai_transcriptome_v1.7.fasta.pfam.domtblout\"\nlORFs_pep=\"/gscratch/scrubbed/samwhite/outputs/20200527_cbai_transdecoder_transcriptome-v1.7/cbai_transcriptome_v1.7.fasta.transdecoder_dir/longest_orfs.pep\"\n\n## Transcriptomics\ntrinity_fasta=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v1.7.fasta\"\ntrinity_gene_map=\"/gscratch/srlab/sam/data/C_bairdi/transcriptomes/cbai_transcriptome_v1.7.fasta.gene_trans_map\"\n\nrnammer_prefix=${trinity_fasta##*/}\nprefix=\"${timestamp}.${rnammer_prefix}.trinotate\"\n\n# Output files\nrnammer_out=\"${rnammer_out_dir}/${rnammer_prefix}.rnammer.gff\"\nsignalp_out=\"${signalp_out_dir}/${prefix}.signalp.out\"\ntmhmm_out=\"${tmhmm_out_dir}/${prefix}.tmhmm.out\"\ntrinotate_report=\"${wd}/${prefix}_annotation_report.txt\"\n\n# Paths to programs\nrnammer_dir=\"/gscratch/srlab/programs/RNAMMER-1.2\"\nrnammer=\"${rnammer_dir}/rnammer\"\nsignalp_dir=\"/gscratch/srlab/programs/signalp-4.1\"\nsignalp=\"${signalp_dir}/signalp\"\ntmhmm_dir=\"/gscratch/srlab/programs/tmhmm-2.0c/bin\"\ntmhmm=\"${tmhmm_dir}/tmhmm\"\ntrinotate_dir=\"/gscratch/srlab/programs/Trinotate-v3.1.1\"\ntrinotate=\"${trinotate_dir}/Trinotate\"\ntrinotate_rnammer=\"${trinotate_dir}/util/rnammer_support/RnammerTranscriptome.pl\"\ntrinotate_GO=\"${trinotate_dir}/util/extract_GO_assignments_from_Trinotate_xls.pl\"\ntrinotate_features=\"${trinotate_dir}/util/Trinotate_get_feature_name_encoding_attributes.pl\"\ntrinotate_sqlite_db=\"Trinotate.sqlite\"\n\n# Generate FastA checksum, for reference if needed.\nmd5sum ${trinity_fasta} > fasta.checksum.md5\n\n# Make output directories\nmkdir \"${rnammer_out_dir}\" \"${signalp_out_dir}\" \"${tmhmm_out_dir}\"\n\n# Copy sqlite database template\n\ncp ${trinotate_dir}/admin/Trinotate.sqlite .\n\n# Run signalp\n${signalp} \\\n-f short \\\n-n \"${signalp_out}\" \\\n${lORFs_pep}\n\n# Run tmHMM\n${tmhmm} \\\n--short \\\n< ${lORFs_pep} \\\n> \"${tmhmm_out}\"\n\n# Run RNAmmer\ncd \"${rnammer_out_dir}\" || exit\n${trinotate_rnammer} \\\n--transcriptome ${trinity_fasta} \\\n--path_to_rnammer ${rnammer}\ncd \"${wd}\" || exit\n\n# Run Trinotate\n## Load transcripts and coding regions into database\n${trinotate} \\\n${trinotate_sqlite_db} \\\ninit \\\n--gene_trans_map \"${trinity_gene_map}\" \\\n--transcript_fasta \"${trinity_fasta}\" \\\n--transdecoder_pep \"${lORFs_pep}\"\n\n## Load BLAST homologies\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_swissprot_blastp \\\n\"${blastp_out}\"\n\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_swissprot_blastx \\\n\"${blastx_out}\"\n\n## Load Pfam\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_pfam \\\n\"${pfam_out}\"\n\n## Load transmembrane domains\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_tmhmm \\\n\"${tmhmm_out}\"\n\n## Load signal peptides\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_signalp \\\n\"${signalp_out}\"\n\n## Load RNAmmer\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nLOAD_rnammer \\\n\"${rnammer_out}\"\n\n## Creat annotation report\n\"${trinotate}\" \\\n\"${trinotate_sqlite_db}\" \\\nreport \\\n> \"${trinotate_report}\"\n\n# Extract GO terms from annotation report\n\"${trinotate_GO}\" \\\n--Trinotate_xls \"${trinotate_report}\" \\\n-G \\\n--include_ancestral_terms \\\n> \"${prefix}\".go_annotations.txt\n\n# Make transcript features annotation map\n\"${trinotate_features}\" \\\n\"${trinotate_report}\" \\\n> \"${prefix}\".annotation_feature_map.txt\n\n\nRESULTS\nPretty quick, ~28 mins:\n\n\n\ncbai v1.7 trinotate runtime\n\n\nOutput folder:\n\n20200529_cbai_trinotate_transcriptome-v1.7/\n\nAnnotation feature map. This can be used to update Trinity-based gene expression matrices like so:\n\n${TRINITY_HOME}/Analysis/DifferentialExpression/rename_matrix_feature_identifiers.pl Trinity_trans.counts.matrix annot_feature_map.txt > Trinity_trans.counts.wAnnot.matrix\n20200529.cbai_transcriptome_v1.7.fasta.trinotate.annotation_feature_map.txt\n\nAnnotation report (CSV)\n\n20200529.cbai_transcriptome_v1.7.fasta.trinotate_annotation_report.txt\n\nGene ontology (GO) annotations (TXT)\n\n20200529.cbai_transcriptome_v1.7.fasta.trinotate.go_annotations.txt\n\nSQlite database:\n\nTrinotate.sqlite"
  },
  {
    "objectID": "posts/2020/2020-09-17-Genome-Assembly---C.bairdi---cbai_v1.0---Using-All-NanoPore-Data-With-Flye-on-Mox/index.html",
    "href": "posts/2020/2020-09-17-Genome-Assembly---C.bairdi---cbai_v1.0---Using-All-NanoPore-Data-With-Flye-on-Mox/index.html",
    "title": "Genome Assembly - C.bairdi - cbai_v1.0 - Using All NanoPore Data With Flye on Mox",
    "section": "",
    "text": "After quality filtering the C.bairdi NanoPore data earlier today, I performed a de novo assembly using Flye on Mox.\nSBATCH script (GitHub):\n\n20200917_cbai_flye_nanopore_genome_assembly.sh\n\n#!/bin/bash\n## Job Name\n#SBATCH --job-name=cbai_flye_nanopore_genome_assembly\n## Allocation Definition\n#SBATCH --account=srlab\n#SBATCH --partition=srlab\n## Resources\n## Nodes\n#SBATCH --nodes=1\n## Walltime (days-hours:minutes:seconds format)\n#SBATCH --time=25-00:00:00\n## Memory per node\n#SBATCH --mem=500G\n##turn on e-mail notification\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=samwhite@uw.edu\n## Specify the working directory for this job\n#SBATCH --chdir=/gscratch/scrubbed/samwhite/outputs/20200915_cbai_flye_nanopore_genome_assembly\n\n# Script to run Flye long read assembler on all quality filtered (Q7) C.bairdi NanoPore reads\n# from 20200917\n\n###################################################################################\n# These variables need to be set by user\n\n# Load Anaconda\n# Uknown why this is needed, but Anaconda will not run if this line is not included.\n. \"/gscratch/srlab/programs/anaconda3/etc/profile.d/conda.sh\"\n\n\n# Activate the flye Anaconda environment\nconda activate flye-2.8.1_env\n\n# Set number of CPUs to use\nthreads=28\n\n# Paths to programs\nflye=flye\n\n# Input FastQ\nfastq=/gscratch/srlab/sam/data/C_bairdi/DNAseq/20200917_cbai_nanopore_all_quality-7.fastq\n\n###################################################################################\n\n\n# Exit script if any command fails\nset -e\n\n\n# Capture this directory\nwd=$(pwd)\n\n# Inititalize arrays\nprograms_array=()\n\n\n# Programs array\nprograms_array=(\"${flye}\")\n\n# Run flye\n${flye} \\\n--nano-raw ${fastq} \\\n--out-dir ${wd} \\\n--threads ${threads}\n\n# Generate checksum file\nmd5sum \"${fastq}\" > fastq_checksums.md5\n\n# Capture program options\nfor program in \"${!programs_array[@]}\"\ndo\n    {\n  echo \"Program options for ${programs_array[program]}: \"\n    echo \"\"\n    ${programs_array[program]} -h\n    echo \"\"\n    echo \"\"\n    echo \"----------------------------------------------\"\n    echo \"\"\n    echo \"\"\n} &>> program_options.log || true\ndone\n\n# Document programs in PATH (primarily for program version ID)\n{\ndate\necho \"\"\necho \"System PATH for $SLURM_JOB_ID\"\necho \"\"\nprintf \"%0.s-\" {1..10}\necho \"${PATH}\" | tr : \\\\n\n} >> system_path.log\n\n\nRESULTS\nRuntime was very fast; just over 1hr!\n\n\n\nFlye runtime for C.bairdi Q7 NanoPore assembly\n\n\nOutput folder:\n\n20200917_cbai_flye_nanopore_genome_assembly/\n\nGenome Assembly (FastA; 19MB)\n\n20200917_cbai_flye_nanopore_genome_assembly/cbai_genome_v1.0.fasta\n\nMD5 checksum (text):\n\n2f3b651bb0b875b0287e71e315cad59a\n\n\n\nNOTE: The output files were named assembly_*. At the time I ran this, I didn’t realize that was the case, so I had to rename them to reflect the cba_genome_v1.0 notation after the fact; thus this step is not present in the SBATCH script.\nWell, this is pretty exciting! Here’s a quick assembly summary (found at the end of the SLURM output file):\nINFO: Assembly statistics:\n\n    Total length:   19216531\n    Fragments:  3294\n    Fragments N50:  14130\n    Largest frg:    141601\n    Scaffolds:  6\n    Mean coverage:  17\nAdmittedly, there are definitely some issues with the assembly. For example, here’s a portion of the FastA index file:\ncontig_3421 1   11083798    1   2\ncontig_2582 3   4548025 3   4\ncontig_3109 46  8747210 46  47\ncontig_2139 49  3182267 49  50\ncontig_4287 58  16100814    58  59\ncontig_3575 66  12248950    60  61\ncontig_793  69  18935471    60  61\ncontig_3976 84  14959281    60  61\ncontig_2281 104 3633003 60  61\ncontig_4015 104 15091851    60  61\nColumn #2 is the sequence length. The first two “contigs” have lengths of < 5bp! Obviously, this is useless. I know we can just filter out small contigs for subsequent analyses, but it’s disconcerting that Flye actually spit these out as “contigs” instead of discarding them. I’ve submitted an issue to see if I can obtain some understanding about why this occurred.\nRegardless, I’ll get this posted to the Genomic Resources wiki.\nSo, where do we go from here? A couple of things:\n\nVisualize the assembly graphs with something like Bandage. I’m hoping this will lead to a better understanding of how these graph assemblies (as opposed to alignment-based assemblies) work.\nRun BUSCO to assess genome “completeness”.\nAttempt to separate out Hematodinium sequences.\nAnnotate the assembly with GenSAS and/or BLAST or something."
  }
]